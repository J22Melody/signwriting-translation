[2023-12-13:06:37:43:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.1.37, commit unknown, path /home/zifjia/sockeye_aws/sockeye/__init__.py
[2023-12-13:06:37:43:INFO:sockeye.utils:log_torch_version] PyTorch: 1.13.1+cu117 (/home/zifjia/data/conda/envs/signbank+/lib/python3.9/site-packages/torch/__init__.py)
[2023-12-13:06:37:43:INFO:sockeye.utils:log_basic_info] Command: /home/zifjia/sockeye_aws/sockeye/translate.py --models models_new/expanded_cleaned --input data_new_expanded_cleaned/test.sign --input-factors data_new_expanded_cleaned/test.feat_x data_new_expanded_cleaned/test.feat_y data_new_expanded_cleaned/test.feat_x_rel data_new_expanded_cleaned/test.feat_y_rel data_new_expanded_cleaned/test.sign+ data_new_expanded_cleaned/test.feat_col data_new_expanded_cleaned/test.feat_row --output models_new/expanded_cleaned/test.hyps.spm.spoken --max-input-length 99999 --beam-size 5 --device-id 0 --brevity-penalty-type constant --seed 42
[2023-12-13:06:37:43:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(config=None, input='data_new_expanded_cleaned/test.sign', input_factors=['data_new_expanded_cleaned/test.feat_x', 'data_new_expanded_cleaned/test.feat_y', 'data_new_expanded_cleaned/test.feat_x_rel', 'data_new_expanded_cleaned/test.feat_y_rel', 'data_new_expanded_cleaned/test.sign+', 'data_new_expanded_cleaned/test.feat_col', 'data_new_expanded_cleaned/test.feat_row'], json_input=False, output='models_new/expanded_cleaned/test.hyps.spm.spoken', models=['models_new/expanded_cleaned'], checkpoints=None, nbest_size=1, beam_size=5, greedy=False, beam_search_stop='all', batch_size=1, chunk_size=None, sample=None, seed=42, ensemble_mode='linear', bucket_width=10, max_input_length=99999, max_output_length_num_stds=2, max_output_length=None, restrict_lexicon=None, restrict_lexicon_topk=None, skip_nvs=False, nvs_thresh=0.5, strip_unknown_words=False, prevent_unk=False, output_type='translation', length_penalty_alpha=1.0, length_penalty_beta=0.0, brevity_penalty_type='constant', brevity_penalty_weight=1.0, brevity_penalty_constant_length_ratio=0.0, dtype=None, clamp_to_dtype=False, device_id=0, use_cpu=False, env=None, tf32=True, quiet=False, quiet_secondary_workers=False, no_logfile=False, loglevel='INFO', loglevel_secondary_workers='INFO', knn_index=None, knn_lambda=0.8)
[2023-12-13:06:37:43:INFO:sockeye.utils:init_device] CUDA: allow tf32 (float32 but with 10 bits precision)
[2023-12-13:06:37:43:INFO:__main__:run_translate] Translate Device: cuda:0
[2023-12-13:06:37:43:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models_new/expanded_cleaned'] ...
[2023-12-13:06:37:43:INFO:sockeye.vocab:vocab_from_json] Vocabulary (15608 words) loaded from "models_new/expanded_cleaned/vocab.src.0.json"
[2023-12-13:06:37:44:INFO:sockeye.vocab:vocab_from_json] Vocabulary (432 words) loaded from "models_new/expanded_cleaned/vocab.src.1.json"
[2023-12-13:06:37:44:INFO:sockeye.vocab:vocab_from_json] Vocabulary (472 words) loaded from "models_new/expanded_cleaned/vocab.src.2.json"
[2023-12-13:06:37:44:INFO:sockeye.vocab:vocab_from_json] Vocabulary (64 words) loaded from "models_new/expanded_cleaned/vocab.src.3.json"
[2023-12-13:06:37:44:INFO:sockeye.vocab:vocab_from_json] Vocabulary (56 words) loaded from "models_new/expanded_cleaned/vocab.src.4.json"
[2023-12-13:06:37:44:INFO:sockeye.vocab:vocab_from_json] Vocabulary (760 words) loaded from "models_new/expanded_cleaned/vocab.src.5.json"
[2023-12-13:06:37:44:INFO:sockeye.vocab:vocab_from_json] Vocabulary (16 words) loaded from "models_new/expanded_cleaned/vocab.src.6.json"
[2023-12-13:06:37:44:INFO:sockeye.vocab:vocab_from_json] Vocabulary (24 words) loaded from "models_new/expanded_cleaned/vocab.src.7.json"
[2023-12-13:06:37:44:INFO:sockeye.vocab:vocab_from_json] Vocabulary (4312 words) loaded from "models_new/expanded_cleaned/vocab.trg.0.json"
[2023-12-13:06:37:44:INFO:sockeye.model:load_model] Model version: 3.1.37
[2023-12-13:06:37:44:INFO:sockeye.model:load_config] Loaded model config from "models_new/expanded_cleaned/config"
[2023-12-13:06:37:44:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=354726, num_discarded=1, num_tokens_source=4201015, num_tokens_target=2127225, num_unks_source=167, num_unks_target=60, max_observed_len_source=96, max_observed_len_target=196, size_vocab_source=15608, size_vocab_target=4312, length_ratio_mean=0.5631922886448255, length_ratio_std=0.4400367158119144, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)], num_sents_per_bucket=[147979, 173980, 14821, 2717, 1671, 1633, 1588, 2191, 2555, 2461, 2299, 763, 20, 12, 5, 8, 7, 4, 1, 1, 0, 1, 2, 3, 4, 0], average_len_target_per_bucket=[4.215956318126238, 5.255615587998739, 8.219755751973558, 13.773279352226734, 18.90724117295031, 22.280465401102255, 24.01889168765744, 26.757188498402567, 28.605479452054844, 31.4091832588378, 33.720313179643405, 37.40891218872868, 100.05000000000001, 107.25000000000001, 115.0, 124.375, 134.42857142857142, 140.5, 148.0, 158.0, None, 173.0, 178.5, 187.33333333333334, 194.5, None], length_ratio_stats_per_bucket=[(0.588892624403916, 0.20760204327439177), (0.5204595399491342, 0.3252743733178762), (0.588567356589642, 0.7037196037060348), (0.9152367604612587, 1.193622730324267), (1.057559786619243, 1.4358288699717354), (1.1639323170716318, 1.7449769807009596), (0.7269578631779554, 1.2037586395713893), (0.5783357659894331, 0.8871833275368517), (0.4947678477691236, 0.7965314276556164), (0.48821635982263106, 0.8632546665181101), (0.4498769928457549, 0.7441730769509901), (0.6038074343546629, 1.376625455660386), (8.52364298944623, 3.7048777075663675), (9.312100383631712, 4.347448593952467), (9.920299043062201, 3.0068695071959968), (7.31775934925658, 4.77182650527961), (15.61417748917749, 3.908159721960673), (13.163636363636364, 1.2339381288318816), (24.666666666666668, 0.0), (22.571428571428573, 0.0), (None, None), (21.625, 0.0), (23.007575757575758, 6.825757575757574), (25.630952380952383, 1.3351390833475298), (20.42063492063492, 4.6258540916351345), (None, None)]), max_seq_len_source=201, max_seq_len_target=201, num_source_factors=8, num_target_factors=1, eop_id=-1), vocab_source_size=15608, vocab_target_size=4312, config_embed_source=EmbeddingConfig(vocab_size=15608, num_embed=512, dropout=0.5, num_factors=8, factor_configs=[FactorConfig(vocab_size=432, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=472, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=64, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=56, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=760, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=16, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=24, num_embed=16, combine='concat', share_embedding=False)], allow_sparse_grad=False), config_embed_target=EmbeddingConfig(vocab_size=4312, num_embed=512, dropout=0.5, num_factors=1, factor_configs=None, allow_sparse_grad=False), config_encoder=TransformerConfig(model_size=624, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.5, dropout_act=0.1, dropout_prepost=0.1, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=624, use_glu=False), config_decoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.5, dropout_act=0.1, dropout_prepost=0.1, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=624, use_glu=False), config_length_task=None, weight_tying_type='trg_softmax', lhuc=False, dtype='float32', neural_vocab_selection=None, neural_vocab_selection_block_loss=False)
[2023-12-13:06:37:47:INFO:sockeye.model:load_parameters] Loaded params from "models_new/expanded_cleaned/params.best" to "cuda:0"
[2023-12-13:06:37:47:INFO:sockeye.model:load_model] Model dtype: torch.float32
[2023-12-13:06:37:47:INFO:sockeye.model:load_models] 1 model(s) loaded in 3.6893s
[2023-12-13:06:37:47:INFO:__main__:run_translate] Using average of constant length ratios saved in the model configs: 0.563192
[2023-12-13:06:37:47:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=5 algorithm=BeamSearch, beam_search_stop=all max_input_length=200 nbest_size=1 ensemble_mode=None max_batch_size=1 dtype=torch.float32 skip_nvs=False nvs_thresh=0.5)
[2023-12-13:06:37:47:INFO:__main__:read_and_translate] Translating...
[2023-12-13:06:40:33:INFO:__main__:read_and_translate] Processed 568 lines. Total time: 165.0882, sec/sent: 0.2906, sent/sec: 3.4406
