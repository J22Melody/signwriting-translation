[2023-11-22:14:46:01:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.1.37, commit unknown, path /home/zifjia/sockeye_aws/sockeye/__init__.py
[2023-11-22:14:46:01:INFO:sockeye.utils:log_torch_version] PyTorch: 1.13.1+cu117 (/home/zifjia/data/conda/envs/signbank+/lib/python3.9/site-packages/torch/__init__.py)
[2023-11-22:14:46:01:INFO:sockeye.utils:log_basic_info] Command: /home/zifjia/sockeye_aws/sockeye/translate.py --models models_new/original --input data_new_original/test.sign --input-factors data_new_original/test.feat_x data_new_original/test.feat_y data_new_original/test.feat_x_rel data_new_original/test.feat_y_rel data_new_original/test.sign+ data_new_original/test.feat_col data_new_original/test.feat_row --output models_new/original/test.hyps.spm.spoken --max-input-length 99999 --beam-size 5 --device-id 0 --brevity-penalty-type constant --seed 42
[2023-11-22:14:46:01:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(config=None, input='data_new_original/test.sign', input_factors=['data_new_original/test.feat_x', 'data_new_original/test.feat_y', 'data_new_original/test.feat_x_rel', 'data_new_original/test.feat_y_rel', 'data_new_original/test.sign+', 'data_new_original/test.feat_col', 'data_new_original/test.feat_row'], json_input=False, output='models_new/original/test.hyps.spm.spoken', models=['models_new/original'], checkpoints=None, nbest_size=1, beam_size=5, greedy=False, beam_search_stop='all', batch_size=1, chunk_size=None, sample=None, seed=42, ensemble_mode='linear', bucket_width=10, max_input_length=99999, max_output_length_num_stds=2, max_output_length=None, restrict_lexicon=None, restrict_lexicon_topk=None, skip_nvs=False, nvs_thresh=0.5, strip_unknown_words=False, prevent_unk=False, output_type='translation', length_penalty_alpha=1.0, length_penalty_beta=0.0, brevity_penalty_type='constant', brevity_penalty_weight=1.0, brevity_penalty_constant_length_ratio=0.0, dtype=None, clamp_to_dtype=False, device_id=0, use_cpu=False, env=None, tf32=True, quiet=False, quiet_secondary_workers=False, no_logfile=False, loglevel='INFO', loglevel_secondary_workers='INFO', knn_index=None, knn_lambda=0.8)
[2023-11-22:14:46:01:INFO:sockeye.utils:init_device] CUDA: allow tf32 (float32 but with 10 bits precision)
[2023-11-22:14:46:01:INFO:__main__:run_translate] Translate Device: cuda:0
[2023-11-22:14:46:01:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models_new/original'] ...
[2023-11-22:14:46:01:INFO:sockeye.vocab:vocab_from_json] Vocabulary (16312 words) loaded from "models_new/original/vocab.src.0.json"
[2023-11-22:14:46:01:INFO:sockeye.vocab:vocab_from_json] Vocabulary (432 words) loaded from "models_new/original/vocab.src.1.json"
[2023-11-22:14:46:01:INFO:sockeye.vocab:vocab_from_json] Vocabulary (480 words) loaded from "models_new/original/vocab.src.2.json"
[2023-11-22:14:46:01:INFO:sockeye.vocab:vocab_from_json] Vocabulary (64 words) loaded from "models_new/original/vocab.src.3.json"
[2023-11-22:14:46:01:INFO:sockeye.vocab:vocab_from_json] Vocabulary (56 words) loaded from "models_new/original/vocab.src.4.json"
[2023-11-22:14:46:01:INFO:sockeye.vocab:vocab_from_json] Vocabulary (768 words) loaded from "models_new/original/vocab.src.5.json"
[2023-11-22:14:46:01:INFO:sockeye.vocab:vocab_from_json] Vocabulary (16 words) loaded from "models_new/original/vocab.src.6.json"
[2023-11-22:14:46:01:INFO:sockeye.vocab:vocab_from_json] Vocabulary (24 words) loaded from "models_new/original/vocab.src.7.json"
[2023-11-22:14:46:01:INFO:sockeye.vocab:vocab_from_json] Vocabulary (3872 words) loaded from "models_new/original/vocab.trg.0.json"
[2023-11-22:14:46:01:INFO:sockeye.model:load_model] Model version: 3.1.37
[2023-11-22:14:46:01:INFO:sockeye.model:load_config] Loaded model config from "models_new/original/config"
[2023-11-22:14:46:01:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=518462, num_discarded=91, num_tokens_source=6064118, num_tokens_target=4535269, num_unks_source=0, num_unks_target=0, max_observed_len_source=97, max_observed_len_target=201, size_vocab_source=16312, size_vocab_target=3872, length_ratio_mean=0.8817726678584379, length_ratio_std=1.2007686809002125, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)], num_sents_per_bucket=[174421, 256461, 38103, 16198, 7353, 5075, 3008, 4219, 4318, 3686, 3288, 1266, 209, 180, 146, 94, 74, 75, 54, 51, 39, 34, 28, 48, 33, 1], average_len_target_per_bucket=[4.560769632097103, 6.116364671431675, 13.678161824528276, 24.99246820595127, 30.49802801577584, 34.58581280788183, 30.352393617021267, 36.05333017302684, 36.97938860583601, 35.04584915897988, 34.59580291970818, 48.097156398104275, 99.95693779904305, 108.92777777777776, 115.93150684931507, 124.39361702127657, 132.3513513513514, 140.03999999999996, 148.3148148148148, 156.39215686274517, 164.15384615384616, 172.85294117647058, 181.60714285714286, 187.875, 196.81818181818178, 201.0], length_ratio_stats_per_bucket=[(0.6360488074693902, 0.23141942350105316), (0.6284959092309799, 0.427861695012509), (1.3044594484301466, 1.0459474608347652), (2.5471913935186548, 1.2407721697645155), (2.944289167007739, 1.684712326385672), (3.1966584185031435, 2.3634426354487807), (2.2684539489378492, 2.707677461641542), (2.64940974077188, 3.171077650744171), (2.296919737603547, 3.2683886561015356), (1.6011553037571746, 2.9650444779127145), (1.2393492735315819, 2.790927670861211), (3.078445390065673, 4.690909759448575), (10.20045102468786, 4.473579667552742), (11.106200722356236, 3.853642106091223), (11.786693709653786, 3.957448693794891), (13.499236178411433, 4.396651652075544), (12.888173054572952, 5.304531294571493), (14.880456422318652, 4.091081890483121), (15.418422620379651, 5.821644534325687), (18.135535373251642, 5.5458424736469105), (19.57152693544096, 5.679287470674945), (19.51440871220283, 5.840272013854848), (19.960049099802006, 7.204426599571264), (18.04052907249985, 5.958775261003661), (18.21732402913095, 6.525886302161232), (10.578947368421053, 0.0)]), max_seq_len_source=201, max_seq_len_target=201, num_source_factors=8, num_target_factors=1, eop_id=-1), vocab_source_size=16312, vocab_target_size=3872, config_embed_source=EmbeddingConfig(vocab_size=16312, num_embed=512, dropout=0.5, num_factors=8, factor_configs=[FactorConfig(vocab_size=432, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=480, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=64, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=56, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=768, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=16, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=24, num_embed=16, combine='concat', share_embedding=False)], allow_sparse_grad=False), config_embed_target=EmbeddingConfig(vocab_size=3872, num_embed=512, dropout=0.5, num_factors=1, factor_configs=None, allow_sparse_grad=False), config_encoder=TransformerConfig(model_size=624, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.5, dropout_act=0.1, dropout_prepost=0.1, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=624, use_glu=False), config_decoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.5, dropout_act=0.1, dropout_prepost=0.1, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=624, use_glu=False), config_length_task=None, weight_tying_type='trg_softmax', lhuc=False, dtype='float32', neural_vocab_selection=None, neural_vocab_selection_block_loss=False)
[2023-11-22:14:46:05:INFO:sockeye.model:load_parameters] Loaded params from "models_new/original/params.best" to "cuda:0"
[2023-11-22:14:46:05:INFO:sockeye.model:load_model] Model dtype: torch.float32
[2023-11-22:14:46:05:INFO:sockeye.model:load_models] 1 model(s) loaded in 4.2560s
[2023-11-22:14:46:05:INFO:__main__:run_translate] Using average of constant length ratios saved in the model configs: 0.881773
[2023-11-22:14:46:05:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=5 algorithm=BeamSearch, beam_search_stop=all max_input_length=200 nbest_size=1 ensemble_mode=None max_batch_size=1 dtype=torch.float32 skip_nvs=False nvs_thresh=0.5)
[2023-11-22:14:46:05:INFO:__main__:read_and_translate] Translating...
[2023-11-22:14:49:29:INFO:__main__:read_and_translate] Processed 568 lines. Total time: 202.8336, sec/sent: 0.3571, sent/sec: 2.8003
