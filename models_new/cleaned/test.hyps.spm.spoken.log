[2023-11-22:14:42:26:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.1.37, commit unknown, path /home/zifjia/sockeye_aws/sockeye/__init__.py
[2023-11-22:14:42:26:INFO:sockeye.utils:log_torch_version] PyTorch: 1.13.1+cu117 (/home/zifjia/data/conda/envs/signbank+/lib/python3.9/site-packages/torch/__init__.py)
[2023-11-22:14:42:26:INFO:sockeye.utils:log_basic_info] Command: /home/zifjia/sockeye_aws/sockeye/translate.py --models models_new/cleaned --input data_new_cleaned/test.sign --input-factors data_new_cleaned/test.feat_x data_new_cleaned/test.feat_y data_new_cleaned/test.feat_x_rel data_new_cleaned/test.feat_y_rel data_new_cleaned/test.sign+ data_new_cleaned/test.feat_col data_new_cleaned/test.feat_row --output models_new/cleaned/test.hyps.spm.spoken --max-input-length 99999 --beam-size 5 --device-id 0 --brevity-penalty-type constant --seed 42
[2023-11-22:14:42:26:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(config=None, input='data_new_cleaned/test.sign', input_factors=['data_new_cleaned/test.feat_x', 'data_new_cleaned/test.feat_y', 'data_new_cleaned/test.feat_x_rel', 'data_new_cleaned/test.feat_y_rel', 'data_new_cleaned/test.sign+', 'data_new_cleaned/test.feat_col', 'data_new_cleaned/test.feat_row'], json_input=False, output='models_new/cleaned/test.hyps.spm.spoken', models=['models_new/cleaned'], checkpoints=None, nbest_size=1, beam_size=5, greedy=False, beam_search_stop='all', batch_size=1, chunk_size=None, sample=None, seed=42, ensemble_mode='linear', bucket_width=10, max_input_length=99999, max_output_length_num_stds=2, max_output_length=None, restrict_lexicon=None, restrict_lexicon_topk=None, skip_nvs=False, nvs_thresh=0.5, strip_unknown_words=False, prevent_unk=False, output_type='translation', length_penalty_alpha=1.0, length_penalty_beta=0.0, brevity_penalty_type='constant', brevity_penalty_weight=1.0, brevity_penalty_constant_length_ratio=0.0, dtype=None, clamp_to_dtype=False, device_id=0, use_cpu=False, env=None, tf32=True, quiet=False, quiet_secondary_workers=False, no_logfile=False, loglevel='INFO', loglevel_secondary_workers='INFO', knn_index=None, knn_lambda=0.8)
[2023-11-22:14:42:27:INFO:sockeye.utils:init_device] CUDA: allow tf32 (float32 but with 10 bits precision)
[2023-11-22:14:42:27:INFO:__main__:run_translate] Translate Device: cuda:0
[2023-11-22:14:42:27:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models_new/cleaned'] ...
[2023-11-22:14:42:27:INFO:sockeye.vocab:vocab_from_json] Vocabulary (15720 words) loaded from "models_new/cleaned/vocab.src.0.json"
[2023-11-22:14:42:27:INFO:sockeye.vocab:vocab_from_json] Vocabulary (432 words) loaded from "models_new/cleaned/vocab.src.1.json"
[2023-11-22:14:42:27:INFO:sockeye.vocab:vocab_from_json] Vocabulary (472 words) loaded from "models_new/cleaned/vocab.src.2.json"
[2023-11-22:14:42:27:INFO:sockeye.vocab:vocab_from_json] Vocabulary (64 words) loaded from "models_new/cleaned/vocab.src.3.json"
[2023-11-22:14:42:27:INFO:sockeye.vocab:vocab_from_json] Vocabulary (56 words) loaded from "models_new/cleaned/vocab.src.4.json"
[2023-11-22:14:42:27:INFO:sockeye.vocab:vocab_from_json] Vocabulary (768 words) loaded from "models_new/cleaned/vocab.src.5.json"
[2023-11-22:14:42:27:INFO:sockeye.vocab:vocab_from_json] Vocabulary (16 words) loaded from "models_new/cleaned/vocab.src.6.json"
[2023-11-22:14:42:27:INFO:sockeye.vocab:vocab_from_json] Vocabulary (24 words) loaded from "models_new/cleaned/vocab.src.7.json"
[2023-11-22:14:42:27:INFO:sockeye.vocab:vocab_from_json] Vocabulary (3752 words) loaded from "models_new/cleaned/vocab.trg.0.json"
[2023-11-22:14:42:27:INFO:sockeye.model:load_model] Model version: 3.1.37
[2023-11-22:14:42:27:INFO:sockeye.model:load_config] Loaded model config from "models_new/cleaned/config"
[2023-11-22:14:42:27:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=354727, num_discarded=0, num_tokens_source=4201025, num_tokens_target=2057535, num_unks_source=0, num_unks_target=0, max_observed_len_source=96, max_observed_len_target=192, size_vocab_source=15720, size_vocab_target=3752, length_ratio_mean=0.5463525593793229, length_ratio_std=0.4182879569055765, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)], num_sents_per_bucket=[149216, 173121, 14560, 2725, 1750, 1479, 1589, 2145, 2565, 2457, 2308, 755, 12, 11, 7, 6, 5, 4, 0, 2, 0, 2, 3, 5, 0, 0], average_len_target_per_bucket=[4.140326774608547, 5.108531027431742, 7.958035714285693, 13.630458715596294, 19.282285714285702, 19.158215010142012, 23.056010069225927, 24.663869463869425, 27.240155945419072, 29.649572649572605, 32.15597920277298, 35.04238410596021, 100.0, 108.09090909090908, 116.57142857142857, 125.0, 131.4, 140.5, None, 158.5, None, 172.0, 179.0, 188.4, None, None], length_ratio_stats_per_bucket=[(0.5781455199493354, 0.20559989890762204), (0.5035479926045533, 0.31443786222138226), (0.5468974987608402, 0.6491670331407603), (0.91248259310849, 1.2010031762840225), (1.1660911955799533, 1.5511466062959094), (0.8187221782430846, 1.3467568304114719), (0.6641840418457079, 1.0642485351442208), (0.5038462754858931, 0.8043286661508741), (0.48069506489906394, 0.7869185585367217), (0.4669203885345722, 0.8762070208109582), (0.44644518448479037, 0.8098897847283998), (0.5449491437402029, 1.2820685486019436), (8.591055328871786, 3.9510322226387298), (7.201917367926802, 3.6758955236249236), (11.221567717996288, 2.1560031382015623), (6.269197912671014, 4.738615940455274), (16.691666666666666, 2.854761904761905), (16.043939393939393, 4.138753056115349), (None, None), (24.547619047619047, 2.1190476190476204), (None, None), (23.044642857142858, 1.6696428571428577), (19.53956228956229, 2.723775920544078), (20.744761904761905, 4.800873503286439), (None, None), (None, None)]), max_seq_len_source=201, max_seq_len_target=201, num_source_factors=8, num_target_factors=1, eop_id=-1), vocab_source_size=15720, vocab_target_size=3752, config_embed_source=EmbeddingConfig(vocab_size=15720, num_embed=512, dropout=0.5, num_factors=8, factor_configs=[FactorConfig(vocab_size=432, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=472, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=64, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=56, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=768, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=16, num_embed=16, combine='concat', share_embedding=False), FactorConfig(vocab_size=24, num_embed=16, combine='concat', share_embedding=False)], allow_sparse_grad=False), config_embed_target=EmbeddingConfig(vocab_size=3752, num_embed=512, dropout=0.5, num_factors=1, factor_configs=None, allow_sparse_grad=False), config_encoder=TransformerConfig(model_size=624, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.5, dropout_act=0.1, dropout_prepost=0.1, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=624, use_glu=False), config_decoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.5, dropout_act=0.1, dropout_prepost=0.1, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', block_prepended_cross_attention=False, use_lhuc=False, depth_key_value=624, use_glu=False), config_length_task=None, weight_tying_type='trg_softmax', lhuc=False, dtype='float32', neural_vocab_selection=None, neural_vocab_selection_block_loss=False)
[2023-11-22:14:42:33:INFO:sockeye.model:load_parameters] Loaded params from "models_new/cleaned/params.best" to "cuda:0"
[2023-11-22:14:42:33:INFO:sockeye.model:load_model] Model dtype: torch.float32
[2023-11-22:14:42:33:INFO:sockeye.model:load_models] 1 model(s) loaded in 6.2306s
[2023-11-22:14:42:33:INFO:__main__:run_translate] Using average of constant length ratios saved in the model configs: 0.546353
[2023-11-22:14:42:33:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=5 algorithm=BeamSearch, beam_search_stop=all max_input_length=200 nbest_size=1 ensemble_mode=None max_batch_size=1 dtype=torch.float32 skip_nvs=False nvs_thresh=0.5)
[2023-11-22:14:42:33:INFO:__main__:read_and_translate] Translating...
[2023-11-22:14:45:24:INFO:__main__:read_and_translate] Processed 568 lines. Total time: 168.7194, sec/sent: 0.2970, sent/sec: 3.3665
