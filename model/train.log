2021-10-11 19:47:22,101 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-10-11 19:47:22,102 - INFO - joeynmt.data - Loading training data...
2021-10-11 19:47:22,375 - INFO - joeynmt.data - Building vocabulary...
2021-10-11 19:47:24,261 - INFO - joeynmt.data - Loading dev data...
2021-10-11 19:47:24,273 - INFO - joeynmt.data - Loading test data...
2021-10-11 19:47:24,283 - INFO - joeynmt.data - Data loaded.
2021-10-11 19:47:24,283 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-10-11 19:47:25,044 - INFO - joeynmt.model - Enc-dec model built.
2021-10-11 19:47:28,194 - DEBUG - tensorflow - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2021-10-11 19:47:28,455 - DEBUG - h5py._conv - Creating converter from 7 to 5
2021-10-11 19:47:28,455 - DEBUG - h5py._conv - Creating converter from 5 to 7
2021-10-11 19:47:28,455 - DEBUG - h5py._conv - Creating converter from 7 to 5
2021-10-11 19:47:28,455 - DEBUG - h5py._conv - Creating converter from 5 to 7
2021-10-11 19:47:29,286 - INFO - joeynmt.training - Total params: 58010112
2021-10-11 19:47:29,288 - DEBUG - joeynmt.training - Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'decoder.output_layer.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2021-10-11 19:47:29,290 - WARNING - joeynmt.training - `keep_last_ckpts` option is outdated. Please use `keep_best_ckpts`, instead.
2021-10-11 19:47:29,291 - INFO - joeynmt.helpers - cfg.name                           : transformer
2021-10-11 19:47:29,291 - INFO - joeynmt.helpers - cfg.data.src                       : sign
2021-10-11 19:47:29,291 - INFO - joeynmt.helpers - cfg.data.trg                       : en
2021-10-11 19:47:29,291 - INFO - joeynmt.helpers - cfg.data.train                     : data/train
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.data.dev                       : data/dev
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.data.test                      : data/test
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.data.level                     : word
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 500
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.testing.postprocess            : False
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2021-10-11 19:47:29,292 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens
2021-10-11 19:47:29,296 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]
2021-10-11 19:47:29,296 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-10-11 19:47:29,296 - INFO - joeynmt.helpers - cfg.training.patience              : 8
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0002
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.batch_size            : 32
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 32
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : loss
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.epochs                : 100
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100
2021-10-11 19:47:29,297 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2021-10-11 19:47:29,298 - INFO - joeynmt.helpers - cfg.training.model_dir             : model
2021-10-11 19:47:29,298 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-10-11 19:47:29,298 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-10-11 19:47:29,298 - INFO - joeynmt.helpers - cfg.training.use_cuda              : False
2021-10-11 19:47:29,298 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 200
2021-10-11 19:47:29,298 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 8
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.0
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.1
2021-10-11 19:47:29,299 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 8
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.0
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.1
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - Data set sizes: 
	train 11822,
	valid 656,
	test 658
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - First training example:
	[SRC] S15a07 S1f010 S26507 S14420 S17620 S38800 S10021 S10029 S22a07 S22a11 S36d03 S2df04 S11e20 S37806 S28a03 S15a56 S37706 S37806 S37806 S10002 S2ff00 S15a10 S22a04 S32107 S28902 S15a37 S10e04 S10e37 S10047 S1dc0a S1dc02 S22a10 S22a00 S38800 S1dc0a S10003 S20500 S20500 S36d03 S30a00 S2ff00 S15a10 S22a04 S32107 S15a48 S15a40 S2c600 S2c611 S37c06 S37c06 S10047 S37d00 S15a1a S10010 S28a0f S38700
	[TRG] Verse 40. but God raised him to life on the third day . Then God allowed him to appear ,
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) S20500 (5) S2ff00 (6) S38700 (7) S38800 (8) S30a00 (9) S22a04
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) the (7) and (8) of (9) to
2021-10-11 19:47:29,300 - INFO - joeynmt.helpers - Number of Src words (types): 3515
2021-10-11 19:47:29,301 - INFO - joeynmt.helpers - Number of Trg words (types): 11787
2021-10-11 19:47:29,301 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=8),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=512, vocab_size=3515),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=11787))
2021-10-11 19:47:29,309 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 32
	total batch size (w. parallel & accumulation): 32
2021-10-11 19:47:29,309 - INFO - joeynmt.training - EPOCH 1
