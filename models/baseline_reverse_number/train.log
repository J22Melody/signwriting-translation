2021-12-13 14:27:06,318 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-12-13 14:27:06,428 - INFO - joeynmt.data - Loading training data...
2021-12-13 14:27:08,343 - INFO - joeynmt.data - Building vocabulary...
2021-12-13 14:27:11,023 - INFO - joeynmt.data - Loading dev data...
2021-12-13 14:27:11,036 - INFO - joeynmt.data - Loading test data...
2021-12-13 14:27:11,051 - INFO - joeynmt.data - Data loaded.
2021-12-13 14:27:11,051 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-12-13 14:27:11,793 - INFO - joeynmt.model - Enc-dec model built.
2021-12-13 14:27:13,735 - DEBUG - tensorflow - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2021-12-13 14:27:14,512 - DEBUG - h5py._conv - Creating converter from 7 to 5
2021-12-13 14:27:14,512 - DEBUG - h5py._conv - Creating converter from 5 to 7
2021-12-13 14:27:14,512 - DEBUG - h5py._conv - Creating converter from 7 to 5
2021-12-13 14:27:14,512 - DEBUG - h5py._conv - Creating converter from 5 to 7
2021-12-13 14:27:16,810 - INFO - joeynmt.training - Total params: 50437120
2021-12-13 14:27:16,812 - DEBUG - joeynmt.training - Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2021-12-13 14:27:16,813 - WARNING - joeynmt.training - `keep_last_ckpts` option is outdated. Please use `keep_best_ckpts`, instead.
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.name                           : baseline_reverse_number
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.data.src                       : symbol
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.data.trg                       : number
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.data.train                     : data_reverse/train
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.data.dev                       : data_reverse/dev
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.data.test                      : data_reverse/test
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.data.level                     : word
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 300
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 3
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.testing.postprocess            : False
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]
2021-12-13 14:27:20,224 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.patience              : 5
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0001
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.2
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.batch_size            : 4096
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.batch_type            : token
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 4096
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : eval_metric
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.epochs                : 300
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 5000
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 500
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.eval_metric           : token_accuracy
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 300
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3, 6]
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 1
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/baseline_reverse_number
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier
2021-12-13 14:27:20,225 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 8
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.5
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.5
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 8
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.5
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.5
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - Data set sizes: 
	train 110700,
	valid 1126,
	test 1125
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - First training example:
	[SRC] M S1ed40 S1ed48 S3780b S20359 S20601 S1a051
	[TRG] 538 548 512 453 462 453 486 514 509 500 490 507 492 520
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) M (5) P (6) S20500 (7) S2ff00 (8) S38700 (9) S38800
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) 482 (5) 483 (6) 496 (7) 518 (8) 479 (9) 493
2021-12-13 14:27:20,226 - INFO - joeynmt.helpers - Number of Src words (types): 11838
2021-12-13 14:27:20,227 - INFO - joeynmt.helpers - Number of Trg words (types): 460
2021-12-13 14:27:20,227 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=8),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=512, vocab_size=11838),
	factor_embeds=None,
	trg_embed=Embeddings(embedding_dim=512, vocab_size=460))
2021-12-13 14:27:20,233 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 4096
	total batch size (w. parallel & accumulation): 4096
2021-12-13 14:27:20,233 - INFO - joeynmt.training - EPOCH 1
2021-12-13 14:28:23,243 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.499717, Tokens per Sec:     5369, Lr: 0.000100
2021-12-13 14:29:25,927 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.333084, Tokens per Sec:     5352, Lr: 0.000100
2021-12-13 14:30:29,194 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.335711, Tokens per Sec:     5414, Lr: 0.000100
2021-12-13 14:31:32,186 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     3.254582, Tokens per Sec:     5395, Lr: 0.000100
2021-12-13 14:32:35,347 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     3.317054, Tokens per Sec:     5330, Lr: 0.000100
2021-12-13 14:33:38,994 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     3.186824, Tokens per Sec:     5238, Lr: 0.000100
2021-12-13 14:34:41,935 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     3.236673, Tokens per Sec:     5400, Lr: 0.000100
2021-12-13 14:35:44,619 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     3.181662, Tokens per Sec:     5369, Lr: 0.000100
2021-12-13 14:36:47,387 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     3.122817, Tokens per Sec:     5434, Lr: 0.000100
2021-12-13 14:37:51,108 - INFO - joeynmt.training - Epoch   1, Step:     5000, Batch Loss:     3.144066, Tokens per Sec:     5279, Lr: 0.000100
2021-12-13 14:40:41,235 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 14:40:42,552 - INFO - joeynmt.training - Example #0
2021-12-13 14:40:42,567 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 14:40:42,569 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '512', '515', '489', '485', '464', '496', '521', '550', '479', '483', '479', '483', '479', '483', '521', '479', '483', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '464', '496']
2021-12-13 14:40:42,569 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 14:40:42,569 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 14:40:42,569 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 512 515 489 485 464 496 521 550 479 483 479 483 479 483 521 479 483 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 464 496
2021-12-13 14:40:42,569 - INFO - joeynmt.training - Example #1
2021-12-13 14:40:42,570 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 14:40:42,570 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '494', '482', '483']
2021-12-13 14:40:42,570 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 14:40:42,570 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 14:40:42,570 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 494 482 483
2021-12-13 14:40:42,570 - INFO - joeynmt.training - Example #2
2021-12-13 14:40:42,570 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 14:40:42,571 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '515', '489', '485', '464', '496', '518', '482', '483', '518', '482', '483', '521', '482', '483', '521', '482', '483', '463', '496', '521', '482', '483', '463', '496', '521', '520', '463', '496', '521', '550', '480', '506', '491', '483', '518', '482', '483', '463', '496', '521', '482', '483', '463', '496', '521', '550', '480', '506', '491', '483', '518', '482', '483', '518', '482', '483', '518', '482', '483', '463', '496', '521', '482', '483', '518', '482', '483', '463', '496', '521', '482', '483', '518', '482', '483', '518', '482', '483', '518', '482', '483', '518', '482', '483', '521', '482', '483', '463', '496', '521', '482', '483', '521', '550', '480', '506', '491', '483', '521', '550', '480', '506', '491', '483', '521', '550', '480', '506', '491', '483', '521', '550', '480', '506', '491', '483', '521', '550', '480', '506', '491', '483', '521', '550', '480', '506', '491', '483', '521', '550', '480', '506', '491', '483', '521', '550', '480', '506', '491', '483', '521', '550', '480', '506', '491', '483', '518', '482', '483', '518', '482', '483', '518', '482', '483', '521', '550', '480', '506', '491', '483', '521', '550', '480', '506', '491', '464', '496']
2021-12-13 14:40:42,571 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 14:40:42,571 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 14:40:42,571 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 515 489 485 464 496 518 482 483 518 482 483 521 482 483 521 482 483 463 496 521 482 483 463 496 521 520 463 496 521 550 480 506 491 483 518 482 483 463 496 521 482 483 463 496 521 550 480 506 491 483 518 482 483 518 482 483 518 482 483 463 496 521 482 483 518 482 483 463 496 521 482 483 518 482 483 518 482 483 518 482 483 518 482 483 521 482 483 463 496 521 482 483 521 550 480 506 491 483 521 550 480 506 491 483 521 550 480 506 491 483 521 550 480 506 491 483 521 550 480 506 491 483 521 550 480 506 491 483 521 550 480 506 491 483 521 550 480 506 491 483 521 550 480 506 491 483 518 482 483 518 482 483 518 482 483 521 550 480 506 491 483 521 550 480 506 491 464 496
2021-12-13 14:40:42,571 - INFO - joeynmt.training - Example #3
2021-12-13 14:40:42,571 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 14:40:42,571 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '485']
2021-12-13 14:40:42,572 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 14:40:42,572 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 14:40:42,572 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 485
2021-12-13 14:40:42,572 - INFO - joeynmt.training - Example #6
2021-12-13 14:40:42,572 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 14:40:42,572 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503']
2021-12-13 14:40:42,572 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 14:40:42,572 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 14:40:42,572 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503
2021-12-13 14:40:42,573 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     5000: token_accuracy:   6.01, loss: 121550.8359, ppl:  23.7527, duration: 171.4639s
2021-12-13 14:41:44,842 - INFO - joeynmt.training - Epoch   1, Step:     5500, Batch Loss:     2.890565, Tokens per Sec:     5342, Lr: 0.000100
2021-12-13 14:42:22,338 - INFO - joeynmt.training - Epoch   1: total training loss 19009.64
2021-12-13 14:42:22,339 - INFO - joeynmt.training - EPOCH 2
2021-12-13 14:42:47,456 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     3.047351, Tokens per Sec:     5242, Lr: 0.000100
2021-12-13 14:43:50,377 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     3.194861, Tokens per Sec:     5405, Lr: 0.000100
2021-12-13 14:44:53,768 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     3.037935, Tokens per Sec:     5404, Lr: 0.000100
2021-12-13 14:45:56,823 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     3.173605, Tokens per Sec:     5307, Lr: 0.000100
2021-12-13 14:46:59,380 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     3.172755, Tokens per Sec:     5466, Lr: 0.000100
2021-12-13 14:48:01,899 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     2.948529, Tokens per Sec:     5275, Lr: 0.000100
2021-12-13 14:49:04,949 - INFO - joeynmt.training - Epoch   2, Step:     9000, Batch Loss:     3.119396, Tokens per Sec:     5348, Lr: 0.000100
2021-12-13 14:50:08,079 - INFO - joeynmt.training - Epoch   2, Step:     9500, Batch Loss:     2.978174, Tokens per Sec:     5419, Lr: 0.000100
2021-12-13 14:51:11,186 - INFO - joeynmt.training - Epoch   2, Step:    10000, Batch Loss:     2.952891, Tokens per Sec:     5413, Lr: 0.000100
2021-12-13 14:54:17,004 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 14:54:18,299 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/5000.ckpt
2021-12-13 14:54:18,300 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/5000.ckpt
2021-12-13 14:54:18,300 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/5000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/5000.ckpt')
2021-12-13 14:54:18,321 - INFO - joeynmt.training - Example #0
2021-12-13 14:54:18,322 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 14:54:18,322 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '514', '490', '486', '464', '496', '521', '574', '479', '483', '479', '483', '479', '516', '479', '483', '521', '479', '517', '480', '506', '491', '483', '463', '496', '521', '517', '480', '506', '491', '483', '479', '483', '479', '483', '463', '496', '521', '550', '480', '506', '479', '483', '479', '483', '521', '550', '480', '506', '479', '483', '479', '517', '480', '506', '491', '483', '521', '484', '479', '483', '479', '483', '479', '483', '521', '517', '480', '506', '491', '483', '479', '483', '479', '483', '521', '484', '479', '483', '479', '483', '479', '483', '479', '493', '479', '493', '479', '493', '479', '493', '479', '493', '479', '493', '521', '517', '480', '506', '491', '483', '479', '483', '521', '484', '479', '483', '479', '483', '479', '483', '521', '517', '480', '506', '491', '483', '479', '483', '521', '484', '479', '483', '479', '483', '479', '483', '463', '496', '521', '550', '480', '506', '479', '483', '479', '470', '464', '496']
2021-12-13 14:54:18,322 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 14:54:18,322 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 14:54:18,322 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 514 490 486 464 496 521 574 479 483 479 483 479 516 479 483 521 479 517 480 506 491 483 463 496 521 517 480 506 491 483 479 483 479 483 463 496 521 550 480 506 479 483 479 483 521 550 480 506 479 483 479 517 480 506 491 483 521 484 479 483 479 483 479 483 521 517 480 506 491 483 479 483 479 483 521 484 479 483 479 483 479 483 479 493 479 493 479 493 479 493 479 493 479 493 521 517 480 506 491 483 479 483 521 484 479 483 479 483 479 483 521 517 480 506 491 483 479 483 521 484 479 483 479 483 479 483 463 496 521 550 480 506 479 483 479 470 464 496
2021-12-13 14:54:18,322 - INFO - joeynmt.training - Example #1
2021-12-13 14:54:18,322 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 14:54:18,322 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '492', '492', '492', '492']
2021-12-13 14:54:18,322 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 14:54:18,322 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 14:54:18,322 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 492 492 492 492
2021-12-13 14:54:18,322 - INFO - joeynmt.training - Example #2
2021-12-13 14:54:18,322 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 14:54:18,323 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '514', '490', '486', '464', '496', '518', '518', '482', '483', '518', '482', '483', '463', '496', '518', '482', '483', '463', '496', '518', '482', '483', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '432', '494', '464', '496']
2021-12-13 14:54:18,323 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 14:54:18,323 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 14:54:18,323 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 514 490 486 464 496 518 518 482 483 518 482 483 463 496 518 482 483 463 496 518 482 483 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 432 494 464 496
2021-12-13 14:54:18,323 - INFO - joeynmt.training - Example #3
2021-12-13 14:54:18,323 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 14:54:18,323 - DEBUG - joeynmt.training - 	Raw hypothesis: ['521', '521', '479', '479', '479', '479', '479', '479']
2021-12-13 14:54:18,323 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 14:54:18,323 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 14:54:18,323 - INFO - joeynmt.training - 	Hypothesis: 521 521 479 479 479 479 479 479
2021-12-13 14:54:18,323 - INFO - joeynmt.training - Example #6
2021-12-13 14:54:18,323 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 14:54:18,323 - DEBUG - joeynmt.training - 	Raw hypothesis: ['515', '515', '485', '485']
2021-12-13 14:54:18,323 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 14:54:18,324 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 14:54:18,324 - INFO - joeynmt.training - 	Hypothesis: 515 515 485 485
2021-12-13 14:54:18,324 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step    10000: token_accuracy:   6.51, loss: 117594.1953, ppl:  21.4255, duration: 187.1371s
2021-12-13 14:55:21,454 - INFO - joeynmt.training - Epoch   2, Step:    10500, Batch Loss:     3.148387, Tokens per Sec:     5363, Lr: 0.000100
2021-12-13 14:56:24,351 - INFO - joeynmt.training - Epoch   2, Step:    11000, Batch Loss:     2.993175, Tokens per Sec:     5351, Lr: 0.000100
2021-12-13 14:57:27,715 - INFO - joeynmt.training - Epoch   2, Step:    11500, Batch Loss:     3.045831, Tokens per Sec:     5449, Lr: 0.000100
2021-12-13 14:57:38,054 - INFO - joeynmt.training - Epoch   2: total training loss 17721.72
2021-12-13 14:57:38,055 - INFO - joeynmt.training - EPOCH 3
2021-12-13 14:58:30,718 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     3.139469, Tokens per Sec:     5342, Lr: 0.000100
2021-12-13 14:59:33,561 - INFO - joeynmt.training - Epoch   3, Step:    12500, Batch Loss:     2.996812, Tokens per Sec:     5528, Lr: 0.000100
2021-12-13 15:00:36,091 - INFO - joeynmt.training - Epoch   3, Step:    13000, Batch Loss:     2.911963, Tokens per Sec:     5375, Lr: 0.000100
2021-12-13 15:01:39,603 - INFO - joeynmt.training - Epoch   3, Step:    13500, Batch Loss:     3.052926, Tokens per Sec:     5331, Lr: 0.000100
2021-12-13 15:02:42,360 - INFO - joeynmt.training - Epoch   3, Step:    14000, Batch Loss:     3.076787, Tokens per Sec:     5407, Lr: 0.000100
2021-12-13 15:03:45,179 - INFO - joeynmt.training - Epoch   3, Step:    14500, Batch Loss:     3.066875, Tokens per Sec:     5422, Lr: 0.000100
2021-12-13 15:04:48,664 - INFO - joeynmt.training - Epoch   3, Step:    15000, Batch Loss:     2.787992, Tokens per Sec:     5424, Lr: 0.000100
2021-12-13 15:07:24,606 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 15:07:25,542 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/10000.ckpt
2021-12-13 15:07:25,543 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/10000.ckpt
2021-12-13 15:07:25,543 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/10000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/10000.ckpt')
2021-12-13 15:07:25,589 - INFO - joeynmt.training - Example #0
2021-12-13 15:07:25,590 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 15:07:25,590 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '475', '485', '504', '485', '464', '496', '521', '574', '479', '516', '479', '516', '479', '483', '479', '516', '479', '485', '463', '496', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '463', '496', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '479', '470', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '479', '470', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '463', '496', '521', '521', '521', '479', '470', '479', '470', '479', '470', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '463', '496', '521', '521', '521', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '479', '470', '479', '470', '463', '496', '521', '521', '521', '521', '521', '479', '470', '479', '470', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '463', '496', '521', '521', '521', '521', '521', '521', '521', '521', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '464', '496']
2021-12-13 15:07:25,590 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 15:07:25,590 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 15:07:25,590 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 475 485 504 485 464 496 521 574 479 516 479 516 479 483 479 516 479 485 463 496 521 550 480 506 495 450 498 527 479 470 463 496 521 550 480 506 495 450 498 527 479 470 479 470 521 550 480 506 495 450 498 527 479 470 479 470 521 550 480 506 495 450 498 527 479 470 463 496 521 521 521 479 470 479 470 479 470 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 463 496 521 521 521 521 550 480 506 495 450 498 527 479 470 479 470 479 470 463 496 521 521 521 521 521 479 470 479 470 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 463 496 521 521 521 521 521 521 521 521 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 464 496
2021-12-13 15:07:25,591 - INFO - joeynmt.training - Example #1
2021-12-13 15:07:25,591 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 15:07:25,591 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '492', '520', '488']
2021-12-13 15:07:25,591 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 15:07:25,591 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 15:07:25,591 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 492 520 488
2021-12-13 15:07:25,591 - INFO - joeynmt.training - Example #2
2021-12-13 15:07:25,592 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 15:07:25,592 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '514', '490', '486', '464', '496', '518', '568', '482', '483', '518', '482', '483', '463', '496', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '518', '482', '483', '494', '432', '494', '432', '494', '464', '482', '483', '518', '482', '483', '494', '432', '494', '432', '494', '464', '482', '483', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '463', '496', '521', '574', '479', '517', '480', '483', '479', '483', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '518', '493', '526', '482', '476', '518', '474', '482', '483', '494', '432', '494', '464', '482', '483', '518', '482', '483', '494', '432', '494', '432', '494', '464', '482', '483', '521', '550', '480', '506', '495', '450', '494', '432', '494', '432', '494', '432', '494', '464', '493', '518', '482', '483', '494', '432', '494', '432', '494', '432', '494', '464', '493', '518', '518', '482', '483', '494', '432', '494', '432', '494', '432', '494', '432', '494', '464', '482', '483', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '527', '479', '470', '518', '493', '526', '482', '476', '474', '493', '475', '463', '496', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '479', '470', '464', '496']
2021-12-13 15:07:25,592 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 15:07:25,592 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 15:07:25,592 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 514 490 486 464 496 518 568 482 483 518 482 483 463 496 521 550 480 506 495 450 498 527 479 470 518 482 483 494 432 494 432 494 464 482 483 518 482 483 494 432 494 432 494 464 482 483 521 550 480 506 495 450 498 527 479 470 463 496 521 574 479 517 480 483 479 483 521 550 480 506 495 450 498 527 479 470 518 493 526 482 476 518 474 482 483 494 432 494 464 482 483 518 482 483 494 432 494 432 494 464 482 483 521 550 480 506 495 450 494 432 494 432 494 432 494 464 493 518 482 483 494 432 494 432 494 432 494 464 493 518 518 482 483 494 432 494 432 494 432 494 432 494 464 482 483 521 550 480 506 495 450 498 527 479 470 527 479 470 518 493 526 482 476 474 493 475 463 496 521 550 480 506 495 450 498 527 479 470 479 470 464 496
2021-12-13 15:07:25,592 - INFO - joeynmt.training - Example #3
2021-12-13 15:07:25,592 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 15:07:25,593 - DEBUG - joeynmt.training - 	Raw hypothesis: ['521', '530', '480', '470', '480', '470', '480', '470', '499']
2021-12-13 15:07:25,593 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 15:07:25,593 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 15:07:25,593 - INFO - joeynmt.training - 	Hypothesis: 521 530 480 470 480 470 480 470 499
2021-12-13 15:07:25,593 - INFO - joeynmt.training - Example #6
2021-12-13 15:07:25,593 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 15:07:25,593 - DEBUG - joeynmt.training - 	Raw hypothesis: ['521', '515', '479', '485', '479', '485']
2021-12-13 15:07:25,593 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 15:07:25,594 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 15:07:25,594 - INFO - joeynmt.training - 	Hypothesis: 521 515 479 485 479 485
2021-12-13 15:07:25,594 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    15000: token_accuracy:   7.15, loss: 110655.7656, ppl:  17.8814, duration: 156.9298s
2021-12-13 15:08:28,529 - INFO - joeynmt.training - Epoch   3, Step:    15500, Batch Loss:     2.919437, Tokens per Sec:     5474, Lr: 0.000100
2021-12-13 15:09:31,294 - INFO - joeynmt.training - Epoch   3, Step:    16000, Batch Loss:     3.041776, Tokens per Sec:     5282, Lr: 0.000100
2021-12-13 15:10:34,029 - INFO - joeynmt.training - Epoch   3, Step:    16500, Batch Loss:     2.804316, Tokens per Sec:     5398, Lr: 0.000100
2021-12-13 15:11:37,360 - INFO - joeynmt.training - Epoch   3, Step:    17000, Batch Loss:     2.996947, Tokens per Sec:     5346, Lr: 0.000100
2021-12-13 15:12:20,998 - INFO - joeynmt.training - Epoch   3: total training loss 16893.12
2021-12-13 15:12:20,998 - INFO - joeynmt.training - EPOCH 4
2021-12-13 15:12:39,757 - INFO - joeynmt.training - Epoch   4, Step:    17500, Batch Loss:     2.913527, Tokens per Sec:     5428, Lr: 0.000100
2021-12-13 15:13:42,306 - INFO - joeynmt.training - Epoch   4, Step:    18000, Batch Loss:     2.936880, Tokens per Sec:     5483, Lr: 0.000100
2021-12-13 15:14:45,015 - INFO - joeynmt.training - Epoch   4, Step:    18500, Batch Loss:     2.835765, Tokens per Sec:     5263, Lr: 0.000100
2021-12-13 15:15:47,486 - INFO - joeynmt.training - Epoch   4, Step:    19000, Batch Loss:     2.729652, Tokens per Sec:     5462, Lr: 0.000100
2021-12-13 15:16:50,977 - INFO - joeynmt.training - Epoch   4, Step:    19500, Batch Loss:     2.821352, Tokens per Sec:     5336, Lr: 0.000100
2021-12-13 15:17:54,266 - INFO - joeynmt.training - Epoch   4, Step:    20000, Batch Loss:     2.960998, Tokens per Sec:     5344, Lr: 0.000100
2021-12-13 15:21:10,324 - INFO - joeynmt.training - Example #0
2021-12-13 15:21:10,324 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 15:21:10,324 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '475', '485', '505', '487', '464', '496', '521', '587', '479', '516', '479', '516', '479', '483', '479', '516', '463', '496', '521', '531', '479', '470', '479', '470', '463', '496', '521', '531', '479', '470', '479', '470', '463', '496', '521', '531', '479', '470', '479', '470', '463', '496', '521', '521', '531', '479', '470', '479', '470', '479', '470', '463', '496', '521', '521', '531', '479', '470', '479', '470', '463', '496', '521', '521', '531', '479', '470', '479', '470', '479', '470', '463', '496', '521', '521', '521', '479', '479', '479', '479', '479', '479', '479', '479', '479', '463', '496', '521', '521', '521', '531', '479', '470', '479', '470', '463', '496', '521', '521', '531', '479', '470', '479', '470', '463', '496', '521', '521', '521', '479', '470', '479', '469', '479', '469', '463', '496', '521', '521', '521', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '521', '521', '531', '479', '470', '463', '496', '521', '531', '479', '470', '479', '470', '463', '496', '521', '531', '479', '470', '479', '470', '521', '531', '479', '470', '479', '470', '521', '521', '531', '479', '470', '479', '470', '479', '470', '521', '521', '521', '521', '479', '470', '479', '469', '479', '469', '479', '469', '463', '496', '521', '521', '521', '521', '521', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '521', '521', '531', '479', '470', '479', '470', '479', '470', '464', '496']
2021-12-13 15:21:10,324 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 15:21:10,324 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 15:21:10,324 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 475 485 505 487 464 496 521 587 479 516 479 516 479 483 479 516 463 496 521 531 479 470 479 470 463 496 521 531 479 470 479 470 463 496 521 531 479 470 479 470 463 496 521 521 531 479 470 479 470 479 470 463 496 521 521 531 479 470 479 470 463 496 521 521 531 479 470 479 470 479 470 463 496 521 521 521 479 479 479 479 479 479 479 479 479 463 496 521 521 521 531 479 470 479 470 463 496 521 521 531 479 470 479 470 463 496 521 521 521 479 470 479 469 479 469 463 496 521 521 521 479 479 479 479 479 479 479 479 479 479 479 521 521 531 479 470 463 496 521 531 479 470 479 470 463 496 521 531 479 470 479 470 521 531 479 470 479 470 521 521 531 479 470 479 470 479 470 521 521 521 521 479 470 479 469 479 469 479 469 463 496 521 521 521 521 521 479 479 479 479 479 479 479 479 479 479 479 479 479 479 479 521 521 531 479 470 479 470 479 470 464 496
2021-12-13 15:21:10,324 - INFO - joeynmt.training - Example #1
2021-12-13 15:21:10,324 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 15:21:10,324 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '492', '492', '492']
2021-12-13 15:21:10,324 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 15:21:10,325 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 15:21:10,325 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 492 492 492
2021-12-13 15:21:10,325 - INFO - joeynmt.training - Example #2
2021-12-13 15:21:10,325 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 15:21:10,325 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '512', '516', '489', '485', '464', '496', '518', '564', '487', '540', '497', '516', '482', '483', '518', '462', '514', '483', '487', '463', '496', '518', '572', '482', '477', '482', '477', '482', '477', '463', '496', '518', '572', '482', '477', '482', '477', '482', '488', '482', '488', '482', '488', '463', '496', '518', '572', '482', '488', '482', '477', '482', '488', '482', '488', '482', '488', '482', '488', '463', '496', '518', '572', '482', '477', '482', '477', '482', '477', '482', '488', '482', '488', '518', '518', '482', '483', '494', '432', '494', '464', '482', '477', '463', '496', '518', '572', '482', '477', '482', '477', '482', '477', '482', '477', '463', '496', '518', '572', '482', '477', '482', '477', '482', '477', '482', '477', '463', '496', '518', '572', '482', '477', '482', '477', '482', '477', '482', '477', '482', '488', '512', '488', '512', '488', '512', '488', '512', '488', '517', '488', '484', '488', '484', '488', '484', '488', '484', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '464', '496']
2021-12-13 15:21:10,325 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 15:21:10,325 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 15:21:10,325 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 512 516 489 485 464 496 518 564 487 540 497 516 482 483 518 462 514 483 487 463 496 518 572 482 477 482 477 482 477 463 496 518 572 482 477 482 477 482 488 482 488 482 488 463 496 518 572 482 488 482 477 482 488 482 488 482 488 482 488 463 496 518 572 482 477 482 477 482 477 482 488 482 488 518 518 482 483 494 432 494 464 482 477 463 496 518 572 482 477 482 477 482 477 482 477 463 496 518 572 482 477 482 477 482 477 482 477 463 496 518 572 482 477 482 477 482 477 482 477 482 488 512 488 512 488 512 488 512 488 517 488 484 488 484 488 484 488 484 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 464 496
2021-12-13 15:21:10,325 - INFO - joeynmt.training - Example #3
2021-12-13 15:21:10,325 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 15:21:10,325 - DEBUG - joeynmt.training - 	Raw hypothesis: ['521', '530', '480', '470', '480', '470', '480', '470', '480']
2021-12-13 15:21:10,325 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 15:21:10,325 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 15:21:10,325 - INFO - joeynmt.training - 	Hypothesis: 521 530 480 470 480 470 480 470 480
2021-12-13 15:21:10,326 - INFO - joeynmt.training - Example #6
2021-12-13 15:21:10,326 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 15:21:10,326 - DEBUG - joeynmt.training - 	Raw hypothesis: ['513', '515', '487', '485', '488']
2021-12-13 15:21:10,326 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 15:21:10,326 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 15:21:10,326 - INFO - joeynmt.training - 	Hypothesis: 513 515 487 485 488
2021-12-13 15:21:10,326 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    20000: token_accuracy:   6.90, loss: 107164.1797, ppl:  16.3262, duration: 196.0597s
2021-12-13 15:22:12,504 - INFO - joeynmt.training - Epoch   4, Step:    20500, Batch Loss:     2.791734, Tokens per Sec:     5462, Lr: 0.000100
2021-12-13 15:23:16,207 - INFO - joeynmt.training - Epoch   4, Step:    21000, Batch Loss:     2.899493, Tokens per Sec:     5372, Lr: 0.000100
2021-12-13 15:24:19,593 - INFO - joeynmt.training - Epoch   4, Step:    21500, Batch Loss:     2.652311, Tokens per Sec:     5341, Lr: 0.000100
2021-12-13 15:25:22,119 - INFO - joeynmt.training - Epoch   4, Step:    22000, Batch Loss:     2.835564, Tokens per Sec:     5375, Lr: 0.000100
2021-12-13 15:26:24,767 - INFO - joeynmt.training - Epoch   4, Step:    22500, Batch Loss:     2.935741, Tokens per Sec:     5477, Lr: 0.000100
2021-12-13 15:27:27,730 - INFO - joeynmt.training - Epoch   4, Step:    23000, Batch Loss:     2.658525, Tokens per Sec:     5348, Lr: 0.000100
2021-12-13 15:27:44,218 - INFO - joeynmt.training - Epoch   4: total training loss 16289.63
2021-12-13 15:27:44,219 - INFO - joeynmt.training - EPOCH 5
2021-12-13 15:28:30,756 - INFO - joeynmt.training - Epoch   5, Step:    23500, Batch Loss:     2.742685, Tokens per Sec:     5369, Lr: 0.000100
2021-12-13 15:29:32,854 - INFO - joeynmt.training - Epoch   5, Step:    24000, Batch Loss:     2.827544, Tokens per Sec:     5332, Lr: 0.000100
2021-12-13 15:30:36,331 - INFO - joeynmt.training - Epoch   5, Step:    24500, Batch Loss:     2.681018, Tokens per Sec:     5374, Lr: 0.000100
2021-12-13 15:31:39,566 - INFO - joeynmt.training - Epoch   5, Step:    25000, Batch Loss:     2.759662, Tokens per Sec:     5494, Lr: 0.000100
2021-12-13 15:34:28,823 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 15:34:29,719 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/15000.ckpt
2021-12-13 15:34:29,720 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/15000.ckpt
2021-12-13 15:34:29,720 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/15000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/15000.ckpt')
2021-12-13 15:34:29,773 - INFO - joeynmt.training - Example #0
2021-12-13 15:34:29,774 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 15:34:29,774 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '475', '485', '504', '485', '464', '496', '521', '574', '479', '553', '479', '553', '479', '516', '479', '483', '463', '496', '521', '527', '479', '474', '479', '474', '463', '496', '521', '527', '479', '474', '479', '474', '463', '496', '521', '527', '479', '474', '479', '474', '463', '496', '521', '527', '479', '474', '479', '474', '518', '479', '483', '494', '432', '494', '464', '482', '483', '463', '496', '521', '527', '479', '473', '479', '473', '479', '474', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '518', '518', '482', '483', '494', '464', '482', '483', '521', '527', '479', '474', '479', '473', '479', '473', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '518', '479', '483', '521', '487', '479', '473', '479', '473', '479', '513', '526', '498', '475', '488', '475', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '488', '463', '496', '521', '521', '521', '479', '479', '479', '479', '479', '479', '479', '479', '479', '464', '496']
2021-12-13 15:34:29,774 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 15:34:29,774 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 15:34:29,774 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 475 485 504 485 464 496 521 574 479 553 479 553 479 516 479 483 463 496 521 527 479 474 479 474 463 496 521 527 479 474 479 474 463 496 521 527 479 474 479 474 463 496 521 527 479 474 479 474 518 479 483 494 432 494 464 482 483 463 496 521 527 479 473 479 473 479 474 518 518 482 483 494 432 494 464 482 483 463 496 521 527 479 473 479 473 479 473 518 518 482 483 494 464 482 483 521 527 479 474 479 473 479 473 518 518 482 483 494 432 494 464 482 483 463 496 521 527 479 473 479 473 479 473 518 479 483 521 487 479 473 479 473 479 513 526 498 475 488 475 488 512 488 512 488 512 488 512 488 512 488 512 488 512 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 488 463 496 521 521 521 479 479 479 479 479 479 479 479 479 464 496
2021-12-13 15:34:29,774 - INFO - joeynmt.training - Example #1
2021-12-13 15:34:29,775 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 15:34:29,775 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '492', '465', '482']
2021-12-13 15:34:29,775 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 15:34:29,775 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 15:34:29,775 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 492 465 482
2021-12-13 15:34:29,775 - INFO - joeynmt.training - Example #2
2021-12-13 15:34:29,775 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 15:34:29,776 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '514', '490', '486', '464', '496', '518', '558', '491', '529', '491', '530', '483', '518', '482', '483', '521', '484', '480', '506', '491', '479', '464', '496', '518', '574', '482', '477', '482', '477', '482', '488', '482', '488', '482', '488', '482', '488', '463', '496', '518', '572', '482', '488', '482', '488', '482', '488', '482', '488', '482', '488', '463', '496', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '494', '464', '482', '483', '463', '496', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '494', '464', '482', '483', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '494', '464', '482', '483', '518', '518', '482', '483', '494', '464', '482', '483', '494', '464', '482', '483', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '494', '464', '482', '483', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '494', '464', '482', '483', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '464', '482', '483', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '464', '482', '483', '464', '482', '483', '464', '496']
2021-12-13 15:34:29,776 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 15:34:29,776 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 15:34:29,776 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 514 490 486 464 496 518 558 491 529 491 530 483 518 482 483 521 484 480 506 491 479 464 496 518 574 482 477 482 477 482 488 482 488 482 488 482 488 463 496 518 572 482 488 482 488 482 488 482 488 482 488 463 496 518 518 482 483 494 432 494 464 482 483 494 464 482 483 463 496 518 518 482 483 494 432 494 464 482 483 494 464 482 483 518 518 482 483 494 432 494 464 482 483 463 496 518 518 482 483 494 432 494 464 482 483 494 464 482 483 518 518 482 483 494 464 482 483 494 464 482 483 518 518 482 483 494 432 494 464 482 483 463 496 518 518 482 483 494 432 494 464 482 483 494 464 482 483 518 518 482 483 494 432 494 464 482 483 494 464 482 483 518 518 482 483 494 432 494 464 482 483 464 482 483 518 518 482 483 494 432 494 464 482 483 464 482 483 464 482 483 464 496
2021-12-13 15:34:29,776 - INFO - joeynmt.training - Example #3
2021-12-13 15:34:29,776 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 15:34:29,776 - DEBUG - joeynmt.training - 	Raw hypothesis: ['521', '533', '480', '468', '480', '468', '480', '468', '505']
2021-12-13 15:34:29,777 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 15:34:29,777 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 15:34:29,777 - INFO - joeynmt.training - 	Hypothesis: 521 533 480 468 480 468 480 468 505
2021-12-13 15:34:29,777 - INFO - joeynmt.training - Example #6
2021-12-13 15:34:29,777 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 15:34:29,777 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '522', '486', '478', '486', '479']
2021-12-13 15:34:29,777 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 15:34:29,777 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 15:34:29,778 - INFO - joeynmt.training - 	Hypothesis: 514 522 486 478 486 479
2021-12-13 15:34:29,778 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    25000: token_accuracy:   7.53, loss: 103744.4141, ppl:  14.9341, duration: 170.2110s
2021-12-13 15:35:32,752 - INFO - joeynmt.training - Epoch   5, Step:    25500, Batch Loss:     2.605032, Tokens per Sec:     5337, Lr: 0.000100
2021-12-13 15:36:35,942 - INFO - joeynmt.training - Epoch   5, Step:    26000, Batch Loss:     2.508590, Tokens per Sec:     5478, Lr: 0.000100
2021-12-13 15:37:38,419 - INFO - joeynmt.training - Epoch   5, Step:    26500, Batch Loss:     2.602694, Tokens per Sec:     5458, Lr: 0.000100
2021-12-13 15:38:40,866 - INFO - joeynmt.training - Epoch   5, Step:    27000, Batch Loss:     2.745537, Tokens per Sec:     5385, Lr: 0.000100
2021-12-13 15:39:43,823 - INFO - joeynmt.training - Epoch   5, Step:    27500, Batch Loss:     2.376529, Tokens per Sec:     5387, Lr: 0.000100
2021-12-13 15:40:46,534 - INFO - joeynmt.training - Epoch   5, Step:    28000, Batch Loss:     2.363241, Tokens per Sec:     5407, Lr: 0.000100
2021-12-13 15:41:49,540 - INFO - joeynmt.training - Epoch   5, Step:    28500, Batch Loss:     2.568081, Tokens per Sec:     5312, Lr: 0.000100
2021-12-13 15:42:40,739 - INFO - joeynmt.training - Epoch   5: total training loss 15729.25
2021-12-13 15:42:40,740 - INFO - joeynmt.training - EPOCH 6
2021-12-13 15:42:52,460 - INFO - joeynmt.training - Epoch   6, Step:    29000, Batch Loss:     2.717876, Tokens per Sec:     5503, Lr: 0.000100
2021-12-13 15:43:55,854 - INFO - joeynmt.training - Epoch   6, Step:    29500, Batch Loss:     2.807743, Tokens per Sec:     5363, Lr: 0.000100
2021-12-13 15:44:58,551 - INFO - joeynmt.training - Epoch   6, Step:    30000, Batch Loss:     2.469784, Tokens per Sec:     5382, Lr: 0.000100
2021-12-13 15:48:05,513 - INFO - joeynmt.training - Example #0
2021-12-13 15:48:05,513 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 15:48:05,513 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '475', '485', '504', '487', '464', '496', '521', '574', '479', '553', '479', '553', '479', '516', '479', '483', '463', '496', '521', '534', '479', '483', '479', '467', '463', '496', '521', '528', '479', '472', '479', '472', '518', '479', '483', '521', '484', '479', '472', '463', '496', '521', '527', '479', '473', '479', '473', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '521', '528', '479', '483', '479', '483', '479', '472', '518', '511', '483', '490', '503', '483', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '521', '528', '479', '483', '479', '472', '518', '511', '479', '472', '518', '511', '483', '494', '464', '482', '521', '534', '479', '467', '479', '466', '524', '466', '477', '476', '509', '509', '511', '509', '490', '463', '496', '521', '528', '479', '472', '479', '472', '518', '472', '482', '479', '472', '534', '526', '468', '511', '505', '475', '520', '511', '467', '475', '520', '511', '480', '490', '480', '490', '463', '496', '521', '534', '479', '466', '479', '466', '524', '525', '503', '495', '476', '476', '476', '527', '550', '513', '518', '493', '526', '482', '476', '527', '550', '513', '518', '493', '526', '482', '476', '527', '550', '513', '518', '493', '526', '482', '476', '526', '482', '476', '521', '475', '479', '475', '479', '513', '509', '490', '479', '479', '464', '496']
2021-12-13 15:48:05,513 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 15:48:05,513 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 15:48:05,513 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 475 485 504 487 464 496 521 574 479 553 479 553 479 516 479 483 463 496 521 534 479 483 479 467 463 496 521 528 479 472 479 472 518 479 483 521 484 479 472 463 496 521 527 479 473 479 473 518 518 482 483 494 432 494 464 482 483 463 496 521 528 479 483 479 483 479 472 518 511 483 490 503 483 518 518 482 483 494 432 494 464 482 483 463 496 521 528 479 483 479 472 518 511 479 472 518 511 483 494 464 482 521 534 479 467 479 466 524 466 477 476 509 509 511 509 490 463 496 521 528 479 472 479 472 518 472 482 479 472 534 526 468 511 505 475 520 511 467 475 520 511 480 490 480 490 463 496 521 534 479 466 479 466 524 525 503 495 476 476 476 527 550 513 518 493 526 482 476 527 550 513 518 493 526 482 476 527 550 513 518 493 526 482 476 526 482 476 521 475 479 475 479 513 509 490 479 479 464 496
2021-12-13 15:48:05,513 - INFO - joeynmt.training - Example #1
2021-12-13 15:48:05,514 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 15:48:05,514 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '494', '470', '482']
2021-12-13 15:48:05,514 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 15:48:05,514 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 15:48:05,514 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 494 470 482
2021-12-13 15:48:05,514 - INFO - joeynmt.training - Example #2
2021-12-13 15:48:05,514 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 15:48:05,514 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '512', '516', '489', '485', '464', '496', '518', '558', '483', '542', '497', '516', '482', '530', '482', '483', '518', '482', '483', '494', '432', '494', '464', '482', '477', '534', '525', '519', '495', '467', '495', '505', '476', '473', '476', '463', '496', '518', '569', '482', '477', '482', '477', '482', '477', '482', '477', '482', '488', '512', '488', '512', '488', '512', '488', '463', '496', '524', '524', '476', '477', '490', '509', '490', '509', '490', '509', '463', '496', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '518', '518', '482', '483', '494', '464', '482', '483', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '518', '518', '482', '483', '494', '464', '482', '483', '518', '518', '482', '483', '494', '464', '482', '483', '463', '496', '524', '524', '482', '500', '476', '477', '490', '509', '511', '509', '490', '509', '490', '479', '463', '496', '518', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '518', '518', '482', '483', '494', '464', '482', '483', '524', '525', '503', '495', '476', '476', '527', '550', '513', '518', '493', '526', '482', '476', '534', '518', '482', '483', '521', '487', '520', '463', '520', '463', '520', '527', '480', '473', '490', '473', '490', '473', '490', '473', '490', '513', '526', '482', '476', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '464', '496']
2021-12-13 15:48:05,514 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 15:48:05,514 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 15:48:05,514 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 512 516 489 485 464 496 518 558 483 542 497 516 482 530 482 483 518 482 483 494 432 494 464 482 477 534 525 519 495 467 495 505 476 473 476 463 496 518 569 482 477 482 477 482 477 482 477 482 488 512 488 512 488 512 488 463 496 524 524 476 477 490 509 490 509 490 509 463 496 518 518 482 483 494 432 494 464 482 483 463 496 518 518 482 483 494 464 482 483 518 518 482 483 494 432 494 464 482 483 463 496 518 518 482 483 494 464 482 483 518 518 482 483 494 464 482 483 463 496 524 524 482 500 476 477 490 509 511 509 490 509 490 479 463 496 518 518 482 483 494 432 494 464 482 483 463 496 518 518 482 483 494 464 482 483 524 525 503 495 476 476 527 550 513 518 493 526 482 476 534 518 482 483 521 487 520 463 520 463 520 527 480 473 490 473 490 473 490 473 490 513 526 482 476 512 488 512 488 512 488 512 488 512 488 512 488 512 488 512 488 512 488 512 488 512 464 496
2021-12-13 15:48:05,514 - INFO - joeynmt.training - Example #3
2021-12-13 15:48:05,514 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 15:48:05,514 - DEBUG - joeynmt.training - 	Raw hypothesis: ['524', '524', '476', '476', '476', '509', '509', '476', '509']
2021-12-13 15:48:05,514 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 15:48:05,514 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 15:48:05,515 - INFO - joeynmt.training - 	Hypothesis: 524 524 476 476 476 509 509 476 509
2021-12-13 15:48:05,515 - INFO - joeynmt.training - Example #6
2021-12-13 15:48:05,515 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 15:48:05,515 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '522', '486', '478', '486', '479']
2021-12-13 15:48:05,515 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 15:48:05,515 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 15:48:05,515 - INFO - joeynmt.training - 	Hypothesis: 514 522 486 478 486 479
2021-12-13 15:48:05,515 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    30000: token_accuracy:   7.43, loss: 100587.1172, ppl:  13.7545, duration: 186.9635s
2021-12-13 15:49:09,069 - INFO - joeynmt.training - Epoch   6, Step:    30500, Batch Loss:     2.700339, Tokens per Sec:     5450, Lr: 0.000100
2021-12-13 15:50:12,217 - INFO - joeynmt.training - Epoch   6, Step:    31000, Batch Loss:     2.576360, Tokens per Sec:     5281, Lr: 0.000100
2021-12-13 15:51:15,268 - INFO - joeynmt.training - Epoch   6, Step:    31500, Batch Loss:     2.769033, Tokens per Sec:     5360, Lr: 0.000100
2021-12-13 15:52:17,860 - INFO - joeynmt.training - Epoch   6, Step:    32000, Batch Loss:     2.372863, Tokens per Sec:     5386, Lr: 0.000100
2021-12-13 15:53:21,102 - INFO - joeynmt.training - Epoch   6, Step:    32500, Batch Loss:     2.469382, Tokens per Sec:     5371, Lr: 0.000100
2021-12-13 15:54:24,527 - INFO - joeynmt.training - Epoch   6, Step:    33000, Batch Loss:     2.511362, Tokens per Sec:     5400, Lr: 0.000100
2021-12-13 15:55:27,756 - INFO - joeynmt.training - Epoch   6, Step:    33500, Batch Loss:     2.743216, Tokens per Sec:     5348, Lr: 0.000100
2021-12-13 15:56:30,406 - INFO - joeynmt.training - Epoch   6, Step:    34000, Batch Loss:     2.288876, Tokens per Sec:     5387, Lr: 0.000100
2021-12-13 15:57:33,453 - INFO - joeynmt.training - Epoch   6, Step:    34500, Batch Loss:     2.402609, Tokens per Sec:     5372, Lr: 0.000100
2021-12-13 15:57:57,127 - INFO - joeynmt.training - Epoch   6: total training loss 15293.28
2021-12-13 15:57:57,128 - INFO - joeynmt.training - EPOCH 7
2021-12-13 15:58:35,723 - INFO - joeynmt.training - Epoch   7, Step:    35000, Batch Loss:     2.568743, Tokens per Sec:     5473, Lr: 0.000100
2021-12-13 16:01:42,940 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 16:01:43,849 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/25000.ckpt
2021-12-13 16:01:43,849 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/25000.ckpt
2021-12-13 16:01:43,850 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/25000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/25000.ckpt')
2021-12-13 16:01:43,894 - INFO - joeynmt.training - Example #0
2021-12-13 16:01:43,894 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 16:01:43,894 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '475', '485', '504', '485', '464', '496', '521', '574', '479', '553', '479', '553', '479', '516', '479', '483', '463', '496', '521', '479', '480', '506', '491', '479', '479', '534', '532', '508', '468', '468', '511', '504', '466', '504', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '518', '511', '482', '483', '463', '496', '521', '527', '479', '473', '479', '473', '518', '511', '482', '483', '489', '502', '497', '540', '520', '519', '490', '482', '483', '518', '462', '518', '462', '462', '462', '482', '483', '463', '496', '521', '529', '479', '483', '479', '472', '479', '472', '518', '506', '491', '483', '483', '483', '483', '534', '532', '508', '468', '468', '511', '504', '466', '504', '463', '496', '521', '529', '479', '472', '479', '472', '479', '472', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '518', '511', '482', '490', '503', '488', '463', '496', '521', '479', '479', '479', '479', '479', '479', '479', '518', '482', '483', '494', '432', '494', '464', '482', '521', '529', '479', '472', '479', '472', '514', '454', '514', '479', '472', '518', '482', '483', '494', '464', '482', '521', '479', '479', '479', '479', '479', '479', '479', '479', '479', '479', '518', '482', '483', '494', '432', '494', '464', '482', '521', '528', '479', '473', '479', '473', '479', '473', '464', '496']
2021-12-13 16:01:43,894 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 16:01:43,894 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 16:01:43,895 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 475 485 504 485 464 496 521 574 479 553 479 553 479 516 479 483 463 496 521 479 480 506 491 479 479 534 532 508 468 468 511 504 466 504 463 496 521 527 479 473 479 473 479 473 463 496 521 527 479 473 479 473 479 473 518 511 482 483 463 496 521 527 479 473 479 473 518 511 482 483 489 502 497 540 520 519 490 482 483 518 462 518 462 462 462 482 483 463 496 521 529 479 483 479 472 479 472 518 506 491 483 483 483 483 534 532 508 468 468 511 504 466 504 463 496 521 529 479 472 479 472 479 472 463 496 521 527 479 473 479 473 479 473 463 496 521 527 479 473 479 473 479 473 518 511 482 490 503 488 463 496 521 479 479 479 479 479 479 479 518 482 483 494 432 494 464 482 521 529 479 472 479 472 514 454 514 479 472 518 482 483 494 464 482 521 479 479 479 479 479 479 479 479 479 479 518 482 483 494 432 494 464 482 521 528 479 473 479 473 479 473 464 496
2021-12-13 16:01:43,895 - INFO - joeynmt.training - Example #1
2021-12-13 16:01:43,895 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 16:01:43,895 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '493', '470', '489']
2021-12-13 16:01:43,895 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 16:01:43,895 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 16:01:43,895 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 493 470 489
2021-12-13 16:01:43,895 - INFO - joeynmt.training - Example #2
2021-12-13 16:01:43,896 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 16:01:43,896 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '514', '490', '486', '464', '496', '518', '572', '483', '548', '494', '522', '494', '525', '482', '483', '513', '515', '487', '504', '488', '485', '464', '496', '518', '576', '482', '477', '482', '488', '482', '477', '524', '525', '503', '495', '476', '476', '476', '533', '522', '498', '499', '507', '508', '468', '467', '504', '463', '496', '524', '525', '503', '495', '476', '476', '476', '463', '496', '524', '525', '503', '495', '476', '476', '476', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '534', '532', '508', '468', '468', '468', '511', '504', '466', '504', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '524', '482', '500', '476', '477', '490', '514', '504', '487', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '524', '524', '482', '500', '476', '477', '490', '514', '504', '487', '496', '494', '521', '479', '480', '506', '491', '479', '480', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '534', '518', '482', '483', '521', '487', '520', '463', '520', '463', '521', '479', '480', '480', '480', '480', '506', '491', '479', '480', '464', '496']
2021-12-13 16:01:43,896 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 16:01:43,896 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 16:01:43,896 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 514 490 486 464 496 518 572 483 548 494 522 494 525 482 483 513 515 487 504 488 485 464 496 518 576 482 477 482 488 482 477 524 525 503 495 476 476 476 533 522 498 499 507 508 468 467 504 463 496 524 525 503 495 476 476 476 463 496 524 525 503 495 476 476 476 463 496 518 482 483 494 432 494 464 482 483 534 532 508 468 468 468 511 504 466 504 463 496 518 482 483 494 432 494 464 482 483 463 496 524 482 500 476 477 490 514 504 487 463 496 518 482 483 494 432 494 464 482 483 463 496 524 482 500 492 476 477 490 514 504 487 463 496 518 482 483 494 432 494 464 482 483 463 496 524 524 482 500 476 477 490 514 504 487 496 494 521 479 480 506 491 479 480 463 496 518 482 483 494 432 494 464 482 483 534 518 482 483 521 487 520 463 520 463 521 479 480 480 480 480 506 491 479 480 464 496
2021-12-13 16:01:43,896 - INFO - joeynmt.training - Example #3
2021-12-13 16:01:43,896 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 16:01:43,897 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '528', '472', '472', '472', '472', '473', '514', '514', '514']
2021-12-13 16:01:43,897 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 16:01:43,897 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 16:01:43,897 - INFO - joeynmt.training - 	Hypothesis: 528 528 472 472 472 472 473 514 514 514
2021-12-13 16:01:43,897 - INFO - joeynmt.training - Example #6
2021-12-13 16:01:43,897 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 16:01:43,897 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '526', '487', '474', '487', '504']
2021-12-13 16:01:43,897 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 16:01:43,897 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 16:01:43,898 - INFO - joeynmt.training - 	Hypothesis: 514 526 487 474 487 504
2021-12-13 16:01:43,898 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    35000: token_accuracy:   7.72, loss: 97628.3438, ppl:  12.7338, duration: 188.1743s
2021-12-13 16:02:47,090 - INFO - joeynmt.training - Epoch   7, Step:    35500, Batch Loss:     2.485541, Tokens per Sec:     5366, Lr: 0.000100
2021-12-13 16:03:50,163 - INFO - joeynmt.training - Epoch   7, Step:    36000, Batch Loss:     2.459158, Tokens per Sec:     5380, Lr: 0.000100
2021-12-13 16:04:53,173 - INFO - joeynmt.training - Epoch   7, Step:    36500, Batch Loss:     2.404365, Tokens per Sec:     5353, Lr: 0.000100
2021-12-13 16:05:56,088 - INFO - joeynmt.training - Epoch   7, Step:    37000, Batch Loss:     2.647986, Tokens per Sec:     5391, Lr: 0.000100
2021-12-13 16:06:59,688 - INFO - joeynmt.training - Epoch   7, Step:    37500, Batch Loss:     2.460117, Tokens per Sec:     5375, Lr: 0.000100
2021-12-13 16:08:02,672 - INFO - joeynmt.training - Epoch   7, Step:    38000, Batch Loss:     3.067341, Tokens per Sec:     5267, Lr: 0.000100
2021-12-13 16:09:05,761 - INFO - joeynmt.training - Epoch   7, Step:    38500, Batch Loss:     2.472222, Tokens per Sec:     5448, Lr: 0.000100
2021-12-13 16:10:08,449 - INFO - joeynmt.training - Epoch   7, Step:    39000, Batch Loss:     2.432261, Tokens per Sec:     5376, Lr: 0.000100
2021-12-13 16:11:11,103 - INFO - joeynmt.training - Epoch   7, Step:    39500, Batch Loss:     2.621355, Tokens per Sec:     5482, Lr: 0.000100
2021-12-13 16:12:13,737 - INFO - joeynmt.training - Epoch   7, Step:    40000, Batch Loss:     2.746535, Tokens per Sec:     5447, Lr: 0.000100
2021-12-13 16:15:04,697 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 16:15:05,516 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/35000.ckpt
2021-12-13 16:15:05,517 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/35000.ckpt
2021-12-13 16:15:05,518 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/35000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/35000.ckpt')
2021-12-13 16:15:05,567 - INFO - joeynmt.training - Example #0
2021-12-13 16:15:05,567 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 16:15:05,567 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '474', '485', '504', '485', '464', '496', '521', '574', '479', '553', '479', '536', '479', '516', '479', '483', '463', '496', '521', '527', '479', '473', '479', '473', '463', '496', '521', '527', '479', '473', '479', '473', '518', '511', '482', '490', '503', '463', '496', '521', '527', '479', '473', '479', '473', '463', '496', '521', '527', '479', '473', '479', '473', '518', '572', '497', '445', '497', '468', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '482', '518', '482', '483', '494', '432', '494', '464', '482', '528', '524', '472', '477', '498', '510', '490', '477', '485', '511', '518', '511', '463', '496', '521', '479', '480', '534', '525', '519', '495', '467', '495', '505', '476', '473', '476', '463', '496', '521', '529', '479', '472', '479', '472', '518', '506', '491', '483', '534', '526', '468', '511', '505', '475', '520', '511', '467', '475', '524', '525', '503', '495', '476', '476', '527', '550', '513', '518', '493', '526', '482', '476', '518', '493', '526', '482', '476', '521', '517', '480', '506', '491', '483', '534', '526', '468', '511', '505', '475', '520', '511', '467', '475', '520', '511', '467', '475', '520', '511', '467', '475', '464', '496']
2021-12-13 16:15:05,568 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 16:15:05,568 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 16:15:05,568 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 474 485 504 485 464 496 521 574 479 553 479 536 479 516 479 483 463 496 521 527 479 473 479 473 463 496 521 527 479 473 479 473 518 511 482 490 503 463 496 521 527 479 473 479 473 463 496 521 527 479 473 479 473 518 572 497 445 497 468 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 482 518 482 483 494 432 494 464 482 528 524 472 477 498 510 490 477 485 511 518 511 463 496 521 479 480 534 525 519 495 467 495 505 476 473 476 463 496 521 529 479 472 479 472 518 506 491 483 534 526 468 511 505 475 520 511 467 475 524 525 503 495 476 476 527 550 513 518 493 526 482 476 518 493 526 482 476 521 517 480 506 491 483 534 526 468 511 505 475 520 511 467 475 520 511 467 475 520 511 467 475 464 496
2021-12-13 16:15:05,568 - INFO - joeynmt.training - Example #1
2021-12-13 16:15:05,568 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 16:15:05,568 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '489', '469', '489']
2021-12-13 16:15:05,569 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 16:15:05,569 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 16:15:05,569 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 489 469 489
2021-12-13 16:15:05,569 - INFO - joeynmt.training - Example #2
2021-12-13 16:15:05,569 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 16:15:05,569 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '512', '516', '489', '485', '464', '496', '518', '572', '483', '548', '494', '522', '494', '525', '482', '483', '513', '526', '498', '475', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '512', '488', '482', '477', '464', '493', '518', '572', '482', '477', '482', '488', '482', '477', '524', '525', '503', '495', '476', '476', '463', '496', '518', '574', '482', '483', '482', '483', '494', '522', '494', '479', '463', '496', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '463', '496', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '484', '487', '537', '518', '497', '507', '463', '507', '507', '483', '473', '493', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '518', '482', '483', '494', '464', '482', '483', '534', '525', '519', '495', '467', '495', '505', '476', '473', '476', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '534', '525', '519', '495', '467', '495', '505', '476', '473', '476', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '534', '525', '519', '495', '467', '495', '505', '476', '473', '476', '473', '476', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '464', '482', '483', '464', '496']
2021-12-13 16:15:05,569 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 16:15:05,570 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 16:15:05,570 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 512 516 489 485 464 496 518 572 483 548 494 522 494 525 482 483 513 526 498 475 488 512 488 512 488 512 488 512 488 512 488 512 488 512 488 512 488 482 477 464 493 518 572 482 477 482 488 482 477 524 525 503 495 476 476 463 496 518 574 482 483 482 483 494 522 494 479 463 496 524 482 500 492 476 477 490 514 504 487 463 496 524 482 500 492 476 477 490 514 504 487 484 487 537 518 497 507 463 507 507 483 473 493 463 496 518 482 483 494 432 494 464 482 483 463 496 518 482 483 494 464 482 483 534 525 519 495 467 495 505 476 473 476 463 496 518 482 483 494 432 494 464 482 483 534 525 519 495 467 495 505 476 473 476 463 496 518 482 483 494 432 494 464 482 483 534 525 519 495 467 495 505 476 473 476 473 476 463 496 518 482 483 494 432 494 464 482 483 464 482 483 464 496
2021-12-13 16:15:05,570 - INFO - joeynmt.training - Example #3
2021-12-13 16:15:05,570 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 16:15:05,570 - DEBUG - joeynmt.training - 	Raw hypothesis: ['519', '531', '481', '470', '481', '504', '504', '504', '504']
2021-12-13 16:15:05,570 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 16:15:05,570 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 16:15:05,571 - INFO - joeynmt.training - 	Hypothesis: 519 531 481 470 481 504 504 504 504
2021-12-13 16:15:05,571 - INFO - joeynmt.training - Example #6
2021-12-13 16:15:05,571 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 16:15:05,571 - DEBUG - joeynmt.training - 	Raw hypothesis: ['513', '526', '487', '474', '488', '512']
2021-12-13 16:15:05,571 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 16:15:05,571 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 16:15:05,571 - INFO - joeynmt.training - 	Hypothesis: 513 526 487 474 488 512
2021-12-13 16:15:05,572 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    40000: token_accuracy:   8.01, loss: 95505.1484, ppl:  12.0484, duration: 171.8338s
2021-12-13 16:16:03,075 - INFO - joeynmt.training - Epoch   7: total training loss 14853.87
2021-12-13 16:16:03,076 - INFO - joeynmt.training - EPOCH 8
2021-12-13 16:16:08,128 - INFO - joeynmt.training - Epoch   8, Step:    40500, Batch Loss:     2.544605, Tokens per Sec:     4847, Lr: 0.000100
2021-12-13 16:17:10,531 - INFO - joeynmt.training - Epoch   8, Step:    41000, Batch Loss:     2.619391, Tokens per Sec:     5428, Lr: 0.000100
2021-12-13 16:18:12,731 - INFO - joeynmt.training - Epoch   8, Step:    41500, Batch Loss:     2.858513, Tokens per Sec:     5474, Lr: 0.000100
2021-12-13 16:19:15,364 - INFO - joeynmt.training - Epoch   8, Step:    42000, Batch Loss:     2.637544, Tokens per Sec:     5260, Lr: 0.000100
2021-12-13 16:20:18,125 - INFO - joeynmt.training - Epoch   8, Step:    42500, Batch Loss:     2.475035, Tokens per Sec:     5331, Lr: 0.000100
2021-12-13 16:21:20,469 - INFO - joeynmt.training - Epoch   8, Step:    43000, Batch Loss:     2.199419, Tokens per Sec:     5510, Lr: 0.000100
2021-12-13 16:22:23,030 - INFO - joeynmt.training - Epoch   8, Step:    43500, Batch Loss:     2.043634, Tokens per Sec:     5522, Lr: 0.000100
2021-12-13 16:23:25,828 - INFO - joeynmt.training - Epoch   8, Step:    44000, Batch Loss:     2.521925, Tokens per Sec:     5492, Lr: 0.000100
2021-12-13 16:24:28,246 - INFO - joeynmt.training - Epoch   8, Step:    44500, Batch Loss:     2.641720, Tokens per Sec:     5376, Lr: 0.000100
2021-12-13 16:25:30,245 - INFO - joeynmt.training - Epoch   8, Step:    45000, Batch Loss:     2.456672, Tokens per Sec:     5434, Lr: 0.000100
2021-12-13 16:28:15,574 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 16:28:16,375 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/40000.ckpt
2021-12-13 16:28:16,376 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/40000.ckpt
2021-12-13 16:28:16,376 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/40000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/40000.ckpt')
2021-12-13 16:28:16,434 - INFO - joeynmt.training - Example #0
2021-12-13 16:28:16,434 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 16:28:16,434 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '475', '485', '504', '487', '464', '496', '521', '574', '479', '553', '479', '553', '479', '536', '479', '516', '479', '483', '515', '511', '485', '490', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '518', '511', '482', '490', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '463', '496', '521', '534', '479', '466', '479', '466', '479', '466', '515', '511', '485', '490', '518', '572', '497', '445', '497', '469', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '528', '479', '483', '464', '496', '521', '574', '479', '483', '479', '516', '479', '483', '534', '526', '468', '511', '505', '475', '520', '511', '467', '475', '463', '496', '521', '534', '479', '466', '479', '466', '479', '466', '511', '515', '490', '485', '463', '496', '521', '534', '479', '466', '479', '466', '479', '466', '524', '525', '503', '495', '476', '476', '463', '496', '521', '534', '479', '466', '479', '466', '524', '525', '503', '495', '476', '476', '521', '517', '480', '506', '491', '483', '524', '525', '503', '495', '476', '476', '476', '527', '550', '513', '518', '493', '526', '482', '476', '523', '520', '499', '492', '500', '491', '478', '480', '464', '496', '521', '534', '479', '466', '479', '466', '479', '466', '479', '466', '524', '525', '503', '495', '476', '476', '476', '464', '496']
2021-12-13 16:28:16,434 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 16:28:16,434 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 16:28:16,435 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 475 485 504 487 464 496 521 574 479 553 479 553 479 536 479 516 479 483 515 511 485 490 463 496 521 527 479 473 479 473 479 473 518 511 482 490 463 496 521 527 479 473 479 473 479 473 463 496 521 534 479 466 479 466 479 466 515 511 485 490 518 572 497 445 497 469 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 497 528 479 483 464 496 521 574 479 483 479 516 479 483 534 526 468 511 505 475 520 511 467 475 463 496 521 534 479 466 479 466 479 466 511 515 490 485 463 496 521 534 479 466 479 466 479 466 524 525 503 495 476 476 463 496 521 534 479 466 479 466 524 525 503 495 476 476 521 517 480 506 491 483 524 525 503 495 476 476 476 527 550 513 518 493 526 482 476 523 520 499 492 500 491 478 480 464 496 521 534 479 466 479 466 479 466 479 466 524 525 503 495 476 476 476 464 496
2021-12-13 16:28:16,435 - INFO - joeynmt.training - Example #1
2021-12-13 16:28:16,435 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 16:28:16,435 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '494', '470', '489', '470']
2021-12-13 16:28:16,435 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 16:28:16,435 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 16:28:16,435 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 494 470 489 470
2021-12-13 16:28:16,436 - INFO - joeynmt.training - Example #2
2021-12-13 16:28:16,436 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 16:28:16,436 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '514', '490', '486', '464', '496', '518', '558', '490', '538', '490', '538', '490', '538', '482', '515', '515', '485', '514', '504', '487', '484', '487', '537', '549', '482', '477', '486', '512', '507', '490', '478', '522', '464', '493', '518', '572', '482', '477', '491', '547', '488', '482', '477', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '464', '493', '518', '572', '482', '482', '488', '524', '489', '548', '489', '548', '489', '529', '504', '563', '482', '463', '496', '524', '559', '495', '542', '474', '542', '506', '525', '481', '525', '481', '476', '498', '501', '476', '476', '533', '518', '482', '483', '521', '484', '514', '454', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '484', '487', '537', '521', '464', '497', '507', '497', '476', '479', '510', '479', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '484', '487', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '484', '487', '537', '518', '497', '507', '463', '507', '507', '507', '483', '473', '493', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '484', '487', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '463', '496']
2021-12-13 16:28:16,436 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 16:28:16,436 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 16:28:16,436 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 514 490 486 464 496 518 558 490 538 490 538 490 538 482 515 515 485 514 504 487 484 487 537 549 482 477 486 512 507 490 478 522 464 493 518 572 482 477 491 547 488 482 477 529 538 472 513 498 462 514 497 471 478 464 493 518 572 482 482 488 524 489 548 489 548 489 529 504 563 482 463 496 524 559 495 542 474 542 506 525 481 525 481 476 498 501 476 476 533 518 482 483 521 484 514 454 463 496 524 524 482 500 492 476 477 490 514 504 487 484 487 537 521 464 497 507 497 476 479 510 479 463 496 524 524 482 500 492 476 477 490 514 504 487 484 487 463 496 524 524 482 500 492 476 477 490 514 504 487 484 487 537 518 497 507 463 507 507 507 483 473 493 518 482 483 494 432 494 464 482 483 463 496 524 524 482 500 492 476 477 490 514 504 487 484 487 463 496 524 524 482 500 492 476 477 490 514 504 487 463 496
2021-12-13 16:28:16,437 - INFO - joeynmt.training - Example #3
2021-12-13 16:28:16,437 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 16:28:16,437 - DEBUG - joeynmt.training - 	Raw hypothesis: ['524', '524', '476', '477', '477', '509', '509', '509', '509', '477']
2021-12-13 16:28:16,437 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 16:28:16,437 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 16:28:16,437 - INFO - joeynmt.training - 	Hypothesis: 524 524 476 477 477 509 509 509 509 477
2021-12-13 16:28:16,437 - INFO - joeynmt.training - Example #6
2021-12-13 16:28:16,437 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 16:28:16,437 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '522', '486', '479', '486', '507']
2021-12-13 16:28:16,438 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 16:28:16,438 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 16:28:16,438 - INFO - joeynmt.training - 	Hypothesis: 514 522 486 479 486 507
2021-12-13 16:28:16,438 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    45000: token_accuracy:   8.25, loss: 92355.1406, ppl:  11.0988, duration: 166.1920s
2021-12-13 16:29:18,418 - INFO - joeynmt.training - Epoch   8, Step:    45500, Batch Loss:     2.371190, Tokens per Sec:     5468, Lr: 0.000100
2021-12-13 16:30:19,785 - INFO - joeynmt.training - Epoch   8, Step:    46000, Batch Loss:     2.418504, Tokens per Sec:     5557, Lr: 0.000100
2021-12-13 16:30:49,921 - INFO - joeynmt.training - Epoch   8: total training loss 14498.61
2021-12-13 16:30:49,921 - INFO - joeynmt.training - EPOCH 9
2021-12-13 16:31:22,601 - INFO - joeynmt.training - Epoch   9, Step:    46500, Batch Loss:     2.820803, Tokens per Sec:     5238, Lr: 0.000100
2021-12-13 16:32:25,347 - INFO - joeynmt.training - Epoch   9, Step:    47000, Batch Loss:     2.334913, Tokens per Sec:     5296, Lr: 0.000100
2021-12-13 16:33:28,497 - INFO - joeynmt.training - Epoch   9, Step:    47500, Batch Loss:     2.509722, Tokens per Sec:     5363, Lr: 0.000100
2021-12-13 16:34:30,885 - INFO - joeynmt.training - Epoch   9, Step:    48000, Batch Loss:     2.442507, Tokens per Sec:     5441, Lr: 0.000100
2021-12-13 16:35:33,184 - INFO - joeynmt.training - Epoch   9, Step:    48500, Batch Loss:     2.208565, Tokens per Sec:     5353, Lr: 0.000100
2021-12-13 16:36:36,300 - INFO - joeynmt.training - Epoch   9, Step:    49000, Batch Loss:     2.080567, Tokens per Sec:     5459, Lr: 0.000100
2021-12-13 16:37:39,999 - INFO - joeynmt.training - Epoch   9, Step:    49500, Batch Loss:     1.990581, Tokens per Sec:     5336, Lr: 0.000100
2021-12-13 16:38:43,191 - INFO - joeynmt.training - Epoch   9, Step:    50000, Batch Loss:     2.314840, Tokens per Sec:     5293, Lr: 0.000100
2021-12-13 16:41:22,209 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 16:41:23,098 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/45000.ckpt
2021-12-13 16:41:23,098 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/45000.ckpt
2021-12-13 16:41:23,098 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/45000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/45000.ckpt')
2021-12-13 16:41:23,138 - INFO - joeynmt.training - Example #0
2021-12-13 16:41:23,138 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 16:41:23,138 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '474', '485', '505', '487', '464', '496', '521', '574', '479', '553', '479', '536', '479', '536', '479', '517', '479', '483', '515', '511', '485', '490', '463', '496', '521', '527', '479', '473', '479', '473', '514', '454', '490', '523', '531', '499', '477', '501', '501', '501', '501', '501', '477', '470', '463', '496', '521', '527', '479', '474', '518', '576', '497', '421', '497', '452', '497', '469', '497', '497', '497', '497', '497', '497', '497', '497', '497', '482', '497', '516', '497', '485', '497', '499', '528', '524', '472', '477', '498', '510', '490', '477', '485', '511', '518', '511', '482', '483', '464', '496', '521', '574', '479', '516', '479', '483', '524', '525', '503', '495', '476', '476', '527', '520', '473', '490', '490', '490', '490', '490', '490', '490', '513', '481', '489', '504', '463', '496', '521', '532', '469', '479', '468', '479', '468', '463', '496', '521', '532', '469', '479', '468', '479', '468', '463', '496', '521', '525', '479', '476', '479', '476', '479', '510', '515', '490', '485', '464', '493', '521', '532', '479', '469', '479', '469', '521', '517', '480', '506', '491', '483', '524', '525', '503', '495', '476', '476', '527', '550', '513', '518', '493', '526', '482', '476', '518', '474', '482', '513', '482', '514', '503', '474', '503', '474', '503', '543', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '512', '512', '512', '512', '512', '512', '512', '512', '512', '512', '512', '540', '540', '540', '540', '540', '460', '460', '460', '460', '460', '460', '460', '460', '460', '460', '460', '460', '464', '496']
2021-12-13 16:41:23,138 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 16:41:23,139 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 16:41:23,139 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 474 485 505 487 464 496 521 574 479 553 479 536 479 536 479 517 479 483 515 511 485 490 463 496 521 527 479 473 479 473 514 454 490 523 531 499 477 501 501 501 501 501 477 470 463 496 521 527 479 474 518 576 497 421 497 452 497 469 497 497 497 497 497 497 497 497 497 482 497 516 497 485 497 499 528 524 472 477 498 510 490 477 485 511 518 511 482 483 464 496 521 574 479 516 479 483 524 525 503 495 476 476 527 520 473 490 490 490 490 490 490 490 513 481 489 504 463 496 521 532 469 479 468 479 468 463 496 521 532 469 479 468 479 468 463 496 521 525 479 476 479 476 479 510 515 490 485 464 493 521 532 479 469 479 469 521 517 480 506 491 483 524 525 503 495 476 476 527 550 513 518 493 526 482 476 518 474 482 513 482 514 503 474 503 474 503 543 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 512 512 512 512 512 512 512 512 512 512 512 540 540 540 540 540 460 460 460 460 460 460 460 460 460 460 460 460 464 496
2021-12-13 16:41:23,139 - INFO - joeynmt.training - Example #1
2021-12-13 16:41:23,139 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 16:41:23,139 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '493', '470', '493', '470']
2021-12-13 16:41:23,139 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 16:41:23,139 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 16:41:23,139 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 493 470 493 470
2021-12-13 16:41:23,139 - INFO - joeynmt.training - Example #2
2021-12-13 16:41:23,140 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 16:41:23,140 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '512', '516', '489', '485', '464', '496', '518', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '513', '535', '489', '465', '489', '465', '489', '512', '488', '512', '488', '512', '537', '549', '482', '477', '486', '512', '521', '517', '480', '506', '491', '483', '534', '525', '519', '495', '467', '495', '505', '476', '473', '476', '464', '493', '518', '576', '487', '529', '487', '529', '487', '563', '482', '463', '496', '524', '569', '494', '548', '474', '548', '506', '525', '481', '525', '482', '476', '463', '496', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '463', '496', '518', '572', '489', '536', '490', '536', '482', '477', '482', '488', '482', '488', '482', '488', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '484', '487', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '519', '482', '498', '497', '463', '496', '524', '482', '500', '492', '476', '477', '490', '514', '504', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '463', '496', '524', '482', '500', '492', '476', '477', '490', '514', '504', '533', '520', '468', '481', '507', '509', '511', '481', '464', '496']
2021-12-13 16:41:23,140 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 16:41:23,140 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 16:41:23,140 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 512 516 489 485 464 496 518 564 487 540 497 516 482 530 519 544 482 513 535 489 465 489 465 489 512 488 512 488 512 537 549 482 477 486 512 521 517 480 506 491 483 534 525 519 495 467 495 505 476 473 476 464 493 518 576 487 529 487 529 487 563 482 463 496 524 569 494 548 474 548 506 525 481 525 482 476 463 496 524 482 500 492 476 477 490 514 504 487 518 482 483 494 432 494 464 482 483 463 496 524 524 482 500 492 476 477 490 514 504 487 463 496 518 572 489 536 490 536 482 477 482 488 482 488 482 488 463 496 524 524 482 500 492 476 477 490 514 504 487 484 487 463 496 524 524 482 500 492 476 477 490 514 504 487 519 482 498 497 463 496 524 482 500 492 476 477 490 514 504 533 520 468 481 507 509 484 509 511 481 463 496 524 482 500 492 476 477 490 514 504 533 520 468 481 507 509 511 481 464 496
2021-12-13 16:41:23,140 - INFO - joeynmt.training - Example #3
2021-12-13 16:41:23,141 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 16:41:23,141 - DEBUG - joeynmt.training - 	Raw hypothesis: ['524', '524', '476', '477', '477', '509', '509', '509', '509', '477']
2021-12-13 16:41:23,141 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 16:41:23,141 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 16:41:23,141 - INFO - joeynmt.training - 	Hypothesis: 524 524 476 477 477 509 509 509 509 477
2021-12-13 16:41:23,141 - INFO - joeynmt.training - Example #6
2021-12-13 16:41:23,141 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 16:41:23,141 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '522', '486', '479', '486', '507']
2021-12-13 16:41:23,141 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 16:41:23,142 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 16:41:23,142 - INFO - joeynmt.training - 	Hypothesis: 514 522 486 479 486 507
2021-12-13 16:41:23,142 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    50000: token_accuracy:   8.77, loss: 90397.2344, ppl:  10.5467, duration: 159.9504s
2021-12-13 16:42:26,404 - INFO - joeynmt.training - Epoch   9, Step:    50500, Batch Loss:     2.255652, Tokens per Sec:     5400, Lr: 0.000100
2021-12-13 16:43:29,173 - INFO - joeynmt.training - Epoch   9, Step:    51000, Batch Loss:     2.489899, Tokens per Sec:     5453, Lr: 0.000100
2021-12-13 16:44:32,531 - INFO - joeynmt.training - Epoch   9, Step:    51500, Batch Loss:     2.230761, Tokens per Sec:     5303, Lr: 0.000100
2021-12-13 16:45:36,362 - INFO - joeynmt.training - Epoch   9, Step:    52000, Batch Loss:     2.380937, Tokens per Sec:     5305, Lr: 0.000100
2021-12-13 16:45:41,317 - INFO - joeynmt.training - Epoch   9: total training loss 14171.34
2021-12-13 16:45:41,317 - INFO - joeynmt.training - EPOCH 10
2021-12-13 16:46:40,005 - INFO - joeynmt.training - Epoch  10, Step:    52500, Batch Loss:     1.995757, Tokens per Sec:     5284, Lr: 0.000100
2021-12-13 16:47:43,121 - INFO - joeynmt.training - Epoch  10, Step:    53000, Batch Loss:     2.369298, Tokens per Sec:     5301, Lr: 0.000100
2021-12-13 16:48:45,910 - INFO - joeynmt.training - Epoch  10, Step:    53500, Batch Loss:     2.556535, Tokens per Sec:     5438, Lr: 0.000100
2021-12-13 16:49:48,617 - INFO - joeynmt.training - Epoch  10, Step:    54000, Batch Loss:     2.533756, Tokens per Sec:     5426, Lr: 0.000100
2021-12-13 16:50:51,673 - INFO - joeynmt.training - Epoch  10, Step:    54500, Batch Loss:     2.272804, Tokens per Sec:     5425, Lr: 0.000100
2021-12-13 16:51:54,997 - INFO - joeynmt.training - Epoch  10, Step:    55000, Batch Loss:     2.951002, Tokens per Sec:     5297, Lr: 0.000100
2021-12-13 16:54:33,173 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 16:54:34,103 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/50000.ckpt
2021-12-13 16:54:34,104 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/50000.ckpt
2021-12-13 16:54:34,104 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/50000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/50000.ckpt')
2021-12-13 16:54:34,153 - INFO - joeynmt.training - Example #0
2021-12-13 16:54:34,153 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 16:54:34,153 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '515', '475', '485', '504', '485', '464', '496', '521', '574', '479', '553', '479', '553', '479', '536', '479', '517', '479', '483', '515', '511', '485', '490', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '514', '454', '490', '523', '531', '499', '477', '501', '501', '477', '501', '501', '477', '501', '501', '463', '496', '521', '535', '479', '465', '479', '465', '479', '465', '514', '515', '487', '504', '491', '486', '521', '529', '480', '503', '471', '479', '502', '471', '515', '575', '494', '425', '494', '464', '494', '464', '494', '521', '574', '479', '483', '479', '516', '514', '504', '487', '484', '487', '464', '496', '521', '574', '479', '483', '479', '516', '479', '483', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '463', '496', '521', '574', '475', '553', '454', '553', '454', '553', '454', '553', '479', '517', '479', '483', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '527', '520', '473', '490', '490', '490', '490', '490', '513', '481', '489', '512', '525', '489', '476', '491', '510', '521', '517', '480', '506', '491', '483', '464', '493', '521', '529', '484', '471', '479', '472', '479', '472', '514', '454', '514', '522', '486', '479', '492', '504', '518', '482', '483', '494', '432', '494', '464', '482', '483', '528', '528', '528', '473', '473', '473', '473', '473', '473', '473', '473', '473', '513', '498', '510', '490', '477', '485', '511', '518', '511', '482', '483', '464', '496']
2021-12-13 16:54:34,153 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 16:54:34,153 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 16:54:34,153 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 515 475 485 504 485 464 496 521 574 479 553 479 553 479 536 479 517 479 483 515 511 485 490 463 496 521 527 479 473 479 473 479 473 514 454 490 523 531 499 477 501 501 477 501 501 477 501 501 463 496 521 535 479 465 479 465 479 465 514 515 487 504 491 486 521 529 480 503 471 479 502 471 515 575 494 425 494 464 494 464 494 521 574 479 483 479 516 514 504 487 484 487 464 496 521 574 479 483 479 516 479 483 529 538 472 513 498 462 514 497 471 478 463 496 521 574 475 553 454 553 454 553 454 553 479 517 479 483 521 550 480 506 495 450 498 527 479 470 527 520 473 490 490 490 490 490 513 481 489 512 525 489 476 491 510 521 517 480 506 491 483 464 493 521 529 484 471 479 472 479 472 514 454 514 522 486 479 492 504 518 482 483 494 432 494 464 482 483 528 528 528 473 473 473 473 473 473 473 473 473 513 498 510 490 477 485 511 518 511 482 483 464 496
2021-12-13 16:54:34,154 - INFO - joeynmt.training - Example #1
2021-12-13 16:54:34,154 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 16:54:34,154 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '559', '482', '483', '493', '520', '493', '533']
2021-12-13 16:54:34,154 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 16:54:34,154 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 16:54:34,154 - INFO - joeynmt.training - 	Hypothesis: 518 559 482 483 493 520 493 533
2021-12-13 16:54:34,154 - INFO - joeynmt.training - Example #2
2021-12-13 16:54:34,155 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 16:54:34,155 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '512', '515', '489', '485', '464', '496', '525', '559', '495', '538', '474', '538', '506', '521', '481', '521', '482', '483', '513', '538', '490', '463', '490', '463', '490', '463', '488', '515', '488', '515', '488', '485', '527', '550', '513', '518', '493', '526', '482', '476', '534', '524', '466', '478', '504', '476', '519', '496', '482', '497', '464', '493', '528', '587', '472', '529', '472', '529', '504', '563', '472', '529', '482', '483', '464', '493', '525', '559', '495', '538', '474', '538', '506', '521', '481', '521', '482', '483', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '518', '482', '483', '494', '432', '494', '464', '482', '488', '482', '477', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '518', '524', '482', '500', '492', '476', '477', '490', '514', '504', '521', '486', '479', '494', '506', '521', '520', '501', '505', '479', '505', '479', '505', '504', '480', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '524', '482', '500', '492', '476', '477', '490', '514', '504', '523', '499', '477', '490', '508', '501', '493', '464', '496']
2021-12-13 16:54:34,155 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 16:54:34,155 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 16:54:34,155 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 512 515 489 485 464 496 525 559 495 538 474 538 506 521 481 521 482 483 513 538 490 463 490 463 490 463 488 515 488 515 488 485 527 550 513 518 493 526 482 476 534 524 466 478 504 476 519 496 482 497 464 493 528 587 472 529 472 529 504 563 472 529 482 483 464 493 525 559 495 538 474 538 506 521 481 521 482 483 529 538 472 513 498 462 514 497 471 478 518 482 483 494 432 494 464 482 483 463 496 524 524 482 500 492 476 477 490 514 504 518 482 483 494 432 494 464 482 488 482 477 463 496 524 524 482 500 492 476 477 490 514 504 518 524 482 500 492 476 477 490 514 504 521 486 479 494 506 521 520 501 505 479 505 479 505 504 480 533 520 468 481 507 509 484 509 511 481 463 496 518 482 483 494 432 494 464 482 483 463 496 524 482 500 492 476 477 490 514 504 523 499 477 490 508 501 493 464 496
2021-12-13 16:54:34,155 - INFO - joeynmt.training - Example #3
2021-12-13 16:54:34,155 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 16:54:34,155 - DEBUG - joeynmt.training - 	Raw hypothesis: ['525', '530', '475', '470', '475', '471', '510', '510', '493', '519']
2021-12-13 16:54:34,155 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 16:54:34,155 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 16:54:34,156 - INFO - joeynmt.training - 	Hypothesis: 525 530 475 470 475 471 510 510 493 519
2021-12-13 16:54:34,156 - INFO - joeynmt.training - Example #6
2021-12-13 16:54:34,156 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 16:54:34,156 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '521', '486', '479', '486', '506']
2021-12-13 16:54:34,156 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 16:54:34,156 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 16:54:34,156 - INFO - joeynmt.training - 	Hypothesis: 514 521 486 479 486 506
2021-12-13 16:54:34,156 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    55000: token_accuracy:   9.22, loss: 88665.9141, ppl:  10.0814, duration: 159.1589s
2021-12-13 16:55:37,698 - INFO - joeynmt.training - Epoch  10, Step:    55500, Batch Loss:     2.455643, Tokens per Sec:     5415, Lr: 0.000100
2021-12-13 16:56:40,798 - INFO - joeynmt.training - Epoch  10, Step:    56000, Batch Loss:     2.141605, Tokens per Sec:     5356, Lr: 0.000100
2021-12-13 16:57:43,007 - INFO - joeynmt.training - Epoch  10, Step:    56500, Batch Loss:     2.398810, Tokens per Sec:     5409, Lr: 0.000100
2021-12-13 16:58:46,062 - INFO - joeynmt.training - Epoch  10, Step:    57000, Batch Loss:     2.532395, Tokens per Sec:     5438, Lr: 0.000100
2021-12-13 16:59:48,757 - INFO - joeynmt.training - Epoch  10, Step:    57500, Batch Loss:     2.387287, Tokens per Sec:     5411, Lr: 0.000100
2021-12-13 17:00:28,491 - INFO - joeynmt.training - Epoch  10: total training loss 13811.34
2021-12-13 17:00:28,491 - INFO - joeynmt.training - EPOCH 11
2021-12-13 17:00:51,808 - INFO - joeynmt.training - Epoch  11, Step:    58000, Batch Loss:     2.441777, Tokens per Sec:     5280, Lr: 0.000100
2021-12-13 17:01:55,323 - INFO - joeynmt.training - Epoch  11, Step:    58500, Batch Loss:     2.060295, Tokens per Sec:     5329, Lr: 0.000100
2021-12-13 17:02:58,688 - INFO - joeynmt.training - Epoch  11, Step:    59000, Batch Loss:     2.128873, Tokens per Sec:     5512, Lr: 0.000100
2021-12-13 17:04:01,527 - INFO - joeynmt.training - Epoch  11, Step:    59500, Batch Loss:     2.269441, Tokens per Sec:     5310, Lr: 0.000100
2021-12-13 17:05:05,024 - INFO - joeynmt.training - Epoch  11, Step:    60000, Batch Loss:     2.595696, Tokens per Sec:     5396, Lr: 0.000100
2021-12-13 17:07:44,556 - INFO - joeynmt.training - Example #0
2021-12-13 17:07:44,557 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 17:07:44,557 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '475', '485', '505', '487', '464', '496', '521', '585', '488', '539', '488', '573', '479', '573', '479', '516', '479', '483', '515', '511', '485', '490', '463', '496', '521', '527', '479', '473', '479', '473', '514', '454', '490', '523', '531', '477', '501', '501', '501', '501', '477', '470', '463', '496', '521', '581', '469', '556', '479', '483', '479', '516', '479', '516', '568', '498', '432', '498', '465', '498', '488', '498', '498', '498', '498', '527', '522', '474', '483', '513', '509', '490', '479', '518', '572', '497', '445', '497', '468', '497', '497', '497', '497', '497', '497', '497', '497', '497', '525', '497', '543', '464', '496', '521', '574', '479', '483', '479', '516', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '521', '479', '480', '506', '506', '506', '479', '480', '463', '496', '521', '574', '475', '553', '454', '553', '454', '553', '454', '553', '486', '536', '461', '536', '479', '517', '479', '483', '523', '484', '493', '488', '477', '464', '493', '521', '533', '469', '499', '479', '467', '524', '482', '500', '492', '476', '477', '490', '514', '504', '487', '523', '520', '499', '492', '500', '491', '478', '480', '464', '493', '521', '527', '479', '473', '479', '473', '514', '454', '490', '523', '520', '499', '492', '500', '491', '478', '480', '527', '550', '513', '518', '493', '526', '482', '476', '527', '532', '473', '502', '469', '473', '502', '502', '469', '473', '469', '464', '496']
2021-12-13 17:07:44,557 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 17:07:44,557 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 17:07:44,557 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 475 485 505 487 464 496 521 585 488 539 488 573 479 573 479 516 479 483 515 511 485 490 463 496 521 527 479 473 479 473 514 454 490 523 531 477 501 501 501 501 477 470 463 496 521 581 469 556 479 483 479 516 479 516 568 498 432 498 465 498 488 498 498 498 498 527 522 474 483 513 509 490 479 518 572 497 445 497 468 497 497 497 497 497 497 497 497 497 525 497 543 464 496 521 574 479 483 479 516 529 538 472 513 498 462 514 497 471 478 521 479 480 506 506 506 479 480 463 496 521 574 475 553 454 553 454 553 454 553 486 536 461 536 479 517 479 483 523 484 493 488 477 464 493 521 533 469 499 479 467 524 482 500 492 476 477 490 514 504 487 523 520 499 492 500 491 478 480 464 493 521 527 479 473 479 473 514 454 490 523 520 499 492 500 491 478 480 527 550 513 518 493 526 482 476 527 532 473 502 469 473 502 502 469 473 469 464 496
2021-12-13 17:07:44,557 - INFO - joeynmt.training - Example #1
2021-12-13 17:07:44,557 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 17:07:44,557 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '493', '470', '493', '470']
2021-12-13 17:07:44,557 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 17:07:44,557 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 17:07:44,558 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 493 470 493 470
2021-12-13 17:07:44,558 - INFO - joeynmt.training - Example #2
2021-12-13 17:07:44,558 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 17:07:44,558 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '514', '490', '486', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '512', '549', '489', '451', '497', '517', '497', '506', '463', '482', '477', '510', '537', '494', '463', '490', '480', '495', '523', '523', '523', '482', '477', '496', '487', '496', '534', '524', '466', '478', '504', '476', '519', '496', '482', '497', '464', '493', '526', '568', '475', '553', '507', '522', '480', '553', '482', '463', '496', '526', '519', '496', '498', '475', '498', '507', '481', '482', '481', '529', '523', '502', '503', '471', '478', '518', '482', '483', '494', '432', '494', '464', '482', '483', '524', '525', '503', '495', '476', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '518', '482', '483', '494', '432', '494', '464', '482', '488', '482', '477', '463', '496', '524', '524', '481', '500', '492', '476', '497', '507', '499', '480', '476', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '521', '486', '479', '494', '506', '521', '520', '501', '505', '479', '505', '506', '481', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '463', '496', '518', '572', '482', '483', '488', '488', '488', '520', '488', '537', '530', '497', '512', '479', '470', '510', '518', '463', '505', '479', '523', '493', '493', '493', '477', '464', '496']
2021-12-13 17:07:44,558 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 17:07:44,558 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 17:07:44,558 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 514 490 486 464 496 529 564 487 540 497 516 482 530 519 544 482 512 549 489 451 497 517 497 506 463 482 477 510 537 494 463 490 480 495 523 523 523 482 477 496 487 496 534 524 466 478 504 476 519 496 482 497 464 493 526 568 475 553 507 522 480 553 482 463 496 526 519 496 498 475 498 507 481 482 481 529 523 502 503 471 478 518 482 483 494 432 494 464 482 483 524 525 503 495 476 463 496 524 524 482 500 492 476 477 490 514 504 518 482 483 494 432 494 464 482 488 482 477 463 496 524 524 481 500 492 476 497 507 499 480 476 463 496 524 524 482 500 492 476 477 490 514 504 521 486 479 494 506 521 520 501 505 479 505 506 481 533 520 468 481 507 509 484 509 511 481 463 496 518 482 483 494 432 494 464 482 483 463 496 518 572 482 483 488 488 488 520 488 537 530 497 512 479 470 510 518 463 505 479 523 493 493 493 477 464 496
2021-12-13 17:07:44,558 - INFO - joeynmt.training - Example #3
2021-12-13 17:07:44,558 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 17:07:44,558 - DEBUG - joeynmt.training - 	Raw hypothesis: ['520', '535', '480', '465', '480', '505', '505', '505', '505', '520']
2021-12-13 17:07:44,558 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 17:07:44,558 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 17:07:44,558 - INFO - joeynmt.training - 	Hypothesis: 520 535 480 465 480 505 505 505 505 520
2021-12-13 17:07:44,558 - INFO - joeynmt.training - Example #6
2021-12-13 17:07:44,558 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 17:07:44,558 - DEBUG - joeynmt.training - 	Raw hypothesis: ['508', '520', '493', '480', '493', '505']
2021-12-13 17:07:44,559 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 17:07:44,559 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 17:07:44,559 - INFO - joeynmt.training - 	Hypothesis: 508 520 493 480 493 505
2021-12-13 17:07:44,559 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    60000: token_accuracy:   9.07, loss: 86881.2188, ppl:   9.6233, duration: 159.5339s
2021-12-13 17:08:47,359 - INFO - joeynmt.training - Epoch  11, Step:    60500, Batch Loss:     2.242889, Tokens per Sec:     5484, Lr: 0.000100
2021-12-13 17:09:50,138 - INFO - joeynmt.training - Epoch  11, Step:    61000, Batch Loss:     2.601672, Tokens per Sec:     5332, Lr: 0.000100
2021-12-13 17:10:53,383 - INFO - joeynmt.training - Epoch  11, Step:    61500, Batch Loss:     2.662070, Tokens per Sec:     5434, Lr: 0.000100
2021-12-13 17:11:56,167 - INFO - joeynmt.training - Epoch  11, Step:    62000, Batch Loss:     2.332614, Tokens per Sec:     5359, Lr: 0.000100
2021-12-13 17:12:59,633 - INFO - joeynmt.training - Epoch  11, Step:    62500, Batch Loss:     2.213178, Tokens per Sec:     5363, Lr: 0.000100
2021-12-13 17:14:02,623 - INFO - joeynmt.training - Epoch  11, Step:    63000, Batch Loss:     2.628527, Tokens per Sec:     5400, Lr: 0.000100
2021-12-13 17:15:05,664 - INFO - joeynmt.training - Epoch  11, Step:    63500, Batch Loss:     2.565455, Tokens per Sec:     5319, Lr: 0.000100
2021-12-13 17:15:15,565 - INFO - joeynmt.training - Epoch  11: total training loss 13504.49
2021-12-13 17:15:15,565 - INFO - joeynmt.training - EPOCH 12
2021-12-13 17:16:08,645 - INFO - joeynmt.training - Epoch  12, Step:    64000, Batch Loss:     2.416672, Tokens per Sec:     5440, Lr: 0.000100
2021-12-13 17:17:11,053 - INFO - joeynmt.training - Epoch  12, Step:    64500, Batch Loss:     2.300372, Tokens per Sec:     5387, Lr: 0.000100
2021-12-13 17:18:14,216 - INFO - joeynmt.training - Epoch  12, Step:    65000, Batch Loss:     1.859239, Tokens per Sec:     5303, Lr: 0.000100
2021-12-13 17:20:50,932 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 17:20:51,820 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/55000.ckpt
2021-12-13 17:20:51,821 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/55000.ckpt
2021-12-13 17:20:51,821 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/55000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/55000.ckpt')
2021-12-13 17:20:51,862 - INFO - joeynmt.training - Example #0
2021-12-13 17:20:51,862 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 17:20:51,863 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '515', '474', '485', '505', '487', '464', '496', '521', '574', '489', '553', '479', '536', '479', '536', '479', '517', '479', '483', '511', '515', '490', '485', '463', '496', '521', '533', '469', '510', '479', '467', '479', '467', '524', '525', '503', '495', '476', '476', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '507', '453', '514', '453', '490', '527', '487', '501', '498', '474', '493', '521', '527', '479', '473', '479', '473', '479', '483', '479', '507', '453', '514', '555', '493', '445', '493', '468', '493', '493', '493', '493', '493', '493', '493', '493', '528', '464', '496', '521', '574', '479', '517', '479', '483', '524', '481', '500', '491', '476', '514', '504', '487', '484', '487', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '523', '520', '499', '492', '500', '491', '478', '480', '463', '496', '521', '574', '475', '553', '454', '553', '454', '553', '486', '536', '461', '536', '479', '517', '479', '483', '523', '531', '501', '477', '501', '501', '501', '477', '470', '464', '493', '521', '534', '475', '510', '479', '466', '479', '466', '524', '518', '477', '490', '503', '488', '509', '483', '464', '493', '521', '527', '479', '473', '479', '473', '479', '473', '514', '454', '490', '523', '520', '499', '492', '500', '491', '478', '480', '527', '550', '513', '518', '493', '526', '482', '476', '527', '531', '473', '469', '473', '469', '497', '504', '504', '504', '504', '504', '504', '464', '496']
2021-12-13 17:20:51,863 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 17:20:51,863 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 17:20:51,863 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 574 489 553 479 536 479 536 479 517 479 483 511 515 490 485 463 496 521 533 469 510 479 467 479 467 524 525 503 495 476 476 463 496 521 527 479 473 479 473 479 473 507 453 514 453 490 527 487 501 498 474 493 521 527 479 473 479 473 479 483 479 507 453 514 555 493 445 493 468 493 493 493 493 493 493 493 493 528 464 496 521 574 479 517 479 483 524 481 500 491 476 514 504 487 484 487 529 538 472 513 498 462 514 497 471 478 523 520 499 492 500 491 478 480 463 496 521 574 475 553 454 553 454 553 486 536 461 536 479 517 479 483 523 531 501 477 501 501 501 477 470 464 493 521 534 475 510 479 466 479 466 524 518 477 490 503 488 509 483 464 493 521 527 479 473 479 473 479 473 514 454 490 523 520 499 492 500 491 478 480 527 550 513 518 493 526 482 476 527 531 473 469 473 469 497 504 504 504 504 504 504 464 496
2021-12-13 17:20:51,863 - INFO - joeynmt.training - Example #1
2021-12-13 17:20:51,863 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 17:20:51,863 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '492', '470', '492', '470']
2021-12-13 17:20:51,863 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 17:20:51,863 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 17:20:51,863 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 492 470 492 470
2021-12-13 17:20:51,864 - INFO - joeynmt.training - Example #2
2021-12-13 17:20:51,864 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 17:20:51,864 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '514', '490', '486', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '512', '537', '489', '463', '490', '480', '495', '505', '490', '522', '570', '482', '477', '497', '539', '488', '539', '488', '539', '523', '482', '477', '518', '462', '538', '527', '513', '518', '493', '526', '482', '474', '503', '511', '504', '475', '464', '493', '526', '569', '496', '548', '474', '548', '506', '522', '480', '522', '482', '483', '463', '496', '524', '481', '500', '491', '476', '500', '491', '476', '527', '522', '504', '479', '474', '481', '483', '513', '509', '490', '479', '518', '543', '492', '512', '482', '483', '467', '518', '504', '463', '496', '524', '481', '500', '491', '476', '497', '507', '499', '480', '518', '482', '483', '494', '432', '494', '464', '482', '488', '496', '518', '576', '489', '532', '490', '532', '490', '532', '490', '532', '482', '488', '482', '477', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '521', '486', '479', '494', '506', '521', '550', '480', '506', '495', '450', '498', '527', '479', '470', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '541', '542', '482', '483', '486', '512', '521', '501', '463', '496', '518', '576', '482', '483', '486', '512', '485', '566', '494', '549', '482', '477', '464', '496']
2021-12-13 17:20:51,864 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 17:20:51,864 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 17:20:51,864 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 514 490 486 464 496 529 564 487 540 497 516 482 530 519 544 482 512 537 489 463 490 480 495 505 490 522 570 482 477 497 539 488 539 488 539 523 482 477 518 462 538 527 513 518 493 526 482 474 503 511 504 475 464 493 526 569 496 548 474 548 506 522 480 522 482 483 463 496 524 481 500 491 476 500 491 476 527 522 504 479 474 481 483 513 509 490 479 518 543 492 512 482 483 467 518 504 463 496 524 481 500 491 476 497 507 499 480 518 482 483 494 432 494 464 482 488 496 518 576 489 532 490 532 490 532 490 532 482 488 482 477 463 496 524 524 482 500 492 476 477 490 514 504 521 486 479 494 506 521 550 480 506 495 450 498 527 479 470 533 520 468 481 507 509 484 509 511 481 541 542 482 483 486 512 521 501 463 496 518 576 482 483 486 512 485 566 494 549 482 477 464 496
2021-12-13 17:20:51,864 - INFO - joeynmt.training - Example #3
2021-12-13 17:20:51,864 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 17:20:51,864 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '541', '482', '459', '497', '492', '492', '492', '526', '492']
2021-12-13 17:20:51,864 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 17:20:51,865 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 17:20:51,865 - INFO - joeynmt.training - 	Hypothesis: 518 541 482 459 497 492 492 492 526 492
2021-12-13 17:20:51,865 - INFO - joeynmt.training - Example #6
2021-12-13 17:20:51,865 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 17:20:51,865 - DEBUG - joeynmt.training - 	Raw hypothesis: ['513', '520', '487', '480', '488', '505']
2021-12-13 17:20:51,865 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 17:20:51,865 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 17:20:51,865 - INFO - joeynmt.training - 	Hypothesis: 513 520 487 480 488 505
2021-12-13 17:20:51,865 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    65000: token_accuracy:   9.31, loss: 85162.0703, ppl:   9.2016, duration: 157.6490s
2021-12-13 17:21:55,609 - INFO - joeynmt.training - Epoch  12, Step:    65500, Batch Loss:     2.267055, Tokens per Sec:     5350, Lr: 0.000100
2021-12-13 17:22:58,275 - INFO - joeynmt.training - Epoch  12, Step:    66000, Batch Loss:     2.182807, Tokens per Sec:     5364, Lr: 0.000100
2021-12-13 17:24:00,706 - INFO - joeynmt.training - Epoch  12, Step:    66500, Batch Loss:     2.136842, Tokens per Sec:     5380, Lr: 0.000100
2021-12-13 17:25:04,341 - INFO - joeynmt.training - Epoch  12, Step:    67000, Batch Loss:     2.178410, Tokens per Sec:     5403, Lr: 0.000100
2021-12-13 17:26:06,918 - INFO - joeynmt.training - Epoch  12, Step:    67500, Batch Loss:     2.030383, Tokens per Sec:     5394, Lr: 0.000100
2021-12-13 17:27:10,054 - INFO - joeynmt.training - Epoch  12, Step:    68000, Batch Loss:     2.752862, Tokens per Sec:     5441, Lr: 0.000100
2021-12-13 17:28:12,610 - INFO - joeynmt.training - Epoch  12, Step:    68500, Batch Loss:     2.321839, Tokens per Sec:     5332, Lr: 0.000100
2021-12-13 17:29:15,417 - INFO - joeynmt.training - Epoch  12, Step:    69000, Batch Loss:     2.614826, Tokens per Sec:     5383, Lr: 0.000100
2021-12-13 17:30:01,245 - INFO - joeynmt.training - Epoch  12: total training loss 13295.59
2021-12-13 17:30:01,245 - INFO - joeynmt.training - EPOCH 13
2021-12-13 17:30:18,455 - INFO - joeynmt.training - Epoch  13, Step:    69500, Batch Loss:     2.205284, Tokens per Sec:     5222, Lr: 0.000100
2021-12-13 17:31:21,794 - INFO - joeynmt.training - Epoch  13, Step:    70000, Batch Loss:     1.815276, Tokens per Sec:     5363, Lr: 0.000100
2021-12-13 17:33:59,031 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 17:33:59,915 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/65000.ckpt
2021-12-13 17:33:59,915 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/65000.ckpt
2021-12-13 17:33:59,916 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/65000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/65000.ckpt')
2021-12-13 17:33:59,970 - INFO - joeynmt.training - Example #0
2021-12-13 17:33:59,971 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 17:33:59,971 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '515', '474', '485', '505', '487', '464', '496', '521', '574', '475', '553', '479', '536', '479', '536', '479', '517', '479', '483', '508', '515', '493', '485', '463', '496', '521', '534', '469', '493', '479', '466', '479', '466', '521', '517', '480', '506', '491', '483', '522', '527', '479', '473', '478', '497', '497', '497', '463', '496', '521', '587', '479', '483', '479', '483', '479', '516', '479', '516', '479', '495', '498', '485', '521', '529', '484', '472', '480', '503', '471', '519', '553', '498', '465', '498', '488', '481', '447', '483', '508', '492', '527', '464', '496', '521', '574', '479', '483', '479', '516', '515', '511', '485', '490', '518', '525', '482', '476', '495', '501', '502', '476', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '522', '478', '478', '492', '504', '479', '463', '496', '521', '574', '475', '553', '454', '553', '454', '553', '454', '553', '486', '536', '461', '536', '479', '517', '479', '483', '523', '531', '477', '501', '501', '501', '501', '477', '470', '520', '517', '481', '506', '490', '483', '464', '493', '521', '527', '479', '474', '479', '483', '479', '507', '453', '514', '454', '490', '523', '520', '499', '492', '500', '491', '478', '480', '518', '482', '483', '494', '432', '494', '464', '482', '483', '523', '520', '499', '492', '500', '491', '478', '480', '544', '565', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '518', '509', '509', '518', '509', '464', '496']
2021-12-13 17:33:59,971 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 17:33:59,971 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 17:33:59,971 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 574 475 553 479 536 479 536 479 517 479 483 508 515 493 485 463 496 521 534 469 493 479 466 479 466 521 517 480 506 491 483 522 527 479 473 478 497 497 497 463 496 521 587 479 483 479 483 479 516 479 516 479 495 498 485 521 529 484 472 480 503 471 519 553 498 465 498 488 481 447 483 508 492 527 464 496 521 574 479 483 479 516 515 511 485 490 518 525 482 476 495 501 502 476 529 538 472 513 498 462 514 497 471 478 522 478 478 492 504 479 463 496 521 574 475 553 454 553 454 553 454 553 486 536 461 536 479 517 479 483 523 531 477 501 501 501 501 477 470 520 517 481 506 490 483 464 493 521 527 479 474 479 483 479 507 453 514 454 490 523 520 499 492 500 491 478 480 518 482 483 494 432 494 464 482 483 523 520 499 492 500 491 478 480 544 565 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 518 509 509 518 509 464 496
2021-12-13 17:33:59,972 - INFO - joeynmt.training - Example #1
2021-12-13 17:33:59,972 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 17:33:59,972 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '543', '482', '483', '493', '520', '493', '520']
2021-12-13 17:33:59,972 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 17:33:59,972 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 17:33:59,972 - INFO - joeynmt.training - 	Hypothesis: 518 543 482 483 493 520 493 520
2021-12-13 17:33:59,972 - INFO - joeynmt.training - Example #2
2021-12-13 17:33:59,973 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 17:33:59,973 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '511', '514', '490', '486', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '510', '537', '494', '463', '490', '480', '495', '505', '490', '522', '543', '482', '477', '486', '521', '517', '480', '506', '491', '483', '540', '520', '519', '490', '482', '477', '518', '462', '534', '524', '466', '478', '504', '476', '519', '496', '482', '497', '464', '493', '526', '574', '496', '553', '474', '553', '507', '522', '482', '483', '463', '496', '526', '519', '496', '498', '475', '498', '507', '481', '482', '481', '529', '523', '480', '503', '473', '477', '501', '489', '518', '543', '492', '512', '482', '483', '467', '518', '504', '518', '531', '486', '469', '493', '504', '483', '493', '508', '463', '496', '518', '576', '489', '530', '490', '530', '490', '530', '490', '530', '482', '488', '482', '477', '520', '529', '481', '499', '494', '472', '495', '505', '495', '518', '506', '510', '463', '496', '528', '587', '486', '548', '486', '548', '482', '488', '482', '477', '521', '508', '501', '493', '479', '493', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '541', '482', '486', '511', '521', '501', '520', '501', '505', '483', '481', '463', '496', '518', '543', '492', '512', '482', '483', '467', '518', '463', '496', '523', '531', '499', '504', '477', '501', '502', '470', '464', '496']
2021-12-13 17:33:59,973 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 17:33:59,973 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 17:33:59,973 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 511 514 490 486 464 496 529 564 487 540 497 516 482 530 519 544 482 510 537 494 463 490 480 495 505 490 522 543 482 477 486 521 517 480 506 491 483 540 520 519 490 482 477 518 462 534 524 466 478 504 476 519 496 482 497 464 493 526 574 496 553 474 553 507 522 482 483 463 496 526 519 496 498 475 498 507 481 482 481 529 523 480 503 473 477 501 489 518 543 492 512 482 483 467 518 504 518 531 486 469 493 504 483 493 508 463 496 518 576 489 530 490 530 490 530 490 530 482 488 482 477 520 529 481 499 494 472 495 505 495 518 506 510 463 496 528 587 486 548 486 548 482 488 482 477 521 508 501 493 479 493 533 520 468 481 507 509 484 509 511 481 541 482 486 511 521 501 520 501 505 483 481 463 496 518 543 492 512 482 483 467 518 463 496 523 531 499 504 477 501 502 470 464 496
2021-12-13 17:33:59,973 - INFO - joeynmt.training - Example #3
2021-12-13 17:33:59,973 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 17:33:59,974 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '541', '482', '459', '482', '482', '493', '522', '492', '492']
2021-12-13 17:33:59,974 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 17:33:59,974 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 17:33:59,974 - INFO - joeynmt.training - 	Hypothesis: 518 541 482 459 482 482 493 522 492 492
2021-12-13 17:33:59,974 - INFO - joeynmt.training - Example #6
2021-12-13 17:33:59,974 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 17:33:59,974 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '503', '482']
2021-12-13 17:33:59,974 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 17:33:59,975 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 17:33:59,975 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 503 482
2021-12-13 17:33:59,975 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    70000: token_accuracy:   9.85, loss: 83643.9922, ppl:   8.8447, duration: 158.1798s
2021-12-13 17:35:02,826 - INFO - joeynmt.training - Epoch  13, Step:    70500, Batch Loss:     1.916482, Tokens per Sec:     5454, Lr: 0.000100
2021-12-13 17:36:06,101 - INFO - joeynmt.training - Epoch  13, Step:    71000, Batch Loss:     1.966678, Tokens per Sec:     5300, Lr: 0.000100
2021-12-13 17:37:09,144 - INFO - joeynmt.training - Epoch  13, Step:    71500, Batch Loss:     2.324158, Tokens per Sec:     5388, Lr: 0.000100
2021-12-13 17:38:11,857 - INFO - joeynmt.training - Epoch  13, Step:    72000, Batch Loss:     2.005264, Tokens per Sec:     5284, Lr: 0.000100
2021-12-13 17:39:14,634 - INFO - joeynmt.training - Epoch  13, Step:    72500, Batch Loss:     2.136653, Tokens per Sec:     5387, Lr: 0.000100
2021-12-13 17:40:17,279 - INFO - joeynmt.training - Epoch  13, Step:    73000, Batch Loss:     2.670505, Tokens per Sec:     5387, Lr: 0.000100
2021-12-13 17:41:20,200 - INFO - joeynmt.training - Epoch  13, Step:    73500, Batch Loss:     2.442272, Tokens per Sec:     5385, Lr: 0.000100
2021-12-13 17:42:23,027 - INFO - joeynmt.training - Epoch  13, Step:    74000, Batch Loss:     2.304668, Tokens per Sec:     5423, Lr: 0.000100
2021-12-13 17:43:25,833 - INFO - joeynmt.training - Epoch  13, Step:    74500, Batch Loss:     2.177081, Tokens per Sec:     5498, Lr: 0.000100
2021-12-13 17:44:28,581 - INFO - joeynmt.training - Epoch  13, Step:    75000, Batch Loss:     2.047796, Tokens per Sec:     5508, Lr: 0.000100
2021-12-13 17:47:07,929 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 17:47:08,798 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/70000.ckpt
2021-12-13 17:47:08,799 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/70000.ckpt
2021-12-13 17:47:08,799 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/70000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/70000.ckpt')
2021-12-13 17:47:08,841 - INFO - joeynmt.training - Example #0
2021-12-13 17:47:08,842 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 17:47:08,842 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '474', '485', '505', '487', '464', '496', '521', '585', '488', '538', '488', '538', '488', '573', '479', '516', '479', '482', '508', '515', '493', '485', '463', '496', '521', '527', '479', '473', '479', '473', '514', '453', '490', '523', '531', '477', '501', '501', '501', '501', '477', '470', '463', '496', '521', '527', '479', '473', '479', '473', '479', '473', '514', '453', '490', '527', '522', '504', '479', '474', '481', '483', '513', '509', '490', '479', '518', '581', '497', '421', '497', '459', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '527', '497', '561', '482', '464', '496', '521', '574', '479', '516', '479', '483', '519', '519', '482', '482', '498', '497', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '521', '479', '480', '506', '493', '463', '496', '521', '532', '469', '510', '501', '479', '468', '515', '511', '485', '490', '463', '496', '521', '532', '469', '510', '479', '468', '521', '527', '479', '473', '479', '473', '479', '473', '514', '454', '490', '464', '493', '521', '527', '479', '473', '479', '473', '514', '454', '490', '464', '493', '521', '527', '479', '473', '479', '473', '479', '483', '479', '507', '453', '514', '520', '493', '505', '487', '481', '521', '520', '501', '505', '479', '505', '479', '505', '480', '540', '570', '460', '460', '460', '460', '460', '460', '460', '460', '460', '471', '471', '471', '471', '471', '508', '474', '508', '474', '508', '474', '543', '471', '545', '464', '496']
2021-12-13 17:47:08,842 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 17:47:08,842 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 17:47:08,842 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 474 485 505 487 464 496 521 585 488 538 488 538 488 573 479 516 479 482 508 515 493 485 463 496 521 527 479 473 479 473 514 453 490 523 531 477 501 501 501 501 477 470 463 496 521 527 479 473 479 473 479 473 514 453 490 527 522 504 479 474 481 483 513 509 490 479 518 581 497 421 497 459 497 497 497 497 497 497 497 497 497 497 497 527 497 561 482 464 496 521 574 479 516 479 483 519 519 482 482 498 497 529 538 472 513 498 462 514 497 471 478 521 479 480 506 493 463 496 521 532 469 510 501 479 468 515 511 485 490 463 496 521 532 469 510 479 468 521 527 479 473 479 473 479 473 514 454 490 464 493 521 527 479 473 479 473 514 454 490 464 493 521 527 479 473 479 473 479 483 479 507 453 514 520 493 505 487 481 521 520 501 505 479 505 479 505 480 540 570 460 460 460 460 460 460 460 460 460 471 471 471 471 471 508 474 508 474 508 474 543 471 545 464 496
2021-12-13 17:47:08,842 - INFO - joeynmt.training - Example #1
2021-12-13 17:47:08,843 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 17:47:08,843 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '543', '482', '483', '493', '520', '493', '520']
2021-12-13 17:47:08,843 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 17:47:08,843 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 17:47:08,843 - INFO - joeynmt.training - 	Hypothesis: 518 543 482 483 493 520 493 520
2021-12-13 17:47:08,843 - INFO - joeynmt.training - Example #2
2021-12-13 17:47:08,843 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 17:47:08,844 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '508', '515', '493', '485', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '510', '537', '494', '463', '490', '480', '495', '505', '490', '522', '570', '482', '477', '520', '493', '537', '488', '543', '482', '477', '518', '490', '523', '482', '488', '522', '534', '524', '466', '478', '504', '476', '519', '496', '482', '497', '464', '493', '526', '574', '475', '553', '507', '522', '475', '522', '482', '483', '463', '496', '526', '519', '496', '498', '475', '498', '507', '481', '482', '481', '524', '525', '503', '495', '476', '476', '518', '543', '492', '512', '482', '483', '467', '518', '526', '520', '496', '480', '475', '486', '497', '500', '463', '496', '524', '524', '482', '500', '492', '476', '477', '490', '514', '504', '518', '489', '496', '503', '482', '521', '498', '489', '496', '524', '481', '500', '492', '476', '497', '463', '496', '528', '524', '473', '477', '498', '510', '490', '477', '485', '511', '518', '511', '521', '520', '501', '505', '479', '505', '488', '481', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '523', '520', '499', '492', '500', '491', '478', '480', '535', '536', '482', '505', '520', '487', '511', '463', '496', '518', '482', '483', '494', '432', '494', '464', '482', '483', '537', '523', '479', '478', '516', '478', '502', '496', '464', '495']
2021-12-13 17:47:08,844 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 17:47:08,844 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 17:47:08,844 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 508 515 493 485 464 496 529 564 487 540 497 516 482 530 519 544 482 510 537 494 463 490 480 495 505 490 522 570 482 477 520 493 537 488 543 482 477 518 490 523 482 488 522 534 524 466 478 504 476 519 496 482 497 464 493 526 574 475 553 507 522 475 522 482 483 463 496 526 519 496 498 475 498 507 481 482 481 524 525 503 495 476 476 518 543 492 512 482 483 467 518 526 520 496 480 475 486 497 500 463 496 524 524 482 500 492 476 477 490 514 504 518 489 496 503 482 521 498 489 496 524 481 500 492 476 497 463 496 528 524 473 477 498 510 490 477 485 511 518 511 521 520 501 505 479 505 488 481 533 520 468 481 507 509 484 509 511 481 523 520 499 492 500 491 478 480 535 536 482 505 520 487 511 463 496 518 482 483 494 432 494 464 482 483 537 523 479 478 516 478 502 496 464 495
2021-12-13 17:47:08,844 - INFO - joeynmt.training - Example #3
2021-12-13 17:47:08,844 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 17:47:08,844 - DEBUG - joeynmt.training - 	Raw hypothesis: ['520', '535', '480', '465', '480', '505', '505', '505', '493', '521']
2021-12-13 17:47:08,844 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 17:47:08,845 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 17:47:08,845 - INFO - joeynmt.training - 	Hypothesis: 520 535 480 465 480 505 505 505 493 521
2021-12-13 17:47:08,845 - INFO - joeynmt.training - Example #6
2021-12-13 17:47:08,845 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 17:47:08,845 - DEBUG - joeynmt.training - 	Raw hypothesis: ['513', '520', '487', '480', '488', '505']
2021-12-13 17:47:08,845 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 17:47:08,845 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 17:47:08,845 - INFO - joeynmt.training - 	Hypothesis: 513 520 487 480 488 505
2021-12-13 17:47:08,846 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    75000: token_accuracy:  10.49, loss: 82310.2266, ppl:   8.5426, duration: 160.2640s
2021-12-13 17:47:25,770 - INFO - joeynmt.training - Epoch  13: total training loss 13017.49
2021-12-13 17:47:25,771 - INFO - joeynmt.training - EPOCH 14
2021-12-13 17:48:11,743 - INFO - joeynmt.training - Epoch  14, Step:    75500, Batch Loss:     2.367442, Tokens per Sec:     5319, Lr: 0.000100
2021-12-13 17:49:14,920 - INFO - joeynmt.training - Epoch  14, Step:    76000, Batch Loss:     2.053118, Tokens per Sec:     5386, Lr: 0.000100
2021-12-13 17:50:17,486 - INFO - joeynmt.training - Epoch  14, Step:    76500, Batch Loss:     2.199537, Tokens per Sec:     5473, Lr: 0.000100
2021-12-13 17:51:20,907 - INFO - joeynmt.training - Epoch  14, Step:    77000, Batch Loss:     1.817957, Tokens per Sec:     5320, Lr: 0.000100
2021-12-13 17:52:24,020 - INFO - joeynmt.training - Epoch  14, Step:    77500, Batch Loss:     1.960900, Tokens per Sec:     5374, Lr: 0.000100
2021-12-13 17:53:27,068 - INFO - joeynmt.training - Epoch  14, Step:    78000, Batch Loss:     2.587669, Tokens per Sec:     5380, Lr: 0.000100
2021-12-13 17:54:29,914 - INFO - joeynmt.training - Epoch  14, Step:    78500, Batch Loss:     1.859636, Tokens per Sec:     5418, Lr: 0.000100
2021-12-13 17:55:32,991 - INFO - joeynmt.training - Epoch  14, Step:    79000, Batch Loss:     2.311564, Tokens per Sec:     5349, Lr: 0.000100
2021-12-13 17:56:36,325 - INFO - joeynmt.training - Epoch  14, Step:    79500, Batch Loss:     1.969092, Tokens per Sec:     5347, Lr: 0.000100
2021-12-13 17:57:39,249 - INFO - joeynmt.training - Epoch  14, Step:    80000, Batch Loss:     2.270575, Tokens per Sec:     5466, Lr: 0.000100
2021-12-13 18:00:17,252 - INFO - joeynmt.training - Example #0
2021-12-13 18:00:17,252 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 18:00:17,252 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '474', '485', '505', '487', '464', '496', '521', '585', '469', '538', '479', '538', '479', '537', '479', '517', '479', '483', '508', '515', '493', '485', '463', '496', '521', '533', '469', '510', '479', '467', '479', '467', '521', '527', '479', '473', '479', '473', '497', '497', '497', '463', '496', '521', '581', '479', '418', '479', '432', '480', '459', '480', '459', '480', '479', '479', '494', '507', '494', '527', '522', '504', '479', '474', '481', '483', '513', '509', '490', '479', '518', '579', '497', '421', '497', '459', '497', '472', '497', '497', '497', '497', '497', '497', '497', '497', '497', '497', '525', '497', '559', '482', '464', '496', '521', '574', '469', '553', '479', '517', '479', '483', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '521', '527', '479', '473', '479', '473', '497', '506', '497', '463', '496', '521', '533', '469', '510', '454', '508', '479', '467', '515', '493', '485', '523', '531', '477', '501', '501', '501', '501', '501', '477', '470', '516', '523', '484', '493', '487', '478', '464', '493', '521', '533', '469', '510', '479', '467', '479', '467', '519', '523', '499', '477', '482', '495', '487', '496', '464', '493', '521', '527', '479', '474', '479', '483', '479', '507', '453', '514', '454', '490', '527', '487', '473', '473', '473', '473', '473', '505', '512', '512', '546', '546', '454', '454', '454', '454', '454', '454', '454', '454', '454', '454', '454', '454', '454', '517', '517', '517', '517', '517', '517', '517', '517', '517', '517', '517', '517', '517', '517', '483', '487', '484', '464', '496']
2021-12-13 18:00:17,252 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 18:00:17,252 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 18:00:17,253 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 474 485 505 487 464 496 521 585 469 538 479 538 479 537 479 517 479 483 508 515 493 485 463 496 521 533 469 510 479 467 479 467 521 527 479 473 479 473 497 497 497 463 496 521 581 479 418 479 432 480 459 480 459 480 479 479 494 507 494 527 522 504 479 474 481 483 513 509 490 479 518 579 497 421 497 459 497 472 497 497 497 497 497 497 497 497 497 497 525 497 559 482 464 496 521 574 469 553 479 517 479 483 529 538 472 513 498 462 514 497 471 478 521 527 479 473 479 473 497 506 497 463 496 521 533 469 510 454 508 479 467 515 493 485 523 531 477 501 501 501 501 501 477 470 516 523 484 493 487 478 464 493 521 533 469 510 479 467 479 467 519 523 499 477 482 495 487 496 464 493 521 527 479 474 479 483 479 507 453 514 454 490 527 487 473 473 473 473 473 505 512 512 546 546 454 454 454 454 454 454 454 454 454 454 454 454 454 517 517 517 517 517 517 517 517 517 517 517 517 517 517 483 487 484 464 496
2021-12-13 18:00:17,253 - INFO - joeynmt.training - Example #1
2021-12-13 18:00:17,253 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 18:00:17,253 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '548', '482', '483', '493', '520', '494', '520']
2021-12-13 18:00:17,253 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 18:00:17,253 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 18:00:17,253 - INFO - joeynmt.training - 	Hypothesis: 518 548 482 483 493 520 494 520
2021-12-13 18:00:17,253 - INFO - joeynmt.training - Example #2
2021-12-13 18:00:17,253 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 18:00:17,253 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '508', '515', '493', '485', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '510', '537', '494', '463', '490', '480', '495', '505', '490', '522', '548', '482', '477', '521', '517', '480', '506', '491', '483', '518', '543', '492', '512', '482', '483', '467', '518', '531', '530', '508', '470', '470', '470', '470', '485', '519', '504', '519', '486', '487', '504', '486', '502', '501', '484', '501', '464', '493', '526', '569', '496', '534', '475', '534', '508', '519', '480', '519', '482', '482', '463', '496', '524', '524', '481', '500', '491', '476', '477', '490', '514', '504', '518', '527', '487', '512', '493', '474', '484', '485', '519', '526', '481', '496', '497', '496', '497', '496', '494', '475', '463', '496', '518', '576', '483', '530', '487', '552', '489', '552', '489', '531', '482', '488', '482', '477', '463', '496', '524', '524', '481', '500', '492', '476', '477', '490', '514', '504', '521', '486', '479', '494', '506', '521', '520', '501', '505', '479', '505', '487', '481', '522', '508', '502', '493', '479', '493', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '541', '482', '486', '512', '521', '501', '463', '496', '518', '543', '492', '512', '482', '483', '467', '518', '463', '496', '518', '523', '483', '493', '488', '477', '464', '496']
2021-12-13 18:00:17,253 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 18:00:17,253 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 18:00:17,253 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 508 515 493 485 464 496 529 564 487 540 497 516 482 530 519 544 482 510 537 494 463 490 480 495 505 490 522 548 482 477 521 517 480 506 491 483 518 543 492 512 482 483 467 518 531 530 508 470 470 470 470 485 519 504 519 486 487 504 486 502 501 484 501 464 493 526 569 496 534 475 534 508 519 480 519 482 482 463 496 524 524 481 500 491 476 477 490 514 504 518 527 487 512 493 474 484 485 519 526 481 496 497 496 497 496 494 475 463 496 518 576 483 530 487 552 489 552 489 531 482 488 482 477 463 496 524 524 481 500 492 476 477 490 514 504 521 486 479 494 506 521 520 501 505 479 505 487 481 522 508 502 493 479 493 533 520 468 481 507 509 484 509 511 481 541 482 486 512 521 501 463 496 518 543 492 512 482 483 467 518 463 496 518 523 483 493 488 477 464 496
2021-12-13 18:00:17,253 - INFO - joeynmt.training - Example #3
2021-12-13 18:00:17,254 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 18:00:17,254 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '541', '487', '459', '486', '493', '493', '493', '526']
2021-12-13 18:00:17,254 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 18:00:17,254 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 18:00:17,254 - INFO - joeynmt.training - 	Hypothesis: 514 541 487 459 486 493 493 493 526
2021-12-13 18:00:17,254 - INFO - joeynmt.training - Example #6
2021-12-13 18:00:17,254 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 18:00:17,254 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '521', '486', '479', '494', '506']
2021-12-13 18:00:17,254 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 18:00:17,254 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 18:00:17,254 - INFO - joeynmt.training - 	Hypothesis: 514 521 486 479 494 506
2021-12-13 18:00:17,254 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    80000: token_accuracy:  10.48, loss: 81676.0391, ppl:   8.4025, duration: 158.0050s
2021-12-13 18:01:20,238 - INFO - joeynmt.training - Epoch  14, Step:    80500, Batch Loss:     1.748850, Tokens per Sec:     5401, Lr: 0.000100
2021-12-13 18:02:10,895 - INFO - joeynmt.training - Epoch  14: total training loss 12796.59
2021-12-13 18:02:10,895 - INFO - joeynmt.training - EPOCH 15
2021-12-13 18:02:23,266 - INFO - joeynmt.training - Epoch  15, Step:    81000, Batch Loss:     1.763695, Tokens per Sec:     5381, Lr: 0.000100
2021-12-13 18:03:25,834 - INFO - joeynmt.training - Epoch  15, Step:    81500, Batch Loss:     1.835261, Tokens per Sec:     5375, Lr: 0.000100
2021-12-13 18:04:28,302 - INFO - joeynmt.training - Epoch  15, Step:    82000, Batch Loss:     2.304653, Tokens per Sec:     5440, Lr: 0.000100
2021-12-13 18:05:31,154 - INFO - joeynmt.training - Epoch  15, Step:    82500, Batch Loss:     1.777961, Tokens per Sec:     5350, Lr: 0.000100
2021-12-13 18:06:34,473 - INFO - joeynmt.training - Epoch  15, Step:    83000, Batch Loss:     2.355258, Tokens per Sec:     5419, Lr: 0.000100
2021-12-13 18:07:37,419 - INFO - joeynmt.training - Epoch  15, Step:    83500, Batch Loss:     2.523642, Tokens per Sec:     5398, Lr: 0.000100
2021-12-13 18:08:40,489 - INFO - joeynmt.training - Epoch  15, Step:    84000, Batch Loss:     2.449686, Tokens per Sec:     5385, Lr: 0.000100
2021-12-13 18:09:43,506 - INFO - joeynmt.training - Epoch  15, Step:    84500, Batch Loss:     2.072795, Tokens per Sec:     5338, Lr: 0.000100
2021-12-13 18:10:46,117 - INFO - joeynmt.training - Epoch  15, Step:    85000, Batch Loss:     2.467321, Tokens per Sec:     5421, Lr: 0.000100
2021-12-13 18:13:24,205 - INFO - joeynmt.training - Example #0
2021-12-13 18:13:24,205 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 18:13:24,205 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '515', '474', '485', '505', '487', '464', '496', '521', '585', '488', '538', '488', '538', '488', '571', '479', '516', '479', '483', '508', '515', '493', '485', '463', '496', '521', '533', '469', '510', '479', '467', '479', '467', '521', '524', '491', '509', '506', '476', '479', '477', '521', '529', '484', '471', '479', '488', '479', '502', '463', '496', '521', '527', '479', '473', '479', '483', '479', '483', '479', '507', '454', '514', '454', '490', '526', '522', '475', '483', '513', '509', '490', '479', '518', '581', '497', '421', '497', '452', '497', '472', '497', '497', '497', '497', '497', '497', '497', '497', '528', '482', '464', '496', '521', '574', '479', '517', '479', '483', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '521', '527', '479', '473', '479', '473', '479', '507', '453', '514', '515', '487', '504', '491', '486', '463', '496', '521', '574', '475', '553', '454', '553', '486', '536', '461', '536', '479', '517', '479', '483', '523', '531', '477', '501', '501', '501', '501', '501', '477', '470', '464', '493', '521', '527', '469', '497', '497', '497', '497', '497', '497', '497', '497', '479', '474', '524', '481', '500', '491', '476', '514', '504', '487', '484', '487', '544', '565', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '457', '517', '517', '517', '517', '517', '517', '517', '517', '537', '537', '527', '473', '473', '473', '473', '473', '473', '473', '497', '512', '464', '496']
2021-12-13 18:13:24,205 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 18:13:24,205 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 18:13:24,205 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 585 488 538 488 538 488 571 479 516 479 483 508 515 493 485 463 496 521 533 469 510 479 467 479 467 521 524 491 509 506 476 479 477 521 529 484 471 479 488 479 502 463 496 521 527 479 473 479 483 479 483 479 507 454 514 454 490 526 522 475 483 513 509 490 479 518 581 497 421 497 452 497 472 497 497 497 497 497 497 497 497 528 482 464 496 521 574 479 517 479 483 529 538 472 513 498 462 514 497 471 478 521 527 479 473 479 473 479 507 453 514 515 487 504 491 486 463 496 521 574 475 553 454 553 486 536 461 536 479 517 479 483 523 531 477 501 501 501 501 501 477 470 464 493 521 527 469 497 497 497 497 497 497 497 497 479 474 524 481 500 491 476 514 504 487 484 487 544 565 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 457 517 517 517 517 517 517 517 517 537 537 527 473 473 473 473 473 473 473 497 512 464 496
2021-12-13 18:13:24,206 - INFO - joeynmt.training - Example #1
2021-12-13 18:13:24,206 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 18:13:24,206 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '548', '482', '483', '493', '520', '494', '520']
2021-12-13 18:13:24,206 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 18:13:24,206 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 18:13:24,206 - INFO - joeynmt.training - 	Hypothesis: 518 548 482 483 493 520 494 520
2021-12-13 18:13:24,206 - INFO - joeynmt.training - Example #2
2021-12-13 18:13:24,206 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 18:13:24,206 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '508', '515', '493', '485', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '510', '537', '494', '463', '490', '480', '495', '505', '490', '522', '548', '482', '477', '521', '517', '480', '506', '491', '483', '541', '542', '482', '477', '486', '512', '521', '501', '529', '530', '510', '503', '470', '470', '485', '519', '486', '487', '504', '486', '502', '501', '464', '493', '529', '575', '502', '528', '481', '560', '503', '528', '470', '528', '482', '482', '463', '496', '524', '481', '500', '491', '476', '500', '491', '476', '540', '520', '519', '490', '482', '482', '518', '462', '524', '481', '500', '491', '476', '500', '491', '463', '496', '531', '568', '488', '544', '490', '544', '490', '544', '490', '544', '482', '488', '482', '477', '524', '481', '500', '491', '476', '500', '491', '476', '463', '496', '524', '524', '481', '500', '491', '476', '477', '490', '514', '504', '463', '496', '523', '596', '508', '533', '477', '568', '482', '488', '521', '508', '501', '493', '479', '493', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '541', '482', '486', '512', '521', '501', '521', '501', '493', '479', '518', '543', '492', '512', '482', '483', '467', '518', '463', '496', '518', '543', '492', '512', '482', '483', '467', '518', '534', '523', '466', '511', '477', '496', '507', '478', '464', '496']
2021-12-13 18:13:24,206 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 18:13:24,206 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 18:13:24,206 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 508 515 493 485 464 496 529 564 487 540 497 516 482 530 519 544 482 510 537 494 463 490 480 495 505 490 522 548 482 477 521 517 480 506 491 483 541 542 482 477 486 512 521 501 529 530 510 503 470 470 485 519 486 487 504 486 502 501 464 493 529 575 502 528 481 560 503 528 470 528 482 482 463 496 524 481 500 491 476 500 491 476 540 520 519 490 482 482 518 462 524 481 500 491 476 500 491 463 496 531 568 488 544 490 544 490 544 490 544 482 488 482 477 524 481 500 491 476 500 491 476 463 496 524 524 481 500 491 476 477 490 514 504 463 496 523 596 508 533 477 568 482 488 521 508 501 493 479 493 533 520 468 481 507 509 484 509 511 481 541 482 486 512 521 501 521 501 493 479 518 543 492 512 482 483 467 518 463 496 518 543 492 512 482 483 467 518 534 523 466 511 477 496 507 478 464 496
2021-12-13 18:13:24,206 - INFO - joeynmt.training - Example #3
2021-12-13 18:13:24,206 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 18:13:24,206 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '541', '487', '459', '486', '494', '494', '494', '526']
2021-12-13 18:13:24,206 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 18:13:24,207 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 18:13:24,207 - INFO - joeynmt.training - 	Hypothesis: 514 541 487 459 486 494 494 494 526
2021-12-13 18:13:24,207 - INFO - joeynmt.training - Example #6
2021-12-13 18:13:24,207 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 18:13:24,207 - DEBUG - joeynmt.training - 	Raw hypothesis: ['508', '520', '493', '505', '493', '481']
2021-12-13 18:13:24,207 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 18:13:24,207 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 18:13:24,207 - INFO - joeynmt.training - 	Hypothesis: 508 520 493 505 493 481
2021-12-13 18:13:24,207 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    85000: token_accuracy:  10.37, loss: 81197.8047, ppl:   8.2985, duration: 158.0897s
2021-12-13 18:14:27,548 - INFO - joeynmt.training - Epoch  15, Step:    85500, Batch Loss:     1.785925, Tokens per Sec:     5393, Lr: 0.000100
2021-12-13 18:15:30,691 - INFO - joeynmt.training - Epoch  15, Step:    86000, Batch Loss:     2.438784, Tokens per Sec:     5346, Lr: 0.000100
2021-12-13 18:16:33,281 - INFO - joeynmt.training - Epoch  15, Step:    86500, Batch Loss:     1.988286, Tokens per Sec:     5361, Lr: 0.000100
2021-12-13 18:16:57,579 - INFO - joeynmt.training - Epoch  15: total training loss 12624.73
2021-12-13 18:16:57,579 - INFO - joeynmt.training - EPOCH 16
2021-12-13 18:17:36,236 - INFO - joeynmt.training - Epoch  16, Step:    87000, Batch Loss:     1.640307, Tokens per Sec:     5489, Lr: 0.000100
2021-12-13 18:18:39,129 - INFO - joeynmt.training - Epoch  16, Step:    87500, Batch Loss:     2.094671, Tokens per Sec:     5499, Lr: 0.000100
2021-12-13 18:19:41,795 - INFO - joeynmt.training - Epoch  16, Step:    88000, Batch Loss:     1.855969, Tokens per Sec:     5367, Lr: 0.000100
2021-12-13 18:20:44,245 - INFO - joeynmt.training - Epoch  16, Step:    88500, Batch Loss:     1.953647, Tokens per Sec:     5464, Lr: 0.000100
2021-12-13 18:21:46,850 - INFO - joeynmt.training - Epoch  16, Step:    89000, Batch Loss:     2.082500, Tokens per Sec:     5406, Lr: 0.000100
2021-12-13 18:22:49,488 - INFO - joeynmt.training - Epoch  16, Step:    89500, Batch Loss:     2.455926, Tokens per Sec:     5364, Lr: 0.000100
2021-12-13 18:23:52,131 - INFO - joeynmt.training - Epoch  16, Step:    90000, Batch Loss:     2.189033, Tokens per Sec:     5385, Lr: 0.000100
2021-12-13 18:26:30,113 - INFO - joeynmt.training - Example #0
2021-12-13 18:26:30,113 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 18:26:30,114 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '515', '474', '485', '505', '487', '464', '496', '521', '585', '489', '539', '488', '539', '488', '573', '479', '516', '479', '483', '508', '515', '493', '485', '463', '496', '521', '533', '469', '510', '479', '467', '479', '467', '521', '527', '479', '473', '479', '473', '479', '473', '507', '463', '496', '521', '581', '479', '420', '484', '444', '484', '479', '494', '500', '500', '500', '529', '479', '495', '526', '522', '475', '483', '513', '509', '490', '479', '518', '576', '483', '421', '497', '459', '497', '497', '497', '497', '497', '497', '497', '525', '497', '543', '497', '566', '464', '496', '521', '574', '479', '483', '479', '516', '529', '484', '472', '492', '478', '497', '506', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '521', '527', '479', '473', '479', '473', '479', '473', '507', '511', '515', '490', '485', '463', '496', '521', '532', '469', '510', '454', '510', '479', '469', '541', '525', '514', '476', '459', '477', '515', '510', '472', '510', '527', '490', '473', '490', '473', '493', '512', '525', '489', '476', '491', '510', '464', '493', '521', '527', '479', '473', '479', '473', '479', '507', '453', '514', '454', '490', '464', '493', '521', '527', '479', '473', '479', '473', '479', '483', '479', '507', '453', '514', '454', '490', '548', '548', '453', '453', '453', '453', '453', '453', '476', '476', '476', '476', '506', '476', '506', '493', '533', '493', '533', '493', '533', '464', '496']
2021-12-13 18:26:30,114 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 18:26:30,114 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 18:26:30,114 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 585 489 539 488 539 488 573 479 516 479 483 508 515 493 485 463 496 521 533 469 510 479 467 479 467 521 527 479 473 479 473 479 473 507 463 496 521 581 479 420 484 444 484 479 494 500 500 500 529 479 495 526 522 475 483 513 509 490 479 518 576 483 421 497 459 497 497 497 497 497 497 497 525 497 543 497 566 464 496 521 574 479 483 479 516 529 484 472 492 478 497 506 529 538 472 513 498 462 514 497 471 478 521 527 479 473 479 473 479 473 507 511 515 490 485 463 496 521 532 469 510 454 510 479 469 541 525 514 476 459 477 515 510 472 510 527 490 473 490 473 493 512 525 489 476 491 510 464 493 521 527 479 473 479 473 479 507 453 514 454 490 464 493 521 527 479 473 479 473 479 483 479 507 453 514 454 490 548 548 453 453 453 453 453 453 476 476 476 476 506 476 506 493 533 493 533 493 533 464 496
2021-12-13 18:26:30,114 - INFO - joeynmt.training - Example #1
2021-12-13 18:26:30,114 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 18:26:30,114 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '548', '482', '483', '493', '520', '494', '520']
2021-12-13 18:26:30,114 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 18:26:30,114 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 18:26:30,114 - INFO - joeynmt.training - 	Hypothesis: 518 548 482 483 493 520 494 520
2021-12-13 18:26:30,114 - INFO - joeynmt.training - Example #2
2021-12-13 18:26:30,114 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 18:26:30,114 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '508', '515', '493', '485', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '510', '537', '494', '463', '490', '480', '495', '505', '490', '522', '518', '507', '490', '478', '483', '506', '504', '518', '523', '491', '493', '488', '477', '518', '543', '492', '512', '482', '483', '467', '518', '531', '530', '508', '470', '470', '470', '485', '519', '504', '519', '486', '487', '504', '486', '502', '501', '484', '501', '464', '493', '529', '575', '502', '529', '470', '529', '503', '560', '482', '463', '496', '523', '531', '501', '477', '501', '502', '470', '540', '532', '482', '483', '519', '502', '524', '481', '476', '497', '507', '499', '480', '476', '463', '496', '518', '576', '483', '548', '489', '548', '489', '531', '490', '531', '469', '531', '486', '531', '486', '531', '482', '488', '482', '477', '524', '481', '476', '497', '507', '499', '480', '476', '500', '463', '496', '523', '596', '508', '560', '478', '560', '503', '529', '478', '529', '482', '488', '482', '477', '521', '508', '501', '493', '479', '493', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '541', '542', '482', '483', '486', '512', '521', '501', '463', '496', '518', '543', '492', '512', '482', '483', '467', '518', '463', '496', '508', '515', '493', '485', '537', '523', '479', '478', '516', '478', '502', '496', '464', '496']
2021-12-13 18:26:30,114 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 18:26:30,115 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 18:26:30,115 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 508 515 493 485 464 496 529 564 487 540 497 516 482 530 519 544 482 510 537 494 463 490 480 495 505 490 522 518 507 490 478 483 506 504 518 523 491 493 488 477 518 543 492 512 482 483 467 518 531 530 508 470 470 470 485 519 504 519 486 487 504 486 502 501 484 501 464 493 529 575 502 529 470 529 503 560 482 463 496 523 531 501 477 501 502 470 540 532 482 483 519 502 524 481 476 497 507 499 480 476 463 496 518 576 483 548 489 548 489 531 490 531 469 531 486 531 486 531 482 488 482 477 524 481 476 497 507 499 480 476 500 463 496 523 596 508 560 478 560 503 529 478 529 482 488 482 477 521 508 501 493 479 493 533 520 468 481 507 509 484 509 511 481 541 542 482 483 486 512 521 501 463 496 518 543 492 512 482 483 467 518 463 496 508 515 493 485 537 523 479 478 516 478 502 496 464 496
2021-12-13 18:26:30,115 - INFO - joeynmt.training - Example #3
2021-12-13 18:26:30,115 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 18:26:30,115 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '541', '487', '459', '486', '494', '494', '526', '493', '526']
2021-12-13 18:26:30,115 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 18:26:30,115 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 18:26:30,115 - INFO - joeynmt.training - 	Hypothesis: 514 541 487 459 486 494 494 526 493 526
2021-12-13 18:26:30,115 - INFO - joeynmt.training - Example #6
2021-12-13 18:26:30,115 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 18:26:30,115 - DEBUG - joeynmt.training - 	Raw hypothesis: ['508', '526', '493', '474', '493', '511']
2021-12-13 18:26:30,115 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 18:26:30,115 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 18:26:30,115 - INFO - joeynmt.training - 	Hypothesis: 508 526 493 474 493 511
2021-12-13 18:26:30,115 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    90000: token_accuracy:  10.34, loss: 79098.3828, ppl:   7.8566, duration: 157.9842s
2021-12-13 18:27:32,988 - INFO - joeynmt.training - Epoch  16, Step:    90500, Batch Loss:     1.794038, Tokens per Sec:     5417, Lr: 0.000100
2021-12-13 18:28:35,622 - INFO - joeynmt.training - Epoch  16, Step:    91000, Batch Loss:     2.357395, Tokens per Sec:     5378, Lr: 0.000100
2021-12-13 18:29:38,446 - INFO - joeynmt.training - Epoch  16, Step:    91500, Batch Loss:     1.933882, Tokens per Sec:     5391, Lr: 0.000100
2021-12-13 18:30:41,388 - INFO - joeynmt.training - Epoch  16, Step:    92000, Batch Loss:     2.366512, Tokens per Sec:     5360, Lr: 0.000100
2021-12-13 18:31:40,330 - INFO - joeynmt.training - Epoch  16: total training loss 12414.03
2021-12-13 18:31:40,331 - INFO - joeynmt.training - EPOCH 17
2021-12-13 18:31:44,607 - INFO - joeynmt.training - Epoch  17, Step:    92500, Batch Loss:     1.820140, Tokens per Sec:     5585, Lr: 0.000100
2021-12-13 18:32:47,562 - INFO - joeynmt.training - Epoch  17, Step:    93000, Batch Loss:     2.119952, Tokens per Sec:     5394, Lr: 0.000100
2021-12-13 18:33:50,088 - INFO - joeynmt.training - Epoch  17, Step:    93500, Batch Loss:     2.676490, Tokens per Sec:     5501, Lr: 0.000100
2021-12-13 18:34:53,329 - INFO - joeynmt.training - Epoch  17, Step:    94000, Batch Loss:     1.975090, Tokens per Sec:     5374, Lr: 0.000100
2021-12-13 18:35:56,154 - INFO - joeynmt.training - Epoch  17, Step:    94500, Batch Loss:     2.658256, Tokens per Sec:     5390, Lr: 0.000100
2021-12-13 18:36:59,151 - INFO - joeynmt.training - Epoch  17, Step:    95000, Batch Loss:     2.299109, Tokens per Sec:     5326, Lr: 0.000100
2021-12-13 18:39:35,379 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 18:39:36,249 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/75000.ckpt
2021-12-13 18:39:36,250 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/75000.ckpt
2021-12-13 18:39:36,250 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/75000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/75000.ckpt')
2021-12-13 18:39:36,292 - INFO - joeynmt.training - Example #0
2021-12-13 18:39:36,292 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 18:39:36,292 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '515', '474', '485', '505', '487', '464', '496', '521', '585', '489', '538', '488', '572', '489', '572', '479', '516', '479', '482', '508', '515', '493', '485', '463', '496', '521', '533', '469', '510', '479', '467', '479', '467', '521', '527', '479', '473', '479', '473', '497', '497', '512', '463', '496', '521', '581', '469', '556', '479', '422', '479', '444', '479', '457', '479', '479', '479', '479', '479', '479', '479', '519', '526', '481', '502', '489', '475', '526', '522', '475', '483', '513', '509', '490', '479', '518', '581', '497', '421', '497', '457', '497', '491', '497', '497', '497', '497', '525', '497', '559', '482', '464', '496', '521', '574', '469', '540', '479', '516', '479', '482', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '523', '520', '499', '492', '500', '491', '478', '480', '511', '515', '490', '485', '463', '496', '521', '531', '477', '510', '455', '510', '456', '510', '479', '470', '515', '490', '485', '523', '523', '478', '478', '478', '478', '478', '493', '493', '493', '493', '493', '512', '525', '489', '476', '491', '510', '528', '524', '472', '477', '498', '510', '490', '477', '485', '511', '518', '511', '464', '493', '521', '527', '477', '498', '479', '473', '518', '514', '491', '486', '528', '560', '472', '452', '472', '440', '472', '440', '472', '478', '478', '478', '514', '514', '514', '514', '546', '546', '546', '454', '454', '454', '454', '454', '454', '454', '454', '454', '454', '454', '454', '454', '454', '516', '516', '516', '516', '516', '516', '516', '516', '464', '496']
2021-12-13 18:39:36,292 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 18:39:36,293 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 18:39:36,293 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 585 489 538 488 572 489 572 479 516 479 482 508 515 493 485 463 496 521 533 469 510 479 467 479 467 521 527 479 473 479 473 497 497 512 463 496 521 581 469 556 479 422 479 444 479 457 479 479 479 479 479 479 479 519 526 481 502 489 475 526 522 475 483 513 509 490 479 518 581 497 421 497 457 497 491 497 497 497 497 525 497 559 482 464 496 521 574 469 540 479 516 479 482 529 538 472 513 498 462 514 497 471 478 523 520 499 492 500 491 478 480 511 515 490 485 463 496 521 531 477 510 455 510 456 510 479 470 515 490 485 523 523 478 478 478 478 478 493 493 493 493 493 512 525 489 476 491 510 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 527 477 498 479 473 518 514 491 486 528 560 472 452 472 440 472 440 472 478 478 478 514 514 514 514 546 546 546 454 454 454 454 454 454 454 454 454 454 454 454 454 454 516 516 516 516 516 516 516 516 464 496
2021-12-13 18:39:36,293 - INFO - joeynmt.training - Example #1
2021-12-13 18:39:36,293 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 18:39:36,293 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '518', '482', '483', '493', '470', '493', '470']
2021-12-13 18:39:36,293 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 18:39:36,293 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 18:39:36,293 - INFO - joeynmt.training - 	Hypothesis: 518 518 482 483 493 470 493 470
2021-12-13 18:39:36,293 - INFO - joeynmt.training - Example #2
2021-12-13 18:39:36,294 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 18:39:36,294 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '508', '515', '493', '485', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '510', '537', '494', '463', '490', '480', '495', '505', '490', '522', '548', '482', '477', '521', '517', '480', '506', '491', '483', '518', '572', '482', '488', '482', '477', '527', '531', '473', '470', '513', '470', '520', '497', '480', '469', '497', '504', '497', '464', '493', '526', '575', '475', '560', '503', '525', '481', '525', '482', '482', '463', '496', '526', '575', '475', '560', '503', '525', '482', '482', '463', '496', '523', '531', '501', '477', '501', '502', '471', '478', '470', '540', '520', '519', '490', '482', '483', '518', '462', '524', '481', '476', '497', '507', '499', '480', '476', '500', '463', '496', '518', '576', '489', '531', '489', '531', '489', '531', '469', '552', '489', '531', '482', '488', '482', '477', '524', '481', '500', '492', '476', '497', '507', '463', '496', '528', '524', '473', '477', '498', '510', '490', '477', '485', '511', '518', '511', '482', '488', '521', '508', '501', '493', '479', '493', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '541', '542', '482', '486', '512', '521', '501', '463', '496', '518', '543', '492', '512', '482', '483', '467', '518', '463', '496', '508', '515', '493', '485', '537', '523', '479', '478', '516', '478', '502', '496', '464', '496']
2021-12-13 18:39:36,294 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 18:39:36,294 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 18:39:36,294 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 508 515 493 485 464 496 529 564 487 540 497 516 482 530 519 544 482 510 537 494 463 490 480 495 505 490 522 548 482 477 521 517 480 506 491 483 518 572 482 488 482 477 527 531 473 470 513 470 520 497 480 469 497 504 497 464 493 526 575 475 560 503 525 481 525 482 482 463 496 526 575 475 560 503 525 482 482 463 496 523 531 501 477 501 502 471 478 470 540 520 519 490 482 483 518 462 524 481 476 497 507 499 480 476 500 463 496 518 576 489 531 489 531 489 531 469 552 489 531 482 488 482 477 524 481 500 492 476 497 507 463 496 528 524 473 477 498 510 490 477 485 511 518 511 482 488 521 508 501 493 479 493 533 520 468 481 507 509 484 509 511 481 541 542 482 486 512 521 501 463 496 518 543 492 512 482 483 467 518 463 496 508 515 493 485 537 523 479 478 516 478 502 496 464 496
2021-12-13 18:39:36,294 - INFO - joeynmt.training - Example #3
2021-12-13 18:39:36,294 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 18:39:36,294 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '542', '482', '459', '482', '482', '493', '526', '493', '526']
2021-12-13 18:39:36,294 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 18:39:36,295 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 18:39:36,295 - INFO - joeynmt.training - 	Hypothesis: 518 542 482 459 482 482 493 526 493 526
2021-12-13 18:39:36,295 - INFO - joeynmt.training - Example #6
2021-12-13 18:39:36,295 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 18:39:36,295 - DEBUG - joeynmt.training - 	Raw hypothesis: ['508', '520', '493', '505', '493', '481']
2021-12-13 18:39:36,295 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 18:39:36,295 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 18:39:36,295 - INFO - joeynmt.training - 	Hypothesis: 508 520 493 505 493 481
2021-12-13 18:39:36,295 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    95000: token_accuracy:  10.99, loss: 78285.0781, ppl:   7.6919, duration: 157.1441s
2021-12-13 18:40:40,195 - INFO - joeynmt.training - Epoch  17, Step:    95500, Batch Loss:     2.614599, Tokens per Sec:     5221, Lr: 0.000100
2021-12-13 18:41:43,290 - INFO - joeynmt.training - Epoch  17, Step:    96000, Batch Loss:     2.177602, Tokens per Sec:     5272, Lr: 0.000100
2021-12-13 18:42:46,194 - INFO - joeynmt.training - Epoch  17, Step:    96500, Batch Loss:     2.233195, Tokens per Sec:     5353, Lr: 0.000100
2021-12-13 18:43:49,127 - INFO - joeynmt.training - Epoch  17, Step:    97000, Batch Loss:     1.903274, Tokens per Sec:     5413, Lr: 0.000100
2021-12-13 18:44:52,332 - INFO - joeynmt.training - Epoch  17, Step:    97500, Batch Loss:     1.944522, Tokens per Sec:     5478, Lr: 0.000100
2021-12-13 18:45:55,834 - INFO - joeynmt.training - Epoch  17, Step:    98000, Batch Loss:     1.831284, Tokens per Sec:     5357, Lr: 0.000100
2021-12-13 18:46:27,110 - INFO - joeynmt.training - Epoch  17: total training loss 12244.52
2021-12-13 18:46:27,111 - INFO - joeynmt.training - EPOCH 18
2021-12-13 18:46:59,089 - INFO - joeynmt.training - Epoch  18, Step:    98500, Batch Loss:     1.900909, Tokens per Sec:     5536, Lr: 0.000100
2021-12-13 18:48:01,973 - INFO - joeynmt.training - Epoch  18, Step:    99000, Batch Loss:     1.810484, Tokens per Sec:     5391, Lr: 0.000100
2021-12-13 18:49:05,376 - INFO - joeynmt.training - Epoch  18, Step:    99500, Batch Loss:     1.887988, Tokens per Sec:     5363, Lr: 0.000100
2021-12-13 18:50:08,211 - INFO - joeynmt.training - Epoch  18, Step:   100000, Batch Loss:     2.684083, Tokens per Sec:     5455, Lr: 0.000100
2021-12-13 18:52:44,526 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 18:52:45,392 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/95000.ckpt
2021-12-13 18:52:45,393 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/95000.ckpt
2021-12-13 18:52:45,393 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/95000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/95000.ckpt')
2021-12-13 18:52:45,432 - INFO - joeynmt.training - Example #0
2021-12-13 18:52:45,432 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 18:52:45,433 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '474', '485', '505', '487', '464', '496', '521', '585', '488', '540', '488', '540', '488', '572', '479', '516', '479', '482', '508', '515', '493', '485', '463', '496', '521', '533', '469', '510', '479', '467', '479', '467', '521', '527', '479', '474', '492', '496', '512', '523', '531', '477', '501', '501', '501', '477', '470', '463', '496', '521', '581', '479', '422', '479', '444', '479', '451', '479', '479', '479', '479', '479', '479', '495', '526', '522', '475', '483', '513', '509', '490', '479', '518', '579', '497', '421', '497', '452', '497', '472', '497', '497', '497', '497', '497', '497', '497', '525', '497', '543', '464', '496', '521', '574', '479', '483', '479', '516', '529', '484', '472', '492', '478', '497', '506', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '521', '527', '479', '473', '479', '473', '506', '498', '463', '496', '521', '531', '477', '510', '455', '510', '456', '510', '479', '470', '541', '541', '525', '460', '498', '479', '476', '526', '526', '475', '475', '496', '494', '496', '494', '513', '526', '498', '475', '488', '512', '464', '493', '521', '527', '477', '498', '479', '474', '464', '493', '521', '527', '477', '498', '479', '474', '514', '454', '490', '520', '518', '508', '491', '480', '483', '528', '528', '473', '473', '473', '505', '473', '505', '513', '505', '513', '472', '513', '544', '527', '504', '473', '473', '473', '473', '473', '473', '473', '520', '497', '456', '497', '464', '496']
2021-12-13 18:52:45,433 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 18:52:45,433 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 18:52:45,433 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 474 485 505 487 464 496 521 585 488 540 488 540 488 572 479 516 479 482 508 515 493 485 463 496 521 533 469 510 479 467 479 467 521 527 479 474 492 496 512 523 531 477 501 501 501 477 470 463 496 521 581 479 422 479 444 479 451 479 479 479 479 479 479 495 526 522 475 483 513 509 490 479 518 579 497 421 497 452 497 472 497 497 497 497 497 497 497 525 497 543 464 496 521 574 479 483 479 516 529 484 472 492 478 497 506 529 538 472 513 498 462 514 497 471 478 521 527 479 473 479 473 506 498 463 496 521 531 477 510 455 510 456 510 479 470 541 541 525 460 498 479 476 526 526 475 475 496 494 496 494 513 526 498 475 488 512 464 493 521 527 477 498 479 474 464 493 521 527 477 498 479 474 514 454 490 520 518 508 491 480 483 528 528 473 473 473 505 473 505 513 505 513 472 513 544 527 504 473 473 473 473 473 473 473 520 497 456 497 464 496
2021-12-13 18:52:45,433 - INFO - joeynmt.training - Example #1
2021-12-13 18:52:45,433 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 18:52:45,433 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '548', '482', '483', '493', '520', '494', '520']
2021-12-13 18:52:45,433 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 18:52:45,433 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 18:52:45,433 - INFO - joeynmt.training - 	Hypothesis: 518 548 482 483 493 520 494 520
2021-12-13 18:52:45,433 - INFO - joeynmt.training - Example #2
2021-12-13 18:52:45,434 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 18:52:45,434 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '508', '515', '493', '485', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '510', '537', '494', '463', '490', '480', '495', '505', '490', '522', '518', '482', '477', '491', '496', '483', '521', '517', '480', '506', '491', '483', '518', '543', '492', '512', '482', '483', '467', '518', '531', '524', '470', '477', '476', '513', '470', '497', '506', '477', '504', '497', '516', '464', '493', '529', '575', '502', '560', '481', '560', '503', '525', '470', '525', '482', '463', '496', '523', '531', '501', '477', '501', '502', '471', '478', '470', '540', '532', '482', '483', '519', '502', '524', '525', '482', '476', '477', '496', '501', '502', '524', '524', '481', '476', '497', '507', '499', '480', '476', '500', '463', '496', '531', '568', '488', '544', '475', '544', '504', '525', '482', '488', '482', '477', '524', '481', '476', '497', '507', '499', '480', '463', '496', '528', '571', '472', '528', '498', '560', '486', '547', '482', '488', '482', '477', '521', '520', '501', '505', '479', '505', '488', '481', '521', '508', '501', '493', '479', '493', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '541', '542', '482', '483', '486', '512', '521', '501', '463', '496', '508', '515', '493', '485', '518', '543', '492', '512', '482', '483', '467', '518', '523', '535', '477', '465', '479', '508', '490', '467', '493', '464', '496']
2021-12-13 18:52:45,434 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 18:52:45,434 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 18:52:45,434 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 508 515 493 485 464 496 529 564 487 540 497 516 482 530 519 544 482 510 537 494 463 490 480 495 505 490 522 518 482 477 491 496 483 521 517 480 506 491 483 518 543 492 512 482 483 467 518 531 524 470 477 476 513 470 497 506 477 504 497 516 464 493 529 575 502 560 481 560 503 525 470 525 482 463 496 523 531 501 477 501 502 471 478 470 540 532 482 483 519 502 524 525 482 476 477 496 501 502 524 524 481 476 497 507 499 480 476 500 463 496 531 568 488 544 475 544 504 525 482 488 482 477 524 481 476 497 507 499 480 463 496 528 571 472 528 498 560 486 547 482 488 482 477 521 520 501 505 479 505 488 481 521 508 501 493 479 493 533 520 468 481 507 509 484 509 511 481 541 542 482 483 486 512 521 501 463 496 508 515 493 485 518 543 492 512 482 483 467 518 523 535 477 465 479 508 490 467 493 464 496
2021-12-13 18:52:45,434 - INFO - joeynmt.training - Example #3
2021-12-13 18:52:45,434 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 18:52:45,434 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '541', '487', '459', '493', '493', '493', '493', '526']
2021-12-13 18:52:45,434 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 18:52:45,434 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 18:52:45,435 - INFO - joeynmt.training - 	Hypothesis: 514 541 487 459 493 493 493 493 526
2021-12-13 18:52:45,435 - INFO - joeynmt.training - Example #6
2021-12-13 18:52:45,435 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 18:52:45,435 - DEBUG - joeynmt.training - 	Raw hypothesis: ['513', '521', '487', '479', '488', '506']
2021-12-13 18:52:45,435 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 18:52:45,435 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 18:52:45,435 - INFO - joeynmt.training - 	Hypothesis: 513 521 487 479 488 506
2021-12-13 18:52:45,435 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step   100000: token_accuracy:  11.70, loss: 77227.4609, ppl:   7.4827, duration: 157.2237s
2021-12-13 18:53:48,724 - INFO - joeynmt.training - Epoch  18, Step:   100500, Batch Loss:     2.116162, Tokens per Sec:     5354, Lr: 0.000100
2021-12-13 18:54:52,223 - INFO - joeynmt.training - Epoch  18, Step:   101000, Batch Loss:     1.840104, Tokens per Sec:     5419, Lr: 0.000100
2021-12-13 18:55:55,342 - INFO - joeynmt.training - Epoch  18, Step:   101500, Batch Loss:     2.737891, Tokens per Sec:     5293, Lr: 0.000100
2021-12-13 18:56:58,624 - INFO - joeynmt.training - Epoch  18, Step:   102000, Batch Loss:     2.134381, Tokens per Sec:     5351, Lr: 0.000100
2021-12-13 18:58:01,486 - INFO - joeynmt.training - Epoch  18, Step:   102500, Batch Loss:     2.119325, Tokens per Sec:     5290, Lr: 0.000100
2021-12-13 18:59:04,784 - INFO - joeynmt.training - Epoch  18, Step:   103000, Batch Loss:     2.281986, Tokens per Sec:     5275, Lr: 0.000100
2021-12-13 19:00:08,267 - INFO - joeynmt.training - Epoch  18, Step:   103500, Batch Loss:     1.633625, Tokens per Sec:     5389, Lr: 0.000100
2021-12-13 19:01:11,536 - INFO - joeynmt.training - Epoch  18, Step:   104000, Batch Loss:     2.012826, Tokens per Sec:     5354, Lr: 0.000100
2021-12-13 19:01:14,692 - INFO - joeynmt.training - Epoch  18: total training loss 12083.12
2021-12-13 19:01:14,693 - INFO - joeynmt.training - EPOCH 19
2021-12-13 19:02:14,030 - INFO - joeynmt.training - Epoch  19, Step:   104500, Batch Loss:     2.482935, Tokens per Sec:     5334, Lr: 0.000100
2021-12-13 19:03:17,205 - INFO - joeynmt.training - Epoch  19, Step:   105000, Batch Loss:     2.139027, Tokens per Sec:     5306, Lr: 0.000100
2021-12-13 19:05:56,966 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 19:05:57,859 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/100000.ckpt
2021-12-13 19:05:57,859 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/100000.ckpt
2021-12-13 19:05:57,860 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/100000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/100000.ckpt')
2021-12-13 19:05:57,902 - INFO - joeynmt.training - Example #0
2021-12-13 19:05:57,902 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 19:05:57,902 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '474', '485', '505', '487', '464', '496', '521', '585', '488', '538', '488', '572', '488', '538', '479', '516', '479', '482', '508', '515', '493', '485', '463', '496', '521', '533', '469', '510', '479', '467', '479', '467', '521', '527', '479', '474', '497', '497', '497', '512', '523', '531', '477', '501', '501', '501', '501', '477', '470', '463', '496', '521', '581', '479', '419', '479', '419', '479', '444', '479', '451', '479', '469', '526', '522', '475', '483', '513', '509', '490', '479', '518', '582', '497', '421', '497', '457', '497', '491', '497', '497', '497', '497', '497', '525', '497', '559', '482', '464', '496', '521', '575', '479', '483', '479', '516', '529', '484', '472', '492', '478', '497', '506', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '521', '527', '479', '473', '497', '497', '497', '497', '497', '511', '515', '490', '485', '463', '496', '521', '532', '469', '510', '479', '485', '464', '501', '479', '468', '541', '525', '460', '498', '479', '469', '525', '521', '475', '479', '489', '494', '498', '528', '524', '472', '477', '498', '510', '490', '477', '485', '511', '518', '511', '464', '493', '521', '527', '477', '498', '478', '497', '456', '497', '479', '473', '520', '518', '508', '491', '480', '483', '528', '570', '472', '452', '472', '451', '473', '473', '514', '514', '514', '514', '514', '514', '514', '514', '546', '471', '547', '547', '547', '523', '453', '477', '502', '478', '507', '453', '509', '464', '496']
2021-12-13 19:05:57,902 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 19:05:57,902 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 19:05:57,903 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 474 485 505 487 464 496 521 585 488 538 488 572 488 538 479 516 479 482 508 515 493 485 463 496 521 533 469 510 479 467 479 467 521 527 479 474 497 497 497 512 523 531 477 501 501 501 501 477 470 463 496 521 581 479 419 479 419 479 444 479 451 479 469 526 522 475 483 513 509 490 479 518 582 497 421 497 457 497 491 497 497 497 497 497 525 497 559 482 464 496 521 575 479 483 479 516 529 484 472 492 478 497 506 529 538 472 513 498 462 514 497 471 478 521 527 479 473 497 497 497 497 497 511 515 490 485 463 496 521 532 469 510 479 485 464 501 479 468 541 525 460 498 479 469 525 521 475 479 489 494 498 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 527 477 498 478 497 456 497 479 473 520 518 508 491 480 483 528 570 472 452 472 451 473 473 514 514 514 514 514 514 514 514 546 471 547 547 547 523 453 477 502 478 507 453 509 464 496
2021-12-13 19:05:57,903 - INFO - joeynmt.training - Example #1
2021-12-13 19:05:57,903 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 19:05:57,903 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '548', '482', '483', '495', '520', '494', '520']
2021-12-13 19:05:57,903 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 19:05:57,903 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 19:05:57,903 - INFO - joeynmt.training - 	Hypothesis: 518 548 482 483 495 520 494 520
2021-12-13 19:05:57,903 - INFO - joeynmt.training - Example #2
2021-12-13 19:05:57,904 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 19:05:57,904 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '508', '515', '493', '485', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '510', '537', '494', '463', '490', '480', '495', '505', '490', '522', '518', '572', '482', '477', '482', '488', '521', '517', '480', '506', '491', '483', '518', '543', '492', '512', '482', '483', '467', '518', '531', '524', '470', '477', '476', '513', '470', '497', '506', '477', '504', '497', '516', '464', '493', '529', '576', '502', '560', '481', '560', '503', '525', '470', '525', '482', '483', '463', '496', '528', '523', '480', '503', '473', '477', '501', '489', '540', '520', '519', '490', '482', '483', '518', '462', '524', '524', '481', '476', '497', '507', '499', '480', '476', '500', '463', '496', '531', '568', '488', '544', '475', '544', '504', '525', '474', '544', '490', '544', '482', '488', '482', '477', '524', '481', '476', '497', '507', '499', '480', '476', '500', '463', '496', '520', '566', '464', '518', '490', '552', '482', '477', '520', '526', '505', '511', '496', '494', '480', '517', '489', '475', '521', '520', '501', '505', '479', '505', '487', '481', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '508', '515', '493', '485', '540', '532', '482', '483', '519', '502', '463', '496', '508', '515', '493', '485', '518', '543', '492', '512', '482', '483', '467', '518', '523', '535', '477', '465', '479', '508', '490', '467', '493', '518', '464', '496']
2021-12-13 19:05:57,904 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 19:05:57,904 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 19:05:57,904 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 508 515 493 485 464 496 529 564 487 540 497 516 482 530 519 544 482 510 537 494 463 490 480 495 505 490 522 518 572 482 477 482 488 521 517 480 506 491 483 518 543 492 512 482 483 467 518 531 524 470 477 476 513 470 497 506 477 504 497 516 464 493 529 576 502 560 481 560 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 540 520 519 490 482 483 518 462 524 524 481 476 497 507 499 480 476 500 463 496 531 568 488 544 475 544 504 525 474 544 490 544 482 488 482 477 524 481 476 497 507 499 480 476 500 463 496 520 566 464 518 490 552 482 477 520 526 505 511 496 494 480 517 489 475 521 520 501 505 479 505 487 481 533 520 468 481 507 509 484 509 511 481 508 515 493 485 540 532 482 483 519 502 463 496 508 515 493 485 518 543 492 512 482 483 467 518 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 19:05:57,904 - INFO - joeynmt.training - Example #3
2021-12-13 19:05:57,904 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 19:05:57,905 - DEBUG - joeynmt.training - 	Raw hypothesis: ['514', '541', '487', '459', '486', '494', '494', '494', '526']
2021-12-13 19:05:57,905 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 19:05:57,905 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 19:05:57,905 - INFO - joeynmt.training - 	Hypothesis: 514 541 487 459 486 494 494 494 526
2021-12-13 19:05:57,905 - INFO - joeynmt.training - Example #6
2021-12-13 19:05:57,905 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 19:05:57,905 - DEBUG - joeynmt.training - 	Raw hypothesis: ['508', '520', '493', '505', '493', '481']
2021-12-13 19:05:57,905 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 19:05:57,905 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 19:05:57,906 - INFO - joeynmt.training - 	Hypothesis: 508 520 493 505 493 481
2021-12-13 19:05:57,906 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step   105000: token_accuracy:  11.84, loss: 75676.2969, ppl:   7.1863, duration: 160.7001s
2021-12-13 19:07:00,530 - INFO - joeynmt.training - Epoch  19, Step:   105500, Batch Loss:     2.217051, Tokens per Sec:     5467, Lr: 0.000100
2021-12-13 19:08:03,812 - INFO - joeynmt.training - Epoch  19, Step:   106000, Batch Loss:     2.087470, Tokens per Sec:     5317, Lr: 0.000100
2021-12-13 19:09:06,653 - INFO - joeynmt.training - Epoch  19, Step:   106500, Batch Loss:     1.605473, Tokens per Sec:     5360, Lr: 0.000100
2021-12-13 19:10:10,181 - INFO - joeynmt.training - Epoch  19, Step:   107000, Batch Loss:     1.787675, Tokens per Sec:     5337, Lr: 0.000100
2021-12-13 19:11:13,063 - INFO - joeynmt.training - Epoch  19, Step:   107500, Batch Loss:     1.833568, Tokens per Sec:     5313, Lr: 0.000100
2021-12-13 19:12:16,098 - INFO - joeynmt.training - Epoch  19, Step:   108000, Batch Loss:     1.942363, Tokens per Sec:     5380, Lr: 0.000100
2021-12-13 19:13:19,267 - INFO - joeynmt.training - Epoch  19, Step:   108500, Batch Loss:     1.602555, Tokens per Sec:     5465, Lr: 0.000100
2021-12-13 19:14:22,373 - INFO - joeynmt.training - Epoch  19, Step:   109000, Batch Loss:     2.029455, Tokens per Sec:     5338, Lr: 0.000100
2021-12-13 19:15:26,128 - INFO - joeynmt.training - Epoch  19, Step:   109500, Batch Loss:     2.638335, Tokens per Sec:     5445, Lr: 0.000100
2021-12-13 19:16:04,950 - INFO - joeynmt.training - Epoch  19: total training loss 11943.10
2021-12-13 19:16:04,951 - INFO - joeynmt.training - EPOCH 20
2021-12-13 19:16:28,872 - INFO - joeynmt.training - Epoch  20, Step:   110000, Batch Loss:     1.995157, Tokens per Sec:     5251, Lr: 0.000100
2021-12-13 19:19:10,301 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-13 19:19:11,180 - INFO - joeynmt.helpers - delete models/baseline_reverse_number/105000.ckpt
2021-12-13 19:19:11,181 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/105000.ckpt
2021-12-13 19:19:11,181 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/105000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_number/105000.ckpt')
2021-12-13 19:19:11,219 - INFO - joeynmt.training - Example #0
2021-12-13 19:19:11,219 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-12-13 19:19:11,219 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '526', '516', '475', '485', '505', '487', '464', '496', '521', '585', '488', '539', '488', '539', '488', '574', '479', '516', '479', '483', '508', '515', '493', '485', '463', '496', '521', '533', '469', '510', '479', '485', '464', '501', '501', '501', '501', '501', '479', '467', '523', '531', '477', '501', '501', '501', '501', '501', '477', '470', '463', '496', '521', '581', '479', '419', '485', '444', '485', '468', '494', '479', '494', '521', '479', '418', '526', '522', '475', '483', '513', '509', '490', '479', '518', '582', '497', '421', '497', '452', '497', '472', '497', '497', '497', '497', '497', '497', '525', '497', '559', '479', '483', '464', '496', '521', '574', '479', '517', '479', '483', '529', '538', '472', '513', '498', '462', '514', '497', '471', '478', '521', '527', '479', '473', '479', '473', '479', '473', '507', '511', '515', '490', '485', '463', '496', '521', '531', '477', '510', '456', '510', '479', '470', '541', '525', '460', '498', '479', '469', '526', '526', '474', '474', '493', '505', '511', '524', '526', '477', '496', '501', '475', '528', '524', '472', '477', '498', '510', '490', '477', '485', '511', '518', '511', '464', '493', '521', '531', '469', '510', '479', '501', '479', '469', '517', '514', '484', '487', '504', '488', '528', '528', '473', '473', '473', '473', '473', '505', '473', '505', '513', '513', '513', '473', '544', '544', '457', '457', '457', '457', '457', '457', '457', '518', '488', '521', '492', '521', '521', '521', '521', '521', '479', '506', '493', '480', '464', '496']
2021-12-13 19:19:11,219 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-13 19:19:11,220 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 526 515 474 485 505 487 464 496 521 598 480 566 493 575 485 534 493 559 479 516 479 483 508 515 493 485 463 496 521 529 465 501 491 499 497 494 479 471 522 525 488 502 479 488 501 475 463 496 521 581 475 456 458 437 475 478 475 513 470 547 474 566 479 420 526 522 475 483 513 509 490 479 518 581 483 419 492 438 488 458 497 491 497 547 488 514 497 566 464 496 521 570 485 540 479 483 479 517 517 527 484 485 492 497 504 473 529 538 472 513 498 462 514 497 471 478 522 519 479 482 496 487 507 495 511 515 490 485 463 496 521 529 474 508 453 508 485 491 460 491 479 472 513 525 488 510 493 475 523 526 477 490 493 505 479 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 530 476 501 477 500 457 490 479 471 517 514 505 487 484 491 533 557 468 444 512 537 482 454 509 504 468 504 469 538 495 462 577 531 536 483 439 484 465 509 520 509 553 469 483 516 424 470 501 516 464 496
2021-12-13 19:19:11,220 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 526 516 475 485 505 487 464 496 521 585 488 539 488 539 488 574 479 516 479 483 508 515 493 485 463 496 521 533 469 510 479 485 464 501 501 501 501 501 479 467 523 531 477 501 501 501 501 501 477 470 463 496 521 581 479 419 485 444 485 468 494 479 494 521 479 418 526 522 475 483 513 509 490 479 518 582 497 421 497 452 497 472 497 497 497 497 497 497 525 497 559 479 483 464 496 521 574 479 517 479 483 529 538 472 513 498 462 514 497 471 478 521 527 479 473 479 473 479 473 507 511 515 490 485 463 496 521 531 477 510 456 510 479 470 541 525 460 498 479 469 526 526 474 474 493 505 511 524 526 477 496 501 475 528 524 472 477 498 510 490 477 485 511 518 511 464 493 521 531 469 510 479 501 479 469 517 514 484 487 504 488 528 528 473 473 473 473 473 505 473 505 513 513 513 473 544 544 457 457 457 457 457 457 457 518 488 521 492 521 521 521 521 521 479 506 493 480 464 496
2021-12-13 19:19:11,220 - INFO - joeynmt.training - Example #1
2021-12-13 19:19:11,220 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S34700', 'S21100', 'S1f410']
2021-12-13 19:19:11,220 - DEBUG - joeynmt.training - 	Raw hypothesis: ['518', '548', '482', '483', '495', '520', '494', '520']
2021-12-13 19:19:11,220 - INFO - joeynmt.training - 	Source:     M S34700 S21100 S1f410
2021-12-13 19:19:11,220 - INFO - joeynmt.training - 	Reference:  549 537 482 483 513 523 520 509
2021-12-13 19:19:11,220 - INFO - joeynmt.training - 	Hypothesis: 518 548 482 483 495 520 494 520
2021-12-13 19:19:11,220 - INFO - joeynmt.training - Example #2
2021-12-13 19:19:11,220 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-12-13 19:19:11,221 - DEBUG - joeynmt.training - 	Raw hypothesis: ['528', '518', '472', '487', '490', '503', '515', '483', '508', '515', '493', '485', '464', '496', '529', '564', '487', '540', '497', '516', '482', '530', '519', '544', '482', '510', '537', '494', '463', '490', '480', '495', '505', '490', '522', '518', '569', '482', '477', '482', '488', '521', '517', '480', '506', '491', '483', '518', '597', '486', '513', '482', '488', '549', '484', '582', '488', '570', '531', '524', '470', '477', '476', '513', '470', '497', '506', '477', '504', '497', '464', '493', '529', '575', '502', '560', '481', '560', '503', '525', '470', '525', '482', '483', '463', '496', '523', '531', '501', '477', '501', '502', '471', '478', '470', '540', '532', '482', '483', '519', '502', '524', '481', '476', '497', '507', '499', '480', '476', '500', '463', '496', '531', '568', '488', '544', '475', '544', '504', '521', '475', '545', '490', '545', '482', '488', '482', '477', '524', '481', '476', '497', '507', '499', '480', '476', '500', '463', '496', '528', '524', '473', '477', '498', '510', '490', '477', '485', '511', '518', '511', '521', '520', '501', '505', '479', '505', '488', '481', '522', '508', '502', '493', '479', '493', '533', '520', '468', '481', '507', '509', '484', '509', '511', '481', '508', '515', '493', '485', '540', '532', '482', '483', '519', '502', '463', '496', '508', '515', '493', '485', '523', '535', '477', '465', '479', '508', '490', '467', '493', '518', '464', '496']
2021-12-13 19:19:11,221 - INFO - joeynmt.training - 	Source:     M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-13 19:19:11,221 - INFO - joeynmt.training - 	Reference:  528 518 472 487 490 503 515 483 508 515 493 485 464 496 525 572 483 548 493 524 478 538 515 552 482 483 518 606 494 532 490 549 495 574 490 591 482 488 482 477 520 517 481 506 490 483 524 549 482 477 486 519 510 521 531 524 470 477 476 513 470 497 506 477 504 497 516 513 464 493 529 576 502 557 481 557 503 525 470 525 482 483 463 496 528 523 480 503 473 477 501 489 539 574 482 483 507 544 490 544 518 491 514 527 524 524 481 476 497 507 499 480 476 500 463 496 530 567 489 545 503 531 469 548 475 531 520 548 489 545 482 488 482 477 524 524 481 476 497 507 499 480 476 500 463 496 518 585 503 570 494 553 478 576 487 534 482 488 482 477 522 520 502 505 479 505 488 480 533 520 468 481 507 509 484 509 511 481 509 523 494 493 492 478 538 518 517 487 482 483 463 496 509 523 494 493 492 478 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 19:19:11,221 - INFO - joeynmt.training - 	Hypothesis: 528 518 472 487 490 503 515 483 508 515 493 485 464 496 529 564 487 540 497 516 482 530 519 544 482 510 537 494 463 490 480 495 505 490 522 518 569 482 477 482 488 521 517 480 506 491 483 518 597 486 513 482 488 549 484 582 488 570 531 524 470 477 476 513 470 497 506 477 504 497 464 493 529 575 502 560 481 560 503 525 470 525 482 483 463 496 523 531 501 477 501 502 471 478 470 540 532 482 483 519 502 524 481 476 497 507 499 480 476 500 463 496 531 568 488 544 475 544 504 521 475 545 490 545 482 488 482 477 524 481 476 497 507 499 480 476 500 463 496 528 524 473 477 498 510 490 477 485 511 518 511 521 520 501 505 479 505 488 481 522 508 502 493 479 493 533 520 468 481 507 509 484 509 511 481 508 515 493 485 540 532 482 483 519 502 463 496 508 515 493 485 523 535 477 465 479 508 490 467 493 518 464 496
2021-12-13 19:19:11,221 - INFO - joeynmt.training - Example #3
2021-12-13 19:19:11,221 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-12-13 19:19:11,221 - DEBUG - joeynmt.training - 	Raw hypothesis: ['513', '544', '492', '456', '492', '492', '492', '492', '529']
2021-12-13 19:19:11,221 - INFO - joeynmt.training - 	Source:     M S10e40 S11040 S26504 S2fb04
2021-12-13 19:19:11,221 - INFO - joeynmt.training - 	Reference:  516 543 501 457 500 508 501 488 485 537
2021-12-13 19:19:11,221 - INFO - joeynmt.training - 	Hypothesis: 513 544 492 456 492 492 492 492 529
2021-12-13 19:19:11,221 - INFO - joeynmt.training - Example #6
2021-12-13 19:19:11,222 - DEBUG - joeynmt.training - 	Raw source:     ['M', 'S20340', 'S21800']
2021-12-13 19:19:11,222 - DEBUG - joeynmt.training - 	Raw hypothesis: ['508', '521', '493', '506', '493', '479']
2021-12-13 19:19:11,222 - INFO - joeynmt.training - 	Source:     M S20340 S21800
2021-12-13 19:19:11,222 - INFO - joeynmt.training - 	Reference:  509 514 493 499 491 486
2021-12-13 19:19:11,222 - INFO - joeynmt.training - 	Hypothesis: 508 521 493 506 493 479
2021-12-13 19:19:11,222 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step   110000: token_accuracy:  12.49, loss: 75114.1328, ppl:   7.0818, duration: 162.3499s
2021-12-13 19:20:13,836 - INFO - joeynmt.training - Epoch  20, Step:   110500, Batch Loss:     1.585938, Tokens per Sec:     5434, Lr: 0.000100
2021-12-13 19:21:16,841 - INFO - joeynmt.training - Epoch  20, Step:   111000, Batch Loss:     1.909833, Tokens per Sec:     5448, Lr: 0.000100
2021-12-13 19:22:20,122 - INFO - joeynmt.training - Epoch  20, Step:   111500, Batch Loss:     1.950739, Tokens per Sec:     5379, Lr: 0.000100
2021-12-13 19:23:23,348 - INFO - joeynmt.training - Epoch  20, Step:   112000, Batch Loss:     1.549240, Tokens per Sec:     5328, Lr: 0.000100
