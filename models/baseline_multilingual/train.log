2021-11-22 19:07:54,529 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-11-22 19:07:54,639 - INFO - joeynmt.data - Loading training data...
2021-11-22 19:08:00,853 - INFO - joeynmt.data - Building vocabulary...
2021-11-22 19:08:05,726 - INFO - joeynmt.data - Loading dev data...
2021-11-22 19:08:05,812 - INFO - joeynmt.data - Loading test data...
2021-11-22 19:08:05,873 - INFO - joeynmt.data - Data loaded.
2021-11-22 19:08:05,873 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-11-22 19:08:06,625 - INFO - joeynmt.model - Enc-dec model built.
2021-11-22 19:08:08,430 - DEBUG - tensorflow - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2021-11-22 19:08:08,740 - DEBUG - h5py._conv - Creating converter from 7 to 5
2021-11-22 19:08:08,740 - DEBUG - h5py._conv - Creating converter from 5 to 7
2021-11-22 19:08:08,740 - DEBUG - h5py._conv - Creating converter from 7 to 5
2021-11-22 19:08:08,740 - DEBUG - h5py._conv - Creating converter from 5 to 7
2021-11-22 19:08:10,752 - INFO - joeynmt.training - Total params: 49994512
2021-11-22 19:08:10,753 - DEBUG - joeynmt.training - Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'factor_embeds.0.lut.weight', 'factor_embeds.1.lut.weight', 'factor_embeds.2.lut.weight', 'factor_embeds.3.lut.weight', 'factor_embeds.4.lut.weight', 'factor_embeds.5.lut.weight', 'factor_embeds.6.lut.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2021-11-22 19:08:10,755 - WARNING - joeynmt.training - `keep_last_ckpts` option is outdated. Please use `keep_best_ckpts`, instead.
2021-11-22 19:08:18,581 - INFO - joeynmt.helpers - cfg.name                           : baseline_multilingual
2021-11-22 19:08:18,596 - INFO - joeynmt.helpers - cfg.data.src                       : sign
2021-11-22 19:08:18,596 - INFO - joeynmt.helpers - cfg.data.trg                       : spm.spoken
2021-11-22 19:08:18,597 - INFO - joeynmt.helpers - cfg.data.factors                   : ['sign+', 'feat_col', 'feat_row', 'feat_x', 'feat_y', 'feat_x_rel', 'feat_y_rel']
2021-11-22 19:08:18,597 - INFO - joeynmt.helpers - cfg.data.train                     : data/train
2021-11-22 19:08:18,597 - INFO - joeynmt.helpers - cfg.data.dev                       : data/dev
2021-11-22 19:08:18,597 - INFO - joeynmt.helpers - cfg.data.test                      : data/test
2021-11-22 19:08:18,597 - INFO - joeynmt.helpers - cfg.data.level                     : word
2021-11-22 19:08:18,598 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-11-22 19:08:18,598 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 500
2021-11-22 19:08:18,598 - INFO - joeynmt.helpers - cfg.data.factor_voc_limit          : 10000
2021-11-22 19:08:18,598 - INFO - joeynmt.helpers - cfg.data.factor_voc_min_freq       : 1
2021-11-22 19:08:18,599 - INFO - joeynmt.helpers - cfg.data.use_factor                : True
2021-11-22 19:08:18,599 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2021-11-22 19:08:18,599 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-11-22 19:08:18,599 - INFO - joeynmt.helpers - cfg.testing.postprocess            : False
2021-11-22 19:08:18,599 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-11-22 19:08:18,599 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2021-11-22 19:08:18,599 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens
2021-11-22 19:08:18,600 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]
2021-11-22 19:08:18,600 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-11-22 19:08:18,600 - INFO - joeynmt.helpers - cfg.training.patience              : 7
2021-11-22 19:08:18,600 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7
2021-11-22 19:08:18,600 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy
2021-11-22 19:08:18,600 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0001
2021-11-22 19:08:18,600 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08
2021-11-22 19:08:18,600 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-11-22 19:08:18,601 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.2
2021-11-22 19:08:18,601 - INFO - joeynmt.helpers - cfg.training.batch_size            : 32
2021-11-22 19:08:18,601 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 32
2021-11-22 19:08:18,601 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1
2021-11-22 19:08:18,601 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : eval_metric
2021-11-22 19:08:18,601 - INFO - joeynmt.helpers - cfg.training.epochs                : 200
2021-11-22 19:08:18,601 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000
2021-11-22 19:08:18,601 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100
2021-11-22 19:08:18,602 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2021-11-22 19:08:18,602 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-11-22 19:08:18,602 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-11-22 19:08:18,602 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True
2021-11-22 19:08:18,602 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 200
2021-11-22 19:08:18,602 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3, 6]
2021-11-22 19:08:18,602 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 1
2021-11-22 19:08:18,602 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/baseline_multilingual
2021-11-22 19:08:18,603 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier
2021-11-22 19:08:18,603 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros
2021-11-22 19:08:18,603 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0
2021-11-22 19:08:18,603 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier
2021-11-22 19:08:18,603 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0
2021-11-22 19:08:18,603 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True
2021-11-22 19:08:18,603 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 8
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 400
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.5
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.factor_embeddings.embedding_dim : 16
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.factor_embeddings.scale : True
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.factor_embeddings.dropout : 0.5
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.factor_combine   : concatenate
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.5
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer
2021-11-22 19:08:18,604 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6
2021-11-22 19:08:18,605 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 8
2021-11-22 19:08:18,605 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2021-11-22 19:08:18,605 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2021-11-22 19:08:18,605 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.5
2021-11-22 19:08:18,605 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512
2021-11-22 19:08:18,605 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048
2021-11-22 19:08:18,605 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.5
2021-11-22 19:08:18,606 - INFO - joeynmt.helpers - Data set sizes: 
	train 108433,
	valid 3426,
	test 2286
2021-11-22 19:08:18,607 - INFO - joeynmt.helpers - First training example:
	[SRC] <2pt> <4br> <dict> M S1dc02 S17610 S1f502 S20320
	[SRC_FACTOR0] <2pt> <4br> <dict> M S1dc S176 S1f5 S203
	[TRG] ▁2 01 8
2021-11-22 19:08:18,608 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) M (5) <dict> (6) P (7) S20500 (8) S2ff00 (9) <2pt>
2021-11-22 19:08:18,610 - INFO - joeynmt.helpers - First 10 words (src_factor0): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) M (5) S15a (6) S100 (7) <dict> (8) P (9) S265
2021-11-22 19:08:18,610 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) ▁the (6) . (7) ▁and (8) - (9) s
2021-11-22 19:08:18,610 - INFO - joeynmt.helpers - Number of Src words (types): 12008
2021-11-22 19:08:18,639 - INFO - joeynmt.helpers - Number of Src_factor0 words (types): 664
2021-11-22 19:08:18,640 - INFO - joeynmt.helpers - Number of Trg words (types): 1999
2021-11-22 19:08:18,645 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=8),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=400, vocab_size=12008),
	factor_embeds=ModuleList(
  (0): Embeddings(embedding_dim=16, vocab_size=664)
  (1): Embeddings(embedding_dim=16, vocab_size=11)
  (2): Embeddings(embedding_dim=16, vocab_size=21)
  (3): Embeddings(embedding_dim=16, vocab_size=395)
  (4): Embeddings(embedding_dim=16, vocab_size=457)
  (5): Embeddings(embedding_dim=16, vocab_size=83)
  (6): Embeddings(embedding_dim=16, vocab_size=74)
),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=1999))
2021-11-22 19:08:18,671 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 32
	total batch size (w. parallel & accumulation): 32
2021-11-22 19:08:18,672 - INFO - joeynmt.training - EPOCH 1
2021-11-22 19:08:34,418 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     4.772725, Tokens per Sec:     2006, Lr: 0.000100
2021-11-22 19:08:49,657 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     4.273416, Tokens per Sec:     2072, Lr: 0.000100
2021-11-22 19:09:04,508 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     4.479935, Tokens per Sec:     2118, Lr: 0.000100
2021-11-22 19:09:19,049 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     4.537188, Tokens per Sec:     2161, Lr: 0.000100
2021-11-22 19:09:33,526 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     4.317264, Tokens per Sec:     2200, Lr: 0.000100
2021-11-22 19:09:47,606 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     4.243454, Tokens per Sec:     2134, Lr: 0.000100
2021-11-22 19:10:01,247 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     4.412111, Tokens per Sec:     2212, Lr: 0.000100
2021-11-22 19:10:15,434 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     4.455102, Tokens per Sec:     2210, Lr: 0.000100
2021-11-22 19:10:30,205 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     4.365224, Tokens per Sec:     2106, Lr: 0.000100
2021-11-22 19:10:44,594 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     4.419322, Tokens per Sec:     2146, Lr: 0.000100
2021-11-22 19:19:48,299 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 19:19:50,060 - INFO - joeynmt.training - Example #0
2021-11-22 19:19:50,060 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 19:19:50,061 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 19:19:50,061 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse']
2021-11-22 19:19:50,061 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 19:19:50,061 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 19:19:50,061 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 19:19:50,061 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse
2021-11-22 19:19:50,061 - INFO - joeynmt.training - Example #1
2021-11-22 19:19:50,061 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 19:19:50,061 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 19:19:50,061 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁rwth', '▁rwth', '▁rwth', '200']
2021-11-22 19:19:50,061 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 19:19:50,062 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 19:19:50,062 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 19:19:50,062 - INFO - joeynmt.training - 	Hypothesis: ▁rwth ▁rwth ▁rwth 200
2021-11-22 19:19:50,062 - INFO - joeynmt.training - Example #2
2021-11-22 19:19:50,062 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 19:19:50,062 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 19:19:50,062 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse', '▁Verse']
2021-11-22 19:19:50,062 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 19:19:50,062 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 19:19:50,062 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 19:19:50,062 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse ▁Verse
2021-11-22 19:19:50,062 - INFO - joeynmt.training - Example #3
2021-11-22 19:19:50,063 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 19:19:50,063 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 19:19:50,063 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁rwth', '▁rwth', '▁rwth', '200']
2021-11-22 19:19:50,063 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 19:19:50,063 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 19:19:50,063 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 19:19:50,063 - INFO - joeynmt.training - 	Hypothesis: ▁rwth ▁rwth ▁rwth 200
2021-11-22 19:19:50,063 - INFO - joeynmt.training - Example #6
2021-11-22 19:19:50,063 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 19:19:50,063 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 19:19:50,063 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁p']
2021-11-22 19:19:50,063 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 19:19:50,063 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 19:19:50,063 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 19:19:50,063 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁p
2021-11-22 19:19:50,064 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     1000: bleu:   0.01, loss: 145995.0156, ppl:  74.5026, duration: 545.4690s
2021-11-22 19:20:04,624 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     4.207229, Tokens per Sec:     2036, Lr: 0.000100
2021-11-22 19:20:19,998 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     4.329406, Tokens per Sec:     2077, Lr: 0.000100
2021-11-22 19:20:34,707 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     4.254802, Tokens per Sec:     2185, Lr: 0.000100
2021-11-22 19:20:48,760 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     4.023345, Tokens per Sec:     2204, Lr: 0.000100
2021-11-22 19:21:03,922 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     4.196370, Tokens per Sec:     2070, Lr: 0.000100
2021-11-22 19:21:18,804 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     4.199595, Tokens per Sec:     2161, Lr: 0.000100
2021-11-22 19:21:33,200 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     4.256303, Tokens per Sec:     2132, Lr: 0.000100
2021-11-22 19:21:48,396 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     4.035385, Tokens per Sec:     2062, Lr: 0.000100
2021-11-22 19:22:02,698 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     4.069456, Tokens per Sec:     2202, Lr: 0.000100
2021-11-22 19:22:17,843 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     4.061082, Tokens per Sec:     2174, Lr: 0.000100
2021-11-22 19:31:21,371 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 19:31:23,050 - INFO - joeynmt.helpers - delete models/baseline_multilingual/1000.ckpt
2021-11-22 19:31:23,051 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/1000.ckpt
2021-11-22 19:31:23,051 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/1000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/1000.ckpt')
2021-11-22 19:31:23,188 - INFO - joeynmt.training - Example #0
2021-11-22 19:31:23,188 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 19:31:23,188 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 19:31:23,188 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '▁3', '▁3', '▁And', '▁the', '▁Verse', '▁The', '▁the', '▁Verse', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3']
2021-11-22 19:31:23,188 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 19:31:23,188 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 ▁3 ▁3 ▁And ▁the ▁Verse ▁The ▁the ▁Verse ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3
2021-11-22 19:31:23,189 - INFO - joeynmt.training - Example #1
2021-11-22 19:31:23,189 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 19:31:23,189 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 19:31:23,189 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'ar']
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Hypothesis: ▁E ar
2021-11-22 19:31:23,189 - INFO - joeynmt.training - Example #2
2021-11-22 19:31:23,189 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 19:31:23,189 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 19:31:23,189 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3', '▁3']
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3 ▁3
2021-11-22 19:31:23,189 - INFO - joeynmt.training - Example #3
2021-11-22 19:31:23,189 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 19:31:23,189 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 19:31:23,189 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'ar']
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 19:31:23,189 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 19:31:23,190 - INFO - joeynmt.training - 	Hypothesis: ▁E ar
2021-11-22 19:31:23,190 - INFO - joeynmt.training - Example #6
2021-11-22 19:31:23,190 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 19:31:23,190 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 19:31:23,190 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '3']
2021-11-22 19:31:23,190 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 19:31:23,190 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 19:31:23,190 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 19:31:23,190 - INFO - joeynmt.training - 	Hypothesis: ▁Verse 3
2021-11-22 19:31:23,190 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     2000: bleu:   0.02, loss: 134805.5781, ppl:  53.5406, duration: 545.3461s
2021-11-22 19:31:37,939 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     3.990916, Tokens per Sec:     2106, Lr: 0.000100
2021-11-22 19:31:52,452 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     4.097729, Tokens per Sec:     2127, Lr: 0.000100
2021-11-22 19:32:07,514 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     3.899189, Tokens per Sec:     2167, Lr: 0.000100
2021-11-22 19:32:23,133 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     3.972727, Tokens per Sec:     2029, Lr: 0.000100
2021-11-22 19:32:37,677 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     3.948503, Tokens per Sec:     2138, Lr: 0.000100
2021-11-22 19:32:53,002 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     3.845330, Tokens per Sec:     2085, Lr: 0.000100
2021-11-22 19:33:07,921 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     3.541080, Tokens per Sec:     2111, Lr: 0.000100
2021-11-22 19:33:22,540 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     3.945087, Tokens per Sec:     2123, Lr: 0.000100
2021-11-22 19:33:37,174 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     4.014977, Tokens per Sec:     2153, Lr: 0.000100
2021-11-22 19:33:51,933 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     4.000257, Tokens per Sec:     2111, Lr: 0.000100
2021-11-22 19:42:51,155 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 19:42:52,853 - INFO - joeynmt.helpers - delete models/baseline_multilingual/2000.ckpt
2021-11-22 19:42:52,854 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/2000.ckpt
2021-11-22 19:42:52,854 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/2000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/2000.ckpt')
2021-11-22 19:42:52,966 - INFO - joeynmt.training - Example #0
2021-11-22 19:42:52,967 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 19:42:52,967 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 19:42:52,967 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '▁And', '▁the', '▁LORD', ',', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', '▁"', 'I', 'I', 'I', 'I', '▁"', 'I', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T']
2021-11-22 19:42:52,967 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 19:42:52,967 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 19:42:52,967 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 19:42:52,967 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 ▁And ▁the ▁LORD , ▁" I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I ▁" I ▁" I ▁" I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I ▁" I ▁" I I I I ▁" I ▁" I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I ▁" T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T T
2021-11-22 19:42:52,967 - INFO - joeynmt.training - Example #1
2021-11-22 19:42:52,968 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 19:42:52,968 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 19:42:52,968 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁P', 'or', 'a']
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Hypothesis: ▁P or a
2021-11-22 19:42:52,968 - INFO - joeynmt.training - Example #2
2021-11-22 19:42:52,968 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 19:42:52,968 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 19:42:52,968 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '▁And', '▁the', '▁LORD', ',', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', '▁"', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I', '▁"', 'I']
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 ▁And ▁the ▁LORD , ▁" I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I ▁" I ▁" I I I I I ▁" I ▁" I ▁" I ▁" I ▁" I I I I I I I I I I I I I I I I I I I I I I I I ▁" I I I I I I I ▁" I ▁" I ▁" I ▁" I ▁" I ▁" I I ▁" I ▁" I ▁" I I I I I I ▁" I I I I I I I I I I I I I I I I I I I I I I ▁" I ▁" I ▁" I ▁" I ▁" I I I I I I I I I ▁" I ▁" I ▁" I I I I I I I I I I I I I I I I I ▁" I ▁" I ▁" I ▁" I
2021-11-22 19:42:52,968 - INFO - joeynmt.training - Example #3
2021-11-22 19:42:52,968 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 19:42:52,968 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 19:42:52,968 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁P', 'or', 'a']
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 19:42:52,968 - INFO - joeynmt.training - 	Hypothesis: ▁P or a
2021-11-22 19:42:52,968 - INFO - joeynmt.training - Example #6
2021-11-22 19:42:52,969 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 19:42:52,969 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 19:42:52,969 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'y']
2021-11-22 19:42:52,969 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 19:42:52,969 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 19:42:52,969 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 19:42:52,969 - INFO - joeynmt.training - 	Hypothesis: ▁p y
2021-11-22 19:42:52,969 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     3000: bleu:   0.07, loss: 130218.5938, ppl:  46.7587, duration: 541.0358s
2021-11-22 19:43:08,693 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     3.737596, Tokens per Sec:     2031, Lr: 0.000100
2021-11-22 19:43:23,751 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     3.843134, Tokens per Sec:     2164, Lr: 0.000100
2021-11-22 19:43:39,145 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     3.940286, Tokens per Sec:     2081, Lr: 0.000100
2021-11-22 19:43:52,414 - INFO - joeynmt.training - Epoch   1: total training loss 14003.75
2021-11-22 19:43:52,414 - INFO - joeynmt.training - EPOCH 2
2021-11-22 19:43:54,310 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:     4.388799, Tokens per Sec:     1839, Lr: 0.000100
2021-11-22 19:44:08,532 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:     3.992280, Tokens per Sec:     2195, Lr: 0.000100
2021-11-22 19:44:23,156 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     3.704592, Tokens per Sec:     2102, Lr: 0.000100
2021-11-22 19:44:37,019 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     3.771539, Tokens per Sec:     2167, Lr: 0.000100
2021-11-22 19:44:51,827 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     3.853473, Tokens per Sec:     2148, Lr: 0.000100
2021-11-22 19:45:06,686 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     3.842660, Tokens per Sec:     2040, Lr: 0.000100
2021-11-22 19:45:21,601 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     4.059186, Tokens per Sec:     2166, Lr: 0.000100
2021-11-22 19:54:04,073 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 19:54:04,073 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 19:54:04,074 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 19:54:04,096 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 19:54:05,857 - INFO - joeynmt.helpers - delete models/baseline_multilingual/3000.ckpt
2021-11-22 19:54:05,858 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/3000.ckpt
2021-11-22 19:54:05,858 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/3000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/3000.ckpt')
2021-11-22 19:54:06,004 - INFO - joeynmt.training - Example #0
2021-11-22 19:54:06,004 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 19:54:06,004 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 19:54:06,004 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '▁And', '▁the', '▁LORD', ',', '▁"', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I']
2021-11-22 19:54:06,004 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 19:54:06,004 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 19:54:06,004 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 19:54:06,004 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 ▁And ▁the ▁LORD , ▁" I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I
2021-11-22 19:54:06,004 - INFO - joeynmt.training - Example #1
2021-11-22 19:54:06,004 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 19:54:06,005 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 19:54:06,005 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'ar']
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Hypothesis: ▁p ar
2021-11-22 19:54:06,005 - INFO - joeynmt.training - Example #2
2021-11-22 19:54:06,005 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 19:54:06,005 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 19:54:06,005 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '▁3', '9']
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 ▁3 9
2021-11-22 19:54:06,005 - INFO - joeynmt.training - Example #3
2021-11-22 19:54:06,005 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 19:54:06,005 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 19:54:06,005 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'ar']
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 19:54:06,005 - INFO - joeynmt.training - 	Hypothesis: ▁p ar
2021-11-22 19:54:06,005 - INFO - joeynmt.training - Example #6
2021-11-22 19:54:06,006 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 19:54:06,006 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 19:54:06,006 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'in']
2021-11-22 19:54:06,006 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 19:54:06,006 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 19:54:06,006 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 19:54:06,006 - INFO - joeynmt.training - 	Hypothesis: ▁p in
2021-11-22 19:54:06,006 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     4000: bleu:   0.15, loss: 127316.3750, ppl:  42.9186, duration: 524.4042s
2021-11-22 19:54:21,728 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     3.497527, Tokens per Sec:     2077, Lr: 0.000100
2021-11-22 19:54:36,288 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     4.296724, Tokens per Sec:     2116, Lr: 0.000100
2021-11-22 19:54:50,421 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     3.764272, Tokens per Sec:     2211, Lr: 0.000100
2021-11-22 19:55:04,554 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     3.820768, Tokens per Sec:     2188, Lr: 0.000100
2021-11-22 19:55:19,116 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     3.831842, Tokens per Sec:     2196, Lr: 0.000100
2021-11-22 19:55:33,669 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     3.732331, Tokens per Sec:     2159, Lr: 0.000100
2021-11-22 19:55:48,394 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     3.721915, Tokens per Sec:     2179, Lr: 0.000100
2021-11-22 19:56:02,801 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     3.580696, Tokens per Sec:     2082, Lr: 0.000100
2021-11-22 19:56:17,499 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     3.697356, Tokens per Sec:     2141, Lr: 0.000100
2021-11-22 19:56:32,336 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     3.735887, Tokens per Sec:     2211, Lr: 0.000100
2021-11-22 20:03:29,230 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 20:03:29,230 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 20:03:29,230 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 20:03:29,247 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 20:03:31,971 - INFO - joeynmt.helpers - delete models/baseline_multilingual/4000.ckpt
2021-11-22 20:03:31,972 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/4000.ckpt
2021-11-22 20:03:31,973 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/4000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/4000.ckpt')
2021-11-22 20:03:32,162 - INFO - joeynmt.training - Example #0
2021-11-22 20:03:32,163 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 20:03:32,163 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 20:03:32,163 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁And', '▁the', '▁LORD', '▁said', ',', '▁"', 'I', "'", 't', '▁said', ',', '▁"', 'I', "'", 't', '▁said', ',', '▁"', 'I', "'", 't', '▁said', ',', '▁"', 'I', "'", 't', '▁said', ',', '▁"', 'I', "'", 't', '▁will', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '.']
2021-11-22 20:03:32,163 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 20:03:32,163 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 20:03:32,163 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 20:03:32,163 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁And ▁the ▁LORD ▁said , ▁" I ' t ▁said , ▁" I ' t ▁said , ▁" I ' t ▁said , ▁" I ' t ▁said , ▁" I ' t ▁will ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be .
2021-11-22 20:03:32,163 - INFO - joeynmt.training - Example #1
2021-11-22 20:03:32,163 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 20:03:32,163 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 20:03:32,163 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁C', 'O']
2021-11-22 20:03:32,163 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 20:03:32,163 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 20:03:32,163 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 20:03:32,163 - INFO - joeynmt.training - 	Hypothesis: ▁C O
2021-11-22 20:03:32,163 - INFO - joeynmt.training - Example #2
2021-11-22 20:03:32,164 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 20:03:32,164 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 20:03:32,164 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁For', '▁you', '▁will', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '.']
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁For ▁you ▁will ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be .
2021-11-22 20:03:32,164 - INFO - joeynmt.training - Example #3
2021-11-22 20:03:32,164 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 20:03:32,164 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 20:03:32,164 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁C', 'O']
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Hypothesis: ▁C O
2021-11-22 20:03:32,164 - INFO - joeynmt.training - Example #6
2021-11-22 20:03:32,164 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 20:03:32,164 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 20:03:32,164 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'in']
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 20:03:32,164 - INFO - joeynmt.training - 	Hypothesis: ▁s in
2021-11-22 20:03:32,165 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     5000: bleu:   0.46, loss: 125334.5859, ppl:  40.4792, duration: 419.8281s
2021-11-22 20:03:46,580 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     3.707824, Tokens per Sec:     2146, Lr: 0.000100
2021-11-22 20:04:01,876 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     3.672286, Tokens per Sec:     2105, Lr: 0.000100
2021-11-22 20:04:16,442 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     3.616874, Tokens per Sec:     2157, Lr: 0.000100
2021-11-22 20:04:30,219 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     3.828767, Tokens per Sec:     2219, Lr: 0.000100
2021-11-22 20:04:45,018 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     3.783290, Tokens per Sec:     2194, Lr: 0.000100
2021-11-22 20:04:59,396 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     3.759510, Tokens per Sec:     2190, Lr: 0.000100
2021-11-22 20:05:13,755 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     3.466235, Tokens per Sec:     2218, Lr: 0.000100
2021-11-22 20:05:29,061 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     3.837162, Tokens per Sec:     2015, Lr: 0.000100
2021-11-22 20:05:42,829 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     3.710209, Tokens per Sec:     2261, Lr: 0.000100
2021-11-22 20:05:57,167 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     3.637837, Tokens per Sec:     2252, Lr: 0.000100
2021-11-22 20:14:13,536 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 20:14:13,536 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 20:14:13,536 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 20:14:13,553 - INFO - joeynmt.training - Example #0
2021-11-22 20:14:13,553 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 20:14:13,553 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 20:14:13,553 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁The', '▁LORD', '▁was', '▁the', '▁LORD', ',', '▁"', 'I', "'", 't', '▁the', '▁LORD', ',', '▁and', '▁the', '▁LORD', ',', '▁and', '▁the', '▁LORD', ',', '▁and', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '.']
2021-11-22 20:14:13,553 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 20:14:13,553 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 20:14:13,553 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 20:14:13,553 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁The ▁LORD ▁was ▁the ▁LORD , ▁" I ' t ▁the ▁LORD , ▁and ▁the ▁LORD , ▁and ▁the ▁LORD , ▁and ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD .
2021-11-22 20:14:13,554 - INFO - joeynmt.training - Example #1
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁C', 'O']
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Hypothesis: ▁C O
2021-11-22 20:14:13,554 - INFO - joeynmt.training - Example #2
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁17.', '▁But', '▁you', '▁are', '▁the', '▁LORD', ',', '▁"', 'I', '▁am', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be']
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁17. ▁But ▁you ▁are ▁the ▁LORD , ▁" I ▁am ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be
2021-11-22 20:14:13,554 - INFO - joeynmt.training - Example #3
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'at', 'ar']
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 20:14:13,554 - INFO - joeynmt.training - 	Hypothesis: ▁c at ar
2021-11-22 20:14:13,554 - INFO - joeynmt.training - Example #6
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 20:14:13,554 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 20:14:13,555 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'at']
2021-11-22 20:14:13,555 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 20:14:13,555 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 20:14:13,555 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 20:14:13,555 - INFO - joeynmt.training - 	Hypothesis: ▁p at
2021-11-22 20:14:13,555 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     6000: bleu:   0.34, loss: 123929.4375, ppl:  38.8341, duration: 496.3872s
2021-11-22 20:14:27,849 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     3.791238, Tokens per Sec:     2131, Lr: 0.000100
2021-11-22 20:14:42,520 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     3.445363, Tokens per Sec:     2085, Lr: 0.000100
2021-11-22 20:14:57,271 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     3.541212, Tokens per Sec:     2170, Lr: 0.000100
2021-11-22 20:15:11,725 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     3.579876, Tokens per Sec:     2190, Lr: 0.000100
2021-11-22 20:15:26,336 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     3.569604, Tokens per Sec:     2127, Lr: 0.000100
2021-11-22 20:15:41,272 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     3.738083, Tokens per Sec:     2104, Lr: 0.000100
2021-11-22 20:15:56,488 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     3.438997, Tokens per Sec:     2131, Lr: 0.000100
2021-11-22 20:16:08,065 - INFO - joeynmt.training - Epoch   2: total training loss 12618.64
2021-11-22 20:16:08,066 - INFO - joeynmt.training - EPOCH 3
2021-11-22 20:16:11,318 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:     3.604115, Tokens per Sec:     1937, Lr: 0.000100
2021-11-22 20:16:25,243 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:     3.638219, Tokens per Sec:     2142, Lr: 0.000100
2021-11-22 20:16:39,957 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     3.568635, Tokens per Sec:     2049, Lr: 0.000100
2021-11-22 20:25:38,997 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 20:25:38,997 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 20:25:38,997 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 20:25:39,016 - INFO - joeynmt.training - Example #0
2021-11-22 20:25:39,016 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 20:25:39,016 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 20:25:39,016 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁Then', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the']
2021-11-22 20:25:39,016 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 20:25:39,016 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 20:25:39,016 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 20:25:39,016 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁Then ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the
2021-11-22 20:25:39,016 - INFO - joeynmt.training - Example #1
2021-11-22 20:25:39,016 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 20:25:39,016 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 20:25:39,016 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁C', 'A']
2021-11-22 20:25:39,016 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 20:25:39,016 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 20:25:39,016 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 20:25:39,016 - INFO - joeynmt.training - 	Hypothesis: ▁C A
2021-11-22 20:25:39,017 - INFO - joeynmt.training - Example #2
2021-11-22 20:25:39,017 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 20:25:39,017 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 20:25:39,017 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁5.', '▁But', '▁you', '▁are', '▁the', '▁LORD', ',', '▁but', '▁you', '▁will', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be']
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁5. ▁But ▁you ▁are ▁the ▁LORD , ▁but ▁you ▁will ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be
2021-11-22 20:25:39,017 - INFO - joeynmt.training - Example #3
2021-11-22 20:25:39,017 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 20:25:39,017 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 20:25:39,017 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'é']
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Hypothesis: ▁c é
2021-11-22 20:25:39,017 - INFO - joeynmt.training - Example #6
2021-11-22 20:25:39,017 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 20:25:39,017 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 20:25:39,017 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁b', 'at']
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 20:25:39,017 - INFO - joeynmt.training - 	Hypothesis: ▁b at
2021-11-22 20:25:39,018 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     7000: bleu:   0.37, loss: 121302.3203, ppl:  35.9355, duration: 539.0600s
2021-11-22 20:25:53,324 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     3.584351, Tokens per Sec:     2192, Lr: 0.000100
2021-11-22 20:26:07,929 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     3.753682, Tokens per Sec:     2058, Lr: 0.000100
2021-11-22 20:26:22,825 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     3.390357, Tokens per Sec:     2143, Lr: 0.000100
2021-11-22 20:26:37,877 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     3.565867, Tokens per Sec:     2142, Lr: 0.000100
2021-11-22 20:26:52,518 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     3.692718, Tokens per Sec:     2147, Lr: 0.000100
2021-11-22 20:27:07,072 - INFO - joeynmt.training - Epoch   3, Step:     7600, Batch Loss:     3.708372, Tokens per Sec:     2116, Lr: 0.000100
2021-11-22 20:27:22,369 - INFO - joeynmt.training - Epoch   3, Step:     7700, Batch Loss:     3.514284, Tokens per Sec:     2044, Lr: 0.000100
2021-11-22 20:27:37,287 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:     3.564576, Tokens per Sec:     2141, Lr: 0.000100
2021-11-22 20:27:51,773 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     3.510076, Tokens per Sec:     2194, Lr: 0.000100
2021-11-22 20:28:05,439 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     3.623758, Tokens per Sec:     2172, Lr: 0.000100
2021-11-22 20:36:43,408 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 20:36:43,408 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 20:36:43,408 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 20:36:43,426 - INFO - joeynmt.training - Example #0
2021-11-22 20:36:43,426 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 20:36:43,426 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 20:36:43,426 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁"', 'I', '▁will', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be']
2021-11-22 20:36:43,426 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 20:36:43,426 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 20:36:43,426 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 20:36:43,426 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁" I ▁will ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be
2021-11-22 20:36:43,426 - INFO - joeynmt.training - Example #1
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁M', 'o']
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Hypothesis: ▁M o
2021-11-22 20:36:43,427 - INFO - joeynmt.training - Example #2
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁10.', '▁But', '▁you', '▁are', '▁you', ',', '▁you', '▁will', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be']
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁10. ▁But ▁you ▁are ▁you , ▁you ▁will ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be
2021-11-22 20:36:43,427 - INFO - joeynmt.training - Example #3
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'ol', 'ar']
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 20:36:43,427 - INFO - joeynmt.training - 	Hypothesis: ▁c ol ar
2021-11-22 20:36:43,427 - INFO - joeynmt.training - Example #6
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 20:36:43,427 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 20:36:43,428 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'ol']
2021-11-22 20:36:43,428 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 20:36:43,428 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 20:36:43,428 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 20:36:43,428 - INFO - joeynmt.training - 	Hypothesis: ▁p ol
2021-11-22 20:36:43,428 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     8000: bleu:   0.26, loss: 119835.2891, ppl:  34.4121, duration: 517.9884s
2021-11-22 20:36:59,057 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     3.480502, Tokens per Sec:     2027, Lr: 0.000100
2021-11-22 20:37:13,815 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     3.548140, Tokens per Sec:     2149, Lr: 0.000100
2021-11-22 20:37:27,420 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     3.407227, Tokens per Sec:     2237, Lr: 0.000100
2021-11-22 20:37:41,489 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     3.469812, Tokens per Sec:     2305, Lr: 0.000100
2021-11-22 20:37:55,602 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     3.425692, Tokens per Sec:     2201, Lr: 0.000100
2021-11-22 20:38:10,770 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     3.704437, Tokens per Sec:     2172, Lr: 0.000100
2021-11-22 20:38:26,012 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     3.635018, Tokens per Sec:     2051, Lr: 0.000100
2021-11-22 20:38:41,269 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     3.530092, Tokens per Sec:     2108, Lr: 0.000100
2021-11-22 20:38:55,610 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     3.453569, Tokens per Sec:     2169, Lr: 0.000100
2021-11-22 20:39:09,676 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     3.354733, Tokens per Sec:     2241, Lr: 0.000100
2021-11-22 20:47:45,607 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 20:47:45,607 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 20:47:45,607 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 20:47:45,623 - INFO - joeynmt.training - Example #0
2021-11-22 20:47:45,623 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 20:47:45,624 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 20:47:45,624 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁"', 'I', '▁have', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁a', '▁son', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁Lord', '▁of', '▁the', '▁Lord', '.']
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁" I ▁have ▁be ▁be ▁be ▁be ▁be ▁be ▁a ▁son ▁of ▁the ▁LORD ▁of ▁the ▁Lord ▁of ▁the ▁Lord .
2021-11-22 20:47:45,624 - INFO - joeynmt.training - Example #1
2021-11-22 20:47:45,624 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 20:47:45,624 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 20:47:45,624 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁P', 'or']
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Hypothesis: ▁P or
2021-11-22 20:47:45,624 - INFO - joeynmt.training - Example #2
2021-11-22 20:47:45,624 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 20:47:45,624 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 20:47:45,624 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁I', '▁have', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be']
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 20:47:45,624 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁I ▁have ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be
2021-11-22 20:47:45,625 - INFO - joeynmt.training - Example #3
2021-11-22 20:47:45,625 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 20:47:45,625 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 20:47:45,625 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'oc', 'ar']
2021-11-22 20:47:45,625 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 20:47:45,625 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 20:47:45,625 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 20:47:45,625 - INFO - joeynmt.training - 	Hypothesis: ▁c oc ar
2021-11-22 20:47:45,625 - INFO - joeynmt.training - Example #6
2021-11-22 20:47:45,625 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 20:47:45,625 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 20:47:45,625 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'an']
2021-11-22 20:47:45,625 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 20:47:45,625 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 20:47:45,625 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 20:47:45,625 - INFO - joeynmt.training - 	Hypothesis: ▁c an
2021-11-22 20:47:45,625 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     9000: bleu:   0.23, loss: 118451.9297, ppl:  33.0348, duration: 515.9485s
2021-11-22 20:48:00,286 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     3.533650, Tokens per Sec:     2154, Lr: 0.000100
2021-11-22 20:48:14,514 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     3.702417, Tokens per Sec:     2166, Lr: 0.000100
2021-11-22 20:48:28,455 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     3.295162, Tokens per Sec:     2262, Lr: 0.000100
2021-11-22 20:48:43,021 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     3.574087, Tokens per Sec:     2139, Lr: 0.000100
2021-11-22 20:48:57,433 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     3.546816, Tokens per Sec:     2169, Lr: 0.000100
2021-11-22 20:49:11,897 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     3.903467, Tokens per Sec:     2091, Lr: 0.000100
2021-11-22 20:49:26,837 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     3.419007, Tokens per Sec:     2146, Lr: 0.000100
2021-11-22 20:49:42,190 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     3.652501, Tokens per Sec:     2131, Lr: 0.000100
2021-11-22 20:49:56,573 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     3.346861, Tokens per Sec:     2248, Lr: 0.000100
2021-11-22 20:50:10,760 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     3.569749, Tokens per Sec:     2214, Lr: 0.000100
2021-11-22 20:57:21,605 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 20:57:21,605 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 20:57:21,605 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 20:57:21,615 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 20:57:22,532 - INFO - joeynmt.helpers - delete models/baseline_multilingual/5000.ckpt
2021-11-22 20:57:22,532 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/5000.ckpt
2021-11-22 20:57:22,533 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/5000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/5000.ckpt')
2021-11-22 20:57:22,553 - INFO - joeynmt.training - Example #0
2021-11-22 20:57:22,553 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 20:57:22,553 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 20:57:22,553 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'W', 'e', 'e', ',', '▁the', '▁LORD', ',', '▁the', '▁LORD', '▁is', '▁the', '▁LORD', ',', '▁and', '▁he', '▁said', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', ',', '▁"', 'W', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e']
2021-11-22 20:57:22,553 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 20:57:22,554 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 20:57:22,554 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 20:57:22,554 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" W e e , ▁the ▁LORD , ▁the ▁LORD ▁is ▁the ▁LORD , ▁and ▁he ▁said , ▁" W e e e e e e e e , ▁" W e e e e e e e e e e e e e e e , ▁" W e e e e e e e , ▁" W e e e e e , ▁" W e e e e e e e e e e , ▁" W e e e e e e e e , ▁" W e e e e e e e e e e e e e e e e e , ▁" W e , ▁" W e e e e e e e e e e e e , ▁" W e e e e e e e e e , ▁" W e e , ▁" W e , ▁" W e e e e , ▁" W e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e
2021-11-22 20:57:22,554 - INFO - joeynmt.training - Example #1
2021-11-22 20:57:22,554 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 20:57:22,554 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 20:57:22,554 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁P', 'or', 'ia']
2021-11-22 20:57:22,554 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 20:57:22,554 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 20:57:22,555 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 20:57:22,555 - INFO - joeynmt.training - 	Hypothesis: ▁P or ia
2021-11-22 20:57:22,555 - INFO - joeynmt.training - Example #2
2021-11-22 20:57:22,555 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 20:57:22,555 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 20:57:22,555 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁I', '▁have', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', '▁be', 'n', '\\', 'n', '\\', 'n', '\\', 'n', '\\', 'n', '\\', 'n', 'I', '▁have', '▁not', '.']
2021-11-22 20:57:22,555 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 20:57:22,555 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 20:57:22,555 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 20:57:22,555 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁I ▁have ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be ▁be n \ n \ n \ n \ n \ n I ▁have ▁not .
2021-11-22 20:57:22,556 - INFO - joeynmt.training - Example #3
2021-11-22 20:57:22,556 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 20:57:22,556 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 20:57:22,556 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'at', 'ar']
2021-11-22 20:57:22,556 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 20:57:22,556 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 20:57:22,556 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 20:57:22,556 - INFO - joeynmt.training - 	Hypothesis: ▁p at ar
2021-11-22 20:57:22,556 - INFO - joeynmt.training - Example #6
2021-11-22 20:57:22,556 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 20:57:22,557 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 20:57:22,557 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'at']
2021-11-22 20:57:22,557 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 20:57:22,557 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 20:57:22,557 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 20:57:22,557 - INFO - joeynmt.training - 	Hypothesis: ▁p at
2021-11-22 20:57:22,557 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    10000: bleu:   0.54, loss: 116769.7109, ppl:  31.4340, duration: 431.7965s
2021-11-22 20:57:37,473 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     3.513649, Tokens per Sec:     2189, Lr: 0.000100
2021-11-22 20:57:47,152 - INFO - joeynmt.training - Epoch   3: total training loss 12019.10
2021-11-22 20:57:47,152 - INFO - joeynmt.training - EPOCH 4
2021-11-22 20:57:52,090 - INFO - joeynmt.training - Epoch   4, Step:    10200, Batch Loss:     3.559351, Tokens per Sec:     2152, Lr: 0.000100
2021-11-22 20:58:06,653 - INFO - joeynmt.training - Epoch   4, Step:    10300, Batch Loss:     3.525743, Tokens per Sec:     2134, Lr: 0.000100
2021-11-22 20:58:22,047 - INFO - joeynmt.training - Epoch   4, Step:    10400, Batch Loss:     3.452616, Tokens per Sec:     2050, Lr: 0.000100
2021-11-22 20:58:36,915 - INFO - joeynmt.training - Epoch   4, Step:    10500, Batch Loss:     3.559429, Tokens per Sec:     2170, Lr: 0.000100
2021-11-22 20:58:51,501 - INFO - joeynmt.training - Epoch   4, Step:    10600, Batch Loss:     3.400454, Tokens per Sec:     2148, Lr: 0.000100
2021-11-22 20:59:06,051 - INFO - joeynmt.training - Epoch   4, Step:    10700, Batch Loss:     3.546223, Tokens per Sec:     2166, Lr: 0.000100
2021-11-22 20:59:20,806 - INFO - joeynmt.training - Epoch   4, Step:    10800, Batch Loss:     3.469633, Tokens per Sec:     2153, Lr: 0.000100
2021-11-22 20:59:34,701 - INFO - joeynmt.training - Epoch   4, Step:    10900, Batch Loss:     3.423472, Tokens per Sec:     2177, Lr: 0.000100
2021-11-22 20:59:48,994 - INFO - joeynmt.training - Epoch   4, Step:    11000, Batch Loss:     3.527492, Tokens per Sec:     2210, Lr: 0.000100
2021-11-22 21:04:59,253 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 21:04:59,253 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 21:04:59,253 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 21:04:59,263 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 21:05:00,067 - INFO - joeynmt.helpers - delete models/baseline_multilingual/10000.ckpt
2021-11-22 21:05:00,068 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/10000.ckpt
2021-11-22 21:05:00,068 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/10000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/10000.ckpt')
2021-11-22 21:05:00,129 - INFO - joeynmt.training - Example #0
2021-11-22 21:05:00,130 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 21:05:00,130 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 21:05:00,130 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁"', 'W', 'e', 'e', 'e', ',', '▁the', '▁LORD', "'", 's', '▁people', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '▁of', '▁the', '▁LORD', '.']
2021-11-22 21:05:00,130 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 21:05:00,130 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 21:05:00,130 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 21:05:00,131 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁" W e e e , ▁the ▁LORD ' s ▁people ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD ▁of ▁the ▁LORD .
2021-11-22 21:05:00,131 - INFO - joeynmt.training - Example #1
2021-11-22 21:05:00,131 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 21:05:00,131 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 21:05:00,131 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁C', 'A']
2021-11-22 21:05:00,131 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 21:05:00,132 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 21:05:00,132 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 21:05:00,132 - INFO - joeynmt.training - 	Hypothesis: ▁C A
2021-11-22 21:05:00,132 - INFO - joeynmt.training - Example #2
2021-11-22 21:05:00,132 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 21:05:00,132 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 21:05:00,133 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁8.', '▁I', '▁have', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '.']
2021-11-22 21:05:00,133 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 21:05:00,133 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 21:05:00,133 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 21:05:00,133 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁8. ▁I ▁have ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not .
2021-11-22 21:05:00,133 - INFO - joeynmt.training - Example #3
2021-11-22 21:05:00,133 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 21:05:00,134 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 21:05:00,134 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'ol', 'ar']
2021-11-22 21:05:00,134 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 21:05:00,134 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 21:05:00,134 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 21:05:00,134 - INFO - joeynmt.training - 	Hypothesis: ▁c ol ar
2021-11-22 21:05:00,134 - INFO - joeynmt.training - Example #6
2021-11-22 21:05:00,135 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 21:05:00,135 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 21:05:00,135 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁b', 'ur']
2021-11-22 21:05:00,135 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 21:05:00,135 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 21:05:00,135 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 21:05:00,135 - INFO - joeynmt.training - 	Hypothesis: ▁b ur
2021-11-22 21:05:00,136 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    11000: bleu:   0.82, loss: 115850.9141, ppl:  30.5927, duration: 311.1411s
2021-11-22 21:05:14,818 - INFO - joeynmt.training - Epoch   4, Step:    11100, Batch Loss:     3.311220, Tokens per Sec:     2127, Lr: 0.000100
2021-11-22 21:05:29,189 - INFO - joeynmt.training - Epoch   4, Step:    11200, Batch Loss:     3.381047, Tokens per Sec:     2168, Lr: 0.000100
2021-11-22 21:05:43,943 - INFO - joeynmt.training - Epoch   4, Step:    11300, Batch Loss:     3.327807, Tokens per Sec:     2258, Lr: 0.000100
2021-11-22 21:05:59,248 - INFO - joeynmt.training - Epoch   4, Step:    11400, Batch Loss:     3.273209, Tokens per Sec:     2069, Lr: 0.000100
2021-11-22 21:06:14,175 - INFO - joeynmt.training - Epoch   4, Step:    11500, Batch Loss:     3.399261, Tokens per Sec:     2123, Lr: 0.000100
2021-11-22 21:06:29,311 - INFO - joeynmt.training - Epoch   4, Step:    11600, Batch Loss:     3.391727, Tokens per Sec:     2090, Lr: 0.000100
2021-11-22 21:06:44,148 - INFO - joeynmt.training - Epoch   4, Step:    11700, Batch Loss:     3.583738, Tokens per Sec:     2173, Lr: 0.000100
2021-11-22 21:06:58,989 - INFO - joeynmt.training - Epoch   4, Step:    11800, Batch Loss:     3.385532, Tokens per Sec:     2102, Lr: 0.000100
2021-11-22 21:07:12,894 - INFO - joeynmt.training - Epoch   4, Step:    11900, Batch Loss:     3.603783, Tokens per Sec:     2255, Lr: 0.000100
2021-11-22 21:07:27,027 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     3.483277, Tokens per Sec:     2245, Lr: 0.000100
2021-11-22 21:13:36,304 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 21:13:36,304 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 21:13:36,304 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 21:13:36,314 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 21:13:37,133 - INFO - joeynmt.helpers - delete models/baseline_multilingual/11000.ckpt
2021-11-22 21:13:37,133 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/11000.ckpt
2021-11-22 21:13:37,134 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/11000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/11000.ckpt')
2021-11-22 21:13:37,189 - INFO - joeynmt.training - Example #0
2021-11-22 21:13:37,190 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 21:13:37,190 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 21:13:37,190 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁Then', '▁the', '▁king', "'", 's', '▁people', '▁of', '▁the', '▁king', "'", 's', '▁people', '▁of', '▁the', '▁king', "'", 's', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 21:13:37,190 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 21:13:37,190 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 21:13:37,190 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 21:13:37,191 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁Then ▁the ▁king ' s ▁people ▁of ▁the ▁king ' s ▁people ▁of ▁the ▁king ' s ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 21:13:37,191 - INFO - joeynmt.training - Example #1
2021-11-22 21:13:37,191 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 21:13:37,191 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 21:13:37,191 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁S', 'u']
2021-11-22 21:13:37,191 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 21:13:37,192 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 21:13:37,192 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 21:13:37,192 - INFO - joeynmt.training - 	Hypothesis: ▁S u
2021-11-22 21:13:37,192 - INFO - joeynmt.training - Example #2
2021-11-22 21:13:37,192 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 21:13:37,192 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 21:13:37,192 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁I', '▁have', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been']
2021-11-22 21:13:37,193 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 21:13:37,193 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 21:13:37,193 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 21:13:37,193 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁I ▁have ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been
2021-11-22 21:13:37,193 - INFO - joeynmt.training - Example #3
2021-11-22 21:13:37,193 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 21:13:37,194 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 21:13:37,194 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'é', 'l']
2021-11-22 21:13:37,194 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 21:13:37,194 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 21:13:37,194 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 21:13:37,194 - INFO - joeynmt.training - 	Hypothesis: ▁c é l
2021-11-22 21:13:37,194 - INFO - joeynmt.training - Example #6
2021-11-22 21:13:37,195 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 21:13:37,195 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 21:13:37,195 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁b', 'ot']
2021-11-22 21:13:37,195 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 21:13:37,195 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 21:13:37,195 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 21:13:37,195 - INFO - joeynmt.training - 	Hypothesis: ▁b ot
2021-11-22 21:13:37,196 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    12000: bleu:   0.88, loss: 114252.4844, ppl:  29.1823, duration: 370.1684s
2021-11-22 21:13:52,034 - INFO - joeynmt.training - Epoch   4, Step:    12100, Batch Loss:     3.461973, Tokens per Sec:     2098, Lr: 0.000100
2021-11-22 21:14:06,273 - INFO - joeynmt.training - Epoch   4, Step:    12200, Batch Loss:     3.373470, Tokens per Sec:     2152, Lr: 0.000100
2021-11-22 21:14:20,119 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     3.299696, Tokens per Sec:     2190, Lr: 0.000100
2021-11-22 21:14:34,435 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     3.459326, Tokens per Sec:     2166, Lr: 0.000100
2021-11-22 21:14:49,010 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     3.370525, Tokens per Sec:     2171, Lr: 0.000100
2021-11-22 21:15:04,517 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     3.203438, Tokens per Sec:     2023, Lr: 0.000100
2021-11-22 21:15:19,221 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     3.500941, Tokens per Sec:     2134, Lr: 0.000100
2021-11-22 21:15:33,133 - INFO - joeynmt.training - Epoch   4, Step:    12800, Batch Loss:     3.305051, Tokens per Sec:     2183, Lr: 0.000100
2021-11-22 21:15:46,907 - INFO - joeynmt.training - Epoch   4, Step:    12900, Batch Loss:     3.569728, Tokens per Sec:     2254, Lr: 0.000100
2021-11-22 21:16:01,750 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     3.364566, Tokens per Sec:     2094, Lr: 0.000100
2021-11-22 21:19:52,086 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 21:19:52,087 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 21:19:52,087 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 21:19:52,097 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 21:19:52,922 - INFO - joeynmt.helpers - delete models/baseline_multilingual/12000.ckpt
2021-11-22 21:19:52,922 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/12000.ckpt
2021-11-22 21:19:52,922 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/12000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/12000.ckpt')
2021-11-22 21:19:52,984 - INFO - joeynmt.training - Example #0
2021-11-22 21:19:52,984 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 21:19:52,985 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 21:19:52,985 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁Then', '▁he', '▁said', ',', '▁"', 'W', 'e', 'e', 'e', 'll', 'ing', '▁the', '▁king', "'", 's', '▁people', '▁of', '▁the', '▁king', "'", 's', '▁people', '▁of', '▁the', '▁king', "'", 's', '▁people', '▁of', '▁the', '▁king', "'", 's', '▁people', '▁of', '▁the', '▁LORD', '.']
2021-11-22 21:19:52,985 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 21:19:52,985 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 21:19:52,985 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 21:19:52,985 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁Then ▁he ▁said , ▁" W e e e ll ing ▁the ▁king ' s ▁people ▁of ▁the ▁king ' s ▁people ▁of ▁the ▁king ' s ▁people ▁of ▁the ▁king ' s ▁people ▁of ▁the ▁LORD .
2021-11-22 21:19:52,986 - INFO - joeynmt.training - Example #1
2021-11-22 21:19:52,986 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 21:19:52,986 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 21:19:52,986 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁M', 'or']
2021-11-22 21:19:52,986 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 21:19:52,986 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 21:19:52,986 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 21:19:52,987 - INFO - joeynmt.training - 	Hypothesis: ▁M or
2021-11-22 21:19:52,987 - INFO - joeynmt.training - Example #2
2021-11-22 21:19:52,987 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 21:19:52,987 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 21:19:52,987 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁I', '▁will', '▁be', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '.']
2021-11-22 21:19:52,987 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 21:19:52,988 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 21:19:52,988 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 21:19:52,988 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁I ▁will ▁be ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not .
2021-11-22 21:19:52,988 - INFO - joeynmt.training - Example #3
2021-11-22 21:19:52,988 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 21:19:52,988 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 21:19:52,989 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'ult', 'ar']
2021-11-22 21:19:52,989 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 21:19:52,989 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 21:19:52,989 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 21:19:52,989 - INFO - joeynmt.training - 	Hypothesis: ▁c ult ar
2021-11-22 21:19:52,989 - INFO - joeynmt.training - Example #6
2021-11-22 21:19:52,989 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 21:19:52,990 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 21:19:52,990 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'ay']
2021-11-22 21:19:52,990 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 21:19:52,990 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 21:19:52,990 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 21:19:52,990 - INFO - joeynmt.training - 	Hypothesis: ▁p ay
2021-11-22 21:19:52,991 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step    13000: bleu:   1.15, loss: 112982.8828, ppl:  28.1086, duration: 231.2397s
2021-11-22 21:20:07,175 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     3.362123, Tokens per Sec:     2148, Lr: 0.000100
2021-11-22 21:20:21,421 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     3.351745, Tokens per Sec:     2145, Lr: 0.000100
2021-11-22 21:20:36,531 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     3.421365, Tokens per Sec:     2093, Lr: 0.000100
2021-11-22 21:20:51,089 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     3.434212, Tokens per Sec:     2156, Lr: 0.000100
2021-11-22 21:21:06,499 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     3.330855, Tokens per Sec:     2185, Lr: 0.000100
2021-11-22 21:21:14,723 - INFO - joeynmt.training - Epoch   4: total training loss 11569.40
2021-11-22 21:21:14,724 - INFO - joeynmt.training - EPOCH 5
2021-11-22 21:21:21,217 - INFO - joeynmt.training - Epoch   5, Step:    13600, Batch Loss:     3.544693, Tokens per Sec:     2077, Lr: 0.000100
2021-11-22 21:21:35,930 - INFO - joeynmt.training - Epoch   5, Step:    13700, Batch Loss:     3.271023, Tokens per Sec:     2143, Lr: 0.000100
2021-11-22 21:21:50,449 - INFO - joeynmt.training - Epoch   5, Step:    13800, Batch Loss:     3.438850, Tokens per Sec:     2161, Lr: 0.000100
2021-11-22 21:22:05,381 - INFO - joeynmt.training - Epoch   5, Step:    13900, Batch Loss:     3.464614, Tokens per Sec:     2163, Lr: 0.000100
2021-11-22 21:22:20,555 - INFO - joeynmt.training - Epoch   5, Step:    14000, Batch Loss:     3.481300, Tokens per Sec:     2092, Lr: 0.000100
2021-11-22 21:30:35,632 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 21:30:35,632 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 21:30:35,632 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 21:30:35,649 - INFO - joeynmt.training - Example #0
2021-11-22 21:30:35,649 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 21:30:35,649 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 21:30:35,649 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'I', '▁have', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been']
2021-11-22 21:30:35,649 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 21:30:35,649 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 21:30:35,649 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 21:30:35,649 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" I ▁have ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been
2021-11-22 21:30:35,650 - INFO - joeynmt.training - Example #1
2021-11-22 21:30:35,650 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 21:30:35,650 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 21:30:35,650 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁M', 'A']
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Hypothesis: ▁M A
2021-11-22 21:30:35,650 - INFO - joeynmt.training - Example #2
2021-11-22 21:30:35,650 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 21:30:35,650 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 21:30:35,650 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁4.', '▁I', '▁have', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been']
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁4. ▁I ▁have ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been
2021-11-22 21:30:35,650 - INFO - joeynmt.training - Example #3
2021-11-22 21:30:35,650 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 21:30:35,650 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 21:30:35,650 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'el']
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 21:30:35,650 - INFO - joeynmt.training - 	Hypothesis: ▁c el
2021-11-22 21:30:35,650 - INFO - joeynmt.training - Example #6
2021-11-22 21:30:35,651 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 21:30:35,651 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 21:30:35,651 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'ra', 'ch']
2021-11-22 21:30:35,651 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 21:30:35,651 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 21:30:35,651 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 21:30:35,651 - INFO - joeynmt.training - 	Hypothesis: ▁c ra ch
2021-11-22 21:30:35,651 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    14000: bleu:   0.40, loss: 111948.2344, ppl:  27.2629, duration: 495.0955s
2021-11-22 21:30:50,544 - INFO - joeynmt.training - Epoch   5, Step:    14100, Batch Loss:     3.269150, Tokens per Sec:     2132, Lr: 0.000100
2021-11-22 21:31:04,818 - INFO - joeynmt.training - Epoch   5, Step:    14200, Batch Loss:     3.266951, Tokens per Sec:     2200, Lr: 0.000100
2021-11-22 21:31:19,295 - INFO - joeynmt.training - Epoch   5, Step:    14300, Batch Loss:     3.517483, Tokens per Sec:     2120, Lr: 0.000100
2021-11-22 21:31:34,476 - INFO - joeynmt.training - Epoch   5, Step:    14400, Batch Loss:     3.267191, Tokens per Sec:     2118, Lr: 0.000100
2021-11-22 21:31:49,185 - INFO - joeynmt.training - Epoch   5, Step:    14500, Batch Loss:     3.407751, Tokens per Sec:     2219, Lr: 0.000100
2021-11-22 21:32:03,673 - INFO - joeynmt.training - Epoch   5, Step:    14600, Batch Loss:     3.223097, Tokens per Sec:     2119, Lr: 0.000100
2021-11-22 21:32:18,265 - INFO - joeynmt.training - Epoch   5, Step:    14700, Batch Loss:     3.271443, Tokens per Sec:     2110, Lr: 0.000100
2021-11-22 21:32:32,690 - INFO - joeynmt.training - Epoch   5, Step:    14800, Batch Loss:     3.289258, Tokens per Sec:     2026, Lr: 0.000100
2021-11-22 21:32:47,353 - INFO - joeynmt.training - Epoch   5, Step:    14900, Batch Loss:     3.255686, Tokens per Sec:     2160, Lr: 0.000100
2021-11-22 21:33:02,457 - INFO - joeynmt.training - Epoch   5, Step:    15000, Batch Loss:     3.492947, Tokens per Sec:     2070, Lr: 0.000100
2021-11-22 21:38:01,547 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 21:38:01,547 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 21:38:01,547 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 21:38:01,558 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 21:38:02,381 - INFO - joeynmt.helpers - delete models/baseline_multilingual/13000.ckpt
2021-11-22 21:38:02,381 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/13000.ckpt
2021-11-22 21:38:02,382 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/13000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/13000.ckpt')
2021-11-22 21:38:02,438 - INFO - joeynmt.training - Example #0
2021-11-22 21:38:02,438 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 21:38:02,438 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 21:38:02,438 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁The', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁LORD', '.']
2021-11-22 21:38:02,438 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 21:38:02,438 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 21:38:02,438 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 21:38:02,439 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁The ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁LORD .
2021-11-22 21:38:02,439 - INFO - joeynmt.training - Example #1
2021-11-22 21:38:02,439 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 21:38:02,439 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 21:38:02,439 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁S', 'u', 'c', 'io']
2021-11-22 21:38:02,439 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 21:38:02,439 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 21:38:02,439 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 21:38:02,439 - INFO - joeynmt.training - 	Hypothesis: ▁S u c io
2021-11-22 21:38:02,439 - INFO - joeynmt.training - Example #2
2021-11-22 21:38:02,439 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 21:38:02,440 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 21:38:02,440 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '.']
2021-11-22 21:38:02,440 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 21:38:02,440 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 21:38:02,440 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 21:38:02,440 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not .
2021-11-22 21:38:02,440 - INFO - joeynmt.training - Example #3
2021-11-22 21:38:02,440 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 21:38:02,440 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 21:38:02,440 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'é', 'l']
2021-11-22 21:38:02,440 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 21:38:02,441 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 21:38:02,441 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 21:38:02,441 - INFO - joeynmt.training - 	Hypothesis: ▁m é l
2021-11-22 21:38:02,441 - INFO - joeynmt.training - Example #6
2021-11-22 21:38:02,441 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 21:38:02,441 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 21:38:02,441 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'ra', 'ge']
2021-11-22 21:38:02,441 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 21:38:02,441 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 21:38:02,441 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 21:38:02,441 - INFO - joeynmt.training - 	Hypothesis: ▁c ra ge
2021-11-22 21:38:02,442 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    15000: bleu:   1.20, loss: 110516.1328, ppl:  26.1341, duration: 299.9843s
2021-11-22 21:38:17,036 - INFO - joeynmt.training - Epoch   5, Step:    15100, Batch Loss:     3.461757, Tokens per Sec:     2177, Lr: 0.000100
2021-11-22 21:38:31,422 - INFO - joeynmt.training - Epoch   5, Step:    15200, Batch Loss:     3.372662, Tokens per Sec:     2145, Lr: 0.000100
2021-11-22 21:38:47,133 - INFO - joeynmt.training - Epoch   5, Step:    15300, Batch Loss:     3.330653, Tokens per Sec:     2116, Lr: 0.000100
2021-11-22 21:39:01,397 - INFO - joeynmt.training - Epoch   5, Step:    15400, Batch Loss:     3.283341, Tokens per Sec:     2227, Lr: 0.000100
2021-11-22 21:39:16,275 - INFO - joeynmt.training - Epoch   5, Step:    15500, Batch Loss:     3.191482, Tokens per Sec:     2110, Lr: 0.000100
2021-11-22 21:39:30,889 - INFO - joeynmt.training - Epoch   5, Step:    15600, Batch Loss:     3.407073, Tokens per Sec:     2173, Lr: 0.000100
2021-11-22 21:39:44,934 - INFO - joeynmt.training - Epoch   5, Step:    15700, Batch Loss:     3.369272, Tokens per Sec:     2225, Lr: 0.000100
2021-11-22 21:40:00,027 - INFO - joeynmt.training - Epoch   5, Step:    15800, Batch Loss:     3.293420, Tokens per Sec:     2127, Lr: 0.000100
2021-11-22 21:40:13,896 - INFO - joeynmt.training - Epoch   5, Step:    15900, Batch Loss:     3.378409, Tokens per Sec:     2161, Lr: 0.000100
2021-11-22 21:40:28,821 - INFO - joeynmt.training - Epoch   5, Step:    16000, Batch Loss:     3.313195, Tokens per Sec:     2116, Lr: 0.000100
2021-11-22 21:45:02,867 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 21:45:02,868 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 21:45:02,868 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 21:45:02,884 - INFO - joeynmt.training - Example #0
2021-11-22 21:45:02,884 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 21:45:02,884 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 21:45:02,884 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '2.', '▁Then', '▁the', '▁disciples', '▁said', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'ver', '▁are', '▁a', '▁man', '▁who', '▁are', '▁a', '▁man', '▁who', '▁are', '▁a', '▁man', '▁who', '▁are', '▁a', '▁man', '▁who', '▁are', '▁a', '▁man', '▁who', '▁are', '▁a', '▁man', '▁who', '▁are', '▁a', '▁man', '▁who', '▁are', '▁a', '▁man', '▁who', '▁are', '▁a', '▁man', '.']
2021-11-22 21:45:02,884 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 21:45:02,884 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 21:45:02,884 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 21:45:02,884 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 2. ▁Then ▁the ▁disciples ▁said , ▁" W e e e e e e e ver ▁are ▁a ▁man ▁who ▁are ▁a ▁man ▁who ▁are ▁a ▁man ▁who ▁are ▁a ▁man ▁who ▁are ▁a ▁man ▁who ▁are ▁a ▁man ▁who ▁are ▁a ▁man ▁who ▁are ▁a ▁man ▁who ▁are ▁a ▁man .
2021-11-22 21:45:02,884 - INFO - joeynmt.training - Example #1
2021-11-22 21:45:02,884 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 21:45:02,884 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 21:45:02,884 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-22 21:45:02,884 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 21:45:02,884 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 21:45:02,884 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 21:45:02,884 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-22 21:45:02,884 - INFO - joeynmt.training - Example #2
2021-11-22 21:45:02,884 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 21:45:02,884 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 21:45:02,884 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁18.', '▁"', 'I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '.']
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁18. ▁" I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not .
2021-11-22 21:45:02,885 - INFO - joeynmt.training - Example #3
2021-11-22 21:45:02,885 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 21:45:02,885 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 21:45:02,885 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ão']
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Hypothesis: ▁m ão
2021-11-22 21:45:02,885 - INFO - joeynmt.training - Example #6
2021-11-22 21:45:02,885 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 21:45:02,885 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 21:45:02,885 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'in']
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 21:45:02,885 - INFO - joeynmt.training - 	Hypothesis: ▁d in
2021-11-22 21:45:02,885 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    16000: bleu:   1.11, loss: 109392.7266, ppl:  25.2814, duration: 274.0634s
2021-11-22 21:45:17,631 - INFO - joeynmt.training - Epoch   5, Step:    16100, Batch Loss:     3.339109, Tokens per Sec:     2077, Lr: 0.000100
2021-11-22 21:45:32,241 - INFO - joeynmt.training - Epoch   5, Step:    16200, Batch Loss:     3.273708, Tokens per Sec:     2228, Lr: 0.000100
2021-11-22 21:45:46,186 - INFO - joeynmt.training - Epoch   5, Step:    16300, Batch Loss:     3.232671, Tokens per Sec:     2231, Lr: 0.000100
2021-11-22 21:46:00,689 - INFO - joeynmt.training - Epoch   5, Step:    16400, Batch Loss:     3.364252, Tokens per Sec:     2125, Lr: 0.000100
2021-11-22 21:46:15,652 - INFO - joeynmt.training - Epoch   5, Step:    16500, Batch Loss:     3.188632, Tokens per Sec:     2143, Lr: 0.000100
2021-11-22 21:46:30,000 - INFO - joeynmt.training - Epoch   5, Step:    16600, Batch Loss:     3.272810, Tokens per Sec:     2205, Lr: 0.000100
2021-11-22 21:46:44,137 - INFO - joeynmt.training - Epoch   5, Step:    16700, Batch Loss:     3.149195, Tokens per Sec:     2176, Lr: 0.000100
2021-11-22 21:46:58,950 - INFO - joeynmt.training - Epoch   5, Step:    16800, Batch Loss:     3.293864, Tokens per Sec:     2163, Lr: 0.000100
2021-11-22 21:47:13,491 - INFO - joeynmt.training - Epoch   5, Step:    16900, Batch Loss:     3.097115, Tokens per Sec:     2192, Lr: 0.000100
2021-11-22 21:47:19,782 - INFO - joeynmt.training - Epoch   5: total training loss 11191.76
2021-11-22 21:47:19,783 - INFO - joeynmt.training - EPOCH 6
2021-11-22 21:47:27,791 - INFO - joeynmt.training - Epoch   6, Step:    17000, Batch Loss:     3.212652, Tokens per Sec:     2214, Lr: 0.000100
2021-11-22 21:54:10,675 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 21:54:10,676 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 21:54:10,676 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 21:54:10,692 - INFO - joeynmt.training - Example #0
2021-11-22 21:54:10,692 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 21:54:10,692 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 21:54:10,692 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁Then', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁J', 'am', 'es', ',', '▁and', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 21:54:10,692 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 21:54:10,692 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 21:54:10,692 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 21:54:10,692 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁Then ▁the ▁people ▁of ▁the ▁people ▁of ▁J am es , ▁and ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 21:54:10,692 - INFO - joeynmt.training - Example #1
2021-11-22 21:54:10,692 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 21:54:10,692 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 21:54:10,692 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁P', 'A']
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Hypothesis: ▁P A
2021-11-22 21:54:10,693 - INFO - joeynmt.training - Example #2
2021-11-22 21:54:10,693 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 21:54:10,693 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 21:54:10,693 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '.']
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not .
2021-11-22 21:54:10,693 - INFO - joeynmt.training - Example #3
2021-11-22 21:54:10,693 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 21:54:10,693 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 21:54:10,693 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'abe', 'ça']
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Hypothesis: ▁c abe ça
2021-11-22 21:54:10,693 - INFO - joeynmt.training - Example #6
2021-11-22 21:54:10,693 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 21:54:10,693 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 21:54:10,693 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'u', 'c']
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 21:54:10,693 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 21:54:10,694 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 21:54:10,694 - INFO - joeynmt.training - 	Hypothesis: ▁d u c
2021-11-22 21:54:10,694 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    17000: bleu:   0.99, loss: 108189.7188, ppl:  24.3991, duration: 402.9025s
2021-11-22 21:54:25,187 - INFO - joeynmt.training - Epoch   6, Step:    17100, Batch Loss:     3.315516, Tokens per Sec:     2164, Lr: 0.000100
2021-11-22 21:54:40,098 - INFO - joeynmt.training - Epoch   6, Step:    17200, Batch Loss:     3.129331, Tokens per Sec:     2161, Lr: 0.000100
2021-11-22 21:54:54,328 - INFO - joeynmt.training - Epoch   6, Step:    17300, Batch Loss:     3.176959, Tokens per Sec:     2225, Lr: 0.000100
2021-11-22 21:55:08,491 - INFO - joeynmt.training - Epoch   6, Step:    17400, Batch Loss:     3.287372, Tokens per Sec:     2176, Lr: 0.000100
2021-11-22 21:55:23,467 - INFO - joeynmt.training - Epoch   6, Step:    17500, Batch Loss:     3.259788, Tokens per Sec:     2121, Lr: 0.000100
2021-11-22 21:55:38,877 - INFO - joeynmt.training - Epoch   6, Step:    17600, Batch Loss:     3.209664, Tokens per Sec:     2183, Lr: 0.000100
2021-11-22 21:55:53,407 - INFO - joeynmt.training - Epoch   6, Step:    17700, Batch Loss:     3.137292, Tokens per Sec:     2159, Lr: 0.000100
2021-11-22 21:56:07,993 - INFO - joeynmt.training - Epoch   6, Step:    17800, Batch Loss:     3.420367, Tokens per Sec:     2091, Lr: 0.000100
2021-11-22 21:56:23,169 - INFO - joeynmt.training - Epoch   6, Step:    17900, Batch Loss:     3.101609, Tokens per Sec:     2191, Lr: 0.000100
2021-11-22 21:56:37,256 - INFO - joeynmt.training - Epoch   6, Step:    18000, Batch Loss:     3.242871, Tokens per Sec:     2245, Lr: 0.000100
2021-11-22 22:02:13,229 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 22:02:13,230 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 22:02:13,230 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 22:02:13,246 - INFO - joeynmt.training - Example #0
2021-11-22 22:02:13,246 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 22:02:13,246 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 22:02:13,246 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁Then', '▁Jesus', '▁said', ',', '▁"', 'W', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',', '▁"', 'W', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', ',']
2021-11-22 22:02:13,246 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 22:02:13,246 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 22:02:13,246 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 22:02:13,246 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁Then ▁Jesus ▁said , ▁" W e e e e , ▁" W e e e e e e e e e e e e e e e e e , ▁" W e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ,
2021-11-22 22:02:13,246 - INFO - joeynmt.training - Example #1
2021-11-22 22:02:13,246 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 22:02:13,246 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 22:02:13,246 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁S', 'em', '-', 'm', '-', 'm']
2021-11-22 22:02:13,246 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 22:02:13,246 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 22:02:13,246 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 22:02:13,246 - INFO - joeynmt.training - 	Hypothesis: ▁S em - m - m
2021-11-22 22:02:13,247 - INFO - joeynmt.training - Example #2
2021-11-22 22:02:13,247 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 22:02:13,247 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 22:02:13,247 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁But', '▁you', '▁are', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '.']
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁But ▁you ▁are ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not .
2021-11-22 22:02:13,247 - INFO - joeynmt.training - Example #3
2021-11-22 22:02:13,247 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 22:02:13,247 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 22:02:13,247 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'ro']
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Hypothesis: ▁c ro
2021-11-22 22:02:13,247 - INFO - joeynmt.training - Example #6
2021-11-22 22:02:13,247 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 22:02:13,247 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 22:02:13,247 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'ross']
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 22:02:13,247 - INFO - joeynmt.training - 	Hypothesis: ▁c ross
2021-11-22 22:02:13,247 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    18000: bleu:   0.99, loss: 107866.4766, ppl:  24.1673, duration: 335.9908s
2021-11-22 22:02:27,733 - INFO - joeynmt.training - Epoch   6, Step:    18100, Batch Loss:     3.008541, Tokens per Sec:     2116, Lr: 0.000100
2021-11-22 22:02:42,104 - INFO - joeynmt.training - Epoch   6, Step:    18200, Batch Loss:     3.310719, Tokens per Sec:     2137, Lr: 0.000100
2021-11-22 22:02:56,463 - INFO - joeynmt.training - Epoch   6, Step:    18300, Batch Loss:     3.160675, Tokens per Sec:     2117, Lr: 0.000100
2021-11-22 22:03:11,156 - INFO - joeynmt.training - Epoch   6, Step:    18400, Batch Loss:     3.395725, Tokens per Sec:     2122, Lr: 0.000100
2021-11-22 22:03:25,503 - INFO - joeynmt.training - Epoch   6, Step:    18500, Batch Loss:     3.129044, Tokens per Sec:     2141, Lr: 0.000100
2021-11-22 22:03:40,310 - INFO - joeynmt.training - Epoch   6, Step:    18600, Batch Loss:     3.233826, Tokens per Sec:     2213, Lr: 0.000100
2021-11-22 22:03:54,416 - INFO - joeynmt.training - Epoch   6, Step:    18700, Batch Loss:     3.186363, Tokens per Sec:     2186, Lr: 0.000100
2021-11-22 22:04:09,929 - INFO - joeynmt.training - Epoch   6, Step:    18800, Batch Loss:     3.116270, Tokens per Sec:     2011, Lr: 0.000100
2021-11-22 22:04:24,318 - INFO - joeynmt.training - Epoch   6, Step:    18900, Batch Loss:     3.140750, Tokens per Sec:     2159, Lr: 0.000100
2021-11-22 22:04:38,427 - INFO - joeynmt.training - Epoch   6, Step:    19000, Batch Loss:     3.337795, Tokens per Sec:     2215, Lr: 0.000100
2021-11-22 22:11:11,887 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 22:11:11,887 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 22:11:11,887 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 22:11:11,903 - INFO - joeynmt.training - Example #0
2021-11-22 22:11:11,903 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 22:11:11,903 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 22:11:11,903 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁The', '▁disciples', '▁said', ',', '▁"', 'W', 'ho', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 22:11:11,903 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 22:11:11,903 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 22:11:11,903 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 22:11:11,903 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁The ▁disciples ▁said , ▁" W ho ▁are ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 22:11:11,903 - INFO - joeynmt.training - Example #1
2021-11-22 22:11:11,903 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 22:11:11,903 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 22:11:11,903 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁P', 'ol', 'i']
2021-11-22 22:11:11,903 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 22:11:11,903 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 22:11:11,903 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Hypothesis: ▁P ol i
2021-11-22 22:11:11,904 - INFO - joeynmt.training - Example #2
2021-11-22 22:11:11,904 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 22:11:11,904 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 22:11:11,904 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁8.', '▁I', '▁have', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been']
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁8. ▁I ▁have ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been
2021-11-22 22:11:11,904 - INFO - joeynmt.training - Example #3
2021-11-22 22:11:11,904 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 22:11:11,904 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 22:11:11,904 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ão']
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Hypothesis: ▁m ão
2021-11-22 22:11:11,904 - INFO - joeynmt.training - Example #6
2021-11-22 22:11:11,904 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 22:11:11,904 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 22:11:11,904 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ix']
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 22:11:11,904 - INFO - joeynmt.training - 	Hypothesis: ▁s ix
2021-11-22 22:11:11,905 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    19000: bleu:   1.09, loss: 106468.9297, ppl:  23.1904, duration: 393.4771s
2021-11-22 22:11:26,934 - INFO - joeynmt.training - Epoch   6, Step:    19100, Batch Loss:     3.077114, Tokens per Sec:     2102, Lr: 0.000100
2021-11-22 22:11:41,995 - INFO - joeynmt.training - Epoch   6, Step:    19200, Batch Loss:     3.033473, Tokens per Sec:     2054, Lr: 0.000100
2021-11-22 22:11:56,314 - INFO - joeynmt.training - Epoch   6, Step:    19300, Batch Loss:     2.855458, Tokens per Sec:     2129, Lr: 0.000100
2021-11-22 22:12:10,545 - INFO - joeynmt.training - Epoch   6, Step:    19400, Batch Loss:     3.281364, Tokens per Sec:     2192, Lr: 0.000100
2021-11-22 22:12:24,669 - INFO - joeynmt.training - Epoch   6, Step:    19500, Batch Loss:     3.077741, Tokens per Sec:     2206, Lr: 0.000100
2021-11-22 22:12:39,306 - INFO - joeynmt.training - Epoch   6, Step:    19600, Batch Loss:     2.941120, Tokens per Sec:     2115, Lr: 0.000100
2021-11-22 22:12:52,986 - INFO - joeynmt.training - Epoch   6, Step:    19700, Batch Loss:     2.962830, Tokens per Sec:     2222, Lr: 0.000100
2021-11-22 22:13:07,682 - INFO - joeynmt.training - Epoch   6, Step:    19800, Batch Loss:     3.251311, Tokens per Sec:     2189, Lr: 0.000100
2021-11-22 22:13:22,408 - INFO - joeynmt.training - Epoch   6, Step:    19900, Batch Loss:     3.360549, Tokens per Sec:     2152, Lr: 0.000100
2021-11-22 22:13:36,435 - INFO - joeynmt.training - Epoch   6, Step:    20000, Batch Loss:     3.057940, Tokens per Sec:     2182, Lr: 0.000100
2021-11-22 22:20:23,884 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 22:20:23,884 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 22:20:23,884 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 22:20:23,900 - INFO - joeynmt.training - Example #0
2021-11-22 22:20:23,900 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 22:20:23,901 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 22:20:23,901 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁"', 'W', 'e', 'e', 'e', ',', '▁you', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁" W e e e , ▁you ▁are ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 22:20:23,901 - INFO - joeynmt.training - Example #1
2021-11-22 22:20:23,901 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 22:20:23,901 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 22:20:23,901 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁B', 'o']
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Hypothesis: ▁B o
2021-11-22 22:20:23,901 - INFO - joeynmt.training - Example #2
2021-11-22 22:20:23,901 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 22:20:23,901 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 22:20:23,901 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁7.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁be', '▁a', 'ct', '.']
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 22:20:23,901 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁7. ▁I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁be ▁a ct .
2021-11-22 22:20:23,902 - INFO - joeynmt.training - Example #3
2021-11-22 22:20:23,902 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 22:20:23,902 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 22:20:23,902 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'abe', 'ça']
2021-11-22 22:20:23,902 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 22:20:23,902 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 22:20:23,902 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 22:20:23,902 - INFO - joeynmt.training - 	Hypothesis: ▁c abe ça
2021-11-22 22:20:23,902 - INFO - joeynmt.training - Example #6
2021-11-22 22:20:23,902 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 22:20:23,902 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 22:20:23,902 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'u', 'c']
2021-11-22 22:20:23,902 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 22:20:23,902 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 22:20:23,902 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 22:20:23,902 - INFO - joeynmt.training - 	Hypothesis: ▁d u c
2021-11-22 22:20:23,902 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    20000: bleu:   1.04, loss: 105828.7500, ppl:  22.7561, duration: 407.4665s
2021-11-22 22:20:38,601 - INFO - joeynmt.training - Epoch   6, Step:    20100, Batch Loss:     3.176496, Tokens per Sec:     2211, Lr: 0.000100
2021-11-22 22:20:53,101 - INFO - joeynmt.training - Epoch   6, Step:    20200, Batch Loss:     3.194057, Tokens per Sec:     2233, Lr: 0.000100
2021-11-22 22:21:08,249 - INFO - joeynmt.training - Epoch   6, Step:    20300, Batch Loss:     3.150784, Tokens per Sec:     2109, Lr: 0.000100
2021-11-22 22:21:12,944 - INFO - joeynmt.training - Epoch   6: total training loss 10849.06
2021-11-22 22:21:12,945 - INFO - joeynmt.training - EPOCH 7
2021-11-22 22:21:23,008 - INFO - joeynmt.training - Epoch   7, Step:    20400, Batch Loss:     3.137707, Tokens per Sec:     2239, Lr: 0.000100
2021-11-22 22:21:38,594 - INFO - joeynmt.training - Epoch   7, Step:    20500, Batch Loss:     3.116948, Tokens per Sec:     2000, Lr: 0.000100
2021-11-22 22:21:53,217 - INFO - joeynmt.training - Epoch   7, Step:    20600, Batch Loss:     3.153846, Tokens per Sec:     2139, Lr: 0.000100
2021-11-22 22:22:07,930 - INFO - joeynmt.training - Epoch   7, Step:    20700, Batch Loss:     3.181842, Tokens per Sec:     2061, Lr: 0.000100
2021-11-22 22:22:22,822 - INFO - joeynmt.training - Epoch   7, Step:    20800, Batch Loss:     3.062026, Tokens per Sec:     2102, Lr: 0.000100
2021-11-22 22:22:37,264 - INFO - joeynmt.training - Epoch   7, Step:    20900, Batch Loss:     3.086793, Tokens per Sec:     2140, Lr: 0.000100
2021-11-22 22:22:51,367 - INFO - joeynmt.training - Epoch   7, Step:    21000, Batch Loss:     3.042796, Tokens per Sec:     2165, Lr: 0.000100
2021-11-22 22:30:45,640 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 22:30:45,640 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 22:30:45,640 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 22:30:45,658 - INFO - joeynmt.training - Example #0
2021-11-22 22:30:45,658 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 22:30:45,658 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 22:30:45,658 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '2.', '▁"', 'I', '▁am', 'az', 'ed', '▁the', '▁king', '▁of', '▁J', 'am', 'an', ',', '▁and', '▁the', '▁people', '▁of', '▁M', 'a', 'a', 'a', 'iah', ',', '▁and', '▁the', '▁people', '▁who', '▁are', '▁the', '▁people', '▁who', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 22:30:45,658 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 22:30:45,658 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 22:30:45,658 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 22:30:45,658 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 2. ▁" I ▁am az ed ▁the ▁king ▁of ▁J am an , ▁and ▁the ▁people ▁of ▁M a a a iah , ▁and ▁the ▁people ▁who ▁are ▁the ▁people ▁who ▁are ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 22:30:45,659 - INFO - joeynmt.training - Example #1
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁B', 'er', 'er']
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Hypothesis: ▁B er er
2021-11-22 22:30:45,659 - INFO - joeynmt.training - Example #2
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁6.', '▁"', 'I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁be', 'aut', 'if', 'ul', 'f', 'ull', 'y', ',', '▁and', '▁you', '▁have', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been', '▁been']
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁6. ▁" I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁be aut if ul f ull y , ▁and ▁you ▁have ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been ▁been
2021-11-22 22:30:45,659 - INFO - joeynmt.training - Example #3
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'ão']
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Hypothesis: ▁p ão
2021-11-22 22:30:45,659 - INFO - joeynmt.training - Example #6
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 22:30:45,659 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ix']
2021-11-22 22:30:45,659 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 22:30:45,660 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 22:30:45,660 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 22:30:45,660 - INFO - joeynmt.training - 	Hypothesis: ▁s ix
2021-11-22 22:30:45,660 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    21000: bleu:   0.77, loss: 105114.9219, ppl:  22.2815, duration: 474.2921s
2021-11-22 22:30:59,841 - INFO - joeynmt.training - Epoch   7, Step:    21100, Batch Loss:     3.078933, Tokens per Sec:     2228, Lr: 0.000100
2021-11-22 22:31:14,384 - INFO - joeynmt.training - Epoch   7, Step:    21200, Batch Loss:     3.168276, Tokens per Sec:     2087, Lr: 0.000100
2021-11-22 22:31:29,037 - INFO - joeynmt.training - Epoch   7, Step:    21300, Batch Loss:     3.082764, Tokens per Sec:     2192, Lr: 0.000100
2021-11-22 22:31:42,911 - INFO - joeynmt.training - Epoch   7, Step:    21400, Batch Loss:     3.010668, Tokens per Sec:     2154, Lr: 0.000100
2021-11-22 22:31:56,886 - INFO - joeynmt.training - Epoch   7, Step:    21500, Batch Loss:     3.235467, Tokens per Sec:     2209, Lr: 0.000100
2021-11-22 22:32:12,417 - INFO - joeynmt.training - Epoch   7, Step:    21600, Batch Loss:     3.033293, Tokens per Sec:     2101, Lr: 0.000100
2021-11-22 22:32:26,687 - INFO - joeynmt.training - Epoch   7, Step:    21700, Batch Loss:     3.112735, Tokens per Sec:     2293, Lr: 0.000100
2021-11-22 22:32:40,869 - INFO - joeynmt.training - Epoch   7, Step:    21800, Batch Loss:     3.084574, Tokens per Sec:     2105, Lr: 0.000100
2021-11-22 22:32:56,036 - INFO - joeynmt.training - Epoch   7, Step:    21900, Batch Loss:     3.039309, Tokens per Sec:     2016, Lr: 0.000100
2021-11-22 22:33:11,102 - INFO - joeynmt.training - Epoch   7, Step:    22000, Batch Loss:     3.175100, Tokens per Sec:     2166, Lr: 0.000100
2021-11-22 22:38:44,973 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 22:38:44,973 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 22:38:44,973 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 22:38:44,985 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 22:38:45,785 - INFO - joeynmt.helpers - delete models/baseline_multilingual/15000.ckpt
2021-11-22 22:38:45,785 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/15000.ckpt
2021-11-22 22:38:45,785 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/15000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/15000.ckpt')
2021-11-22 22:38:45,847 - INFO - joeynmt.training - Example #0
2021-11-22 22:38:45,848 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 22:38:45,848 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 22:38:45,848 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'I', '▁am', '▁the', '▁people', '▁of', '▁J', 'am', 'an', ',', '▁and', '▁the', '▁people', '▁of', '▁J', 'am', 'an', 'an', 'an', ',', '▁and', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁g', 'round', '.']
2021-11-22 22:38:45,848 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 22:38:45,848 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 22:38:45,849 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 22:38:45,849 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" I ▁am ▁the ▁people ▁of ▁J am an , ▁and ▁the ▁people ▁of ▁J am an an an , ▁and ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁g round .
2021-11-22 22:38:45,849 - INFO - joeynmt.training - Example #1
2021-11-22 22:38:45,849 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 22:38:45,849 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 22:38:45,849 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁B', 'er', 'g', 'a']
2021-11-22 22:38:45,849 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 22:38:45,850 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 22:38:45,850 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 22:38:45,850 - INFO - joeynmt.training - 	Hypothesis: ▁B er g a
2021-11-22 22:38:45,850 - INFO - joeynmt.training - Example #2
2021-11-22 22:38:45,850 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 22:38:45,850 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 22:38:45,851 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁9.', '▁"', 'I', '▁am', '▁not', '▁not', '▁not', '▁to', '▁you', ',', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁a', '▁little', '▁long', 'er', '▁than', '▁you', '.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '.']
2021-11-22 22:38:45,851 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 22:38:45,851 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 22:38:45,851 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 22:38:45,851 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁9. ▁" I ▁am ▁not ▁not ▁not ▁to ▁you , ▁I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁a ▁little ▁long er ▁than ▁you . ▁I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not .
2021-11-22 22:38:45,851 - INFO - joeynmt.training - Example #3
2021-11-22 22:38:45,851 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 22:38:45,852 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 22:38:45,852 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'abe', 'ça']
2021-11-22 22:38:45,852 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 22:38:45,852 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 22:38:45,852 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 22:38:45,852 - INFO - joeynmt.training - 	Hypothesis: ▁c abe ça
2021-11-22 22:38:45,852 - INFO - joeynmt.training - Example #6
2021-11-22 22:38:45,852 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 22:38:45,853 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 22:38:45,853 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ix']
2021-11-22 22:38:45,853 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 22:38:45,853 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 22:38:45,853 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 22:38:45,853 - INFO - joeynmt.training - 	Hypothesis: ▁s ix
2021-11-22 22:38:45,854 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    22000: bleu:   1.54, loss: 104278.1406, ppl:  21.7377, duration: 334.7511s
2021-11-22 22:38:59,888 - INFO - joeynmt.training - Epoch   7, Step:    22100, Batch Loss:     3.013207, Tokens per Sec:     2313, Lr: 0.000100
2021-11-22 22:39:14,175 - INFO - joeynmt.training - Epoch   7, Step:    22200, Batch Loss:     3.141869, Tokens per Sec:     2106, Lr: 0.000100
2021-11-22 22:39:29,379 - INFO - joeynmt.training - Epoch   7, Step:    22300, Batch Loss:     3.451041, Tokens per Sec:     2059, Lr: 0.000100
2021-11-22 22:39:43,825 - INFO - joeynmt.training - Epoch   7, Step:    22400, Batch Loss:     3.083161, Tokens per Sec:     2209, Lr: 0.000100
2021-11-22 22:39:58,663 - INFO - joeynmt.training - Epoch   7, Step:    22500, Batch Loss:     3.161167, Tokens per Sec:     2157, Lr: 0.000100
2021-11-22 22:40:12,989 - INFO - joeynmt.training - Epoch   7, Step:    22600, Batch Loss:     3.214585, Tokens per Sec:     2159, Lr: 0.000100
2021-11-22 22:40:27,829 - INFO - joeynmt.training - Epoch   7, Step:    22700, Batch Loss:     3.163649, Tokens per Sec:     2228, Lr: 0.000100
2021-11-22 22:40:42,698 - INFO - joeynmt.training - Epoch   7, Step:    22800, Batch Loss:     3.271934, Tokens per Sec:     2100, Lr: 0.000100
2021-11-22 22:40:56,430 - INFO - joeynmt.training - Epoch   7, Step:    22900, Batch Loss:     3.112792, Tokens per Sec:     2209, Lr: 0.000100
2021-11-22 22:41:11,271 - INFO - joeynmt.training - Epoch   7, Step:    23000, Batch Loss:     3.067210, Tokens per Sec:     2133, Lr: 0.000100
2021-11-22 22:47:23,718 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 22:47:23,718 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 22:47:23,718 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 22:47:23,735 - INFO - joeynmt.training - Example #0
2021-11-22 22:47:23,735 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 22:47:23,735 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 22:47:23,735 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '3.', '▁Then', '▁the', '▁disciples', '▁said', ',', '▁"', 'I', '▁am', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 22:47:23,735 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 22:47:23,735 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 3. ▁Then ▁the ▁disciples ▁said , ▁" I ▁am ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 22:47:23,736 - INFO - joeynmt.training - Example #1
2021-11-22 22:47:23,736 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 22:47:23,736 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 22:47:23,736 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 's', 'u']
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Hypothesis: ▁E s u
2021-11-22 22:47:23,736 - INFO - joeynmt.training - Example #2
2021-11-22 22:47:23,736 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 22:47:23,736 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 22:47:23,736 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁12.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁to', '▁you', ',', '▁but', '▁I', '▁have', '▁been', '▁been', '▁been', '▁given', '▁me', '.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '.']
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁12. ▁I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁to ▁you , ▁but ▁I ▁have ▁been ▁been ▁been ▁given ▁me . ▁I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not .
2021-11-22 22:47:23,736 - INFO - joeynmt.training - Example #3
2021-11-22 22:47:23,736 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 22:47:23,736 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 22:47:23,736 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁p', 'od', 'o']
2021-11-22 22:47:23,736 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 22:47:23,737 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 22:47:23,737 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 22:47:23,737 - INFO - joeynmt.training - 	Hypothesis: ▁p od o
2021-11-22 22:47:23,737 - INFO - joeynmt.training - Example #6
2021-11-22 22:47:23,737 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 22:47:23,737 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 22:47:23,737 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'et']
2021-11-22 22:47:23,737 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 22:47:23,737 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 22:47:23,737 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 22:47:23,737 - INFO - joeynmt.training - 	Hypothesis: ▁d et
2021-11-22 22:47:23,737 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    23000: bleu:   1.22, loss: 103603.9375, ppl:  21.3092, duration: 372.4660s
2021-11-22 22:47:38,383 - INFO - joeynmt.training - Epoch   7, Step:    23100, Batch Loss:     3.100960, Tokens per Sec:     2133, Lr: 0.000100
2021-11-22 22:47:53,635 - INFO - joeynmt.training - Epoch   7, Step:    23200, Batch Loss:     2.952238, Tokens per Sec:     2113, Lr: 0.000100
2021-11-22 22:48:08,218 - INFO - joeynmt.training - Epoch   7, Step:    23300, Batch Loss:     3.207844, Tokens per Sec:     2159, Lr: 0.000100
2021-11-22 22:48:22,758 - INFO - joeynmt.training - Epoch   7, Step:    23400, Batch Loss:     3.133119, Tokens per Sec:     2183, Lr: 0.000100
2021-11-22 22:48:37,287 - INFO - joeynmt.training - Epoch   7, Step:    23500, Batch Loss:     3.136239, Tokens per Sec:     2224, Lr: 0.000100
2021-11-22 22:48:52,169 - INFO - joeynmt.training - Epoch   7, Step:    23600, Batch Loss:     2.904188, Tokens per Sec:     2144, Lr: 0.000100
2021-11-22 22:49:06,408 - INFO - joeynmt.training - Epoch   7, Step:    23700, Batch Loss:     3.003109, Tokens per Sec:     2140, Lr: 0.000100
2021-11-22 22:49:09,609 - INFO - joeynmt.training - Epoch   7: total training loss 10565.88
2021-11-22 22:49:09,609 - INFO - joeynmt.training - EPOCH 8
2021-11-22 22:49:21,302 - INFO - joeynmt.training - Epoch   8, Step:    23800, Batch Loss:     3.038092, Tokens per Sec:     2060, Lr: 0.000100
2021-11-22 22:49:35,761 - INFO - joeynmt.training - Epoch   8, Step:    23900, Batch Loss:     2.993228, Tokens per Sec:     2169, Lr: 0.000100
2021-11-22 22:49:50,018 - INFO - joeynmt.training - Epoch   8, Step:    24000, Batch Loss:     2.985757, Tokens per Sec:     2162, Lr: 0.000100
2021-11-22 22:55:20,808 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 22:55:20,808 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 22:55:20,808 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 22:55:20,825 - INFO - joeynmt.training - Example #0
2021-11-22 22:55:20,825 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 22:55:20,825 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 22:55:20,825 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'I', '▁am', '▁the', '▁king', '▁of', '▁J', 'am', 'an', ',', '▁and', '▁the', '▁people', '▁of', '▁J', 'am', 'an', 'an', ',', '▁but', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 22:55:20,825 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 22:55:20,825 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 22:55:20,825 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 22:55:20,825 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" I ▁am ▁the ▁king ▁of ▁J am an , ▁and ▁the ▁people ▁of ▁J am an an , ▁but ▁the ▁people ▁of ▁Judah , ▁but ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 22:55:20,825 - INFO - joeynmt.training - Example #1
2021-11-22 22:55:20,825 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 22:55:20,825 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 22:55:20,825 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 's', 's', 'u']
2021-11-22 22:55:20,825 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 22:55:20,825 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 22:55:20,825 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 22:55:20,825 - INFO - joeynmt.training - 	Hypothesis: ▁E s s u
2021-11-22 22:55:20,825 - INFO - joeynmt.training - Example #2
2021-11-22 22:55:20,825 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 22:55:20,826 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 22:55:20,826 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁9.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁to', '▁me', '.']
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁9. ▁I ▁am ▁not ▁not ▁not ▁not ▁to ▁you , ▁and ▁I ▁am ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁not ▁to ▁me .
2021-11-22 22:55:20,826 - INFO - joeynmt.training - Example #3
2021-11-22 22:55:20,826 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 22:55:20,826 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 22:55:20,826 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-22 22:55:20,826 - INFO - joeynmt.training - Example #6
2021-11-22 22:55:20,826 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 22:55:20,826 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 22:55:20,826 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁b', 'ir', 'th']
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 22:55:20,826 - INFO - joeynmt.training - 	Hypothesis: ▁b ir th
2021-11-22 22:55:20,826 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    24000: bleu:   1.46, loss: 103048.9219, ppl:  20.9629, duration: 330.8081s
2021-11-22 22:55:35,657 - INFO - joeynmt.training - Epoch   8, Step:    24100, Batch Loss:     2.884979, Tokens per Sec:     2129, Lr: 0.000100
2021-11-22 22:55:51,187 - INFO - joeynmt.training - Epoch   8, Step:    24200, Batch Loss:     3.009512, Tokens per Sec:     2064, Lr: 0.000100
2021-11-22 22:56:04,842 - INFO - joeynmt.training - Epoch   8, Step:    24300, Batch Loss:     2.906447, Tokens per Sec:     2245, Lr: 0.000100
2021-11-22 22:56:19,576 - INFO - joeynmt.training - Epoch   8, Step:    24400, Batch Loss:     3.041082, Tokens per Sec:     2162, Lr: 0.000100
2021-11-22 22:56:34,468 - INFO - joeynmt.training - Epoch   8, Step:    24500, Batch Loss:     3.108616, Tokens per Sec:     2129, Lr: 0.000100
2021-11-22 22:56:49,157 - INFO - joeynmt.training - Epoch   8, Step:    24600, Batch Loss:     2.931532, Tokens per Sec:     2103, Lr: 0.000100
2021-11-22 22:57:03,464 - INFO - joeynmt.training - Epoch   8, Step:    24700, Batch Loss:     2.934826, Tokens per Sec:     2151, Lr: 0.000100
2021-11-22 22:57:18,038 - INFO - joeynmt.training - Epoch   8, Step:    24800, Batch Loss:     2.943033, Tokens per Sec:     2146, Lr: 0.000100
2021-11-22 22:57:32,272 - INFO - joeynmt.training - Epoch   8, Step:    24900, Batch Loss:     3.036103, Tokens per Sec:     2226, Lr: 0.000100
2021-11-22 22:57:46,804 - INFO - joeynmt.training - Epoch   8, Step:    25000, Batch Loss:     2.948035, Tokens per Sec:     2202, Lr: 0.000100
2021-11-22 23:05:25,753 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 23:05:25,753 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 23:05:25,753 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 23:05:25,770 - INFO - joeynmt.training - Example #0
2021-11-22 23:05:25,770 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 23:05:25,770 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 23:05:25,770 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '4.', '▁"', 'W', 'hen', '▁you', '▁are', '▁the', '▁king', '▁of', '▁J', 'ose', 'ph', ',', '▁the', '▁people', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 23:05:25,770 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 23:05:25,770 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 23:05:25,770 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 23:05:25,770 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 4. ▁" W hen ▁you ▁are ▁the ▁king ▁of ▁J ose ph , ▁the ▁people ▁of ▁J ose ph , ▁but ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 23:05:25,770 - INFO - joeynmt.training - Example #1
2021-11-22 23:05:25,770 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 23:05:25,770 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 23:05:25,770 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 's', 'u']
2021-11-22 23:05:25,770 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Hypothesis: ▁E s u
2021-11-22 23:05:25,771 - INFO - joeynmt.training - Example #2
2021-11-22 23:05:25,771 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 23:05:25,771 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 23:05:25,771 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁9.', '▁"', 'W', 'hy', '▁are', '▁a', '▁man', '▁who', '▁are', '▁not', '▁in', '▁the', '▁truth', ',', '▁and', '▁I', '▁am', '▁not', '▁not', '▁not', '▁in', '▁the', '▁truth', '.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁in', '▁my', '▁own', '▁own', '▁own', '▁own', '.']
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁9. ▁" W hy ▁are ▁a ▁man ▁who ▁are ▁not ▁in ▁the ▁truth , ▁and ▁I ▁am ▁not ▁not ▁not ▁in ▁the ▁truth . ▁I ▁am ▁not ▁not ▁not ▁not ▁in ▁my ▁own ▁own ▁own ▁own .
2021-11-22 23:05:25,771 - INFO - joeynmt.training - Example #3
2021-11-22 23:05:25,771 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 23:05:25,771 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 23:05:25,771 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'uito']
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Hypothesis: ▁m uito
2021-11-22 23:05:25,771 - INFO - joeynmt.training - Example #6
2021-11-22 23:05:25,771 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 23:05:25,771 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 23:05:25,771 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'an']
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 23:05:25,771 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 23:05:25,772 - INFO - joeynmt.training - 	Hypothesis: ▁d an
2021-11-22 23:05:25,772 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    25000: bleu:   1.08, loss: 102552.3594, ppl:  20.6578, duration: 458.9678s
2021-11-22 23:05:41,539 - INFO - joeynmt.training - Epoch   8, Step:    25100, Batch Loss:     3.037297, Tokens per Sec:     2041, Lr: 0.000100
2021-11-22 23:05:56,073 - INFO - joeynmt.training - Epoch   8, Step:    25200, Batch Loss:     3.161366, Tokens per Sec:     2160, Lr: 0.000100
2021-11-22 23:06:11,711 - INFO - joeynmt.training - Epoch   8, Step:    25300, Batch Loss:     3.276073, Tokens per Sec:     2043, Lr: 0.000100
2021-11-22 23:06:25,743 - INFO - joeynmt.training - Epoch   8, Step:    25400, Batch Loss:     3.135872, Tokens per Sec:     2164, Lr: 0.000100
2021-11-22 23:06:39,830 - INFO - joeynmt.training - Epoch   8, Step:    25500, Batch Loss:     2.976306, Tokens per Sec:     2174, Lr: 0.000100
2021-11-22 23:06:53,551 - INFO - joeynmt.training - Epoch   8, Step:    25600, Batch Loss:     2.808969, Tokens per Sec:     2173, Lr: 0.000100
2021-11-22 23:07:08,389 - INFO - joeynmt.training - Epoch   8, Step:    25700, Batch Loss:     3.087275, Tokens per Sec:     2104, Lr: 0.000100
2021-11-22 23:07:23,101 - INFO - joeynmt.training - Epoch   8, Step:    25800, Batch Loss:     3.076822, Tokens per Sec:     2189, Lr: 0.000100
2021-11-22 23:07:37,702 - INFO - joeynmt.training - Epoch   8, Step:    25900, Batch Loss:     2.960078, Tokens per Sec:     2188, Lr: 0.000100
2021-11-22 23:07:52,428 - INFO - joeynmt.training - Epoch   8, Step:    26000, Batch Loss:     3.104432, Tokens per Sec:     2107, Lr: 0.000100
2021-11-22 23:12:33,586 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 23:12:33,586 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 23:12:33,586 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 23:12:33,597 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 23:12:34,420 - INFO - joeynmt.helpers - delete models/baseline_multilingual/22000.ckpt
2021-11-22 23:12:34,421 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/22000.ckpt
2021-11-22 23:12:34,421 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/22000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/22000.ckpt')
2021-11-22 23:12:34,477 - INFO - joeynmt.training - Example #0
2021-11-22 23:12:34,478 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 23:12:34,478 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 23:12:34,478 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'I', '▁am', '▁the', '▁king', '▁of', '▁J', 'am', 'an', ',', '▁but', '▁the', '▁people', '▁of', '▁J', 'am', 'an', 'an', 'an', ',', '▁but', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 23:12:34,478 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 23:12:34,478 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 23:12:34,478 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 23:12:34,479 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" I ▁am ▁the ▁king ▁of ▁J am an , ▁but ▁the ▁people ▁of ▁J am an an an , ▁but ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 23:12:34,479 - INFO - joeynmt.training - Example #1
2021-11-22 23:12:34,479 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 23:12:34,479 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 23:12:34,479 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'u']
2021-11-22 23:12:34,479 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 23:12:34,479 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 23:12:34,480 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 23:12:34,480 - INFO - joeynmt.training - 	Hypothesis: ▁E u
2021-11-22 23:12:34,480 - INFO - joeynmt.training - Example #2
2021-11-22 23:12:34,480 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 23:12:34,480 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 23:12:34,480 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁9.', '▁"', 'I', '▁am', '▁not', '▁not', '▁to', '▁you', ',', '▁but', '▁you', '▁are', '▁not', '▁not', '▁in', '▁your', '▁own', '▁own', '▁own', '.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁not', '▁to', '▁be', '▁a', 'ct', 'if', 'ul', 'y', '.']
2021-11-22 23:12:34,481 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 23:12:34,481 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 23:12:34,481 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 23:12:34,481 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁9. ▁" I ▁am ▁not ▁not ▁to ▁you , ▁but ▁you ▁are ▁not ▁not ▁in ▁your ▁own ▁own ▁own . ▁I ▁am ▁not ▁not ▁not ▁not ▁not ▁to ▁be ▁a ct if ul y .
2021-11-22 23:12:34,481 - INFO - joeynmt.training - Example #3
2021-11-22 23:12:34,481 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 23:12:34,482 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 23:12:34,482 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ão']
2021-11-22 23:12:34,482 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 23:12:34,482 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 23:12:34,482 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 23:12:34,482 - INFO - joeynmt.training - 	Hypothesis: ▁m ão
2021-11-22 23:12:34,482 - INFO - joeynmt.training - Example #6
2021-11-22 23:12:34,482 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 23:12:34,483 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 23:12:34,483 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁b', 'ir']
2021-11-22 23:12:34,483 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 23:12:34,483 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 23:12:34,483 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 23:12:34,483 - INFO - joeynmt.training - 	Hypothesis: ▁b ir
2021-11-22 23:12:34,484 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    26000: bleu:   1.91, loss: 101674.3828, ppl:  20.1291, duration: 282.0556s
2021-11-22 23:12:48,964 - INFO - joeynmt.training - Epoch   8, Step:    26100, Batch Loss:     3.003354, Tokens per Sec:     2263, Lr: 0.000100
2021-11-22 23:13:03,550 - INFO - joeynmt.training - Epoch   8, Step:    26200, Batch Loss:     3.035186, Tokens per Sec:     2198, Lr: 0.000100
2021-11-22 23:13:19,525 - INFO - joeynmt.training - Epoch   8, Step:    26300, Batch Loss:     3.259408, Tokens per Sec:     2026, Lr: 0.000100
2021-11-22 23:13:34,248 - INFO - joeynmt.training - Epoch   8, Step:    26400, Batch Loss:     3.003991, Tokens per Sec:     2071, Lr: 0.000100
2021-11-22 23:13:48,713 - INFO - joeynmt.training - Epoch   8, Step:    26500, Batch Loss:     2.995340, Tokens per Sec:     2189, Lr: 0.000100
2021-11-22 23:14:03,798 - INFO - joeynmt.training - Epoch   8, Step:    26600, Batch Loss:     2.978933, Tokens per Sec:     2047, Lr: 0.000100
2021-11-22 23:14:18,329 - INFO - joeynmt.training - Epoch   8, Step:    26700, Batch Loss:     3.102525, Tokens per Sec:     2201, Lr: 0.000100
2021-11-22 23:14:32,987 - INFO - joeynmt.training - Epoch   8, Step:    26800, Batch Loss:     3.064541, Tokens per Sec:     2155, Lr: 0.000100
2021-11-22 23:14:47,859 - INFO - joeynmt.training - Epoch   8, Step:    26900, Batch Loss:     2.965873, Tokens per Sec:     2173, Lr: 0.000100
2021-11-22 23:15:01,885 - INFO - joeynmt.training - Epoch   8, Step:    27000, Batch Loss:     2.988789, Tokens per Sec:     2127, Lr: 0.000100
2021-11-22 23:20:29,474 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 23:20:29,474 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 23:20:29,474 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 23:20:29,491 - INFO - joeynmt.training - Example #0
2021-11-22 23:20:29,492 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 23:20:29,492 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 23:20:29,492 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁"', 'I', '▁am', '▁the', '▁king', '▁of', '▁J', 'ose', 'ph', ',', '▁the', '▁people', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁" I ▁am ▁the ▁king ▁of ▁J ose ph , ▁the ▁people ▁of ▁J ose ph , ▁but ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 23:20:29,492 - INFO - joeynmt.training - Example #1
2021-11-22 23:20:29,492 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 23:20:29,492 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 23:20:29,492 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'o', 'R']
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Hypothesis: ▁G o R
2021-11-22 23:20:29,492 - INFO - joeynmt.training - Example #2
2021-11-22 23:20:29,492 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 23:20:29,492 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 23:20:29,492 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁13.', '▁I', '▁am', '▁not', '▁a', '▁man', '▁who', '▁had', '▁been', '▁been', '▁a', '▁man', '▁who', '▁had', '▁been', '▁done', '▁to', '▁me', '.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁a', '▁long', 'er', '▁than', 'k', 'y', '.']
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 23:20:29,492 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁13. ▁I ▁am ▁not ▁a ▁man ▁who ▁had ▁been ▁been ▁a ▁man ▁who ▁had ▁been ▁done ▁to ▁me . ▁I ▁am ▁not ▁not ▁not ▁a ▁long er ▁than k y .
2021-11-22 23:20:29,493 - INFO - joeynmt.training - Example #3
2021-11-22 23:20:29,493 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 23:20:29,493 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 23:20:29,493 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'uito']
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Hypothesis: ▁m uito
2021-11-22 23:20:29,493 - INFO - joeynmt.training - Example #6
2021-11-22 23:20:29,493 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 23:20:29,493 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 23:20:29,493 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 23:20:29,493 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-22 23:20:29,493 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step    27000: bleu:   1.64, loss: 101042.7266, ppl:  19.7572, duration: 327.6076s
2021-11-22 23:20:43,869 - INFO - joeynmt.training - Epoch   8, Step:    27100, Batch Loss:     2.900456, Tokens per Sec:     2247, Lr: 0.000100
2021-11-22 23:20:45,718 - INFO - joeynmt.training - Epoch   8: total training loss 10320.11
2021-11-22 23:20:45,718 - INFO - joeynmt.training - EPOCH 9
2021-11-22 23:20:58,482 - INFO - joeynmt.training - Epoch   9, Step:    27200, Batch Loss:     2.965805, Tokens per Sec:     2160, Lr: 0.000100
2021-11-22 23:21:13,413 - INFO - joeynmt.training - Epoch   9, Step:    27300, Batch Loss:     2.792240, Tokens per Sec:     2117, Lr: 0.000100
2021-11-22 23:21:27,246 - INFO - joeynmt.training - Epoch   9, Step:    27400, Batch Loss:     3.267181, Tokens per Sec:     2263, Lr: 0.000100
2021-11-22 23:21:41,747 - INFO - joeynmt.training - Epoch   9, Step:    27500, Batch Loss:     2.804717, Tokens per Sec:     2163, Lr: 0.000100
2021-11-22 23:21:56,679 - INFO - joeynmt.training - Epoch   9, Step:    27600, Batch Loss:     3.166401, Tokens per Sec:     2137, Lr: 0.000100
2021-11-22 23:22:11,642 - INFO - joeynmt.training - Epoch   9, Step:    27700, Batch Loss:     3.158153, Tokens per Sec:     2050, Lr: 0.000100
2021-11-22 23:22:26,486 - INFO - joeynmt.training - Epoch   9, Step:    27800, Batch Loss:     3.166928, Tokens per Sec:     2161, Lr: 0.000100
2021-11-22 23:22:40,782 - INFO - joeynmt.training - Epoch   9, Step:    27900, Batch Loss:     3.013998, Tokens per Sec:     2168, Lr: 0.000100
2021-11-22 23:22:55,646 - INFO - joeynmt.training - Epoch   9, Step:    28000, Batch Loss:     3.020429, Tokens per Sec:     2120, Lr: 0.000100
2021-11-22 23:30:06,668 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 23:30:06,668 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 23:30:06,668 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 23:30:06,687 - INFO - joeynmt.training - Example #0
2021-11-22 23:30:06,687 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 23:30:06,687 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 23:30:06,687 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁a', '▁man', '▁who', '▁are', '▁the', '▁people', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 23:30:06,687 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 23:30:06,687 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 23:30:06,687 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 23:30:06,687 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" W hen ▁you ▁have ▁been ▁a ▁man ▁who ▁are ▁the ▁people ▁of ▁J ose ph , ▁but ▁they ▁are ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 23:30:06,687 - INFO - joeynmt.training - Example #1
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'nt', 're', 'ira']
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Hypothesis: ▁E nt re ira
2021-11-22 23:30:06,688 - INFO - joeynmt.training - Example #2
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁19.', '▁"', 'W', 'hy', '▁are', '▁not', '▁a', '▁little', '▁man', '▁who', '▁are', '▁not', '▁not', '▁in', '▁the', '▁law', '▁of', '▁Christ', '.', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁in', '▁the', '▁law', '▁of', '▁my', '▁faith', 'ful', '.']
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁19. ▁" W hy ▁are ▁not ▁a ▁little ▁man ▁who ▁are ▁not ▁not ▁in ▁the ▁law ▁of ▁Christ . ▁I ▁am ▁not ▁not ▁not ▁not ▁in ▁the ▁law ▁of ▁my ▁faith ful .
2021-11-22 23:30:06,688 - INFO - joeynmt.training - Example #3
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'abe', 'ça']
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 23:30:06,688 - INFO - joeynmt.training - 	Hypothesis: ▁c abe ça
2021-11-22 23:30:06,688 - INFO - joeynmt.training - Example #6
2021-11-22 23:30:06,688 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 23:30:06,689 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 23:30:06,689 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁b', 'ran', 'k']
2021-11-22 23:30:06,689 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 23:30:06,689 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 23:30:06,689 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 23:30:06,689 - INFO - joeynmt.training - 	Hypothesis: ▁b ran k
2021-11-22 23:30:06,689 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    28000: bleu:   1.41, loss: 100425.2812, ppl:  19.4002, duration: 431.0420s
2021-11-22 23:30:21,122 - INFO - joeynmt.training - Epoch   9, Step:    28100, Batch Loss:     2.845728, Tokens per Sec:     2179, Lr: 0.000100
2021-11-22 23:30:35,929 - INFO - joeynmt.training - Epoch   9, Step:    28200, Batch Loss:     3.050347, Tokens per Sec:     2054, Lr: 0.000100
2021-11-22 23:30:50,871 - INFO - joeynmt.training - Epoch   9, Step:    28300, Batch Loss:     3.035550, Tokens per Sec:     2077, Lr: 0.000100
2021-11-22 23:31:05,415 - INFO - joeynmt.training - Epoch   9, Step:    28400, Batch Loss:     3.009951, Tokens per Sec:     2165, Lr: 0.000100
2021-11-22 23:31:19,945 - INFO - joeynmt.training - Epoch   9, Step:    28500, Batch Loss:     3.159684, Tokens per Sec:     2196, Lr: 0.000100
2021-11-22 23:31:34,558 - INFO - joeynmt.training - Epoch   9, Step:    28600, Batch Loss:     2.901441, Tokens per Sec:     2198, Lr: 0.000100
2021-11-22 23:31:49,570 - INFO - joeynmt.training - Epoch   9, Step:    28700, Batch Loss:     3.076952, Tokens per Sec:     2113, Lr: 0.000100
2021-11-22 23:32:04,622 - INFO - joeynmt.training - Epoch   9, Step:    28800, Batch Loss:     3.115334, Tokens per Sec:     2083, Lr: 0.000100
2021-11-22 23:32:19,336 - INFO - joeynmt.training - Epoch   9, Step:    28900, Batch Loss:     3.032560, Tokens per Sec:     2117, Lr: 0.000100
2021-11-22 23:32:33,804 - INFO - joeynmt.training - Epoch   9, Step:    29000, Batch Loss:     2.792351, Tokens per Sec:     2107, Lr: 0.000100
2021-11-22 23:36:51,677 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 23:36:51,677 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 23:36:51,677 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 23:36:51,688 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 23:36:52,502 - INFO - joeynmt.helpers - delete models/baseline_multilingual/26000.ckpt
2021-11-22 23:36:52,502 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/26000.ckpt
2021-11-22 23:36:52,502 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/26000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/26000.ckpt')
2021-11-22 23:36:52,564 - INFO - joeynmt.training - Example #0
2021-11-22 23:36:52,564 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 23:36:52,564 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 23:36:52,564 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'W', 'hen', '▁you', '▁are', '▁the', '▁king', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁are', '▁a', 'head', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.', '▁But', '▁they', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 23:36:52,564 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 23:36:52,565 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 23:36:52,565 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 23:36:52,565 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" W hen ▁you ▁are ▁the ▁king ▁of ▁J ose ph , ▁but ▁they ▁are ▁a head ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people . ▁But ▁they ▁are ▁the ▁people ▁of ▁the ▁people .
2021-11-22 23:36:52,565 - INFO - joeynmt.training - Example #1
2021-11-22 23:36:52,565 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 23:36:52,565 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 23:36:52,566 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 's', 's', 'per', 'a']
2021-11-22 23:36:52,566 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 23:36:52,566 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 23:36:52,566 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 23:36:52,566 - INFO - joeynmt.training - 	Hypothesis: ▁E s s per a
2021-11-22 23:36:52,566 - INFO - joeynmt.training - Example #2
2021-11-22 23:36:52,566 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 23:36:52,567 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 23:36:52,567 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁29.', '▁Then', '▁he', '▁said', ',', '▁"', 'I', '▁am', '▁not', '▁to', '▁you', ',', "▁'", 'I', '▁am', '▁not', '▁not', '▁a', 'ct', '▁of', '▁my', '▁faith', 'ful', '.', '▁I', '▁am', '▁not', '▁not', '▁a', 'ct', '▁of', '▁my', '▁faith', 'ful', '.']
2021-11-22 23:36:52,567 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 23:36:52,567 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 23:36:52,567 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 23:36:52,567 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁29. ▁Then ▁he ▁said , ▁" I ▁am ▁not ▁to ▁you , ▁' I ▁am ▁not ▁not ▁a ct ▁of ▁my ▁faith ful . ▁I ▁am ▁not ▁not ▁a ct ▁of ▁my ▁faith ful .
2021-11-22 23:36:52,567 - INFO - joeynmt.training - Example #3
2021-11-22 23:36:52,567 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 23:36:52,567 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 23:36:52,567 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'uito']
2021-11-22 23:36:52,567 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 23:36:52,567 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 23:36:52,567 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 23:36:52,567 - INFO - joeynmt.training - 	Hypothesis: ▁m uito
2021-11-22 23:36:52,568 - INFO - joeynmt.training - Example #6
2021-11-22 23:36:52,568 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 23:36:52,568 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 23:36:52,568 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-22 23:36:52,568 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 23:36:52,568 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 23:36:52,568 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 23:36:52,568 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-22 23:36:52,568 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    29000: bleu:   1.98, loss: 100263.3906, ppl:  19.3077, duration: 258.7638s
2021-11-22 23:37:06,798 - INFO - joeynmt.training - Epoch   9, Step:    29100, Batch Loss:     3.024421, Tokens per Sec:     2144, Lr: 0.000100
2021-11-22 23:37:21,525 - INFO - joeynmt.training - Epoch   9, Step:    29200, Batch Loss:     2.844711, Tokens per Sec:     2049, Lr: 0.000100
2021-11-22 23:37:36,203 - INFO - joeynmt.training - Epoch   9, Step:    29300, Batch Loss:     2.969703, Tokens per Sec:     2074, Lr: 0.000100
2021-11-22 23:37:50,952 - INFO - joeynmt.training - Epoch   9, Step:    29400, Batch Loss:     2.926867, Tokens per Sec:     2115, Lr: 0.000100
2021-11-22 23:38:05,222 - INFO - joeynmt.training - Epoch   9, Step:    29500, Batch Loss:     2.745772, Tokens per Sec:     2188, Lr: 0.000100
2021-11-22 23:38:19,754 - INFO - joeynmt.training - Epoch   9, Step:    29600, Batch Loss:     3.027060, Tokens per Sec:     2150, Lr: 0.000100
2021-11-22 23:38:34,634 - INFO - joeynmt.training - Epoch   9, Step:    29700, Batch Loss:     3.246535, Tokens per Sec:     2129, Lr: 0.000100
2021-11-22 23:38:48,547 - INFO - joeynmt.training - Epoch   9, Step:    29800, Batch Loss:     3.013738, Tokens per Sec:     2164, Lr: 0.000100
2021-11-22 23:39:03,866 - INFO - joeynmt.training - Epoch   9, Step:    29900, Batch Loss:     3.309335, Tokens per Sec:     2175, Lr: 0.000100
2021-11-22 23:39:18,154 - INFO - joeynmt.training - Epoch   9, Step:    30000, Batch Loss:     2.912215, Tokens per Sec:     2278, Lr: 0.000100
2021-11-22 23:42:49,940 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 23:42:49,940 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 23:42:49,940 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 23:42:49,951 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 23:42:50,777 - INFO - joeynmt.helpers - delete models/baseline_multilingual/29000.ckpt
2021-11-22 23:42:50,777 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/29000.ckpt
2021-11-22 23:42:50,777 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/29000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/29000.ckpt')
2021-11-22 23:42:50,833 - INFO - joeynmt.training - Example #0
2021-11-22 23:42:50,833 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 23:42:50,833 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 23:42:50,833 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁"', 'I', '▁am', '▁the', '▁Jews', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁the', '▁Jews', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 23:42:50,834 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 23:42:50,834 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 23:42:50,834 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 23:42:50,834 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁" I ▁am ▁the ▁Jews ▁of ▁J ose ph , ▁but ▁the ▁Jews , ▁but ▁they ▁are ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 23:42:50,834 - INFO - joeynmt.training - Example #1
2021-11-22 23:42:50,834 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 23:42:50,835 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 23:42:50,835 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'u']
2021-11-22 23:42:50,835 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 23:42:50,835 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 23:42:50,835 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 23:42:50,835 - INFO - joeynmt.training - 	Hypothesis: ▁E u
2021-11-22 23:42:50,835 - INFO - joeynmt.training - Example #2
2021-11-22 23:42:50,835 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 23:42:50,836 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 23:42:50,836 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁13.', '▁"', 'I', '▁am', '▁not', '▁to', '▁you', ',', '▁I', '▁am', '▁not', '▁not', '▁to', '▁you', ',', '▁I', '▁am', '▁not', '▁not', '▁with', '▁you', '.', '▁I', '▁am', '▁not', '▁not', '▁with', '▁you', ',', '▁I', '▁am', '▁not', '▁not', '▁with', '▁you', '.']
2021-11-22 23:42:50,836 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 23:42:50,836 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 23:42:50,836 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 23:42:50,836 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁13. ▁" I ▁am ▁not ▁to ▁you , ▁I ▁am ▁not ▁not ▁to ▁you , ▁I ▁am ▁not ▁not ▁with ▁you . ▁I ▁am ▁not ▁not ▁with ▁you , ▁I ▁am ▁not ▁not ▁with ▁you .
2021-11-22 23:42:50,836 - INFO - joeynmt.training - Example #3
2021-11-22 23:42:50,836 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 23:42:50,836 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 23:42:50,837 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-22 23:42:50,837 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 23:42:50,837 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 23:42:50,837 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 23:42:50,837 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-22 23:42:50,837 - INFO - joeynmt.training - Example #6
2021-11-22 23:42:50,837 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 23:42:50,837 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 23:42:50,837 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-22 23:42:50,837 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 23:42:50,837 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 23:42:50,837 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 23:42:50,837 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-22 23:42:50,838 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    30000: bleu:   2.48, loss: 99624.7812, ppl:  18.9470, duration: 212.6829s
2021-11-22 23:43:05,250 - INFO - joeynmt.training - Epoch   9, Step:    30100, Batch Loss:     2.996215, Tokens per Sec:     2118, Lr: 0.000100
2021-11-22 23:43:20,147 - INFO - joeynmt.training - Epoch   9, Step:    30200, Batch Loss:     2.945431, Tokens per Sec:     2234, Lr: 0.000100
2021-11-22 23:43:35,366 - INFO - joeynmt.training - Epoch   9, Step:    30300, Batch Loss:     2.806671, Tokens per Sec:     2222, Lr: 0.000100
2021-11-22 23:43:50,135 - INFO - joeynmt.training - Epoch   9, Step:    30400, Batch Loss:     2.976467, Tokens per Sec:     2129, Lr: 0.000100
2021-11-22 23:44:05,157 - INFO - joeynmt.training - Epoch   9, Step:    30500, Batch Loss:     2.857821, Tokens per Sec:     2079, Lr: 0.000100
2021-11-22 23:44:05,266 - INFO - joeynmt.training - Epoch   9: total training loss 10100.95
2021-11-22 23:44:05,266 - INFO - joeynmt.training - EPOCH 10
2021-11-22 23:44:20,018 - INFO - joeynmt.training - Epoch  10, Step:    30600, Batch Loss:     2.893757, Tokens per Sec:     2111, Lr: 0.000100
2021-11-22 23:44:34,907 - INFO - joeynmt.training - Epoch  10, Step:    30700, Batch Loss:     3.115487, Tokens per Sec:     2159, Lr: 0.000100
2021-11-22 23:44:49,978 - INFO - joeynmt.training - Epoch  10, Step:    30800, Batch Loss:     3.110035, Tokens per Sec:     2125, Lr: 0.000100
2021-11-22 23:45:05,218 - INFO - joeynmt.training - Epoch  10, Step:    30900, Batch Loss:     3.232808, Tokens per Sec:     1941, Lr: 0.000100
2021-11-22 23:45:18,767 - INFO - joeynmt.training - Epoch  10, Step:    31000, Batch Loss:     2.810538, Tokens per Sec:     2214, Lr: 0.000100
2021-11-22 23:51:00,580 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 23:51:00,580 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 23:51:00,580 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 23:51:00,601 - INFO - joeynmt.training - Example #0
2021-11-22 23:51:00,601 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 23:51:00,601 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 23:51:00,601 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'I', '▁am', '▁the', '▁time', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁the', '▁Jews', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" I ▁am ▁the ▁time ▁of ▁J ose ph , ▁but ▁the ▁Jews ▁of ▁J ose ph , ▁but ▁the ▁people ▁of ▁Judah , ▁but ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 23:51:00,602 - INFO - joeynmt.training - Example #1
2021-11-22 23:51:00,602 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 23:51:00,602 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 23:51:00,602 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'x', 'x', 'x', 'ual']
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Hypothesis: ▁E x x x ual
2021-11-22 23:51:00,602 - INFO - joeynmt.training - Example #2
2021-11-22 23:51:00,602 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 23:51:00,602 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 23:51:00,602 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁12.', '▁And', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁am', '▁not', '▁not', '▁to', '▁do', '▁what', '▁is', '▁not', '▁not', '▁to', '▁do', '.']
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁12. ▁And ▁I ▁am ▁not ▁to ▁you , ▁I ▁am ▁not ▁to ▁you , ▁and ▁I ▁am ▁not ▁not ▁to ▁do ▁what ▁is ▁not ▁not ▁to ▁do .
2021-11-22 23:51:00,602 - INFO - joeynmt.training - Example #3
2021-11-22 23:51:00,602 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 23:51:00,602 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 23:51:00,602 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ão']
2021-11-22 23:51:00,602 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 23:51:00,603 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 23:51:00,603 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 23:51:00,603 - INFO - joeynmt.training - 	Hypothesis: ▁m ão
2021-11-22 23:51:00,603 - INFO - joeynmt.training - Example #6
2021-11-22 23:51:00,603 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 23:51:00,603 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 23:51:00,603 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ix']
2021-11-22 23:51:00,603 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 23:51:00,603 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 23:51:00,603 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 23:51:00,603 - INFO - joeynmt.training - 	Hypothesis: ▁s ix
2021-11-22 23:51:00,603 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    31000: bleu:   2.06, loss: 98826.6016, ppl:  18.5057, duration: 341.8356s
2021-11-22 23:51:14,776 - INFO - joeynmt.training - Epoch  10, Step:    31100, Batch Loss:     2.809861, Tokens per Sec:     2308, Lr: 0.000100
2021-11-22 23:51:29,293 - INFO - joeynmt.training - Epoch  10, Step:    31200, Batch Loss:     2.880522, Tokens per Sec:     2160, Lr: 0.000100
2021-11-22 23:51:43,902 - INFO - joeynmt.training - Epoch  10, Step:    31300, Batch Loss:     3.116665, Tokens per Sec:     2172, Lr: 0.000100
2021-11-22 23:51:58,900 - INFO - joeynmt.training - Epoch  10, Step:    31400, Batch Loss:     2.871534, Tokens per Sec:     2096, Lr: 0.000100
2021-11-22 23:52:13,881 - INFO - joeynmt.training - Epoch  10, Step:    31500, Batch Loss:     3.191994, Tokens per Sec:     2085, Lr: 0.000100
2021-11-22 23:52:28,520 - INFO - joeynmt.training - Epoch  10, Step:    31600, Batch Loss:     2.667015, Tokens per Sec:     2201, Lr: 0.000100
2021-11-22 23:52:43,078 - INFO - joeynmt.training - Epoch  10, Step:    31700, Batch Loss:     2.844175, Tokens per Sec:     2137, Lr: 0.000100
2021-11-22 23:52:58,546 - INFO - joeynmt.training - Epoch  10, Step:    31800, Batch Loss:     2.888669, Tokens per Sec:     2178, Lr: 0.000100
2021-11-22 23:53:13,925 - INFO - joeynmt.training - Epoch  10, Step:    31900, Batch Loss:     2.914645, Tokens per Sec:     2047, Lr: 0.000100
2021-11-22 23:53:28,629 - INFO - joeynmt.training - Epoch  10, Step:    32000, Batch Loss:     2.715003, Tokens per Sec:     2161, Lr: 0.000100
2021-11-22 23:56:08,211 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-22 23:56:08,211 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-22 23:56:08,211 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-22 23:56:08,222 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-22 23:56:09,119 - INFO - joeynmt.helpers - delete models/baseline_multilingual/30000.ckpt
2021-11-22 23:56:09,127 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/30000.ckpt
2021-11-22 23:56:09,134 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/30000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/30000.ckpt')
2021-11-22 23:56:09,213 - INFO - joeynmt.training - Example #0
2021-11-22 23:56:09,213 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-22 23:56:09,214 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-22 23:56:09,214 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'I', '▁am', '▁the', '▁Jews', ',', '▁but', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-22 23:56:09,214 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-22 23:56:09,214 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-22 23:56:09,214 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-22 23:56:09,214 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" I ▁am ▁the ▁Jews , ▁but ▁you ▁are ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁are ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-22 23:56:09,215 - INFO - joeynmt.training - Example #1
2021-11-22 23:56:09,215 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-22 23:56:09,215 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-22 23:56:09,215 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 's', 'per', 'a']
2021-11-22 23:56:09,215 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-22 23:56:09,215 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-22 23:56:09,215 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-22 23:56:09,215 - INFO - joeynmt.training - 	Hypothesis: ▁E s per a
2021-11-22 23:56:09,216 - INFO - joeynmt.training - Example #2
2021-11-22 23:56:09,216 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-22 23:56:09,216 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-22 23:56:09,216 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁12.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁have', '▁been', '▁a', 'ct', '▁of', '▁Christ', '.']
2021-11-22 23:56:09,216 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-22 23:56:09,216 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-22 23:56:09,216 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-22 23:56:09,217 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁12. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁I ▁am ▁not ▁to ▁you , ▁and ▁I ▁have ▁been ▁a ct ▁of ▁Christ .
2021-11-22 23:56:09,217 - INFO - joeynmt.training - Example #3
2021-11-22 23:56:09,217 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-22 23:56:09,217 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-22 23:56:09,217 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-22 23:56:09,217 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-22 23:56:09,217 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-22 23:56:09,218 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-22 23:56:09,218 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-22 23:56:09,218 - INFO - joeynmt.training - Example #6
2021-11-22 23:56:09,218 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-22 23:56:09,218 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-22 23:56:09,218 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-22 23:56:09,218 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-22 23:56:09,218 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-22 23:56:09,219 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-22 23:56:09,219 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-22 23:56:09,219 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    32000: bleu:   2.90, loss: 98491.2812, ppl:  18.3234, duration: 160.5891s
2021-11-22 23:56:23,607 - INFO - joeynmt.training - Epoch  10, Step:    32100, Batch Loss:     3.136347, Tokens per Sec:     2162, Lr: 0.000100
2021-11-22 23:56:37,730 - INFO - joeynmt.training - Epoch  10, Step:    32200, Batch Loss:     2.990012, Tokens per Sec:     2133, Lr: 0.000100
2021-11-22 23:56:52,093 - INFO - joeynmt.training - Epoch  10, Step:    32300, Batch Loss:     2.887882, Tokens per Sec:     2176, Lr: 0.000100
2021-11-22 23:57:06,488 - INFO - joeynmt.training - Epoch  10, Step:    32400, Batch Loss:     3.089236, Tokens per Sec:     2081, Lr: 0.000100
2021-11-22 23:57:21,884 - INFO - joeynmt.training - Epoch  10, Step:    32500, Batch Loss:     2.747675, Tokens per Sec:     2149, Lr: 0.000100
2021-11-22 23:57:36,024 - INFO - joeynmt.training - Epoch  10, Step:    32600, Batch Loss:     2.784556, Tokens per Sec:     2170, Lr: 0.000100
2021-11-22 23:57:51,474 - INFO - joeynmt.training - Epoch  10, Step:    32700, Batch Loss:     2.886707, Tokens per Sec:     2037, Lr: 0.000100
2021-11-22 23:58:06,257 - INFO - joeynmt.training - Epoch  10, Step:    32800, Batch Loss:     2.902718, Tokens per Sec:     2113, Lr: 0.000100
2021-11-22 23:58:21,137 - INFO - joeynmt.training - Epoch  10, Step:    32900, Batch Loss:     2.786296, Tokens per Sec:     2211, Lr: 0.000100
2021-11-22 23:58:36,120 - INFO - joeynmt.training - Epoch  10, Step:    33000, Batch Loss:     2.978729, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 00:02:47,893 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:02:47,893 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:02:47,893 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:02:47,945 - INFO - joeynmt.training - Example #0
2021-11-23 00:02:47,945 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:02:47,945 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:02:47,945 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'I', '▁am', '▁the', '▁lead', 'ing', '▁of', '▁the', '▁Temple', '▁of', '▁J', 'am', 'an', ',', '▁but', '▁the', '▁people', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 00:02:47,945 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:02:47,945 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:02:47,946 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:02:47,946 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" I ▁am ▁the ▁lead ing ▁of ▁the ▁Temple ▁of ▁J am an , ▁but ▁the ▁people ▁of ▁J ose ph , ▁but ▁they ▁are ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 00:02:47,946 - INFO - joeynmt.training - Example #1
2021-11-23 00:02:47,946 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:02:47,946 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:02:47,946 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 00:02:47,946 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:02:47,946 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:02:47,946 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:02:47,946 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 00:02:47,947 - INFO - joeynmt.training - Example #2
2021-11-23 00:02:47,947 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:02:47,947 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:02:47,947 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁18.', '▁Then', '▁I', '▁am', '▁not', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁am', '▁not', '▁not', '▁a', 'ct', '▁of', '▁my', '▁own', '▁own', '▁way', '.']
2021-11-23 00:02:47,947 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:02:47,947 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:02:47,947 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:02:47,947 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁18. ▁Then ▁I ▁am ▁not ▁not ▁to ▁you , ▁and ▁I ▁am ▁not ▁not ▁a ct ▁of ▁my ▁own ▁own ▁way .
2021-11-23 00:02:47,947 - INFO - joeynmt.training - Example #3
2021-11-23 00:02:47,947 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:02:47,948 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:02:47,948 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'uito']
2021-11-23 00:02:47,948 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:02:47,948 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:02:47,948 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:02:47,948 - INFO - joeynmt.training - 	Hypothesis: ▁m uito
2021-11-23 00:02:47,948 - INFO - joeynmt.training - Example #6
2021-11-23 00:02:47,948 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:02:47,948 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:02:47,948 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 00:02:47,948 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:02:47,948 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:02:47,949 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:02:47,949 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 00:02:47,949 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    33000: bleu:   2.44, loss: 97863.0938, ppl:  17.9867, duration: 251.8280s
2021-11-23 00:03:02,985 - INFO - joeynmt.training - Epoch  10, Step:    33100, Batch Loss:     2.836081, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 00:03:18,127 - INFO - joeynmt.training - Epoch  10, Step:    33200, Batch Loss:     2.890517, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 00:03:32,420 - INFO - joeynmt.training - Epoch  10, Step:    33300, Batch Loss:     2.857381, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 00:03:47,547 - INFO - joeynmt.training - Epoch  10, Step:    33400, Batch Loss:     2.818852, Tokens per Sec:     2071, Lr: 0.000100
2021-11-23 00:04:01,910 - INFO - joeynmt.training - Epoch  10, Step:    33500, Batch Loss:     3.132354, Tokens per Sec:     2223, Lr: 0.000100
2021-11-23 00:04:16,231 - INFO - joeynmt.training - Epoch  10, Step:    33600, Batch Loss:     2.844792, Tokens per Sec:     2129, Lr: 0.000100
2021-11-23 00:04:30,590 - INFO - joeynmt.training - Epoch  10, Step:    33700, Batch Loss:     2.792246, Tokens per Sec:     2237, Lr: 0.000100
2021-11-23 00:04:43,826 - INFO - joeynmt.training - Epoch  10, Step:    33800, Batch Loss:     2.932533, Tokens per Sec:     2163, Lr: 0.000100
2021-11-23 00:04:57,036 - INFO - joeynmt.training - Epoch  10: total training loss 9901.06
2021-11-23 00:04:57,036 - INFO - joeynmt.training - EPOCH 11
2021-11-23 00:04:58,718 - INFO - joeynmt.training - Epoch  11, Step:    33900, Batch Loss:     2.962524, Tokens per Sec:     1926, Lr: 0.000100
2021-11-23 00:05:13,471 - INFO - joeynmt.training - Epoch  11, Step:    34000, Batch Loss:     2.662839, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 00:09:18,047 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:09:18,048 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:09:18,048 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:09:18,077 - INFO - joeynmt.training - Example #0
2021-11-23 00:09:18,078 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:09:18,078 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:09:18,078 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '2.', '▁"', 'I', '▁am', '▁the', '▁Jewish', '▁leaders', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁are', '▁a', '▁c', 'reat', 'ed', '▁by', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.', '▁But', '▁they', '▁are', '▁a', '▁c', 'reat', 'ed', '.']
2021-11-23 00:09:18,078 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:09:18,078 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:09:18,078 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:09:18,078 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 2. ▁" I ▁am ▁the ▁Jewish ▁leaders ▁of ▁J ose ph , ▁but ▁they ▁are ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁are ▁a ▁c reat ed ▁by ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people . ▁But ▁they ▁are ▁a ▁c reat ed .
2021-11-23 00:09:18,078 - INFO - joeynmt.training - Example #1
2021-11-23 00:09:18,078 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:09:18,078 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:09:18,078 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'u']
2021-11-23 00:09:18,078 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:09:18,078 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:09:18,078 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:09:18,078 - INFO - joeynmt.training - 	Hypothesis: ▁E u
2021-11-23 00:09:18,078 - INFO - joeynmt.training - Example #2
2021-11-23 00:09:18,078 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:09:18,079 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:09:18,079 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁8.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁you', '▁are', '▁not', '▁to', '▁you', ',', '▁for', '▁you', '▁are', '▁not', '▁to', '▁do', '▁what', '▁I', '▁am', '▁not', '▁not', '▁not', '▁not', '▁to', '▁do', '▁what', '▁is', '▁not', '▁not', '▁not', '▁not', '▁not', '▁not', '▁to', '▁do', '.']
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁8. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁you ▁are ▁not ▁to ▁you , ▁for ▁you ▁are ▁not ▁to ▁do ▁what ▁I ▁am ▁not ▁not ▁not ▁not ▁to ▁do ▁what ▁is ▁not ▁not ▁not ▁not ▁not ▁not ▁to ▁do .
2021-11-23 00:09:18,079 - INFO - joeynmt.training - Example #3
2021-11-23 00:09:18,079 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:09:18,079 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:09:18,079 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'uito']
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Hypothesis: ▁m uito
2021-11-23 00:09:18,079 - INFO - joeynmt.training - Example #6
2021-11-23 00:09:18,079 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:09:18,079 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:09:18,079 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:09:18,079 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:09:18,080 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:09:18,080 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 00:09:18,080 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    34000: bleu:   2.67, loss: 97359.3125, ppl:  17.7211, duration: 244.6079s
2021-11-23 00:09:32,568 - INFO - joeynmt.training - Epoch  11, Step:    34100, Batch Loss:     2.935157, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 00:09:47,543 - INFO - joeynmt.training - Epoch  11, Step:    34200, Batch Loss:     2.557833, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 00:10:01,442 - INFO - joeynmt.training - Epoch  11, Step:    34300, Batch Loss:     3.012911, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 00:10:16,210 - INFO - joeynmt.training - Epoch  11, Step:    34400, Batch Loss:     3.093203, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 00:10:31,054 - INFO - joeynmt.training - Epoch  11, Step:    34500, Batch Loss:     2.924934, Tokens per Sec:     2000, Lr: 0.000100
2021-11-23 00:10:46,570 - INFO - joeynmt.training - Epoch  11, Step:    34600, Batch Loss:     2.826487, Tokens per Sec:     2040, Lr: 0.000100
2021-11-23 00:11:01,043 - INFO - joeynmt.training - Epoch  11, Step:    34700, Batch Loss:     2.993355, Tokens per Sec:     2082, Lr: 0.000100
2021-11-23 00:11:15,927 - INFO - joeynmt.training - Epoch  11, Step:    34800, Batch Loss:     2.865008, Tokens per Sec:     2068, Lr: 0.000100
2021-11-23 00:11:30,938 - INFO - joeynmt.training - Epoch  11, Step:    34900, Batch Loss:     3.101880, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 00:11:45,425 - INFO - joeynmt.training - Epoch  11, Step:    35000, Batch Loss:     2.801629, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 00:15:27,679 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:15:27,679 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:15:27,679 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:15:27,690 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 00:15:28,597 - INFO - joeynmt.helpers - delete models/baseline_multilingual/32000.ckpt
2021-11-23 00:15:28,610 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/32000.ckpt
2021-11-23 00:15:28,617 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/32000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/32000.ckpt')
2021-11-23 00:15:28,688 - INFO - joeynmt.training - Example #0
2021-11-23 00:15:28,688 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:15:28,689 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:15:28,689 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'A', 'n', "'", 't', '▁you', '▁the', '▁lead', 'ing', '▁priests', '▁and', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 00:15:28,689 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:15:28,689 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:15:28,689 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:15:28,689 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" A n ' t ▁you ▁the ▁lead ing ▁priests ▁and ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 00:15:28,690 - INFO - joeynmt.training - Example #1
2021-11-23 00:15:28,690 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:15:28,690 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:15:28,690 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁S', 'ur', 'dos']
2021-11-23 00:15:28,690 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:15:28,690 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:15:28,690 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:15:28,690 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁S ur dos
2021-11-23 00:15:28,691 - INFO - joeynmt.training - Example #2
2021-11-23 00:15:28,691 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:15:28,691 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:15:28,691 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁12.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁am', '▁not', '▁to', '▁do', '▁what', '▁I', '▁am', '▁not', '▁to', '▁do', '.', '▁I', '▁am', '▁not', '▁not', '▁to', '▁do', '▁what', '▁I', '▁am', '▁not', '▁not', '▁not', '▁to', '▁do', '.']
2021-11-23 00:15:28,691 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:15:28,691 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:15:28,691 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:15:28,692 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁12. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁and ▁I ▁am ▁not ▁to ▁do ▁what ▁I ▁am ▁not ▁to ▁do . ▁I ▁am ▁not ▁not ▁to ▁do ▁what ▁I ▁am ▁not ▁not ▁not ▁to ▁do .
2021-11-23 00:15:28,692 - INFO - joeynmt.training - Example #3
2021-11-23 00:15:28,692 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:15:28,692 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:15:28,692 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 00:15:28,692 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:15:28,692 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:15:28,693 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:15:28,693 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 00:15:28,693 - INFO - joeynmt.training - Example #6
2021-11-23 00:15:28,693 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:15:28,693 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:15:28,693 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 00:15:28,693 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:15:28,693 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:15:28,694 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:15:28,694 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 00:15:28,694 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    35000: bleu:   2.99, loss: 96956.1484, ppl:  17.5114, duration: 223.2684s
2021-11-23 00:15:43,851 - INFO - joeynmt.training - Epoch  11, Step:    35100, Batch Loss:     2.964445, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 00:15:59,075 - INFO - joeynmt.training - Epoch  11, Step:    35200, Batch Loss:     2.970932, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 00:16:13,970 - INFO - joeynmt.training - Epoch  11, Step:    35300, Batch Loss:     2.992368, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 00:16:28,267 - INFO - joeynmt.training - Epoch  11, Step:    35400, Batch Loss:     2.889642, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 00:16:42,618 - INFO - joeynmt.training - Epoch  11, Step:    35500, Batch Loss:     2.879137, Tokens per Sec:     2090, Lr: 0.000100
2021-11-23 00:16:57,226 - INFO - joeynmt.training - Epoch  11, Step:    35600, Batch Loss:     2.821510, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 00:17:11,883 - INFO - joeynmt.training - Epoch  11, Step:    35700, Batch Loss:     2.940624, Tokens per Sec:     2200, Lr: 0.000100
2021-11-23 00:17:26,865 - INFO - joeynmt.training - Epoch  11, Step:    35800, Batch Loss:     2.891613, Tokens per Sec:     2085, Lr: 0.000100
2021-11-23 00:17:40,986 - INFO - joeynmt.training - Epoch  11, Step:    35900, Batch Loss:     2.772903, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 00:17:55,736 - INFO - joeynmt.training - Epoch  11, Step:    36000, Batch Loss:     2.734694, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 00:22:34,753 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:22:34,753 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:22:34,753 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:22:34,769 - INFO - joeynmt.training - Example #0
2021-11-23 00:22:34,769 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:22:34,770 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:22:34,770 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'I', '▁am', '▁the', '▁lead', 'ing', '▁of', '▁the', '▁Temple', '▁of', '▁Judah', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" I ▁am ▁the ▁lead ing ▁of ▁the ▁Temple ▁of ▁Judah , ▁but ▁they ▁are ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 00:22:34,770 - INFO - joeynmt.training - Example #1
2021-11-23 00:22:34,770 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:22:34,770 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:22:34,770 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 's', 'per', 'a']
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Hypothesis: ▁E s per a
2021-11-23 00:22:34,770 - INFO - joeynmt.training - Example #2
2021-11-23 00:22:34,770 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:22:34,770 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:22:34,770 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁12.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁you', '▁are', '▁not', '▁a', 'ct', '▁of', '▁my', 'self', ',', '▁and', '▁I', '▁am', '▁not', '▁a', 'ct', 'if', 'ul', 'y', '.']
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:22:34,770 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁12. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁you ▁are ▁not ▁a ct ▁of ▁my self , ▁and ▁I ▁am ▁not ▁a ct if ul y .
2021-11-23 00:22:34,770 - INFO - joeynmt.training - Example #3
2021-11-23 00:22:34,771 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:22:34,771 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:22:34,771 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 00:22:34,771 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:22:34,771 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:22:34,771 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:22:34,771 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 00:22:34,771 - INFO - joeynmt.training - Example #6
2021-11-23 00:22:34,771 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:22:34,771 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:22:34,771 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 00:22:34,771 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:22:34,771 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:22:34,771 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:22:34,771 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 00:22:34,771 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    36000: bleu:   2.87, loss: 96583.0469, ppl:  17.3195, duration: 279.0344s
2021-11-23 00:22:49,655 - INFO - joeynmt.training - Epoch  11, Step:    36100, Batch Loss:     2.733314, Tokens per Sec:     2164, Lr: 0.000100
2021-11-23 00:23:04,238 - INFO - joeynmt.training - Epoch  11, Step:    36200, Batch Loss:     2.847512, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 00:23:18,969 - INFO - joeynmt.training - Epoch  11, Step:    36300, Batch Loss:     3.009022, Tokens per Sec:     2064, Lr: 0.000100
2021-11-23 00:23:32,907 - INFO - joeynmt.training - Epoch  11, Step:    36400, Batch Loss:     2.974445, Tokens per Sec:     2268, Lr: 0.000100
2021-11-23 00:23:47,461 - INFO - joeynmt.training - Epoch  11, Step:    36500, Batch Loss:     2.813227, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 00:24:01,662 - INFO - joeynmt.training - Epoch  11, Step:    36600, Batch Loss:     2.782699, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 00:24:16,536 - INFO - joeynmt.training - Epoch  11, Step:    36700, Batch Loss:     2.967441, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 00:24:31,702 - INFO - joeynmt.training - Epoch  11, Step:    36800, Batch Loss:     2.739035, Tokens per Sec:     2016, Lr: 0.000100
2021-11-23 00:24:46,147 - INFO - joeynmt.training - Epoch  11, Step:    36900, Batch Loss:     2.958606, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 00:25:01,290 - INFO - joeynmt.training - Epoch  11, Step:    37000, Batch Loss:     3.064267, Tokens per Sec:     2157, Lr: 0.000100
2021-11-23 00:29:45,867 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:29:45,867 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:29:45,867 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:29:45,884 - INFO - joeynmt.training - Example #0
2021-11-23 00:29:45,884 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:29:45,884 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:29:45,884 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁"', 'I', '▁am', '▁the', '▁time', '▁of', '▁J', 'ord', 'an', 'an', ',', '▁the', '▁lead', 'ing', '▁priests', ',', '▁but', '▁they', '▁were', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.', '▁But', '▁they', '▁were', '▁destroy', 'ed', '.']
2021-11-23 00:29:45,884 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:29:45,884 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:29:45,884 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:29:45,884 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁" I ▁am ▁the ▁time ▁of ▁J ord an an , ▁the ▁lead ing ▁priests , ▁but ▁they ▁were ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people . ▁But ▁they ▁were ▁destroy ed .
2021-11-23 00:29:45,884 - INFO - joeynmt.training - Example #1
2021-11-23 00:29:45,884 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:29:45,884 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:29:45,884 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁S', 'ur', 'dos']
2021-11-23 00:29:45,884 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:29:45,884 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:29:45,884 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁S ur dos
2021-11-23 00:29:45,885 - INFO - joeynmt.training - Example #2
2021-11-23 00:29:45,885 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:29:45,885 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:29:45,885 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁17.', '▁Then', '▁I', '▁am', '▁not', '▁a', '▁long', 'er', '▁to', '▁you', ',', '▁and', '▁I', '▁have', '▁been', '▁given', '▁you', '▁to', '▁do', '▁what', '▁is', '▁not', '▁a', 'ct', '▁of', '▁Christ', '.']
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁17. ▁Then ▁I ▁am ▁not ▁a ▁long er ▁to ▁you , ▁and ▁I ▁have ▁been ▁given ▁you ▁to ▁do ▁what ▁is ▁not ▁a ct ▁of ▁Christ .
2021-11-23 00:29:45,885 - INFO - joeynmt.training - Example #3
2021-11-23 00:29:45,885 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:29:45,885 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:29:45,885 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 00:29:45,885 - INFO - joeynmt.training - Example #6
2021-11-23 00:29:45,885 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:29:45,885 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:29:45,885 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:29:45,885 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 00:29:45,886 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    37000: bleu:   2.88, loss: 95628.8516, ppl:  16.8383, duration: 284.5947s
2021-11-23 00:30:00,631 - INFO - joeynmt.training - Epoch  11, Step:    37100, Batch Loss:     2.902436, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 00:30:15,532 - INFO - joeynmt.training - Epoch  11, Step:    37200, Batch Loss:     2.866549, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 00:30:27,119 - INFO - joeynmt.training - Epoch  11: total training loss 9719.80
2021-11-23 00:30:27,119 - INFO - joeynmt.training - EPOCH 12
2021-11-23 00:30:30,446 - INFO - joeynmt.training - Epoch  12, Step:    37300, Batch Loss:     2.942917, Tokens per Sec:     2026, Lr: 0.000100
2021-11-23 00:30:45,690 - INFO - joeynmt.training - Epoch  12, Step:    37400, Batch Loss:     2.926092, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 00:31:00,417 - INFO - joeynmt.training - Epoch  12, Step:    37500, Batch Loss:     2.528802, Tokens per Sec:     2164, Lr: 0.000100
2021-11-23 00:31:14,802 - INFO - joeynmt.training - Epoch  12, Step:    37600, Batch Loss:     2.711508, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 00:31:29,457 - INFO - joeynmt.training - Epoch  12, Step:    37700, Batch Loss:     2.687687, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 00:31:43,672 - INFO - joeynmt.training - Epoch  12, Step:    37800, Batch Loss:     2.838158, Tokens per Sec:     2189, Lr: 0.000100
2021-11-23 00:31:58,010 - INFO - joeynmt.training - Epoch  12, Step:    37900, Batch Loss:     2.863841, Tokens per Sec:     2140, Lr: 0.000100
2021-11-23 00:32:11,595 - INFO - joeynmt.training - Epoch  12, Step:    38000, Batch Loss:     2.862820, Tokens per Sec:     2286, Lr: 0.000100
2021-11-23 00:36:58,114 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:36:58,114 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:36:58,114 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:36:58,145 - INFO - joeynmt.training - Example #0
2021-11-23 00:36:58,145 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:36:58,146 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:36:58,146 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁"', 'I', '▁am', '▁the', '▁time', '▁of', '▁J', 'ose', 'ph', ',', '▁the', '▁people', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 00:36:58,146 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:36:58,146 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:36:58,146 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:36:58,146 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁" I ▁am ▁the ▁time ▁of ▁J ose ph , ▁the ▁people ▁of ▁J ose ph , ▁but ▁they ▁are ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁are ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 00:36:58,146 - INFO - joeynmt.training - Example #1
2021-11-23 00:36:58,146 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:36:58,146 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:36:58,146 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁S', 'ur', 'dos']
2021-11-23 00:36:58,146 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:36:58,146 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:36:58,146 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:36:58,147 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁S ur dos
2021-11-23 00:36:58,147 - INFO - joeynmt.training - Example #2
2021-11-23 00:36:58,147 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:36:58,147 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:36:58,147 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁I', '▁am', '▁not', '▁a', '▁long', 'er', '▁than', '▁you', ',', '▁and', '▁I', '▁am', '▁not', '▁not', '▁in', '▁your', 'selves', '.']
2021-11-23 00:36:58,147 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:36:58,147 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:36:58,147 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:36:58,147 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁I ▁am ▁not ▁a ▁long er ▁than ▁you , ▁and ▁I ▁am ▁not ▁not ▁in ▁your selves .
2021-11-23 00:36:58,147 - INFO - joeynmt.training - Example #3
2021-11-23 00:36:58,147 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:36:58,147 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:36:58,147 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'uito']
2021-11-23 00:36:58,147 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:36:58,147 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:36:58,148 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:36:58,148 - INFO - joeynmt.training - 	Hypothesis: ▁m uito
2021-11-23 00:36:58,148 - INFO - joeynmt.training - Example #6
2021-11-23 00:36:58,148 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:36:58,148 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:36:58,148 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 00:36:58,148 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:36:58,148 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:36:58,148 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:36:58,148 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 00:36:58,148 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    38000: bleu:   2.85, loss: 95465.1406, ppl:  16.7571, duration: 286.5533s
2021-11-23 00:37:11,922 - INFO - joeynmt.training - Epoch  12, Step:    38100, Batch Loss:     2.807239, Tokens per Sec:     2243, Lr: 0.000100
2021-11-23 00:37:26,839 - INFO - joeynmt.training - Epoch  12, Step:    38200, Batch Loss:     3.132823, Tokens per Sec:     2020, Lr: 0.000100
2021-11-23 00:37:41,121 - INFO - joeynmt.training - Epoch  12, Step:    38300, Batch Loss:     2.785268, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 00:37:55,648 - INFO - joeynmt.training - Epoch  12, Step:    38400, Batch Loss:     2.621101, Tokens per Sec:     2138, Lr: 0.000100
2021-11-23 00:38:10,662 - INFO - joeynmt.training - Epoch  12, Step:    38500, Batch Loss:     2.578286, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 00:38:25,870 - INFO - joeynmt.training - Epoch  12, Step:    38600, Batch Loss:     2.847191, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 00:38:40,492 - INFO - joeynmt.training - Epoch  12, Step:    38700, Batch Loss:     2.962743, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 00:38:54,838 - INFO - joeynmt.training - Epoch  12, Step:    38800, Batch Loss:     2.815466, Tokens per Sec:     2202, Lr: 0.000100
2021-11-23 00:39:09,357 - INFO - joeynmt.training - Epoch  12, Step:    38900, Batch Loss:     2.892148, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 00:39:23,766 - INFO - joeynmt.training - Epoch  12, Step:    39000, Batch Loss:     2.789266, Tokens per Sec:     2196, Lr: 0.000100
2021-11-23 00:43:19,880 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:43:19,880 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:43:19,880 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:43:19,891 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 00:43:20,705 - INFO - joeynmt.helpers - delete models/baseline_multilingual/35000.ckpt
2021-11-23 00:43:20,706 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/35000.ckpt
2021-11-23 00:43:20,706 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/35000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/35000.ckpt')
2021-11-23 00:43:20,766 - INFO - joeynmt.training - Example #0
2021-11-23 00:43:20,766 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:43:20,766 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:43:20,767 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '8.', '▁"', 'I', '▁am', '▁the', '▁time', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁are', '▁not', '▁a', '▁c', 'ross', '▁from', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 00:43:20,767 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:43:20,767 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:43:20,767 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:43:20,767 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 8. ▁" I ▁am ▁the ▁time ▁of ▁J ose ph , ▁but ▁they ▁are ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁are ▁not ▁a ▁c ross ▁from ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 00:43:20,767 - INFO - joeynmt.training - Example #1
2021-11-23 00:43:20,767 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:43:20,767 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:43:20,768 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'nt', 're', 'ira']
2021-11-23 00:43:20,768 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:43:20,768 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:43:20,768 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:43:20,768 - INFO - joeynmt.training - 	Hypothesis: ▁E nt re ira
2021-11-23 00:43:20,768 - INFO - joeynmt.training - Example #2
2021-11-23 00:43:20,768 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:43:20,768 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:43:20,768 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁have', '▁been', '▁given', '▁you', '▁to', '▁you', '▁to', '▁help', '▁you', '▁to', '▁help', '▁you', '.']
2021-11-23 00:43:20,769 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:43:20,769 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:43:20,769 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:43:20,769 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁and ▁I ▁have ▁been ▁given ▁you ▁to ▁you ▁to ▁help ▁you ▁to ▁help ▁you .
2021-11-23 00:43:20,769 - INFO - joeynmt.training - Example #3
2021-11-23 00:43:20,769 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:43:20,769 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:43:20,769 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 00:43:20,769 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:43:20,769 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:43:20,770 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:43:20,770 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 00:43:20,770 - INFO - joeynmt.training - Example #6
2021-11-23 00:43:20,770 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:43:20,770 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:43:20,770 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 00:43:20,770 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:43:20,770 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:43:20,770 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:43:20,770 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 00:43:20,771 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    39000: bleu:   3.63, loss: 94908.4844, ppl:  16.4840, duration: 237.0044s
2021-11-23 00:43:35,122 - INFO - joeynmt.training - Epoch  12, Step:    39100, Batch Loss:     2.593948, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 00:43:50,084 - INFO - joeynmt.training - Epoch  12, Step:    39200, Batch Loss:     2.773474, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 00:44:05,227 - INFO - joeynmt.training - Epoch  12, Step:    39300, Batch Loss:     2.937157, Tokens per Sec:     2055, Lr: 0.000100
2021-11-23 00:44:20,718 - INFO - joeynmt.training - Epoch  12, Step:    39400, Batch Loss:     2.514955, Tokens per Sec:     2088, Lr: 0.000100
2021-11-23 00:44:35,004 - INFO - joeynmt.training - Epoch  12, Step:    39500, Batch Loss:     2.706583, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 00:44:49,558 - INFO - joeynmt.training - Epoch  12, Step:    39600, Batch Loss:     2.660376, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 00:45:04,382 - INFO - joeynmt.training - Epoch  12, Step:    39700, Batch Loss:     2.772626, Tokens per Sec:     2124, Lr: 0.000100
2021-11-23 00:45:19,351 - INFO - joeynmt.training - Epoch  12, Step:    39800, Batch Loss:     2.838040, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 00:45:34,557 - INFO - joeynmt.training - Epoch  12, Step:    39900, Batch Loss:     2.951333, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 00:45:49,837 - INFO - joeynmt.training - Epoch  12, Step:    40000, Batch Loss:     2.842034, Tokens per Sec:     2120, Lr: 0.000100
2021-11-23 00:48:24,234 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:48:24,234 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:48:24,234 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:48:24,244 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 00:48:25,064 - INFO - joeynmt.helpers - delete models/baseline_multilingual/39000.ckpt
2021-11-23 00:48:25,065 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/39000.ckpt
2021-11-23 00:48:25,065 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/39000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/39000.ckpt')
2021-11-23 00:48:25,119 - INFO - joeynmt.training - Example #0
2021-11-23 00:48:25,120 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:48:25,120 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:48:25,120 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁"', 'I', 'n', "'", 't', '▁you', '▁go', '▁to', '▁the', '▁Temple', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁are', '▁not', '▁a', '▁st', 'ran', 'ge', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 00:48:25,120 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:48:25,120 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:48:25,120 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:48:25,120 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁" I n ' t ▁you ▁go ▁to ▁the ▁Temple ▁of ▁J ose ph , ▁but ▁they ▁are ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁are ▁not ▁a ▁st ran ge ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 00:48:25,121 - INFO - joeynmt.training - Example #1
2021-11-23 00:48:25,121 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:48:25,121 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:48:25,121 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁S', 'ur', 'dos']
2021-11-23 00:48:25,121 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:48:25,121 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:48:25,121 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:48:25,121 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁S ur dos
2021-11-23 00:48:25,121 - INFO - joeynmt.training - Example #2
2021-11-23 00:48:25,122 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:48:25,122 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:48:25,122 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁am', '▁not', '▁a', 'ct', '▁of', '▁my', 'self', '.']
2021-11-23 00:48:25,122 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:48:25,122 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:48:25,122 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:48:25,122 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁and ▁I ▁am ▁not ▁a ct ▁of ▁my self .
2021-11-23 00:48:25,122 - INFO - joeynmt.training - Example #3
2021-11-23 00:48:25,123 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:48:25,123 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:48:25,123 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ão']
2021-11-23 00:48:25,123 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:48:25,123 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:48:25,123 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:48:25,123 - INFO - joeynmt.training - 	Hypothesis: ▁m ão
2021-11-23 00:48:25,123 - INFO - joeynmt.training - Example #6
2021-11-23 00:48:25,123 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:48:25,123 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:48:25,124 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ix']
2021-11-23 00:48:25,124 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:48:25,124 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:48:25,124 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:48:25,124 - INFO - joeynmt.training - 	Hypothesis: ▁s ix
2021-11-23 00:48:25,124 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    40000: bleu:   4.17, loss: 94466.3047, ppl:  16.2701, duration: 155.2868s
2021-11-23 00:48:40,778 - INFO - joeynmt.training - Epoch  12, Step:    40100, Batch Loss:     2.999725, Tokens per Sec:     2015, Lr: 0.000100
2021-11-23 00:48:55,992 - INFO - joeynmt.training - Epoch  12, Step:    40200, Batch Loss:     3.193881, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 00:49:09,698 - INFO - joeynmt.training - Epoch  12, Step:    40300, Batch Loss:     2.801169, Tokens per Sec:     2242, Lr: 0.000100
2021-11-23 00:49:24,291 - INFO - joeynmt.training - Epoch  12, Step:    40400, Batch Loss:     2.771835, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 00:49:38,660 - INFO - joeynmt.training - Epoch  12, Step:    40500, Batch Loss:     2.824302, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 00:49:53,178 - INFO - joeynmt.training - Epoch  12, Step:    40600, Batch Loss:     2.837969, Tokens per Sec:     2164, Lr: 0.000100
2021-11-23 00:50:03,103 - INFO - joeynmt.training - Epoch  12: total training loss 9552.78
2021-11-23 00:50:03,103 - INFO - joeynmt.training - EPOCH 13
2021-11-23 00:50:07,839 - INFO - joeynmt.training - Epoch  13, Step:    40700, Batch Loss:     2.652770, Tokens per Sec:     2181, Lr: 0.000100
2021-11-23 00:50:23,059 - INFO - joeynmt.training - Epoch  13, Step:    40800, Batch Loss:     2.834666, Tokens per Sec:     2233, Lr: 0.000100
2021-11-23 00:50:38,740 - INFO - joeynmt.training - Epoch  13, Step:    40900, Batch Loss:     2.703481, Tokens per Sec:     2006, Lr: 0.000100
2021-11-23 00:50:53,897 - INFO - joeynmt.training - Epoch  13, Step:    41000, Batch Loss:     2.696818, Tokens per Sec:     2086, Lr: 0.000100
2021-11-23 00:53:31,861 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:53:31,861 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:53:31,861 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:53:31,872 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 00:53:32,693 - INFO - joeynmt.helpers - delete models/baseline_multilingual/40000.ckpt
2021-11-23 00:53:32,696 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/40000.ckpt
2021-11-23 00:53:32,697 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/40000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/40000.ckpt')
2021-11-23 00:53:32,761 - INFO - joeynmt.training - Example #0
2021-11-23 00:53:32,762 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:53:32,762 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:53:32,762 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '4.', '▁"', 'A', 'n', "'", 't', '▁you', '▁go', '▁to', '▁Jerusalem', ',', '▁but', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁are', '▁not', '▁like', '▁a', '▁p', 'ubl', 'ic', 'an', 'ge', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 00:53:32,762 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:53:32,762 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:53:32,762 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:53:32,762 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 4. ▁" A n ' t ▁you ▁go ▁to ▁Jerusalem , ▁but ▁you ▁are ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁are ▁not ▁like ▁a ▁p ubl ic an ge ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 00:53:32,762 - INFO - joeynmt.training - Example #1
2021-11-23 00:53:32,762 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:53:32,762 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:53:32,763 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'd', 'es']
2021-11-23 00:53:32,763 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:53:32,763 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:53:32,763 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:53:32,763 - INFO - joeynmt.training - 	Hypothesis: ▁G ra d es
2021-11-23 00:53:32,763 - INFO - joeynmt.training - Example #2
2021-11-23 00:53:32,763 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:53:32,763 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:53:32,763 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁have', '▁given', '▁you', '▁to', '▁you', '▁to', '▁do', '▁what', '▁is', '▁my', 'self', '.']
2021-11-23 00:53:32,763 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:53:32,763 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:53:32,764 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:53:32,764 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁and ▁I ▁have ▁given ▁you ▁to ▁you ▁to ▁do ▁what ▁is ▁my self .
2021-11-23 00:53:32,764 - INFO - joeynmt.training - Example #3
2021-11-23 00:53:32,764 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:53:32,764 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:53:32,764 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁o', 's', 'per', 'ar']
2021-11-23 00:53:32,764 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:53:32,764 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:53:32,764 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:53:32,764 - INFO - joeynmt.training - 	Hypothesis: ▁o s per ar
2021-11-23 00:53:32,765 - INFO - joeynmt.training - Example #6
2021-11-23 00:53:32,765 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:53:32,765 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:53:32,765 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 00:53:32,765 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:53:32,765 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:53:32,765 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:53:32,765 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 00:53:32,765 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    41000: bleu:   4.39, loss: 94388.3594, ppl:  16.2327, duration: 158.8681s
2021-11-23 00:53:47,786 - INFO - joeynmt.training - Epoch  13, Step:    41100, Batch Loss:     2.722042, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 00:54:01,870 - INFO - joeynmt.training - Epoch  13, Step:    41200, Batch Loss:     2.795066, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 00:54:16,736 - INFO - joeynmt.training - Epoch  13, Step:    41300, Batch Loss:     2.738707, Tokens per Sec:     2084, Lr: 0.000100
2021-11-23 00:54:32,202 - INFO - joeynmt.training - Epoch  13, Step:    41400, Batch Loss:     2.964826, Tokens per Sec:     2097, Lr: 0.000100
2021-11-23 00:54:48,022 - INFO - joeynmt.training - Epoch  13, Step:    41500, Batch Loss:     2.749440, Tokens per Sec:     2070, Lr: 0.000100
2021-11-23 00:55:02,517 - INFO - joeynmt.training - Epoch  13, Step:    41600, Batch Loss:     2.911585, Tokens per Sec:     2188, Lr: 0.000100
2021-11-23 00:55:16,031 - INFO - joeynmt.training - Epoch  13, Step:    41700, Batch Loss:     2.807278, Tokens per Sec:     2255, Lr: 0.000100
2021-11-23 00:55:31,203 - INFO - joeynmt.training - Epoch  13, Step:    41800, Batch Loss:     2.711648, Tokens per Sec:     2120, Lr: 0.000100
2021-11-23 00:55:45,557 - INFO - joeynmt.training - Epoch  13, Step:    41900, Batch Loss:     2.814312, Tokens per Sec:     2173, Lr: 0.000100
2021-11-23 00:55:59,817 - INFO - joeynmt.training - Epoch  13, Step:    42000, Batch Loss:     2.907094, Tokens per Sec:     2194, Lr: 0.000100
2021-11-23 00:59:25,065 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 00:59:25,065 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 00:59:25,065 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 00:59:25,082 - INFO - joeynmt.training - Example #0
2021-11-23 00:59:25,082 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 00:59:25,082 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 00:59:25,082 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '9.', '▁"', 'I', '▁am', 'az', 'ed', '▁to', '▁Jerusalem', ',', '▁J', 'ose', 'ph', ',', '▁but', '▁you', '▁are', '▁the', '▁people', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁are', '▁not', '▁a', '▁st', 'ran', 'ge', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁who', '▁are', '▁not', '▁be', 'ast', 'ing', '.']
2021-11-23 00:59:25,082 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 00:59:25,082 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 00:59:25,082 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 00:59:25,082 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 9. ▁" I ▁am az ed ▁to ▁Jerusalem , ▁J ose ph , ▁but ▁you ▁are ▁the ▁people ▁of ▁J ose ph , ▁but ▁they ▁are ▁not ▁a ▁st ran ge ▁of ▁the ▁people ▁of ▁the ▁people ▁who ▁are ▁not ▁be ast ing .
2021-11-23 00:59:25,082 - INFO - joeynmt.training - Example #1
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁Sinais']
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁Sinais
2021-11-23 00:59:25,083 - INFO - joeynmt.training - Example #2
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁and', '▁you', '▁are', '▁not', '▁with', '▁you', '.', '▁I', '▁have', '▁been', '▁given', '▁to', '▁you', '▁to', '▁help', '▁you', ',', '▁and', '▁I', '▁am', '▁not', '▁to', '▁help', '▁you', '.']
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁and ▁you ▁are ▁not ▁with ▁you . ▁I ▁have ▁been ▁given ▁to ▁you ▁to ▁help ▁you , ▁and ▁I ▁am ▁not ▁to ▁help ▁you .
2021-11-23 00:59:25,083 - INFO - joeynmt.training - Example #3
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ada']
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 00:59:25,083 - INFO - joeynmt.training - 	Hypothesis: ▁n ada
2021-11-23 00:59:25,083 - INFO - joeynmt.training - Example #6
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 00:59:25,083 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 00:59:25,084 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 00:59:25,084 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 00:59:25,084 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 00:59:25,084 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 00:59:25,084 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 00:59:25,084 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    42000: bleu:   4.25, loss: 93586.1562, ppl:  15.8528, duration: 205.2667s
2021-11-23 00:59:39,500 - INFO - joeynmt.training - Epoch  13, Step:    42100, Batch Loss:     2.918291, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 00:59:54,039 - INFO - joeynmt.training - Epoch  13, Step:    42200, Batch Loss:     2.805869, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 01:00:08,029 - INFO - joeynmt.training - Epoch  13, Step:    42300, Batch Loss:     2.695820, Tokens per Sec:     2178, Lr: 0.000100
2021-11-23 01:00:23,189 - INFO - joeynmt.training - Epoch  13, Step:    42400, Batch Loss:     2.572404, Tokens per Sec:     2053, Lr: 0.000100
2021-11-23 01:00:37,590 - INFO - joeynmt.training - Epoch  13, Step:    42500, Batch Loss:     2.952729, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 01:00:51,851 - INFO - joeynmt.training - Epoch  13, Step:    42600, Batch Loss:     2.780905, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 01:01:06,541 - INFO - joeynmt.training - Epoch  13, Step:    42700, Batch Loss:     2.705408, Tokens per Sec:     2227, Lr: 0.000100
2021-11-23 01:01:21,443 - INFO - joeynmt.training - Epoch  13, Step:    42800, Batch Loss:     2.736371, Tokens per Sec:     2103, Lr: 0.000100
2021-11-23 01:01:36,247 - INFO - joeynmt.training - Epoch  13, Step:    42900, Batch Loss:     2.718247, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 01:01:51,435 - INFO - joeynmt.training - Epoch  13, Step:    43000, Batch Loss:     2.742113, Tokens per Sec:     2062, Lr: 0.000100
2021-11-23 01:05:16,254 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:05:16,255 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:05:16,255 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:05:16,272 - INFO - joeynmt.training - Example #0
2021-11-23 01:05:16,272 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:05:16,272 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:05:16,272 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁sent', '▁to', '▁Jerusalem', '▁to', '▁Jerusalem', ',', '▁but', '▁they', '▁are', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁are', '▁not', '▁a', '▁lar', 'ge', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 01:05:16,272 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:05:16,272 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:05:16,272 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:05:16,272 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁" W hen ▁you ▁have ▁been ▁sent ▁to ▁Jerusalem ▁to ▁Jerusalem , ▁but ▁they ▁are ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁are ▁not ▁a ▁lar ge ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 01:05:16,272 - INFO - joeynmt.training - Example #1
2021-11-23 01:05:16,272 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:05:16,272 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:05:16,272 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 01:05:16,272 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:05:16,272 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:05:16,272 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 01:05:16,273 - INFO - joeynmt.training - Example #2
2021-11-23 01:05:16,273 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:05:16,273 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:05:16,273 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁want', '▁to', '▁you', '▁to', '▁be', '▁with', '▁you', ',', '▁and', '▁you', '▁are', '▁not', '▁to', '▁love', '▁to', '▁love', '▁each', '▁other', '.', '▁I', '▁am', '▁not', '▁to', '▁do', '▁this', ',', '▁for', '▁you', '▁can', "'", 't', '▁know', '▁what', '▁is', '▁not', '.']
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁want ▁to ▁you ▁to ▁be ▁with ▁you , ▁and ▁you ▁are ▁not ▁to ▁love ▁to ▁love ▁each ▁other . ▁I ▁am ▁not ▁to ▁do ▁this , ▁for ▁you ▁can ' t ▁know ▁what ▁is ▁not .
2021-11-23 01:05:16,273 - INFO - joeynmt.training - Example #3
2021-11-23 01:05:16,273 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:05:16,273 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:05:16,273 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 01:05:16,273 - INFO - joeynmt.training - Example #6
2021-11-23 01:05:16,273 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:05:16,273 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:05:16,273 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:05:16,273 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:05:16,274 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    43000: bleu:   4.29, loss: 93320.9531, ppl:  15.7291, duration: 204.8384s
2021-11-23 01:05:30,545 - INFO - joeynmt.training - Epoch  13, Step:    43100, Batch Loss:     2.628766, Tokens per Sec:     2074, Lr: 0.000100
2021-11-23 01:05:45,605 - INFO - joeynmt.training - Epoch  13, Step:    43200, Batch Loss:     2.661949, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 01:06:00,294 - INFO - joeynmt.training - Epoch  13, Step:    43300, Batch Loss:     2.766589, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 01:06:14,782 - INFO - joeynmt.training - Epoch  13, Step:    43400, Batch Loss:     2.751246, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 01:06:29,029 - INFO - joeynmt.training - Epoch  13, Step:    43500, Batch Loss:     2.738302, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 01:06:43,756 - INFO - joeynmt.training - Epoch  13, Step:    43600, Batch Loss:     2.803632, Tokens per Sec:     2184, Lr: 0.000100
2021-11-23 01:06:58,224 - INFO - joeynmt.training - Epoch  13, Step:    43700, Batch Loss:     2.658667, Tokens per Sec:     2182, Lr: 0.000100
2021-11-23 01:07:11,962 - INFO - joeynmt.training - Epoch  13, Step:    43800, Batch Loss:     2.964820, Tokens per Sec:     2310, Lr: 0.000100
2021-11-23 01:07:25,807 - INFO - joeynmt.training - Epoch  13, Step:    43900, Batch Loss:     2.758485, Tokens per Sec:     2211, Lr: 0.000100
2021-11-23 01:07:41,218 - INFO - joeynmt.training - Epoch  13, Step:    44000, Batch Loss:     3.439368, Tokens per Sec:     2059, Lr: 0.000100
2021-11-23 01:11:18,728 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:11:18,729 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:11:18,729 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:11:18,746 - INFO - joeynmt.training - Example #0
2021-11-23 01:11:18,746 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:11:18,746 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:11:18,746 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁You', '▁have', '▁been', '▁a', 'head', '▁of', '▁Judah', ',', '▁but', '▁they', '▁were', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁were', '▁not', '▁to', '▁be', '▁destroy', 'ed', '▁by', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁poor', '.']
2021-11-23 01:11:18,746 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:11:18,746 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:11:18,746 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:11:18,746 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁You ▁have ▁been ▁a head ▁of ▁Judah , ▁but ▁they ▁were ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁were ▁not ▁to ▁be ▁destroy ed ▁by ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁poor .
2021-11-23 01:11:18,747 - INFO - joeynmt.training - Example #1
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 01:11:18,747 - INFO - joeynmt.training - Example #2
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁you', '▁have', '▁been', '▁given', '▁me', '▁to', '▁me', ',', '▁and', '▁I', '▁have', '▁been', '▁given', '▁you', '▁to', '▁do', '▁what', '▁is', '▁my', '▁faith', 'ful', '.']
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁you ▁have ▁been ▁given ▁me ▁to ▁me , ▁and ▁I ▁have ▁been ▁given ▁you ▁to ▁do ▁what ▁is ▁my ▁faith ful .
2021-11-23 01:11:18,747 - INFO - joeynmt.training - Example #3
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:11:18,747 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 01:11:18,747 - INFO - joeynmt.training - Example #6
2021-11-23 01:11:18,747 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:11:18,748 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:11:18,748 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:11:18,748 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:11:18,748 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:11:18,748 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:11:18,748 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:11:18,748 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    44000: bleu:   4.37, loss: 92924.1094, ppl:  15.5459, duration: 217.5295s
2021-11-23 01:11:26,723 - INFO - joeynmt.training - Epoch  13: total training loss 9396.19
2021-11-23 01:11:26,724 - INFO - joeynmt.training - EPOCH 14
2021-11-23 01:11:33,349 - INFO - joeynmt.training - Epoch  14, Step:    44100, Batch Loss:     2.761783, Tokens per Sec:     2027, Lr: 0.000100
2021-11-23 01:11:48,324 - INFO - joeynmt.training - Epoch  14, Step:    44200, Batch Loss:     2.704047, Tokens per Sec:     2086, Lr: 0.000100
2021-11-23 01:12:03,703 - INFO - joeynmt.training - Epoch  14, Step:    44300, Batch Loss:     2.684930, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 01:12:18,334 - INFO - joeynmt.training - Epoch  14, Step:    44400, Batch Loss:     2.624501, Tokens per Sec:     2221, Lr: 0.000100
2021-11-23 01:12:33,308 - INFO - joeynmt.training - Epoch  14, Step:    44500, Batch Loss:     2.826025, Tokens per Sec:     2051, Lr: 0.000100
2021-11-23 01:12:47,932 - INFO - joeynmt.training - Epoch  14, Step:    44600, Batch Loss:     2.657827, Tokens per Sec:     2218, Lr: 0.000100
2021-11-23 01:13:03,057 - INFO - joeynmt.training - Epoch  14, Step:    44700, Batch Loss:     2.658313, Tokens per Sec:     2181, Lr: 0.000100
2021-11-23 01:13:17,922 - INFO - joeynmt.training - Epoch  14, Step:    44800, Batch Loss:     2.620398, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 01:13:32,660 - INFO - joeynmt.training - Epoch  14, Step:    44900, Batch Loss:     2.848030, Tokens per Sec:     2128, Lr: 0.000100
2021-11-23 01:13:46,674 - INFO - joeynmt.training - Epoch  14, Step:    45000, Batch Loss:     2.699306, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 01:17:20,482 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:17:20,483 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:17:20,483 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:17:20,502 - INFO - joeynmt.training - Example #0
2021-11-23 01:17:20,502 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:17:20,502 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:17:20,502 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁You', '▁have', '▁been', '▁a', 'head', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁were', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁were', '▁not', '▁to', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.', '▁But', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 01:17:20,502 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:17:20,502 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁You ▁have ▁been ▁a head ▁of ▁J ose ph , ▁but ▁they ▁were ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁were ▁not ▁to ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people . ▁But ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 01:17:20,503 - INFO - joeynmt.training - Example #1
2021-11-23 01:17:20,503 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:17:20,503 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:17:20,503 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁S', 'ur', 'do']
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁S ur do
2021-11-23 01:17:20,503 - INFO - joeynmt.training - Example #2
2021-11-23 01:17:20,503 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:17:20,503 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:17:20,503 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁have', '▁been', '▁given', '▁you', '▁to', '▁you', ',', '▁and', '▁I', '▁have', '▁been', '▁given', '▁you', '▁to', '▁do', '▁what', '▁is', '▁not', '▁to', '▁do', '.']
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁have ▁been ▁given ▁you ▁to ▁you , ▁and ▁I ▁have ▁been ▁given ▁you ▁to ▁do ▁what ▁is ▁not ▁to ▁do .
2021-11-23 01:17:20,503 - INFO - joeynmt.training - Example #3
2021-11-23 01:17:20,503 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:17:20,503 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:17:20,503 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:17:20,503 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:17:20,504 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 01:17:20,504 - INFO - joeynmt.training - Example #6
2021-11-23 01:17:20,504 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:17:20,504 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:17:20,504 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:17:20,504 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:17:20,504 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:17:20,504 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:17:20,504 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:17:20,504 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    45000: bleu:   4.31, loss: 92638.5703, ppl:  15.4154, duration: 213.8299s
2021-11-23 01:17:34,465 - INFO - joeynmt.training - Epoch  14, Step:    45100, Batch Loss:     2.702497, Tokens per Sec:     2215, Lr: 0.000100
2021-11-23 01:17:48,609 - INFO - joeynmt.training - Epoch  14, Step:    45200, Batch Loss:     2.688007, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 01:18:02,735 - INFO - joeynmt.training - Epoch  14, Step:    45300, Batch Loss:     2.645788, Tokens per Sec:     2208, Lr: 0.000100
2021-11-23 01:18:17,692 - INFO - joeynmt.training - Epoch  14, Step:    45400, Batch Loss:     3.095092, Tokens per Sec:     2092, Lr: 0.000100
2021-11-23 01:18:33,282 - INFO - joeynmt.training - Epoch  14, Step:    45500, Batch Loss:     2.774659, Tokens per Sec:     2103, Lr: 0.000100
2021-11-23 01:18:47,498 - INFO - joeynmt.training - Epoch  14, Step:    45600, Batch Loss:     2.699460, Tokens per Sec:     2233, Lr: 0.000100
2021-11-23 01:19:01,901 - INFO - joeynmt.training - Epoch  14, Step:    45700, Batch Loss:     2.762174, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 01:19:15,871 - INFO - joeynmt.training - Epoch  14, Step:    45800, Batch Loss:     2.669469, Tokens per Sec:     2201, Lr: 0.000100
2021-11-23 01:19:31,019 - INFO - joeynmt.training - Epoch  14, Step:    45900, Batch Loss:     2.722553, Tokens per Sec:     2124, Lr: 0.000100
2021-11-23 01:19:46,249 - INFO - joeynmt.training - Epoch  14, Step:    46000, Batch Loss:     2.679972, Tokens per Sec:     2130, Lr: 0.000100
2021-11-23 01:22:44,239 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:22:44,240 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:22:44,240 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:22:44,251 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 01:22:45,077 - INFO - joeynmt.helpers - delete models/baseline_multilingual/41000.ckpt
2021-11-23 01:22:45,078 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/41000.ckpt
2021-11-23 01:22:45,078 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/41000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/41000.ckpt')
2021-11-23 01:22:45,132 - INFO - joeynmt.training - Example #0
2021-11-23 01:22:45,132 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:22:45,133 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:22:45,133 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '3.', '▁You', '▁have', '▁been', '▁a', 'head', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁they', '▁were', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁were', '▁not', '▁to', '▁be', '▁c', 'ru', 'cif', 'ied', '.', '▁But', '▁they', '▁were', '▁not', '▁to', '▁be', '▁destroy', 'ed', '.']
2021-11-23 01:22:45,133 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:22:45,133 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:22:45,133 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:22:45,133 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 3. ▁You ▁have ▁been ▁a head ▁of ▁J ose ph , ▁but ▁they ▁were ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁were ▁not ▁to ▁be ▁c ru cif ied . ▁But ▁they ▁were ▁not ▁to ▁be ▁destroy ed .
2021-11-23 01:22:45,134 - INFO - joeynmt.training - Example #1
2021-11-23 01:22:45,134 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:22:45,134 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:22:45,134 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁Sinais']
2021-11-23 01:22:45,134 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:22:45,134 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:22:45,134 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:22:45,135 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁Sinais
2021-11-23 01:22:45,135 - INFO - joeynmt.training - Example #2
2021-11-23 01:22:45,135 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:22:45,135 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:22:45,135 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁want', '▁to', '▁you', '▁to', '▁be', '▁with', '▁you', '▁to', '▁be', '▁with', '▁you', '.', '▁If', '▁you', '▁are', '▁not', '▁to', '▁help', '▁each', '▁other', ',', '▁I', '▁am', '▁not', '▁to', '▁do', '.']
2021-11-23 01:22:45,135 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:22:45,135 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:22:45,136 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:22:45,136 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁want ▁to ▁you ▁to ▁be ▁with ▁you ▁to ▁be ▁with ▁you . ▁If ▁you ▁are ▁not ▁to ▁help ▁each ▁other , ▁I ▁am ▁not ▁to ▁do .
2021-11-23 01:22:45,136 - INFO - joeynmt.training - Example #3
2021-11-23 01:22:45,136 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:22:45,136 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:22:45,136 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 01:22:45,136 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:22:45,136 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:22:45,137 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:22:45,137 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 01:22:45,137 - INFO - joeynmt.training - Example #6
2021-11-23 01:22:45,137 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:22:45,137 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:22:45,137 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:22:45,137 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:22:45,137 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:22:45,138 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:22:45,138 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:22:45,138 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    46000: bleu:   4.75, loss: 92077.9062, ppl:  15.1623, duration: 178.8884s
2021-11-23 01:23:00,101 - INFO - joeynmt.training - Epoch  14, Step:    46100, Batch Loss:     2.574899, Tokens per Sec:     2017, Lr: 0.000100
2021-11-23 01:23:14,916 - INFO - joeynmt.training - Epoch  14, Step:    46200, Batch Loss:     2.990704, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 01:23:29,170 - INFO - joeynmt.training - Epoch  14, Step:    46300, Batch Loss:     2.904433, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 01:23:43,090 - INFO - joeynmt.training - Epoch  14, Step:    46400, Batch Loss:     2.733530, Tokens per Sec:     2191, Lr: 0.000100
2021-11-23 01:23:58,495 - INFO - joeynmt.training - Epoch  14, Step:    46500, Batch Loss:     2.765354, Tokens per Sec:     2043, Lr: 0.000100
2021-11-23 01:24:12,472 - INFO - joeynmt.training - Epoch  14, Step:    46600, Batch Loss:     2.810178, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 01:24:27,686 - INFO - joeynmt.training - Epoch  14, Step:    46700, Batch Loss:     2.912854, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 01:24:42,064 - INFO - joeynmt.training - Epoch  14, Step:    46800, Batch Loss:     2.779744, Tokens per Sec:     2202, Lr: 0.000100
2021-11-23 01:24:56,509 - INFO - joeynmt.training - Epoch  14, Step:    46900, Batch Loss:     2.680819, Tokens per Sec:     2088, Lr: 0.000100
2021-11-23 01:25:11,713 - INFO - joeynmt.training - Epoch  14, Step:    47000, Batch Loss:     2.760750, Tokens per Sec:     2128, Lr: 0.000100
2021-11-23 01:29:34,324 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:29:34,324 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:29:34,324 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:29:34,341 - INFO - joeynmt.training - Example #0
2021-11-23 01:29:34,341 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:29:34,341 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:29:34,341 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '0.', '▁You', '▁have', '▁been', '▁a', 'head', '▁of', '▁Jerusalem', ',', '▁but', '▁they', '▁were', '▁going', '▁to', '▁Jerusalem', ',', '▁but', '▁they', '▁were', '▁not', '▁to', '▁the', '▁people', '▁of', '▁Judah', '.', '▁But', '▁they', '▁will', '▁be', '▁destroy', 'ed', '▁to', '▁be', '▁destroy', 'ed', '.']
2021-11-23 01:29:34,341 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 0. ▁You ▁have ▁been ▁a head ▁of ▁Jerusalem , ▁but ▁they ▁were ▁going ▁to ▁Jerusalem , ▁but ▁they ▁were ▁not ▁to ▁the ▁people ▁of ▁Judah . ▁But ▁they ▁will ▁be ▁destroy ed ▁to ▁be ▁destroy ed .
2021-11-23 01:29:34,342 - INFO - joeynmt.training - Example #1
2021-11-23 01:29:34,342 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:29:34,342 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:29:34,342 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁Sinais']
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁Sinais
2021-11-23 01:29:34,342 - INFO - joeynmt.training - Example #2
2021-11-23 01:29:34,342 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:29:34,342 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:29:34,342 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁am', '▁not', '▁to', '▁do', '▁this', '▁to', '▁do', '▁this', '.']
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁and ▁I ▁am ▁not ▁to ▁do ▁this ▁to ▁do ▁this .
2021-11-23 01:29:34,342 - INFO - joeynmt.training - Example #3
2021-11-23 01:29:34,342 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:29:34,342 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:29:34,342 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ada']
2021-11-23 01:29:34,342 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:29:34,343 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:29:34,343 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:29:34,343 - INFO - joeynmt.training - 	Hypothesis: ▁n ada
2021-11-23 01:29:34,343 - INFO - joeynmt.training - Example #6
2021-11-23 01:29:34,343 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:29:34,343 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:29:34,343 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:29:34,343 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:29:34,343 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:29:34,343 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:29:34,343 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:29:34,343 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    47000: bleu:   4.00, loss: 91782.8750, ppl:  15.0307, duration: 262.6298s
2021-11-23 01:29:48,475 - INFO - joeynmt.training - Epoch  14, Step:    47100, Batch Loss:     2.729906, Tokens per Sec:     2138, Lr: 0.000100
2021-11-23 01:30:03,505 - INFO - joeynmt.training - Epoch  14, Step:    47200, Batch Loss:     2.655163, Tokens per Sec:     2120, Lr: 0.000100
2021-11-23 01:30:18,475 - INFO - joeynmt.training - Epoch  14, Step:    47300, Batch Loss:     2.713833, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 01:30:32,669 - INFO - joeynmt.training - Epoch  14, Step:    47400, Batch Loss:     2.640394, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 01:30:39,245 - INFO - joeynmt.training - Epoch  14: total training loss 9255.08
2021-11-23 01:30:39,246 - INFO - joeynmt.training - EPOCH 15
2021-11-23 01:30:46,965 - INFO - joeynmt.training - Epoch  15, Step:    47500, Batch Loss:     2.623311, Tokens per Sec:     2091, Lr: 0.000100
2021-11-23 01:31:01,906 - INFO - joeynmt.training - Epoch  15, Step:    47600, Batch Loss:     2.715878, Tokens per Sec:     2079, Lr: 0.000100
2021-11-23 01:31:16,904 - INFO - joeynmt.training - Epoch  15, Step:    47700, Batch Loss:     2.642081, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 01:31:31,428 - INFO - joeynmt.training - Epoch  15, Step:    47800, Batch Loss:     2.648979, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 01:31:45,898 - INFO - joeynmt.training - Epoch  15, Step:    47900, Batch Loss:     2.715104, Tokens per Sec:     2111, Lr: 0.000100
2021-11-23 01:32:01,423 - INFO - joeynmt.training - Epoch  15, Step:    48000, Batch Loss:     2.867474, Tokens per Sec:     2055, Lr: 0.000100
2021-11-23 01:35:33,388 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:35:33,389 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:35:33,389 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:35:33,408 - INFO - joeynmt.training - Example #0
2021-11-23 01:35:33,409 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:35:33,409 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:35:33,409 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '1.', '▁He', '▁went', '▁to', '▁the', '▁town', '▁of', '▁J', 'e', 'an', ',', '▁but', '▁they', '▁went', '▁to', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁they', '▁were', '▁not', '▁to', '▁be', '▁af', 'raid', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 01:35:33,409 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:35:33,409 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:35:33,409 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:35:33,409 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 1. ▁He ▁went ▁to ▁the ▁town ▁of ▁J e an , ▁but ▁they ▁went ▁to ▁the ▁people ▁of ▁Gal ile e , ▁but ▁they ▁were ▁not ▁to ▁be ▁af raid ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 01:35:33,409 - INFO - joeynmt.training - Example #1
2021-11-23 01:35:33,409 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:35:33,409 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:35:33,409 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 01:35:33,409 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:35:33,409 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:35:33,409 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:35:33,409 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 01:35:33,409 - INFO - joeynmt.training - Example #2
2021-11-23 01:35:33,409 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:35:33,409 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:35:33,409 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁for', '▁you', '▁are', '▁my', 'self', ',', '▁for', '▁you', '▁are', '▁my', 'self', '.']
2021-11-23 01:35:33,409 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁for ▁you ▁are ▁my self , ▁for ▁you ▁are ▁my self .
2021-11-23 01:35:33,410 - INFO - joeynmt.training - Example #3
2021-11-23 01:35:33,410 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:35:33,410 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:35:33,410 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ada']
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Hypothesis: ▁n ada
2021-11-23 01:35:33,410 - INFO - joeynmt.training - Example #6
2021-11-23 01:35:33,410 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:35:33,410 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:35:33,410 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:35:33,410 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:35:33,410 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    48000: bleu:   4.57, loss: 91639.5547, ppl:  14.9673, duration: 211.9870s
2021-11-23 01:35:47,552 - INFO - joeynmt.training - Epoch  15, Step:    48100, Batch Loss:     2.600787, Tokens per Sec:     2090, Lr: 0.000100
2021-11-23 01:36:01,933 - INFO - joeynmt.training - Epoch  15, Step:    48200, Batch Loss:     2.767524, Tokens per Sec:     2163, Lr: 0.000100
2021-11-23 01:36:16,318 - INFO - joeynmt.training - Epoch  15, Step:    48300, Batch Loss:     2.675620, Tokens per Sec:     2170, Lr: 0.000100
2021-11-23 01:36:31,285 - INFO - joeynmt.training - Epoch  15, Step:    48400, Batch Loss:     2.577554, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 01:36:45,974 - INFO - joeynmt.training - Epoch  15, Step:    48500, Batch Loss:     2.641693, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 01:37:00,834 - INFO - joeynmt.training - Epoch  15, Step:    48600, Batch Loss:     2.812218, Tokens per Sec:     2128, Lr: 0.000100
2021-11-23 01:37:15,722 - INFO - joeynmt.training - Epoch  15, Step:    48700, Batch Loss:     2.720957, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 01:37:30,729 - INFO - joeynmt.training - Epoch  15, Step:    48800, Batch Loss:     2.526207, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 01:37:45,506 - INFO - joeynmt.training - Epoch  15, Step:    48900, Batch Loss:     2.764991, Tokens per Sec:     2157, Lr: 0.000100
2021-11-23 01:38:00,151 - INFO - joeynmt.training - Epoch  15, Step:    49000, Batch Loss:     2.745287, Tokens per Sec:     2046, Lr: 0.000100
2021-11-23 01:41:12,016 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:41:12,016 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:41:12,016 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:41:12,029 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 01:41:12,840 - INFO - joeynmt.helpers - delete models/baseline_multilingual/46000.ckpt
2021-11-23 01:41:12,841 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/46000.ckpt
2021-11-23 01:41:12,841 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/46000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/46000.ckpt')
2021-11-23 01:41:12,901 - INFO - joeynmt.training - Example #0
2021-11-23 01:41:12,901 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:41:12,901 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:41:12,901 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁They', '▁were', '▁in', '▁Jerusalem', ',', '▁and', '▁they', '▁were', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁were', '▁not', '▁to', '▁the', '▁people', '▁of', '▁Judah', '.', '▁But', '▁they', '▁were', '▁not', '▁to', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 01:41:12,901 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:41:12,902 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:41:12,902 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:41:12,902 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁They ▁were ▁in ▁Jerusalem , ▁and ▁they ▁were ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁were ▁not ▁to ▁the ▁people ▁of ▁Judah . ▁But ▁they ▁were ▁not ▁to ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 01:41:12,902 - INFO - joeynmt.training - Example #1
2021-11-23 01:41:12,902 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:41:12,902 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:41:12,902 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁Sinais']
2021-11-23 01:41:12,903 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:41:12,903 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:41:12,903 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:41:12,903 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁Sinais
2021-11-23 01:41:12,903 - INFO - joeynmt.training - Example #2
2021-11-23 01:41:12,903 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:41:12,904 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:41:12,904 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁let', '▁you', '▁have', '▁given', '▁you', '▁to', '▁each', '▁other', '.', '▁O', 'ther', 'ther', 's', ',', '▁let', 'ter', '▁is', '▁not', '▁the', '▁same', ',', '▁and', '▁I', '▁am', '▁not', '▁to', '▁do', '.']
2021-11-23 01:41:12,904 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:41:12,904 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:41:12,904 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:41:12,904 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁let ▁you ▁have ▁given ▁you ▁to ▁each ▁other . ▁O ther ther s , ▁let ter ▁is ▁not ▁the ▁same , ▁and ▁I ▁am ▁not ▁to ▁do .
2021-11-23 01:41:12,904 - INFO - joeynmt.training - Example #3
2021-11-23 01:41:12,905 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:41:12,905 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:41:12,905 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ais']
2021-11-23 01:41:12,905 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:41:12,905 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:41:12,905 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:41:12,905 - INFO - joeynmt.training - 	Hypothesis: ▁m ais
2021-11-23 01:41:12,905 - INFO - joeynmt.training - Example #6
2021-11-23 01:41:12,905 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:41:12,905 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:41:12,905 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:41:12,905 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:41:12,906 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:41:12,906 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:41:12,906 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:41:12,906 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    49000: bleu:   5.06, loss: 91393.3594, ppl:  14.8589, duration: 192.7549s
2021-11-23 01:41:26,841 - INFO - joeynmt.training - Epoch  15, Step:    49100, Batch Loss:     2.602286, Tokens per Sec:     2248, Lr: 0.000100
2021-11-23 01:41:41,519 - INFO - joeynmt.training - Epoch  15, Step:    49200, Batch Loss:     2.614479, Tokens per Sec:     2259, Lr: 0.000100
2021-11-23 01:41:56,738 - INFO - joeynmt.training - Epoch  15, Step:    49300, Batch Loss:     2.662451, Tokens per Sec:     2063, Lr: 0.000100
2021-11-23 01:42:11,578 - INFO - joeynmt.training - Epoch  15, Step:    49400, Batch Loss:     2.863866, Tokens per Sec:     2067, Lr: 0.000100
2021-11-23 01:42:26,687 - INFO - joeynmt.training - Epoch  15, Step:    49500, Batch Loss:     2.977809, Tokens per Sec:     2083, Lr: 0.000100
2021-11-23 01:42:40,667 - INFO - joeynmt.training - Epoch  15, Step:    49600, Batch Loss:     2.736627, Tokens per Sec:     2232, Lr: 0.000100
2021-11-23 01:42:55,311 - INFO - joeynmt.training - Epoch  15, Step:    49700, Batch Loss:     2.571639, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 01:43:10,129 - INFO - joeynmt.training - Epoch  15, Step:    49800, Batch Loss:     2.737560, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 01:43:24,701 - INFO - joeynmt.training - Epoch  15, Step:    49900, Batch Loss:     2.766608, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 01:43:39,763 - INFO - joeynmt.training - Epoch  15, Step:    50000, Batch Loss:     2.761461, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 01:46:51,661 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:46:51,662 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:46:51,662 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:46:51,672 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 01:46:52,499 - INFO - joeynmt.helpers - delete models/baseline_multilingual/49000.ckpt
2021-11-23 01:46:52,500 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/49000.ckpt
2021-11-23 01:46:52,500 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/49000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/49000.ckpt')
2021-11-23 01:46:52,554 - INFO - joeynmt.training - Example #0
2021-11-23 01:46:52,554 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:46:52,555 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:46:52,555 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'ry', 'er', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁you', '▁have', '▁been', '▁a', 'head', '▁of', '▁Judah', '.', '▁But', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 01:46:52,555 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:46:52,555 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:46:52,555 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:46:52,555 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c ry er ▁of ▁J ose ph , ▁but ▁you ▁have ▁been ▁a head ▁of ▁Judah . ▁But ▁you ▁are ▁not ▁a head ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 01:46:52,556 - INFO - joeynmt.training - Example #1
2021-11-23 01:46:52,556 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:46:52,556 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:46:52,556 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'ola']
2021-11-23 01:46:52,556 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:46:52,556 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:46:52,556 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:46:52,557 - INFO - joeynmt.training - 	Hypothesis: ▁E sc ola
2021-11-23 01:46:52,557 - INFO - joeynmt.training - Example #2
2021-11-23 01:46:52,557 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:46:52,557 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:46:52,557 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁have', '▁been', '▁given', '▁to', '▁you', '▁to', '▁each', '▁other', ',', '▁and', '▁let', '▁us', ',', '▁and', '▁let', '▁us', ',', '▁and', '▁let', '▁me', ',', '▁and', '▁now', '▁I', '▁am', '▁not', '▁only', '▁one', '.']
2021-11-23 01:46:52,557 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:46:52,557 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:46:52,558 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:46:52,558 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁have ▁been ▁given ▁to ▁you ▁to ▁each ▁other , ▁and ▁let ▁us , ▁and ▁let ▁us , ▁and ▁let ▁me , ▁and ▁now ▁I ▁am ▁not ▁only ▁one .
2021-11-23 01:46:52,558 - INFO - joeynmt.training - Example #3
2021-11-23 01:46:52,558 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:46:52,558 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:46:52,558 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 01:46:52,558 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:46:52,558 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:46:52,559 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:46:52,559 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 01:46:52,559 - INFO - joeynmt.training - Example #6
2021-11-23 01:46:52,559 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:46:52,559 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:46:52,559 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:46:52,559 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:46:52,559 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:46:52,560 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:46:52,560 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:46:52,560 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    50000: bleu:   5.22, loss: 90935.7422, ppl:  14.6594, duration: 192.7970s
2021-11-23 01:47:06,882 - INFO - joeynmt.training - Epoch  15, Step:    50100, Batch Loss:     2.966259, Tokens per Sec:     2124, Lr: 0.000100
2021-11-23 01:47:21,501 - INFO - joeynmt.training - Epoch  15, Step:    50200, Batch Loss:     2.584316, Tokens per Sec:     2099, Lr: 0.000100
2021-11-23 01:47:36,105 - INFO - joeynmt.training - Epoch  15, Step:    50300, Batch Loss:     2.601551, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 01:47:51,899 - INFO - joeynmt.training - Epoch  15, Step:    50400, Batch Loss:     2.687960, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 01:48:07,119 - INFO - joeynmt.training - Epoch  15, Step:    50500, Batch Loss:     3.307378, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 01:48:21,099 - INFO - joeynmt.training - Epoch  15, Step:    50600, Batch Loss:     2.543485, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 01:48:35,210 - INFO - joeynmt.training - Epoch  15, Step:    50700, Batch Loss:     2.760594, Tokens per Sec:     2199, Lr: 0.000100
2021-11-23 01:48:50,038 - INFO - joeynmt.training - Epoch  15, Step:    50800, Batch Loss:     2.389192, Tokens per Sec:     2182, Lr: 0.000100
2021-11-23 01:48:55,539 - INFO - joeynmt.training - Epoch  15: total training loss 9124.19
2021-11-23 01:48:55,539 - INFO - joeynmt.training - EPOCH 16
2021-11-23 01:49:04,852 - INFO - joeynmt.training - Epoch  16, Step:    50900, Batch Loss:     2.614739, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 01:49:19,405 - INFO - joeynmt.training - Epoch  16, Step:    51000, Batch Loss:     2.622603, Tokens per Sec:     2227, Lr: 0.000100
2021-11-23 01:52:46,907 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:52:46,908 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:52:46,908 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:52:46,926 - INFO - joeynmt.training - Example #0
2021-11-23 01:52:46,926 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:52:46,926 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:52:46,926 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', 'head', '▁of', '▁Judah', ',', '▁J', 'ose', 'ph', ',', '▁and', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁were', '▁not', '▁to', '▁be', '▁a', 'head', '▁of', '▁the', '▁people', '.', '▁But', '▁the', '▁people', '▁of', '▁the', '▁people', '▁were', '▁not', '▁to', '▁the', '▁people', '.']
2021-11-23 01:52:46,926 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:52:46,926 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:52:46,926 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:52:46,926 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a head ▁of ▁Judah , ▁J ose ph , ▁and ▁you ▁are ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁were ▁not ▁to ▁be ▁a head ▁of ▁the ▁people . ▁But ▁the ▁people ▁of ▁the ▁people ▁were ▁not ▁to ▁the ▁people .
2021-11-23 01:52:46,926 - INFO - joeynmt.training - Example #1
2021-11-23 01:52:46,926 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:52:46,926 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:52:46,926 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁Sinais']
2021-11-23 01:52:46,926 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:52:46,926 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:52:46,926 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:52:46,926 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁Sinais
2021-11-23 01:52:46,926 - INFO - joeynmt.training - Example #2
2021-11-23 01:52:46,926 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:52:46,927 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:52:46,927 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁make', '▁you', '▁to', '▁make', '▁you', '▁to', '▁each', '▁other', '.', '▁Let', '▁each', '▁other', ',', '▁let', '▁us', ',', '▁and', '▁I', '▁am', '▁not', '▁to', '▁do', '▁this', '.']
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁make ▁you ▁to ▁make ▁you ▁to ▁each ▁other . ▁Let ▁each ▁other , ▁let ▁us , ▁and ▁I ▁am ▁not ▁to ▁do ▁this .
2021-11-23 01:52:46,927 - INFO - joeynmt.training - Example #3
2021-11-23 01:52:46,927 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:52:46,927 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:52:46,927 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 01:52:46,927 - INFO - joeynmt.training - Example #6
2021-11-23 01:52:46,927 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:52:46,927 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:52:46,927 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:52:46,927 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:52:46,927 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    51000: bleu:   4.88, loss: 90413.9453, ppl:  14.4353, duration: 207.5217s
2021-11-23 01:53:01,598 - INFO - joeynmt.training - Epoch  16, Step:    51100, Batch Loss:     2.674486, Tokens per Sec:     2222, Lr: 0.000100
2021-11-23 01:53:16,355 - INFO - joeynmt.training - Epoch  16, Step:    51200, Batch Loss:     2.544231, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 01:53:30,146 - INFO - joeynmt.training - Epoch  16, Step:    51300, Batch Loss:     2.534275, Tokens per Sec:     2223, Lr: 0.000100
2021-11-23 01:53:44,610 - INFO - joeynmt.training - Epoch  16, Step:    51400, Batch Loss:     2.553168, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 01:53:59,036 - INFO - joeynmt.training - Epoch  16, Step:    51500, Batch Loss:     2.602461, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 01:54:13,352 - INFO - joeynmt.training - Epoch  16, Step:    51600, Batch Loss:     2.952688, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 01:54:27,400 - INFO - joeynmt.training - Epoch  16, Step:    51700, Batch Loss:     2.567191, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 01:54:41,466 - INFO - joeynmt.training - Epoch  16, Step:    51800, Batch Loss:     2.715192, Tokens per Sec:     2224, Lr: 0.000100
2021-11-23 01:54:56,797 - INFO - joeynmt.training - Epoch  16, Step:    51900, Batch Loss:     2.595690, Tokens per Sec:     1978, Lr: 0.000100
2021-11-23 01:55:10,995 - INFO - joeynmt.training - Epoch  16, Step:    52000, Batch Loss:     2.562757, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 01:58:07,642 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 01:58:07,642 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 01:58:07,642 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 01:58:07,654 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 01:58:08,469 - INFO - joeynmt.helpers - delete models/baseline_multilingual/50000.ckpt
2021-11-23 01:58:08,470 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/50000.ckpt
2021-11-23 01:58:08,470 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/50000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/50000.ckpt')
2021-11-23 01:58:08,530 - INFO - joeynmt.training - Example #0
2021-11-23 01:58:08,530 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 01:58:08,530 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 01:58:08,530 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'apt', 'ain', '▁of', '▁the', '▁Temple', '▁of', '▁Judah', ',', '▁but', '▁they', '▁were', '▁c', 'apt', 'ain', 'ed', '▁to', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.', '▁But', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁who', '▁were', '▁destroy', 'ed', '.']
2021-11-23 01:58:08,531 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 01:58:08,531 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 01:58:08,531 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 01:58:08,531 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c apt ain ▁of ▁the ▁Temple ▁of ▁Judah , ▁but ▁they ▁were ▁c apt ain ed ▁to ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people . ▁But ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁who ▁were ▁destroy ed .
2021-11-23 01:58:08,531 - INFO - joeynmt.training - Example #1
2021-11-23 01:58:08,531 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 01:58:08,532 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 01:58:08,532 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sp', 'an', 'cia']
2021-11-23 01:58:08,532 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 01:58:08,532 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 01:58:08,532 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 01:58:08,532 - INFO - joeynmt.training - 	Hypothesis: ▁E sp an cia
2021-11-23 01:58:08,532 - INFO - joeynmt.training - Example #2
2021-11-23 01:58:08,533 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 01:58:08,533 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 01:58:08,533 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁my', '▁body', ',', '▁and', '▁I', '▁am', '▁with', '▁you', '.', '▁Don', "'", 't', '▁let', 'ter', ',', '▁for', '▁you', '▁are', '▁my', 'self', ',', '▁and', '▁now', '▁I', '▁am', '▁not', '▁to', '▁live', '▁in', '▁the', '▁one', '.']
2021-11-23 01:58:08,533 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 01:58:08,533 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 01:58:08,533 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 01:58:08,533 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁my ▁body , ▁and ▁I ▁am ▁with ▁you . ▁Don ' t ▁let ter , ▁for ▁you ▁are ▁my self , ▁and ▁now ▁I ▁am ▁not ▁to ▁live ▁in ▁the ▁one .
2021-11-23 01:58:08,534 - INFO - joeynmt.training - Example #3
2021-11-23 01:58:08,534 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 01:58:08,534 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 01:58:08,534 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 01:58:08,534 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 01:58:08,534 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 01:58:08,534 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 01:58:08,534 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 01:58:08,534 - INFO - joeynmt.training - Example #6
2021-11-23 01:58:08,534 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 01:58:08,534 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 01:58:08,534 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 01:58:08,534 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 01:58:08,534 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 01:58:08,535 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 01:58:08,535 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 01:58:08,535 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    52000: bleu:   5.23, loss: 90526.4297, ppl:  14.4833, duration: 177.5390s
2021-11-23 01:58:22,876 - INFO - joeynmt.training - Epoch  16, Step:    52100, Batch Loss:     2.605495, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 01:58:38,021 - INFO - joeynmt.training - Epoch  16, Step:    52200, Batch Loss:     2.811312, Tokens per Sec:     2083, Lr: 0.000100
2021-11-23 01:58:52,337 - INFO - joeynmt.training - Epoch  16, Step:    52300, Batch Loss:     2.695218, Tokens per Sec:     2184, Lr: 0.000100
2021-11-23 01:59:07,605 - INFO - joeynmt.training - Epoch  16, Step:    52400, Batch Loss:     2.619825, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 01:59:22,569 - INFO - joeynmt.training - Epoch  16, Step:    52500, Batch Loss:     2.655917, Tokens per Sec:     2168, Lr: 0.000100
2021-11-23 01:59:37,474 - INFO - joeynmt.training - Epoch  16, Step:    52600, Batch Loss:     2.485142, Tokens per Sec:     2181, Lr: 0.000100
2021-11-23 01:59:52,914 - INFO - joeynmt.training - Epoch  16, Step:    52700, Batch Loss:     2.832133, Tokens per Sec:     2075, Lr: 0.000100
2021-11-23 02:00:07,254 - INFO - joeynmt.training - Epoch  16, Step:    52800, Batch Loss:     2.854549, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 02:00:22,344 - INFO - joeynmt.training - Epoch  16, Step:    52900, Batch Loss:     2.536182, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 02:00:36,412 - INFO - joeynmt.training - Epoch  16, Step:    53000, Batch Loss:     2.735250, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 02:04:13,202 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:04:13,202 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:04:13,203 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:04:13,220 - INFO - joeynmt.training - Example #0
2021-11-23 02:04:13,220 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:04:13,220 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:04:13,220 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'ert', 'ain', '▁of', '▁J', 'e', 'ho', 'ho', 'ho', 'ho', 'e', ',', '▁but', '▁the', '▁people', '▁of', '▁Judah', ',', '▁but', '▁they', '▁were', '▁not', '▁to', '▁be', '▁a', 'head', '▁of', '▁the', '▁people', '.']
2021-11-23 02:04:13,220 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:04:13,220 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:04:13,220 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:04:13,220 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c ert ain ▁of ▁J e ho ho ho ho e , ▁but ▁the ▁people ▁of ▁Judah , ▁but ▁they ▁were ▁not ▁to ▁be ▁a head ▁of ▁the ▁people .
2021-11-23 02:04:13,221 - INFO - joeynmt.training - Example #1
2021-11-23 02:04:13,221 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:04:13,221 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:04:13,221 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 02:04:13,221 - INFO - joeynmt.training - Example #2
2021-11-23 02:04:13,221 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:04:13,221 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:04:13,221 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁not', '▁to', '▁you', ',', '▁and', '▁I', '▁am', '▁with', '▁you', '.', '▁Let', '▁each', '▁other', ',', '▁and', '▁let', 'ter', ',', '▁and', '▁let', 'ter', ',', '▁and', '▁now', ',', '▁and', '▁now', ',', '▁and', '▁now', ',', '▁and', '▁now', ',', '▁or', '▁I', '▁am', '▁writ', 'ing', '.']
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁not ▁to ▁you , ▁and ▁I ▁am ▁with ▁you . ▁Let ▁each ▁other , ▁and ▁let ter , ▁and ▁let ter , ▁and ▁now , ▁and ▁now , ▁and ▁now , ▁and ▁now , ▁or ▁I ▁am ▁writ ing .
2021-11-23 02:04:13,221 - INFO - joeynmt.training - Example #3
2021-11-23 02:04:13,221 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:04:13,221 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:04:13,221 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:04:13,221 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 02:04:13,221 - INFO - joeynmt.training - Example #6
2021-11-23 02:04:13,222 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:04:13,222 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:04:13,222 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 02:04:13,222 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:04:13,222 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:04:13,222 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:04:13,222 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 02:04:13,222 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    53000: bleu:   5.15, loss: 89665.3984, ppl:  14.1197, duration: 216.8094s
2021-11-23 02:04:28,694 - INFO - joeynmt.training - Epoch  16, Step:    53100, Batch Loss:     2.357673, Tokens per Sec:     2052, Lr: 0.000100
2021-11-23 02:04:43,537 - INFO - joeynmt.training - Epoch  16, Step:    53200, Batch Loss:     2.510812, Tokens per Sec:     2068, Lr: 0.000100
2021-11-23 02:04:58,505 - INFO - joeynmt.training - Epoch  16, Step:    53300, Batch Loss:     2.734640, Tokens per Sec:     2058, Lr: 0.000100
2021-11-23 02:05:13,269 - INFO - joeynmt.training - Epoch  16, Step:    53400, Batch Loss:     2.749855, Tokens per Sec:     2173, Lr: 0.000100
2021-11-23 02:05:27,461 - INFO - joeynmt.training - Epoch  16, Step:    53500, Batch Loss:     2.719044, Tokens per Sec:     2173, Lr: 0.000100
2021-11-23 02:05:42,334 - INFO - joeynmt.training - Epoch  16, Step:    53600, Batch Loss:     2.790222, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 02:05:57,476 - INFO - joeynmt.training - Epoch  16, Step:    53700, Batch Loss:     3.080508, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 02:06:13,118 - INFO - joeynmt.training - Epoch  16, Step:    53800, Batch Loss:     2.647355, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 02:06:27,972 - INFO - joeynmt.training - Epoch  16, Step:    53900, Batch Loss:     2.660994, Tokens per Sec:     2161, Lr: 0.000100
2021-11-23 02:06:42,444 - INFO - joeynmt.training - Epoch  16, Step:    54000, Batch Loss:     2.781744, Tokens per Sec:     2181, Lr: 0.000100
2021-11-23 02:09:03,763 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:09:03,763 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:09:03,763 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:09:03,774 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 02:09:04,601 - INFO - joeynmt.helpers - delete models/baseline_multilingual/52000.ckpt
2021-11-23 02:09:04,602 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/52000.ckpt
2021-11-23 02:09:04,602 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/52000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/52000.ckpt')
2021-11-23 02:09:04,668 - INFO - joeynmt.training - Example #0
2021-11-23 02:09:04,668 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:09:04,669 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:09:04,669 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'apt', 'ure', 'd', '▁of', '▁J', 'ose', 'ph', ',', '▁but', '▁you', '▁are', '▁a', 'head', '▁of', '▁J', 'ose', 'ph', '.', '▁But', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 02:09:04,669 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:09:04,669 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:09:04,669 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:09:04,669 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c apt ure d ▁of ▁J ose ph , ▁but ▁you ▁are ▁a head ▁of ▁J ose ph . ▁But ▁you ▁are ▁not ▁a head ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 02:09:04,670 - INFO - joeynmt.training - Example #1
2021-11-23 02:09:04,670 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:09:04,670 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:09:04,670 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 02:09:04,670 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:09:04,670 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:09:04,670 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:09:04,671 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 02:09:04,671 - INFO - joeynmt.training - Example #2
2021-11-23 02:09:04,671 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:09:04,671 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:09:04,671 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁have', '▁given', '▁you', '▁to', '▁give', '▁you', '▁to', '▁you', '▁to', '▁love', '▁each', '▁other', '.', '▁Don', "'", 't', '▁let', '▁me', ',', '▁and', '▁let', '▁me', ',', '▁and', '▁now', '▁I', '▁am', '▁not', '▁to', '▁understand', '.']
2021-11-23 02:09:04,671 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:09:04,671 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:09:04,672 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:09:04,672 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁have ▁given ▁you ▁to ▁give ▁you ▁to ▁you ▁to ▁love ▁each ▁other . ▁Don ' t ▁let ▁me , ▁and ▁let ▁me , ▁and ▁now ▁I ▁am ▁not ▁to ▁understand .
2021-11-23 02:09:04,672 - INFO - joeynmt.training - Example #3
2021-11-23 02:09:04,672 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:09:04,672 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:09:04,672 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 02:09:04,672 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:09:04,672 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:09:04,673 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:09:04,673 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 02:09:04,673 - INFO - joeynmt.training - Example #6
2021-11-23 02:09:04,673 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:09:04,673 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:09:04,673 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 02:09:04,673 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:09:04,673 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:09:04,674 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:09:04,674 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 02:09:04,674 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    54000: bleu:   5.59, loss: 89666.2422, ppl:  14.1201, duration: 142.2301s
2021-11-23 02:09:19,466 - INFO - joeynmt.training - Epoch  16, Step:    54100, Batch Loss:     2.764132, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 02:09:34,405 - INFO - joeynmt.training - Epoch  16, Step:    54200, Batch Loss:     2.607230, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 02:09:38,066 - INFO - joeynmt.training - Epoch  16: total training loss 8999.76
2021-11-23 02:09:38,066 - INFO - joeynmt.training - EPOCH 17
2021-11-23 02:09:49,310 - INFO - joeynmt.training - Epoch  17, Step:    54300, Batch Loss:     2.608267, Tokens per Sec:     2074, Lr: 0.000100
2021-11-23 02:10:03,866 - INFO - joeynmt.training - Epoch  17, Step:    54400, Batch Loss:     2.410747, Tokens per Sec:     2091, Lr: 0.000100
2021-11-23 02:10:19,126 - INFO - joeynmt.training - Epoch  17, Step:    54500, Batch Loss:     2.730286, Tokens per Sec:     2014, Lr: 0.000100
2021-11-23 02:10:33,854 - INFO - joeynmt.training - Epoch  17, Step:    54600, Batch Loss:     2.643360, Tokens per Sec:     2092, Lr: 0.000100
2021-11-23 02:10:47,859 - INFO - joeynmt.training - Epoch  17, Step:    54700, Batch Loss:     2.608655, Tokens per Sec:     2189, Lr: 0.000100
2021-11-23 02:11:02,005 - INFO - joeynmt.training - Epoch  17, Step:    54800, Batch Loss:     2.427068, Tokens per Sec:     2253, Lr: 0.000100
2021-11-23 02:11:17,482 - INFO - joeynmt.training - Epoch  17, Step:    54900, Batch Loss:     2.634726, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 02:11:32,049 - INFO - joeynmt.training - Epoch  17, Step:    55000, Batch Loss:     2.578640, Tokens per Sec:     2213, Lr: 0.000100
2021-11-23 02:15:26,438 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:15:26,438 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:15:26,438 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:15:26,457 - INFO - joeynmt.training - Example #0
2021-11-23 02:15:26,457 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:15:26,457 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:15:26,457 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'apt', 'ure', 'd', '▁in', '▁Jerusalem', ',', '▁but', '▁they', '▁were', '▁a', '▁R', 'u', 'th', '▁of', '▁J', 'e', 'ho', 'ho', 'l', ',', '▁but', '▁they', '▁were', '▁not', '▁to', '▁be', '▁a', '▁great', '▁great', 'er', '.']
2021-11-23 02:15:26,457 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:15:26,457 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:15:26,457 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:15:26,457 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c apt ure d ▁in ▁Jerusalem , ▁but ▁they ▁were ▁a ▁R u th ▁of ▁J e ho ho l , ▁but ▁they ▁were ▁not ▁to ▁be ▁a ▁great ▁great er .
2021-11-23 02:15:26,457 - INFO - joeynmt.training - Example #1
2021-11-23 02:15:26,457 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:15:26,457 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:15:26,457 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 02:15:26,457 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:15:26,457 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:15:26,457 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:15:26,457 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 02:15:26,457 - INFO - joeynmt.training - Example #2
2021-11-23 02:15:26,457 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:15:26,458 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:15:26,458 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁with', '▁you', ',', '▁and', '▁I', '▁have', '▁been', '▁with', '▁you', '▁with', '▁each', '▁other', '▁with', '▁each', '▁other', '.', '▁Don', "'", 't', '▁know', '▁that', '▁is', '▁only', '▁only', '▁only', '▁only', '▁one', '▁who', '▁is', '▁only', '▁only', '▁only', '▁only', '▁one', '.']
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁with ▁you , ▁and ▁I ▁have ▁been ▁with ▁you ▁with ▁each ▁other ▁with ▁each ▁other . ▁Don ' t ▁know ▁that ▁is ▁only ▁only ▁only ▁only ▁one ▁who ▁is ▁only ▁only ▁only ▁only ▁one .
2021-11-23 02:15:26,458 - INFO - joeynmt.training - Example #3
2021-11-23 02:15:26,458 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:15:26,458 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:15:26,458 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 02:15:26,458 - INFO - joeynmt.training - Example #6
2021-11-23 02:15:26,458 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:15:26,458 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:15:26,458 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:15:26,458 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 02:15:26,458 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    55000: bleu:   4.98, loss: 89468.5312, ppl:  14.0379, duration: 234.4086s
2021-11-23 02:15:41,207 - INFO - joeynmt.training - Epoch  17, Step:    55100, Batch Loss:     2.661788, Tokens per Sec:     2104, Lr: 0.000100
2021-11-23 02:15:56,185 - INFO - joeynmt.training - Epoch  17, Step:    55200, Batch Loss:     2.675021, Tokens per Sec:     2097, Lr: 0.000100
2021-11-23 02:16:10,502 - INFO - joeynmt.training - Epoch  17, Step:    55300, Batch Loss:     2.659402, Tokens per Sec:     2182, Lr: 0.000100
2021-11-23 02:16:24,775 - INFO - joeynmt.training - Epoch  17, Step:    55400, Batch Loss:     2.520600, Tokens per Sec:     2196, Lr: 0.000100
2021-11-23 02:16:39,204 - INFO - joeynmt.training - Epoch  17, Step:    55500, Batch Loss:     2.780615, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 02:16:54,690 - INFO - joeynmt.training - Epoch  17, Step:    55600, Batch Loss:     2.688090, Tokens per Sec:     2056, Lr: 0.000100
2021-11-23 02:17:09,750 - INFO - joeynmt.training - Epoch  17, Step:    55700, Batch Loss:     2.705333, Tokens per Sec:     2158, Lr: 0.000100
2021-11-23 02:17:25,392 - INFO - joeynmt.training - Epoch  17, Step:    55800, Batch Loss:     2.740670, Tokens per Sec:     2033, Lr: 0.000100
2021-11-23 02:17:40,281 - INFO - joeynmt.training - Epoch  17, Step:    55900, Batch Loss:     2.702120, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 02:17:54,659 - INFO - joeynmt.training - Epoch  17, Step:    56000, Batch Loss:     2.656662, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 02:20:08,974 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:20:08,974 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:20:08,974 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:20:08,986 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 02:20:09,802 - INFO - joeynmt.helpers - delete models/baseline_multilingual/54000.ckpt
2021-11-23 02:20:09,803 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/54000.ckpt
2021-11-23 02:20:09,803 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/54000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/54000.ckpt')
2021-11-23 02:20:09,862 - INFO - joeynmt.training - Example #0
2021-11-23 02:20:09,862 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:20:09,863 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:20:09,863 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'ert', 'ain', '▁of', '▁Jerusalem', ',', '▁but', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁a', '▁p', 'ubl', 'ic', 'es', ',', '▁but', '▁you', '▁are', '▁a', '▁p', 'ubl', 'ic', 'ation', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 02:20:09,863 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:20:09,863 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:20:09,863 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:20:09,863 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c ert ain ▁of ▁Jerusalem , ▁but ▁you ▁are ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁a ▁p ubl ic es , ▁but ▁you ▁are ▁a ▁p ubl ic ation ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 02:20:09,864 - INFO - joeynmt.training - Example #1
2021-11-23 02:20:09,864 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:20:09,864 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:20:09,864 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 02:20:09,864 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:20:09,864 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:20:09,864 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:20:09,864 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 02:20:09,865 - INFO - joeynmt.training - Example #2
2021-11-23 02:20:09,865 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:20:09,865 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:20:09,865 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁a', '▁p', 'ubl', 'ic', 'ation', ',', '▁for', '▁you', '▁are', '▁a', '▁fe', 'llow', 'ship', '▁with', '▁each', '▁other', '.', '▁O', 'ther', 's', ',', '▁it', '▁is', '▁a', '▁little', '▁one', '▁who', '▁is', '▁only', '▁one', '.']
2021-11-23 02:20:09,865 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:20:09,865 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:20:09,865 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:20:09,866 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁a ▁p ubl ic ation , ▁for ▁you ▁are ▁a ▁fe llow ship ▁with ▁each ▁other . ▁O ther s , ▁it ▁is ▁a ▁little ▁one ▁who ▁is ▁only ▁one .
2021-11-23 02:20:09,866 - INFO - joeynmt.training - Example #3
2021-11-23 02:20:09,866 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:20:09,866 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:20:09,866 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'uito']
2021-11-23 02:20:09,866 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:20:09,866 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:20:09,867 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:20:09,867 - INFO - joeynmt.training - 	Hypothesis: ▁m uito
2021-11-23 02:20:09,867 - INFO - joeynmt.training - Example #6
2021-11-23 02:20:09,867 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:20:09,867 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:20:09,867 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 02:20:09,867 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:20:09,867 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:20:09,868 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:20:09,868 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 02:20:09,868 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    56000: bleu:   5.81, loss: 89134.5547, ppl:  13.9002, duration: 135.2085s
2021-11-23 02:20:24,661 - INFO - joeynmt.training - Epoch  17, Step:    56100, Batch Loss:     2.269172, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 02:20:39,587 - INFO - joeynmt.training - Epoch  17, Step:    56200, Batch Loss:     2.824181, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 02:20:54,867 - INFO - joeynmt.training - Epoch  17, Step:    56300, Batch Loss:     2.441004, Tokens per Sec:     2093, Lr: 0.000100
2021-11-23 02:21:08,903 - INFO - joeynmt.training - Epoch  17, Step:    56400, Batch Loss:     2.624882, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 02:21:23,816 - INFO - joeynmt.training - Epoch  17, Step:    56500, Batch Loss:     2.768409, Tokens per Sec:     2082, Lr: 0.000100
2021-11-23 02:21:37,870 - INFO - joeynmt.training - Epoch  17, Step:    56600, Batch Loss:     2.661181, Tokens per Sec:     2158, Lr: 0.000100
2021-11-23 02:21:53,468 - INFO - joeynmt.training - Epoch  17, Step:    56700, Batch Loss:     2.610973, Tokens per Sec:     2172, Lr: 0.000100
2021-11-23 02:22:08,618 - INFO - joeynmt.training - Epoch  17, Step:    56800, Batch Loss:     2.562771, Tokens per Sec:     2077, Lr: 0.000100
2021-11-23 02:22:23,200 - INFO - joeynmt.training - Epoch  17, Step:    56900, Batch Loss:     2.638455, Tokens per Sec:     2126, Lr: 0.000100
2021-11-23 02:22:37,685 - INFO - joeynmt.training - Epoch  17, Step:    57000, Batch Loss:     2.737431, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 02:25:45,554 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:25:45,554 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:25:45,554 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:25:45,577 - INFO - joeynmt.training - Example #0
2021-11-23 02:25:45,577 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:25:45,577 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:25:45,577 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', 'head', '▁of', '▁the', '▁church', ',', '▁but', '▁they', '▁were', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁the', '▁people', '▁of', '▁Judah', '▁were', '▁not', '▁to', '▁be', '▁re', 'ally', '▁re', 'ally', '▁been', '▁d', 'en', 'ied', '.']
2021-11-23 02:25:45,577 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:25:45,577 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:25:45,577 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:25:45,577 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a head ▁of ▁the ▁church , ▁but ▁they ▁were ▁the ▁people ▁of ▁Gal ile e . ▁But ▁the ▁people ▁of ▁Judah ▁were ▁not ▁to ▁be ▁re ally ▁re ally ▁been ▁d en ied .
2021-11-23 02:25:45,577 - INFO - joeynmt.training - Example #1
2021-11-23 02:25:45,577 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:25:45,577 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 02:25:45,578 - INFO - joeynmt.training - Example #2
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁a', '▁fe', 'llow', 'ship', '▁with', '▁you', ',', '▁and', '▁let', 'ter', '▁is', '▁the', '▁body', '▁of', '▁each', '▁other', '.', '▁Let', '▁each', '▁other', ',', '▁and', '▁now', '▁is', '▁the', '▁one', '▁who', '▁is', '▁not', '▁only', '▁one', '.']
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁a ▁fe llow ship ▁with ▁you , ▁and ▁let ter ▁is ▁the ▁body ▁of ▁each ▁other . ▁Let ▁each ▁other , ▁and ▁now ▁is ▁the ▁one ▁who ▁is ▁not ▁only ▁one .
2021-11-23 02:25:45,578 - INFO - joeynmt.training - Example #3
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ais']
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Hypothesis: ▁m ais
2021-11-23 02:25:45,578 - INFO - joeynmt.training - Example #6
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:25:45,578 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:25:45,578 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:25:45,579 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:25:45,579 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 02:25:45,579 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    57000: bleu:   5.57, loss: 88566.8828, ppl:  13.6691, duration: 187.8933s
2021-11-23 02:26:00,297 - INFO - joeynmt.training - Epoch  17, Step:    57100, Batch Loss:     2.642874, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 02:26:15,157 - INFO - joeynmt.training - Epoch  17, Step:    57200, Batch Loss:     2.818778, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 02:26:29,363 - INFO - joeynmt.training - Epoch  17, Step:    57300, Batch Loss:     2.566705, Tokens per Sec:     2221, Lr: 0.000100
2021-11-23 02:26:43,853 - INFO - joeynmt.training - Epoch  17, Step:    57400, Batch Loss:     2.522567, Tokens per Sec:     2217, Lr: 0.000100
2021-11-23 02:26:58,741 - INFO - joeynmt.training - Epoch  17, Step:    57500, Batch Loss:     2.642028, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 02:27:13,704 - INFO - joeynmt.training - Epoch  17, Step:    57600, Batch Loss:     2.579995, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 02:27:15,556 - INFO - joeynmt.training - Epoch  17: total training loss 8883.04
2021-11-23 02:27:15,556 - INFO - joeynmt.training - EPOCH 18
2021-11-23 02:27:28,683 - INFO - joeynmt.training - Epoch  18, Step:    57700, Batch Loss:     2.494700, Tokens per Sec:     2058, Lr: 0.000100
2021-11-23 02:27:43,039 - INFO - joeynmt.training - Epoch  18, Step:    57800, Batch Loss:     2.468502, Tokens per Sec:     2188, Lr: 0.000100
2021-11-23 02:27:57,339 - INFO - joeynmt.training - Epoch  18, Step:    57900, Batch Loss:     2.473249, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 02:28:12,269 - INFO - joeynmt.training - Epoch  18, Step:    58000, Batch Loss:     2.713078, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 02:30:52,400 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:30:52,401 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:30:52,401 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:30:52,412 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 02:30:53,248 - INFO - joeynmt.helpers - delete models/baseline_multilingual/56000.ckpt
2021-11-23 02:30:53,250 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/56000.ckpt
2021-11-23 02:30:53,251 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/56000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/56000.ckpt')
2021-11-23 02:30:53,309 - INFO - joeynmt.training - Example #0
2021-11-23 02:30:53,309 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:30:53,310 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:30:53,310 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁c', 'ert', 'ain', 'ed', '▁to', '▁Jerusalem', ',', '▁but', '▁they', '▁were', '▁c', 'ert', 'ain', 'ed', '▁in', '▁Gal', 'ile', 'e', '.', '▁But', '▁they', '▁were', '▁c', 'ert', 'ain', 'ed', '▁to', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 02:30:53,310 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:30:53,310 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:30:53,310 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:30:53,310 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁c ert ain ed ▁to ▁Jerusalem , ▁but ▁they ▁were ▁c ert ain ed ▁in ▁Gal ile e . ▁But ▁they ▁were ▁c ert ain ed ▁to ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 02:30:53,310 - INFO - joeynmt.training - Example #1
2021-11-23 02:30:53,311 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:30:53,311 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:30:53,311 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'd', 'ire']
2021-11-23 02:30:53,311 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:30:53,311 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:30:53,311 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:30:53,311 - INFO - joeynmt.training - 	Hypothesis: ▁E d ire
2021-11-23 02:30:53,311 - INFO - joeynmt.training - Example #2
2021-11-23 02:30:53,311 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:30:53,312 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:30:53,312 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁a', '▁p', 'ur', 'p', 'ose', '▁to', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁each', '▁other', '.', '▁L', 'ove', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁no', '▁one', '.']
2021-11-23 02:30:53,312 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:30:53,312 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:30:53,312 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:30:53,312 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁a ▁p ur p ose ▁to ▁each ▁other , ▁and ▁let ter ▁each ▁other . ▁L ove ▁each ▁other , ▁and ▁let ter ▁is ▁no ▁one .
2021-11-23 02:30:53,312 - INFO - joeynmt.training - Example #3
2021-11-23 02:30:53,312 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:30:53,312 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:30:53,312 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ada']
2021-11-23 02:30:53,312 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:30:53,312 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:30:53,313 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:30:53,313 - INFO - joeynmt.training - 	Hypothesis: ▁n ada
2021-11-23 02:30:53,313 - INFO - joeynmt.training - Example #6
2021-11-23 02:30:53,313 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:30:53,313 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:30:53,313 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 02:30:53,313 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:30:53,313 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:30:53,313 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:30:53,313 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 02:30:53,314 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    58000: bleu:   6.03, loss: 88470.7812, ppl:  13.6304, duration: 161.0447s
2021-11-23 02:31:08,021 - INFO - joeynmt.training - Epoch  18, Step:    58100, Batch Loss:     2.386522, Tokens per Sec:     2098, Lr: 0.000100
2021-11-23 02:31:22,352 - INFO - joeynmt.training - Epoch  18, Step:    58200, Batch Loss:     2.506600, Tokens per Sec:     2164, Lr: 0.000100
2021-11-23 02:31:37,592 - INFO - joeynmt.training - Epoch  18, Step:    58300, Batch Loss:     2.642833, Tokens per Sec:     2079, Lr: 0.000100
2021-11-23 02:31:51,988 - INFO - joeynmt.training - Epoch  18, Step:    58400, Batch Loss:     2.621197, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 02:32:06,654 - INFO - joeynmt.training - Epoch  18, Step:    58500, Batch Loss:     2.714972, Tokens per Sec:     2093, Lr: 0.000100
2021-11-23 02:32:21,569 - INFO - joeynmt.training - Epoch  18, Step:    58600, Batch Loss:     2.537525, Tokens per Sec:     2069, Lr: 0.000100
2021-11-23 02:32:35,788 - INFO - joeynmt.training - Epoch  18, Step:    58700, Batch Loss:     2.723318, Tokens per Sec:     2247, Lr: 0.000100
2021-11-23 02:32:50,386 - INFO - joeynmt.training - Epoch  18, Step:    58800, Batch Loss:     2.848795, Tokens per Sec:     2305, Lr: 0.000100
2021-11-23 02:33:05,940 - INFO - joeynmt.training - Epoch  18, Step:    58900, Batch Loss:     2.435818, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 02:33:20,819 - INFO - joeynmt.training - Epoch  18, Step:    59000, Batch Loss:     2.562449, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 02:36:06,912 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:36:06,912 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:36:06,912 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:36:06,930 - INFO - joeynmt.training - Example #0
2021-11-23 02:36:06,930 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:36:06,930 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:36:06,930 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'apt', 'ure', 'd', '▁of', '▁J', 'e', 'us', ',', '▁and', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁a', 'head', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁who', '▁are', '▁not', '▁to', '▁be', 'h', 'ind', '.']
2021-11-23 02:36:06,930 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:36:06,930 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:36:06,930 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:36:06,930 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c apt ure d ▁of ▁J e us , ▁and ▁you ▁are ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁are ▁a head ▁of ▁the ▁people ▁of ▁the ▁people ▁who ▁are ▁not ▁to ▁be h ind .
2021-11-23 02:36:06,930 - INFO - joeynmt.training - Example #1
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'ng', 'l', 'os']
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Hypothesis: ▁E ng l os
2021-11-23 02:36:06,931 - INFO - joeynmt.training - Example #2
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁want', '▁to', '▁you', '▁to', '▁be', '▁with', '▁you', ',', '▁for', '▁you', '▁have', '▁been', '▁a', 'ct', 'u', 'ally', '▁love', '▁each', '▁other', '.']
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁want ▁to ▁you ▁to ▁be ▁with ▁you , ▁for ▁you ▁have ▁been ▁a ct u ally ▁love ▁each ▁other .
2021-11-23 02:36:06,931 - INFO - joeynmt.training - Example #3
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:36:06,931 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 02:36:06,931 - INFO - joeynmt.training - Example #6
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:36:06,931 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 02:36:06,932 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:36:06,932 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:36:06,932 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:36:06,932 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 02:36:06,932 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    59000: bleu:   5.94, loss: 88403.0781, ppl:  13.6031, duration: 166.1122s
2021-11-23 02:36:21,463 - INFO - joeynmt.training - Epoch  18, Step:    59100, Batch Loss:     2.453659, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 02:36:36,641 - INFO - joeynmt.training - Epoch  18, Step:    59200, Batch Loss:     2.730459, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 02:36:51,434 - INFO - joeynmt.training - Epoch  18, Step:    59300, Batch Loss:     2.502166, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 02:37:06,791 - INFO - joeynmt.training - Epoch  18, Step:    59400, Batch Loss:     2.733419, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 02:37:21,597 - INFO - joeynmt.training - Epoch  18, Step:    59500, Batch Loss:     2.605117, Tokens per Sec:     2061, Lr: 0.000100
2021-11-23 02:37:36,013 - INFO - joeynmt.training - Epoch  18, Step:    59600, Batch Loss:     2.506571, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 02:37:50,525 - INFO - joeynmt.training - Epoch  18, Step:    59700, Batch Loss:     2.564680, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 02:38:05,117 - INFO - joeynmt.training - Epoch  18, Step:    59800, Batch Loss:     2.767904, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 02:38:20,132 - INFO - joeynmt.training - Epoch  18, Step:    59900, Batch Loss:     2.585243, Tokens per Sec:     2092, Lr: 0.000100
2021-11-23 02:38:35,615 - INFO - joeynmt.training - Epoch  18, Step:    60000, Batch Loss:     2.676956, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 02:41:07,777 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:41:07,778 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:41:07,778 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:41:07,790 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 02:41:08,608 - INFO - joeynmt.helpers - delete models/baseline_multilingual/58000.ckpt
2021-11-23 02:41:08,609 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/58000.ckpt
2021-11-23 02:41:08,609 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/58000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/58000.ckpt')
2021-11-23 02:41:08,669 - INFO - joeynmt.training - Example #0
2021-11-23 02:41:08,669 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:41:08,669 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:41:08,669 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'ert', 'ain', '▁of', '▁J', 'e', 'ar', 'us', ',', '▁and', '▁you', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁they', '▁were', '▁c', 'ru', 'cif', 'ied', '.', '▁But', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '.']
2021-11-23 02:41:08,669 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:41:08,670 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:41:08,670 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:41:08,670 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c ert ain ▁of ▁J e ar us , ▁and ▁you ▁are ▁a head ▁of ▁Gal ile e , ▁but ▁they ▁were ▁c ru cif ied . ▁But ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people ▁of ▁the ▁people .
2021-11-23 02:41:08,670 - INFO - joeynmt.training - Example #1
2021-11-23 02:41:08,670 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:41:08,670 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:41:08,670 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'o', 'og', 'ia']
2021-11-23 02:41:08,671 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:41:08,671 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:41:08,671 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:41:08,671 - INFO - joeynmt.training - 	Hypothesis: ▁G o og ia
2021-11-23 02:41:08,671 - INFO - joeynmt.training - Example #2
2021-11-23 02:41:08,671 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:41:08,672 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:41:08,672 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁a', '▁p', 'ubl', 'ic', 'ation', '▁to', '▁be', '▁with', '▁each', '▁other', '.', '▁Let', '▁each', '▁other', ',', '▁let', 'ter', ',', '▁let', 'ter', '▁is', '▁the', '▁one', '▁who', '▁is', '▁no', '▁one', '▁who', '▁is', '▁no', '▁one', '▁who', '▁is', '▁no', '▁one', '.']
2021-11-23 02:41:08,672 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:41:08,672 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:41:08,672 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:41:08,672 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁a ▁p ubl ic ation ▁to ▁be ▁with ▁each ▁other . ▁Let ▁each ▁other , ▁let ter , ▁let ter ▁is ▁the ▁one ▁who ▁is ▁no ▁one ▁who ▁is ▁no ▁one ▁who ▁is ▁no ▁one .
2021-11-23 02:41:08,672 - INFO - joeynmt.training - Example #3
2021-11-23 02:41:08,673 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:41:08,673 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:41:08,673 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ada']
2021-11-23 02:41:08,673 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:41:08,673 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:41:08,673 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:41:08,673 - INFO - joeynmt.training - 	Hypothesis: ▁n ada
2021-11-23 02:41:08,673 - INFO - joeynmt.training - Example #6
2021-11-23 02:41:08,674 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:41:08,674 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:41:08,674 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 02:41:08,674 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:41:08,674 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:41:08,674 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:41:08,674 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 02:41:08,675 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    60000: bleu:   6.23, loss: 87803.8125, ppl:  13.3646, duration: 153.0589s
2021-11-23 02:41:22,642 - INFO - joeynmt.training - Epoch  18, Step:    60100, Batch Loss:     2.590363, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 02:41:36,680 - INFO - joeynmt.training - Epoch  18, Step:    60200, Batch Loss:     2.665428, Tokens per Sec:     2161, Lr: 0.000100
2021-11-23 02:41:51,230 - INFO - joeynmt.training - Epoch  18, Step:    60300, Batch Loss:     2.534339, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 02:42:06,309 - INFO - joeynmt.training - Epoch  18, Step:    60400, Batch Loss:     2.475128, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 02:42:20,203 - INFO - joeynmt.training - Epoch  18, Step:    60500, Batch Loss:     2.431484, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 02:42:34,857 - INFO - joeynmt.training - Epoch  18, Step:    60600, Batch Loss:     2.584686, Tokens per Sec:     2129, Lr: 0.000100
2021-11-23 02:42:50,145 - INFO - joeynmt.training - Epoch  18, Step:    60700, Batch Loss:     2.596579, Tokens per Sec:     2027, Lr: 0.000100
2021-11-23 02:43:05,373 - INFO - joeynmt.training - Epoch  18, Step:    60800, Batch Loss:     2.787903, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 02:43:20,605 - INFO - joeynmt.training - Epoch  18, Step:    60900, Batch Loss:     2.832448, Tokens per Sec:     2066, Lr: 0.000100
2021-11-23 02:43:34,937 - INFO - joeynmt.training - Epoch  18, Step:    61000, Batch Loss:     2.800656, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 02:46:50,711 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:46:50,711 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:46:50,711 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:46:50,728 - INFO - joeynmt.training - Example #0
2021-11-23 02:46:50,728 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:46:50,728 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:46:50,728 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁to', '▁Jerusalem', '.', '▁But', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁they', '▁are', '▁a', '▁p', 'ubl', 'ic', 'ian', 's', ',', '▁but', '▁they', '▁are', '▁not', '▁to', '▁be', '▁re', 'ward', '▁to', '▁the', '▁people', '.']
2021-11-23 02:46:50,728 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:46:50,728 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:46:50,728 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:46:50,728 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁to ▁Jerusalem . ▁But ▁you ▁are ▁the ▁people ▁of ▁Gal ile e , ▁but ▁they ▁are ▁a ▁p ubl ic ian s , ▁but ▁they ▁are ▁not ▁to ▁be ▁re ward ▁to ▁the ▁people .
2021-11-23 02:46:50,728 - INFO - joeynmt.training - Example #1
2021-11-23 02:46:50,728 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:46:50,728 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:46:50,728 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita', '▁de', '▁Sinais']
2021-11-23 02:46:50,728 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:46:50,728 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:46:50,728 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:46:50,728 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita ▁de ▁Sinais
2021-11-23 02:46:50,728 - INFO - joeynmt.training - Example #2
2021-11-23 02:46:50,729 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:46:50,729 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:46:50,729 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁the', '▁one', '▁of', '▁you', ',', '▁and', '▁let', '▁us', '▁with', '▁each', '▁other', ',', '▁and', '▁let', '▁us', ',', '▁and', '▁let', '▁us', ',', '▁and', '▁let', 'ter', '▁is', '▁one', '▁of', '▁the', '▁one', '▁of', '▁Christ', '.']
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁the ▁one ▁of ▁you , ▁and ▁let ▁us ▁with ▁each ▁other , ▁and ▁let ▁us , ▁and ▁let ▁us , ▁and ▁let ter ▁is ▁one ▁of ▁the ▁one ▁of ▁Christ .
2021-11-23 02:46:50,729 - INFO - joeynmt.training - Example #3
2021-11-23 02:46:50,729 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:46:50,729 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:46:50,729 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 02:46:50,729 - INFO - joeynmt.training - Example #6
2021-11-23 02:46:50,729 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:46:50,729 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:46:50,729 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ive']
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:46:50,729 - INFO - joeynmt.training - 	Hypothesis: ▁f ive
2021-11-23 02:46:50,729 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    61000: bleu:   5.87, loss: 87475.6953, ppl:  13.2357, duration: 195.7916s
2021-11-23 02:46:50,964 - INFO - joeynmt.training - Epoch  18: total training loss 8771.93
2021-11-23 02:46:50,964 - INFO - joeynmt.training - EPOCH 19
2021-11-23 02:47:05,239 - INFO - joeynmt.training - Epoch  19, Step:    61100, Batch Loss:     2.533622, Tokens per Sec:     2158, Lr: 0.000100
2021-11-23 02:47:19,946 - INFO - joeynmt.training - Epoch  19, Step:    61200, Batch Loss:     2.402559, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 02:47:34,599 - INFO - joeynmt.training - Epoch  19, Step:    61300, Batch Loss:     2.626283, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 02:47:49,812 - INFO - joeynmt.training - Epoch  19, Step:    61400, Batch Loss:     2.580587, Tokens per Sec:     2122, Lr: 0.000100
2021-11-23 02:48:04,246 - INFO - joeynmt.training - Epoch  19, Step:    61500, Batch Loss:     2.500850, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 02:48:18,486 - INFO - joeynmt.training - Epoch  19, Step:    61600, Batch Loss:     2.503633, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 02:48:33,716 - INFO - joeynmt.training - Epoch  19, Step:    61700, Batch Loss:     2.363458, Tokens per Sec:     2101, Lr: 0.000100
2021-11-23 02:48:48,163 - INFO - joeynmt.training - Epoch  19, Step:    61800, Batch Loss:     2.604640, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 02:49:03,153 - INFO - joeynmt.training - Epoch  19, Step:    61900, Batch Loss:     2.266281, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 02:49:17,809 - INFO - joeynmt.training - Epoch  19, Step:    62000, Batch Loss:     2.648590, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 02:52:05,646 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:52:05,646 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:52:05,646 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:52:05,658 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 02:52:06,485 - INFO - joeynmt.helpers - delete models/baseline_multilingual/60000.ckpt
2021-11-23 02:52:06,485 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/60000.ckpt
2021-11-23 02:52:06,486 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/60000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/60000.ckpt')
2021-11-23 02:52:06,540 - INFO - joeynmt.training - Example #0
2021-11-23 02:52:06,540 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:52:06,540 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:52:06,541 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁c', 'ert', 'ain', 'ed', '▁to', '▁the', '▁Temple', '▁of', '▁Judah', '.', '▁But', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁not', '▁a', '▁p', 'ubl', 'ic', '.', '▁But', '▁you', '▁are', '▁all', '▁the', '▁people', '▁of', '▁their', '▁enem', 'ies', '▁are', '▁all', '▁their', '▁enem', 'ies', '.']
2021-11-23 02:52:06,541 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:52:06,541 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:52:06,541 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:52:06,541 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁c ert ain ed ▁to ▁the ▁Temple ▁of ▁Judah . ▁But ▁you ▁are ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁not ▁a ▁p ubl ic . ▁But ▁you ▁are ▁all ▁the ▁people ▁of ▁their ▁enem ies ▁are ▁all ▁their ▁enem ies .
2021-11-23 02:52:06,541 - INFO - joeynmt.training - Example #1
2021-11-23 02:52:06,541 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:52:06,541 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:52:06,541 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'd', 'ia']
2021-11-23 02:52:06,542 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:52:06,542 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:52:06,542 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:52:06,542 - INFO - joeynmt.training - 	Hypothesis: ▁E d ia
2021-11-23 02:52:06,542 - INFO - joeynmt.training - Example #2
2021-11-23 02:52:06,542 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:52:06,542 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:52:06,542 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁a', '▁great', 'er', '▁than', 'k', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁each', '▁other', ',', '▁and', '▁let', 'ter', ',', '▁and', '▁let', 'ter', ',', '▁and', '▁let', 'ter', ',', '▁and', '▁now', '▁now', ',', '▁and', '▁now', '▁now', ',', '▁only', '▁one', '▁can', '▁see', '▁me', '.']
2021-11-23 02:52:06,542 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:52:06,542 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:52:06,543 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:52:06,543 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁a ▁great er ▁than k ▁each ▁other , ▁and ▁let ter ▁each ▁other , ▁and ▁let ter , ▁and ▁let ter , ▁and ▁let ter , ▁and ▁now ▁now , ▁and ▁now ▁now , ▁only ▁one ▁can ▁see ▁me .
2021-11-23 02:52:06,543 - INFO - joeynmt.training - Example #3
2021-11-23 02:52:06,543 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:52:06,543 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:52:06,543 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁n', 'ao']
2021-11-23 02:52:06,543 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:52:06,543 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:52:06,543 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:52:06,543 - INFO - joeynmt.training - 	Hypothesis: ▁n ao
2021-11-23 02:52:06,544 - INFO - joeynmt.training - Example #6
2021-11-23 02:52:06,544 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:52:06,544 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:52:06,544 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁f', 'ir', 'th']
2021-11-23 02:52:06,544 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:52:06,544 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:52:06,544 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:52:06,544 - INFO - joeynmt.training - 	Hypothesis: ▁f ir th
2021-11-23 02:52:06,544 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    62000: bleu:   6.31, loss: 87481.1406, ppl:  13.2378, duration: 168.7354s
2021-11-23 02:52:21,804 - INFO - joeynmt.training - Epoch  19, Step:    62100, Batch Loss:     2.522538, Tokens per Sec:     2038, Lr: 0.000100
2021-11-23 02:52:37,434 - INFO - joeynmt.training - Epoch  19, Step:    62200, Batch Loss:     2.744342, Tokens per Sec:     2110, Lr: 0.000100
2021-11-23 02:52:52,256 - INFO - joeynmt.training - Epoch  19, Step:    62300, Batch Loss:     2.672156, Tokens per Sec:     2038, Lr: 0.000100
2021-11-23 02:53:07,134 - INFO - joeynmt.training - Epoch  19, Step:    62400, Batch Loss:     2.645509, Tokens per Sec:     2092, Lr: 0.000100
2021-11-23 02:53:22,294 - INFO - joeynmt.training - Epoch  19, Step:    62500, Batch Loss:     2.662322, Tokens per Sec:     2161, Lr: 0.000100
2021-11-23 02:53:36,059 - INFO - joeynmt.training - Epoch  19, Step:    62600, Batch Loss:     2.603935, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 02:53:50,598 - INFO - joeynmt.training - Epoch  19, Step:    62700, Batch Loss:     2.553630, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 02:54:06,008 - INFO - joeynmt.training - Epoch  19, Step:    62800, Batch Loss:     2.566104, Tokens per Sec:     2061, Lr: 0.000100
2021-11-23 02:54:20,006 - INFO - joeynmt.training - Epoch  19, Step:    62900, Batch Loss:     2.428084, Tokens per Sec:     2170, Lr: 0.000100
2021-11-23 02:54:34,453 - INFO - joeynmt.training - Epoch  19, Step:    63000, Batch Loss:     2.426346, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 02:56:59,666 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 02:56:59,666 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 02:56:59,666 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 02:56:59,677 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 02:57:00,488 - INFO - joeynmt.helpers - delete models/baseline_multilingual/62000.ckpt
2021-11-23 02:57:00,489 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/62000.ckpt
2021-11-23 02:57:00,489 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/62000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/62000.ckpt')
2021-11-23 02:57:00,548 - INFO - joeynmt.training - Example #0
2021-11-23 02:57:00,548 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 02:57:00,548 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 02:57:00,548 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'ert', 'ain', '▁of', '▁the', '▁Temple', '▁of', '▁Judah', '.', '▁They', '▁were', '▁c', 'ru', 'cif', 'ied', '▁with', '▁the', '▁people', '▁of', '▁G', 'il', 'i', 'us', '.', '▁But', '▁they', '▁were', '▁still', '▁still', '▁still', '▁still', '▁still', '▁still', '▁with', '▁their', '▁own', '▁people', '.']
2021-11-23 02:57:00,548 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 02:57:00,549 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 02:57:00,549 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 02:57:00,549 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c ert ain ▁of ▁the ▁Temple ▁of ▁Judah . ▁They ▁were ▁c ru cif ied ▁with ▁the ▁people ▁of ▁G il i us . ▁But ▁they ▁were ▁still ▁still ▁still ▁still ▁still ▁still ▁with ▁their ▁own ▁people .
2021-11-23 02:57:00,549 - INFO - joeynmt.training - Example #1
2021-11-23 02:57:00,549 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 02:57:00,549 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 02:57:00,550 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'd', 'ia']
2021-11-23 02:57:00,550 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 02:57:00,550 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 02:57:00,550 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 02:57:00,550 - INFO - joeynmt.training - 	Hypothesis: ▁E d ia
2021-11-23 02:57:00,550 - INFO - joeynmt.training - Example #2
2021-11-23 02:57:00,550 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 02:57:00,551 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 02:57:00,551 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁a', '▁good', '▁way', '▁to', '▁you', ',', '▁and', '▁let', '▁each', '▁other', '▁other', ',', '▁and', '▁let', 'ter', ',', '▁and', '▁let', 'ter', '▁is', '▁only', '▁one', '▁of', '▁love', '.']
2021-11-23 02:57:00,551 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 02:57:00,551 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 02:57:00,551 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 02:57:00,551 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁a ▁good ▁way ▁to ▁you , ▁and ▁let ▁each ▁other ▁other , ▁and ▁let ter , ▁and ▁let ter ▁is ▁only ▁one ▁of ▁love .
2021-11-23 02:57:00,551 - INFO - joeynmt.training - Example #3
2021-11-23 02:57:00,552 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 02:57:00,552 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 02:57:00,552 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 02:57:00,552 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 02:57:00,552 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 02:57:00,552 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 02:57:00,552 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 02:57:00,552 - INFO - joeynmt.training - Example #6
2021-11-23 02:57:00,553 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 02:57:00,553 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 02:57:00,553 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 02:57:00,553 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 02:57:00,553 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 02:57:00,553 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 02:57:00,553 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 02:57:00,554 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    63000: bleu:   6.35, loss: 87216.0469, ppl:  13.1346, duration: 146.1000s
2021-11-23 02:57:15,253 - INFO - joeynmt.training - Epoch  19, Step:    63100, Batch Loss:     2.457786, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 02:57:29,733 - INFO - joeynmt.training - Epoch  19, Step:    63200, Batch Loss:     2.583337, Tokens per Sec:     2226, Lr: 0.000100
2021-11-23 02:57:44,048 - INFO - joeynmt.training - Epoch  19, Step:    63300, Batch Loss:     2.613252, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 02:57:59,153 - INFO - joeynmt.training - Epoch  19, Step:    63400, Batch Loss:     2.587025, Tokens per Sec:     2081, Lr: 0.000100
2021-11-23 02:58:13,596 - INFO - joeynmt.training - Epoch  19, Step:    63500, Batch Loss:     2.431498, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 02:58:28,678 - INFO - joeynmt.training - Epoch  19, Step:    63600, Batch Loss:     2.612402, Tokens per Sec:     2099, Lr: 0.000100
2021-11-23 02:58:42,955 - INFO - joeynmt.training - Epoch  19, Step:    63700, Batch Loss:     2.457472, Tokens per Sec:     2122, Lr: 0.000100
2021-11-23 02:58:58,166 - INFO - joeynmt.training - Epoch  19, Step:    63800, Batch Loss:     2.435807, Tokens per Sec:     2084, Lr: 0.000100
2021-11-23 02:59:12,852 - INFO - joeynmt.training - Epoch  19, Step:    63900, Batch Loss:     2.525947, Tokens per Sec:     2263, Lr: 0.000100
2021-11-23 02:59:27,067 - INFO - joeynmt.training - Epoch  19, Step:    64000, Batch Loss:     2.578259, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 03:01:34,712 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:01:34,712 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:01:34,712 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:01:34,723 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 03:01:35,550 - INFO - joeynmt.helpers - delete models/baseline_multilingual/63000.ckpt
2021-11-23 03:01:35,551 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/63000.ckpt
2021-11-23 03:01:35,551 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/63000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/63000.ckpt')
2021-11-23 03:01:35,606 - INFO - joeynmt.training - Example #0
2021-11-23 03:01:35,607 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:01:35,607 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:01:35,607 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', 'head', '▁of', '▁J', 'e', 'us', 'a', 'es', ',', '▁the', '▁J', 'e', 'ho', 'z', 'zar', ',', '▁but', '▁you', '▁have', '▁been', '▁a', 'head', '▁of', '▁the', '▁people', '▁of', '▁Judah', '.', '▁But', '▁you', '▁have', '▁been', '▁a', 'head', '▁of', '▁your', 'selves', ',', '▁and', '▁you', '▁are', '▁still', '▁still', '▁all', '▁the', '▁g', 'ates', '.']
2021-11-23 03:01:35,607 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:01:35,607 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:01:35,607 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:01:35,608 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a head ▁of ▁J e us a es , ▁the ▁J e ho z zar , ▁but ▁you ▁have ▁been ▁a head ▁of ▁the ▁people ▁of ▁Judah . ▁But ▁you ▁have ▁been ▁a head ▁of ▁your selves , ▁and ▁you ▁are ▁still ▁still ▁all ▁the ▁g ates .
2021-11-23 03:01:35,608 - INFO - joeynmt.training - Example #1
2021-11-23 03:01:35,608 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:01:35,608 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:01:35,608 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 03:01:35,608 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:01:35,608 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:01:35,609 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:01:35,609 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 03:01:35,609 - INFO - joeynmt.training - Example #2
2021-11-23 03:01:35,609 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:01:35,609 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:01:35,609 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁am', '▁a', '▁good', '▁way', '▁to', '▁you', ',', '▁and', '▁let', '▁us', '▁with', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁let', 'ter', ',', '▁and', '▁let', 'ter', '▁is', '▁only', '▁one', '▁of', '▁love', '.']
2021-11-23 03:01:35,609 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:01:35,610 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:01:35,610 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:01:35,610 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁am ▁a ▁good ▁way ▁to ▁you , ▁and ▁let ▁us ▁with ▁each ▁other ▁with ▁each ▁other , ▁and ▁let ter , ▁and ▁let ter ▁is ▁only ▁one ▁of ▁love .
2021-11-23 03:01:35,610 - INFO - joeynmt.training - Example #3
2021-11-23 03:01:35,610 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:01:35,610 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:01:35,610 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 03:01:35,610 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:01:35,611 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:01:35,611 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:01:35,611 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 03:01:35,611 - INFO - joeynmt.training - Example #6
2021-11-23 03:01:35,611 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:01:35,611 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:01:35,611 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:01:35,611 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:01:35,611 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:01:35,611 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:01:35,611 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:01:35,611 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    64000: bleu:   6.54, loss: 86946.3438, ppl:  13.0304, duration: 128.5440s
2021-11-23 03:01:50,327 - INFO - joeynmt.training - Epoch  19, Step:    64100, Batch Loss:     2.526171, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 03:02:05,539 - INFO - joeynmt.training - Epoch  19, Step:    64200, Batch Loss:     2.494799, Tokens per Sec:     2126, Lr: 0.000100
2021-11-23 03:02:20,665 - INFO - joeynmt.training - Epoch  19, Step:    64300, Batch Loss:     2.696548, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 03:02:33,837 - INFO - joeynmt.training - Epoch  19: total training loss 8661.33
2021-11-23 03:02:33,838 - INFO - joeynmt.training - EPOCH 20
2021-11-23 03:02:35,096 - INFO - joeynmt.training - Epoch  20, Step:    64400, Batch Loss:     2.502583, Tokens per Sec:     1992, Lr: 0.000100
2021-11-23 03:02:49,024 - INFO - joeynmt.training - Epoch  20, Step:    64500, Batch Loss:     2.643920, Tokens per Sec:     2233, Lr: 0.000100
2021-11-23 03:03:03,836 - INFO - joeynmt.training - Epoch  20, Step:    64600, Batch Loss:     2.718288, Tokens per Sec:     2101, Lr: 0.000100
2021-11-23 03:03:18,919 - INFO - joeynmt.training - Epoch  20, Step:    64700, Batch Loss:     2.382052, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 03:03:34,459 - INFO - joeynmt.training - Epoch  20, Step:    64800, Batch Loss:     2.349080, Tokens per Sec:     2004, Lr: 0.000100
2021-11-23 03:03:49,191 - INFO - joeynmt.training - Epoch  20, Step:    64900, Batch Loss:     2.657280, Tokens per Sec:     2201, Lr: 0.000100
2021-11-23 03:04:04,939 - INFO - joeynmt.training - Epoch  20, Step:    65000, Batch Loss:     2.574354, Tokens per Sec:     2071, Lr: 0.000100
2021-11-23 03:06:02,470 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:06:02,471 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:06:02,471 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:06:02,482 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 03:06:03,297 - INFO - joeynmt.helpers - delete models/baseline_multilingual/64000.ckpt
2021-11-23 03:06:03,298 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/64000.ckpt
2021-11-23 03:06:03,298 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/64000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/64000.ckpt')
2021-11-23 03:06:03,360 - INFO - joeynmt.training - Example #0
2021-11-23 03:06:03,360 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:06:03,360 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:06:03,360 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'it', 'us', ',', '▁and', '▁you', '▁are', '▁the', '▁J', 'e', 'ar', 'us', ',', '▁but', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁still', '▁a', 'head', '▁of', '▁your', '▁own', '▁people', '.']
2021-11-23 03:06:03,360 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:06:03,360 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:06:03,361 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:06:03,361 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c it us , ▁and ▁you ▁are ▁the ▁J e ar us , ▁but ▁you ▁are ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁still ▁a head ▁of ▁your ▁own ▁people .
2021-11-23 03:06:03,361 - INFO - joeynmt.training - Example #1
2021-11-23 03:06:03,361 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:06:03,361 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:06:03,361 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sp', 'an', 'ho']
2021-11-23 03:06:03,362 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:06:03,362 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:06:03,362 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:06:03,362 - INFO - joeynmt.training - 	Hypothesis: ▁E sp an ho
2021-11-23 03:06:03,362 - INFO - joeynmt.training - Example #2
2021-11-23 03:06:03,362 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:06:03,362 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:06:03,362 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', ',', '▁let', 'ter', ',', '▁let', '▁us', ',', '▁let', 'ter', '▁with', '▁each', '▁other', ',', '▁and', '▁let', 'ter', ',', '▁and', '▁let', 'ter', '▁is', '▁the', '▁one', '▁of', '▁Christ', '.']
2021-11-23 03:06:03,363 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:06:03,363 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:06:03,363 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:06:03,363 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me , ▁let ter , ▁let ▁us , ▁let ter ▁with ▁each ▁other , ▁and ▁let ter , ▁and ▁let ter ▁is ▁the ▁one ▁of ▁Christ .
2021-11-23 03:06:03,363 - INFO - joeynmt.training - Example #3
2021-11-23 03:06:03,363 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:06:03,363 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:06:03,363 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ais']
2021-11-23 03:06:03,363 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:06:03,363 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:06:03,363 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:06:03,363 - INFO - joeynmt.training - 	Hypothesis: ▁m ais
2021-11-23 03:06:03,364 - INFO - joeynmt.training - Example #6
2021-11-23 03:06:03,364 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:06:03,364 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:06:03,364 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:06:03,364 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:06:03,364 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:06:03,364 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:06:03,364 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:06:03,364 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    65000: bleu:   6.90, loss: 86640.2734, ppl:  12.9132, duration: 118.4250s
2021-11-23 03:06:18,364 - INFO - joeynmt.training - Epoch  20, Step:    65100, Batch Loss:     2.366827, Tokens per Sec:     2130, Lr: 0.000100
2021-11-23 03:06:32,602 - INFO - joeynmt.training - Epoch  20, Step:    65200, Batch Loss:     2.511417, Tokens per Sec:     2180, Lr: 0.000100
2021-11-23 03:06:46,916 - INFO - joeynmt.training - Epoch  20, Step:    65300, Batch Loss:     2.653039, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 03:07:01,787 - INFO - joeynmt.training - Epoch  20, Step:    65400, Batch Loss:     2.570019, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 03:07:16,520 - INFO - joeynmt.training - Epoch  20, Step:    65500, Batch Loss:     2.431165, Tokens per Sec:     2085, Lr: 0.000100
2021-11-23 03:07:31,434 - INFO - joeynmt.training - Epoch  20, Step:    65600, Batch Loss:     2.476420, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 03:07:46,001 - INFO - joeynmt.training - Epoch  20, Step:    65700, Batch Loss:     2.533867, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 03:08:01,343 - INFO - joeynmt.training - Epoch  20, Step:    65800, Batch Loss:     2.490865, Tokens per Sec:     2099, Lr: 0.000100
2021-11-23 03:08:15,510 - INFO - joeynmt.training - Epoch  20, Step:    65900, Batch Loss:     2.430639, Tokens per Sec:     2170, Lr: 0.000100
2021-11-23 03:08:30,493 - INFO - joeynmt.training - Epoch  20, Step:    66000, Batch Loss:     2.599888, Tokens per Sec:     2062, Lr: 0.000100
2021-11-23 03:10:53,269 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:10:53,270 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:10:53,270 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:10:53,287 - INFO - joeynmt.training - Example #0
2021-11-23 03:10:53,287 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:10:53,287 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:10:53,287 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'ert', 'ain', '▁of', '▁J', 'ust', 'r', 'us', '.', '▁But', '▁you', '▁are', '▁a', 'ct', 'u', 'ally', '▁from', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁your', '▁own', '▁people', ',', '▁but', '▁you', '▁are', '▁still', '▁a', 'head', '▁of', '▁their', '▁own', '▁people', '.']
2021-11-23 03:10:53,287 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:10:53,287 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c ert ain ▁of ▁J ust r us . ▁But ▁you ▁are ▁a ct u ally ▁from ▁Gal ile e , ▁but ▁you ▁are ▁not ▁a head ▁of ▁your ▁own ▁people , ▁but ▁you ▁are ▁still ▁a head ▁of ▁their ▁own ▁people .
2021-11-23 03:10:53,288 - INFO - joeynmt.training - Example #1
2021-11-23 03:10:53,288 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:10:53,288 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:10:53,288 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'N', 'T', 'AR']
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Hypothesis: ▁E N T AR
2021-11-23 03:10:53,288 - INFO - joeynmt.training - Example #2
2021-11-23 03:10:53,288 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:10:53,288 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:10:53,288 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', ',', '▁let', 'ter', ',', '▁for', '▁you', '▁have', '▁been', '▁a', 'ct', 'u', 'ally', '▁with', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁a', 'ct', 'u', 'ally', '▁only', '▁one', '▁who', '▁is', '▁only', '▁one', '▁who', '▁is', '▁only', '▁one', '.']
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me , ▁let ter , ▁for ▁you ▁have ▁been ▁a ct u ally ▁with ▁each ▁other , ▁and ▁let ter ▁is ▁a ct u ally ▁only ▁one ▁who ▁is ▁only ▁one ▁who ▁is ▁only ▁one .
2021-11-23 03:10:53,288 - INFO - joeynmt.training - Example #3
2021-11-23 03:10:53,288 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:10:53,288 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:10:53,288 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'u', 'pl', 'o']
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:10:53,288 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:10:53,289 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:10:53,289 - INFO - joeynmt.training - 	Hypothesis: ▁d u pl o
2021-11-23 03:10:53,289 - INFO - joeynmt.training - Example #6
2021-11-23 03:10:53,289 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:10:53,289 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:10:53,289 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:10:53,289 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:10:53,289 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:10:53,289 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:10:53,289 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:10:53,289 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    66000: bleu:   6.69, loss: 86344.1719, ppl:  12.8008, duration: 142.7957s
2021-11-23 03:11:08,915 - INFO - joeynmt.training - Epoch  20, Step:    66100, Batch Loss:     2.611521, Tokens per Sec:     2097, Lr: 0.000100
2021-11-23 03:11:23,766 - INFO - joeynmt.training - Epoch  20, Step:    66200, Batch Loss:     2.639943, Tokens per Sec:     2091, Lr: 0.000100
2021-11-23 03:11:38,348 - INFO - joeynmt.training - Epoch  20, Step:    66300, Batch Loss:     2.465075, Tokens per Sec:     2165, Lr: 0.000100
2021-11-23 03:11:52,953 - INFO - joeynmt.training - Epoch  20, Step:    66400, Batch Loss:     2.461401, Tokens per Sec:     2082, Lr: 0.000100
2021-11-23 03:12:07,939 - INFO - joeynmt.training - Epoch  20, Step:    66500, Batch Loss:     2.845031, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 03:12:22,473 - INFO - joeynmt.training - Epoch  20, Step:    66600, Batch Loss:     2.499507, Tokens per Sec:     2108, Lr: 0.000100
2021-11-23 03:12:37,109 - INFO - joeynmt.training - Epoch  20, Step:    66700, Batch Loss:     2.646923, Tokens per Sec:     2063, Lr: 0.000100
2021-11-23 03:12:51,391 - INFO - joeynmt.training - Epoch  20, Step:    66800, Batch Loss:     2.567951, Tokens per Sec:     2128, Lr: 0.000100
2021-11-23 03:13:06,382 - INFO - joeynmt.training - Epoch  20, Step:    66900, Batch Loss:     2.627053, Tokens per Sec:     2104, Lr: 0.000100
2021-11-23 03:13:20,441 - INFO - joeynmt.training - Epoch  20, Step:    67000, Batch Loss:     2.411143, Tokens per Sec:     2161, Lr: 0.000100
2021-11-23 03:16:17,014 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:16:17,014 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:16:17,014 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:16:17,035 - INFO - joeynmt.training - Example #0
2021-11-23 03:16:17,035 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:16:17,035 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:16:17,035 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'apt', 'ure', 'd', '▁in', '▁Jerusalem', '.', '▁But', '▁you', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁your', '▁own', '▁people', '.']
2021-11-23 03:16:17,035 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:16:17,035 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c apt ure d ▁in ▁Jerusalem . ▁But ▁you ▁are ▁a head ▁of ▁Gal ile e , ▁but ▁you ▁are ▁not ▁a head ▁of ▁your ▁own ▁people .
2021-11-23 03:16:17,036 - INFO - joeynmt.training - Example #1
2021-11-23 03:16:17,036 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:16:17,036 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:16:17,036 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 03:16:17,036 - INFO - joeynmt.training - Example #2
2021-11-23 03:16:17,036 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:16:17,036 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:16:17,036 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', ',', '▁let', 'ter', '▁be', '▁with', '▁you', ',', '▁and', '▁let', 'ter', '▁each', '▁other', '.', '▁Let', '▁each', '▁other', ',', '▁one', '▁another', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '▁one', '.']
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me , ▁let ter ▁be ▁with ▁you , ▁and ▁let ter ▁each ▁other . ▁Let ▁each ▁other , ▁one ▁another ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one ▁one .
2021-11-23 03:16:17,036 - INFO - joeynmt.training - Example #3
2021-11-23 03:16:17,036 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:16:17,036 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:16:17,036 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:16:17,036 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:16:17,037 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:16:17,037 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 03:16:17,037 - INFO - joeynmt.training - Example #6
2021-11-23 03:16:17,037 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:16:17,037 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:16:17,037 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:16:17,037 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:16:17,037 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:16:17,037 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:16:17,037 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:16:17,037 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    67000: bleu:   6.54, loss: 86163.0781, ppl:  12.7325, duration: 176.5959s
2021-11-23 03:16:31,894 - INFO - joeynmt.training - Epoch  20, Step:    67100, Batch Loss:     2.421265, Tokens per Sec:     2168, Lr: 0.000100
2021-11-23 03:16:46,084 - INFO - joeynmt.training - Epoch  20, Step:    67200, Batch Loss:     2.462738, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 03:17:00,334 - INFO - joeynmt.training - Epoch  20, Step:    67300, Batch Loss:     2.495894, Tokens per Sec:     2201, Lr: 0.000100
2021-11-23 03:17:14,738 - INFO - joeynmt.training - Epoch  20, Step:    67400, Batch Loss:     2.548165, Tokens per Sec:     2199, Lr: 0.000100
2021-11-23 03:17:29,790 - INFO - joeynmt.training - Epoch  20, Step:    67500, Batch Loss:     2.361754, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 03:17:44,902 - INFO - joeynmt.training - Epoch  20, Step:    67600, Batch Loss:     2.603086, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 03:18:00,189 - INFO - joeynmt.training - Epoch  20, Step:    67700, Batch Loss:     2.460072, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 03:18:12,736 - INFO - joeynmt.training - Epoch  20: total training loss 8557.79
2021-11-23 03:18:12,737 - INFO - joeynmt.training - EPOCH 21
2021-11-23 03:18:15,748 - INFO - joeynmt.training - Epoch  21, Step:    67800, Batch Loss:     2.582546, Tokens per Sec:     2006, Lr: 0.000100
2021-11-23 03:18:30,966 - INFO - joeynmt.training - Epoch  21, Step:    67900, Batch Loss:     2.444066, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 03:18:45,949 - INFO - joeynmt.training - Epoch  21, Step:    68000, Batch Loss:     2.453418, Tokens per Sec:     2015, Lr: 0.000100
2021-11-23 03:21:39,467 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:21:39,467 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:21:39,467 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:21:39,479 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 03:21:40,304 - INFO - joeynmt.helpers - delete models/baseline_multilingual/65000.ckpt
2021-11-23 03:21:40,305 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/65000.ckpt
2021-11-23 03:21:40,306 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/65000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/65000.ckpt')
2021-11-23 03:21:40,361 - INFO - joeynmt.training - Example #0
2021-11-23 03:21:40,361 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:21:40,361 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:21:40,361 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'apt', 'ure', 'd', '▁in', '▁Jerusalem', '.', '▁But', '▁you', '▁are', '▁a', '▁c', 'ru', 'cif', 'ul', 'y', '▁of', '▁Judah', ',', '▁but', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁your', '▁own', '▁people', ',', '▁and', '▁they', '▁are', '▁all', '▁the', '▁w', 'ild', 'ers', '.']
2021-11-23 03:21:40,361 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:21:40,361 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:21:40,362 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:21:40,362 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c apt ure d ▁in ▁Jerusalem . ▁But ▁you ▁are ▁a ▁c ru cif ul y ▁of ▁Judah , ▁but ▁you ▁are ▁not ▁a head ▁of ▁your ▁own ▁people , ▁and ▁they ▁are ▁all ▁the ▁w ild ers .
2021-11-23 03:21:40,362 - INFO - joeynmt.training - Example #1
2021-11-23 03:21:40,362 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:21:40,362 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:21:40,362 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 03:21:40,362 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:21:40,363 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:21:40,363 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:21:40,363 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 03:21:40,363 - INFO - joeynmt.training - Example #2
2021-11-23 03:21:40,363 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:21:40,363 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:21:40,363 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁have', '▁been', '▁made', '▁to', '▁you', '▁to', '▁be', '▁with', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁only', '▁one', '▁with', '▁each', '▁other', '.']
2021-11-23 03:21:40,364 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:21:40,364 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:21:40,364 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:21:40,364 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁have ▁been ▁made ▁to ▁you ▁to ▁be ▁with ▁each ▁other , ▁and ▁let ▁each ▁other , ▁and ▁let ter ▁is ▁only ▁one ▁with ▁each ▁other .
2021-11-23 03:21:40,364 - INFO - joeynmt.training - Example #3
2021-11-23 03:21:40,364 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:21:40,364 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:21:40,364 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 03:21:40,364 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:21:40,364 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:21:40,364 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:21:40,364 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 03:21:40,364 - INFO - joeynmt.training - Example #6
2021-11-23 03:21:40,364 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:21:40,365 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:21:40,365 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:21:40,365 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:21:40,365 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:21:40,365 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:21:40,365 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:21:40,365 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    68000: bleu:   7.06, loss: 85805.9844, ppl:  12.5990, duration: 174.4155s
2021-11-23 03:21:55,545 - INFO - joeynmt.training - Epoch  21, Step:    68100, Batch Loss:     2.603146, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 03:22:10,860 - INFO - joeynmt.training - Epoch  21, Step:    68200, Batch Loss:     2.557173, Tokens per Sec:     2104, Lr: 0.000100
2021-11-23 03:22:25,444 - INFO - joeynmt.training - Epoch  21, Step:    68300, Batch Loss:     2.544229, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 03:22:40,394 - INFO - joeynmt.training - Epoch  21, Step:    68400, Batch Loss:     2.663924, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 03:22:54,333 - INFO - joeynmt.training - Epoch  21, Step:    68500, Batch Loss:     2.498905, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 03:23:09,669 - INFO - joeynmt.training - Epoch  21, Step:    68600, Batch Loss:     2.448532, Tokens per Sec:     2035, Lr: 0.000100
2021-11-23 03:23:24,047 - INFO - joeynmt.training - Epoch  21, Step:    68700, Batch Loss:     2.516127, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 03:23:38,590 - INFO - joeynmt.training - Epoch  21, Step:    68800, Batch Loss:     2.440645, Tokens per Sec:     2232, Lr: 0.000100
2021-11-23 03:23:53,685 - INFO - joeynmt.training - Epoch  21, Step:    68900, Batch Loss:     2.397312, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 03:24:08,042 - INFO - joeynmt.training - Epoch  21, Step:    69000, Batch Loss:     2.621780, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 03:27:04,330 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:27:04,330 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:27:04,330 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:27:04,348 - INFO - joeynmt.training - Example #0
2021-11-23 03:27:04,348 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:27:04,348 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:27:04,348 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'ert', 'ain', '▁in', '▁Jerusalem', '.', '▁But', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁not', '▁a', '▁p', 'ur', 'der', ',', '▁but', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁your', '▁own', '▁people', '.']
2021-11-23 03:27:04,348 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:27:04,348 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:27:04,348 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:27:04,348 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c ert ain ▁in ▁Jerusalem . ▁But ▁you ▁are ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁are ▁not ▁a ▁p ur der , ▁but ▁you ▁are ▁not ▁a head ▁of ▁your ▁own ▁people .
2021-11-23 03:27:04,348 - INFO - joeynmt.training - Example #1
2021-11-23 03:27:04,348 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:27:04,348 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:27:04,348 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'AL', '▁SC']
2021-11-23 03:27:04,348 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:27:04,348 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:27:04,348 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:27:04,348 - INFO - joeynmt.training - 	Hypothesis: ▁E AL ▁SC
2021-11-23 03:27:04,348 - INFO - joeynmt.training - Example #2
2021-11-23 03:27:04,348 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:27:04,348 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:27:04,349 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁with', '▁joy', ',', '▁and', '▁let', '▁us', '▁with', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁with', '▁each', '▁other', '.']
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁with ▁joy , ▁and ▁let ▁us ▁with ▁each ▁other , ▁and ▁let ter ▁is ▁with ▁each ▁other .
2021-11-23 03:27:04,349 - INFO - joeynmt.training - Example #3
2021-11-23 03:27:04,349 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:27:04,349 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:27:04,349 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ais']
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Hypothesis: ▁m ais
2021-11-23 03:27:04,349 - INFO - joeynmt.training - Example #6
2021-11-23 03:27:04,349 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:27:04,349 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:27:04,349 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:27:04,349 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:27:04,349 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    69000: bleu:   6.73, loss: 85635.6484, ppl:  12.5358, duration: 176.3070s
2021-11-23 03:27:19,726 - INFO - joeynmt.training - Epoch  21, Step:    69100, Batch Loss:     2.264677, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 03:27:34,785 - INFO - joeynmt.training - Epoch  21, Step:    69200, Batch Loss:     2.485579, Tokens per Sec:     2062, Lr: 0.000100
2021-11-23 03:27:49,202 - INFO - joeynmt.training - Epoch  21, Step:    69300, Batch Loss:     2.301870, Tokens per Sec:     2280, Lr: 0.000100
2021-11-23 03:28:04,561 - INFO - joeynmt.training - Epoch  21, Step:    69400, Batch Loss:     2.646499, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 03:28:19,534 - INFO - joeynmt.training - Epoch  21, Step:    69500, Batch Loss:     2.482909, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 03:28:33,627 - INFO - joeynmt.training - Epoch  21, Step:    69600, Batch Loss:     2.586007, Tokens per Sec:     2103, Lr: 0.000100
2021-11-23 03:28:48,720 - INFO - joeynmt.training - Epoch  21, Step:    69700, Batch Loss:     2.457811, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 03:29:04,090 - INFO - joeynmt.training - Epoch  21, Step:    69800, Batch Loss:     2.512096, Tokens per Sec:     2035, Lr: 0.000100
2021-11-23 03:29:18,286 - INFO - joeynmt.training - Epoch  21, Step:    69900, Batch Loss:     2.389203, Tokens per Sec:     2191, Lr: 0.000100
2021-11-23 03:29:32,143 - INFO - joeynmt.training - Epoch  21, Step:    70000, Batch Loss:     2.785027, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 03:32:17,693 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:32:17,694 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:32:17,694 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:32:17,705 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 03:32:18,523 - INFO - joeynmt.helpers - delete models/baseline_multilingual/68000.ckpt
2021-11-23 03:32:18,523 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/68000.ckpt
2021-11-23 03:32:18,524 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/68000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/68000.ckpt')
2021-11-23 03:32:18,584 - INFO - joeynmt.training - Example #0
2021-11-23 03:32:18,584 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:32:18,584 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:32:18,585 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Judah', ',', '▁and', '▁you', '▁are', '▁the', '▁gra', 'in', 'ning', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁the', '▁people', '▁of', '▁the', '▁people', '▁who', '▁are', '▁still', '▁still', '▁p', 'ur', 'p', 'ed', '▁by', '▁their', '▁own', '▁people', '.']
2021-11-23 03:32:18,585 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:32:18,585 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:32:18,585 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:32:18,585 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁Judah , ▁and ▁you ▁are ▁the ▁gra in ning ▁from ▁Gal ile e . ▁But ▁you ▁are ▁not ▁a head ▁of ▁the ▁people ▁of ▁the ▁people ▁who ▁are ▁still ▁still ▁p ur p ed ▁by ▁their ▁own ▁people .
2021-11-23 03:32:18,585 - INFO - joeynmt.training - Example #1
2021-11-23 03:32:18,586 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:32:18,586 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:32:18,586 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 03:32:18,586 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:32:18,586 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:32:18,586 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:32:18,586 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 03:32:18,586 - INFO - joeynmt.training - Example #2
2021-11-23 03:32:18,586 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:32:18,586 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:32:18,586 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁sa', 'ved', '▁with', '▁me', ',', '▁for', '▁let', '▁us', '▁the', '▁body', '▁of', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', '.']
2021-11-23 03:32:18,586 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:32:18,586 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:32:18,587 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:32:18,587 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁sa ved ▁with ▁me , ▁for ▁let ▁us ▁the ▁body ▁of ▁each ▁other , ▁and ▁let ▁each ▁other .
2021-11-23 03:32:18,587 - INFO - joeynmt.training - Example #3
2021-11-23 03:32:18,587 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:32:18,587 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:32:18,587 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 03:32:18,587 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:32:18,587 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:32:18,587 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:32:18,587 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 03:32:18,587 - INFO - joeynmt.training - Example #6
2021-11-23 03:32:18,588 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:32:18,588 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:32:18,588 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:32:18,588 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:32:18,588 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:32:18,588 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:32:18,588 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:32:18,588 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    70000: bleu:   7.07, loss: 85376.0391, ppl:  12.4401, duration: 166.4455s
2021-11-23 03:32:33,741 - INFO - joeynmt.training - Epoch  21, Step:    70100, Batch Loss:     2.515851, Tokens per Sec:     2070, Lr: 0.000100
2021-11-23 03:32:49,016 - INFO - joeynmt.training - Epoch  21, Step:    70200, Batch Loss:     2.589489, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 03:33:03,232 - INFO - joeynmt.training - Epoch  21, Step:    70300, Batch Loss:     2.576257, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 03:33:17,696 - INFO - joeynmt.training - Epoch  21, Step:    70400, Batch Loss:     2.570021, Tokens per Sec:     2234, Lr: 0.000100
2021-11-23 03:33:32,112 - INFO - joeynmt.training - Epoch  21, Step:    70500, Batch Loss:     2.502460, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 03:33:46,265 - INFO - joeynmt.training - Epoch  21, Step:    70600, Batch Loss:     2.585305, Tokens per Sec:     2215, Lr: 0.000100
2021-11-23 03:34:01,069 - INFO - joeynmt.training - Epoch  21, Step:    70700, Batch Loss:     2.422683, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 03:34:14,911 - INFO - joeynmt.training - Epoch  21, Step:    70800, Batch Loss:     2.369361, Tokens per Sec:     2213, Lr: 0.000100
2021-11-23 03:34:28,828 - INFO - joeynmt.training - Epoch  21, Step:    70900, Batch Loss:     2.378095, Tokens per Sec:     2255, Lr: 0.000100
2021-11-23 03:34:43,225 - INFO - joeynmt.training - Epoch  21, Step:    71000, Batch Loss:     2.583841, Tokens per Sec:     2178, Lr: 0.000100
2021-11-23 03:36:58,472 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:36:58,472 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:36:58,472 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:36:58,484 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 03:36:59,310 - INFO - joeynmt.helpers - delete models/baseline_multilingual/70000.ckpt
2021-11-23 03:36:59,311 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/70000.ckpt
2021-11-23 03:36:59,311 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/70000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/70000.ckpt')
2021-11-23 03:36:59,367 - INFO - joeynmt.training - Example #0
2021-11-23 03:36:59,367 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:36:59,367 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:36:59,367 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Judah', ',', '▁but', '▁you', '▁are', '▁a', 'head', '▁of', '▁Judah', '.', '▁But', '▁you', '▁are', '▁going', '▁to', '▁be', '▁a', 'head', '▁of', '▁the', '▁people', ',', '▁but', '▁you', '▁are', '▁going', '▁to', '▁be', '▁sa', 'ved', '.']
2021-11-23 03:36:59,367 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:36:59,367 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:36:59,368 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:36:59,368 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁Judah , ▁but ▁you ▁are ▁a head ▁of ▁Judah . ▁But ▁you ▁are ▁going ▁to ▁be ▁a head ▁of ▁the ▁people , ▁but ▁you ▁are ▁going ▁to ▁be ▁sa ved .
2021-11-23 03:36:59,368 - INFO - joeynmt.training - Example #1
2021-11-23 03:36:59,368 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:36:59,368 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:36:59,368 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'd', 'ia']
2021-11-23 03:36:59,368 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:36:59,369 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:36:59,369 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:36:59,369 - INFO - joeynmt.training - 	Hypothesis: ▁E d ia
2021-11-23 03:36:59,369 - INFO - joeynmt.training - Example #2
2021-11-23 03:36:59,369 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:36:59,369 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:36:59,369 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', ',', '▁be', '▁with', '▁me', ',', '▁and', '▁let', 'ter', '▁with', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁only', '▁one', '▁with', '▁each', '▁other', '.']
2021-11-23 03:36:59,370 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:36:59,370 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:36:59,370 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:36:59,370 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me , ▁be ▁with ▁me , ▁and ▁let ter ▁with ▁each ▁other , ▁and ▁let ter ▁is ▁only ▁one ▁with ▁each ▁other .
2021-11-23 03:36:59,370 - INFO - joeynmt.training - Example #3
2021-11-23 03:36:59,370 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:36:59,371 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:36:59,371 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 03:36:59,371 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:36:59,371 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:36:59,371 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:36:59,371 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 03:36:59,371 - INFO - joeynmt.training - Example #6
2021-11-23 03:36:59,371 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:36:59,372 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:36:59,372 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:36:59,372 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:36:59,372 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:36:59,372 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:36:59,372 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:36:59,373 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    71000: bleu:   7.18, loss: 85171.7109, ppl:  12.3652, duration: 136.1476s
2021-11-23 03:37:14,624 - INFO - joeynmt.training - Epoch  21, Step:    71100, Batch Loss:     2.817519, Tokens per Sec:     2052, Lr: 0.000100
2021-11-23 03:37:24,789 - INFO - joeynmt.training - Epoch  21: total training loss 8460.84
2021-11-23 03:37:24,789 - INFO - joeynmt.training - EPOCH 22
2021-11-23 03:37:29,772 - INFO - joeynmt.training - Epoch  22, Step:    71200, Batch Loss:     2.392666, Tokens per Sec:     1995, Lr: 0.000100
2021-11-23 03:37:44,973 - INFO - joeynmt.training - Epoch  22, Step:    71300, Batch Loss:     2.771722, Tokens per Sec:     2051, Lr: 0.000100
2021-11-23 03:37:59,633 - INFO - joeynmt.training - Epoch  22, Step:    71400, Batch Loss:     2.236817, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 03:38:14,918 - INFO - joeynmt.training - Epoch  22, Step:    71500, Batch Loss:     2.234251, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 03:38:29,194 - INFO - joeynmt.training - Epoch  22, Step:    71600, Batch Loss:     2.567186, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 03:38:43,876 - INFO - joeynmt.training - Epoch  22, Step:    71700, Batch Loss:     2.406214, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 03:38:58,302 - INFO - joeynmt.training - Epoch  22, Step:    71800, Batch Loss:     2.734493, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 03:39:12,963 - INFO - joeynmt.training - Epoch  22, Step:    71900, Batch Loss:     2.393037, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 03:39:27,231 - INFO - joeynmt.training - Epoch  22, Step:    72000, Batch Loss:     2.535219, Tokens per Sec:     2172, Lr: 0.000100
2021-11-23 03:41:59,168 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:41:59,168 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:41:59,168 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:41:59,187 - INFO - joeynmt.training - Example #0
2021-11-23 03:41:59,187 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:41:59,187 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:41:59,187 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁c', 'apt', 'ure', 'd', '▁by', '▁the', '▁Temple', '▁of', '▁Judah', '.', '▁But', '▁you', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁all', '▁the', '▁people', '.']
2021-11-23 03:41:59,187 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:41:59,187 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:41:59,187 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:41:59,187 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁c apt ure d ▁by ▁the ▁Temple ▁of ▁Judah . ▁But ▁you ▁are ▁a head ▁of ▁Gal ile e , ▁but ▁you ▁are ▁not ▁a head ▁of ▁all ▁the ▁people .
2021-11-23 03:41:59,187 - INFO - joeynmt.training - Example #1
2021-11-23 03:41:59,187 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:41:59,187 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:41:59,187 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'AL', '▁SC']
2021-11-23 03:41:59,187 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:41:59,187 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:41:59,187 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:41:59,187 - INFO - joeynmt.training - 	Hypothesis: ▁E AL ▁SC
2021-11-23 03:41:59,188 - INFO - joeynmt.training - Example #2
2021-11-23 03:41:59,188 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:41:59,188 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:41:59,188 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁for', '▁me', ',', '▁and', '▁let', '▁us', '▁the', '▁same', '▁way', ',', '▁let', 'ter', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁the', '▁one', '▁of', '▁Christ', '.']
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁for ▁me , ▁and ▁let ▁us ▁the ▁same ▁way , ▁let ter ▁each ▁other , ▁and ▁let ter ▁is ▁the ▁one ▁of ▁Christ .
2021-11-23 03:41:59,188 - INFO - joeynmt.training - Example #3
2021-11-23 03:41:59,188 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:41:59,188 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:41:59,188 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'uito']
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Hypothesis: ▁m uito
2021-11-23 03:41:59,188 - INFO - joeynmt.training - Example #6
2021-11-23 03:41:59,188 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:41:59,188 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:41:59,188 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:41:59,188 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:41:59,189 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    72000: bleu:   7.15, loss: 85310.6875, ppl:  12.4161, duration: 151.9569s
2021-11-23 03:42:13,379 - INFO - joeynmt.training - Epoch  22, Step:    72100, Batch Loss:     2.499053, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 03:42:28,259 - INFO - joeynmt.training - Epoch  22, Step:    72200, Batch Loss:     2.441254, Tokens per Sec:     2072, Lr: 0.000100
2021-11-23 03:42:42,732 - INFO - joeynmt.training - Epoch  22, Step:    72300, Batch Loss:     2.541860, Tokens per Sec:     2072, Lr: 0.000100
2021-11-23 03:42:57,023 - INFO - joeynmt.training - Epoch  22, Step:    72400, Batch Loss:     2.499790, Tokens per Sec:     2219, Lr: 0.000100
2021-11-23 03:43:12,209 - INFO - joeynmt.training - Epoch  22, Step:    72500, Batch Loss:     2.422471, Tokens per Sec:     2099, Lr: 0.000100
2021-11-23 03:43:26,696 - INFO - joeynmt.training - Epoch  22, Step:    72600, Batch Loss:     2.365568, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 03:43:41,875 - INFO - joeynmt.training - Epoch  22, Step:    72700, Batch Loss:     2.670210, Tokens per Sec:     2193, Lr: 0.000100
2021-11-23 03:43:56,419 - INFO - joeynmt.training - Epoch  22, Step:    72800, Batch Loss:     2.408770, Tokens per Sec:     2199, Lr: 0.000100
2021-11-23 03:44:10,927 - INFO - joeynmt.training - Epoch  22, Step:    72900, Batch Loss:     2.481610, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 03:44:25,752 - INFO - joeynmt.training - Epoch  22, Step:    73000, Batch Loss:     2.365813, Tokens per Sec:     2202, Lr: 0.000100
2021-11-23 03:46:56,391 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:46:56,391 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:46:56,391 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:46:56,402 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 03:46:57,216 - INFO - joeynmt.helpers - delete models/baseline_multilingual/71000.ckpt
2021-11-23 03:46:57,217 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/71000.ckpt
2021-11-23 03:46:57,217 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/71000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/71000.ckpt')
2021-11-23 03:46:57,279 - INFO - joeynmt.training - Example #0
2021-11-23 03:46:57,280 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:46:57,280 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:46:57,280 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁J', 'ust', 'a', '.', '▁They', '▁were', '▁in', '▁Gal', 'ile', 'e', ',', '▁but', '▁they', '▁were', '▁c', 'ert', 'ain', 'ed', '▁in', '▁Gal', 'ile', 'e', ',', '▁but', '▁they', '▁were', '▁all', '▁the', '▁people', '▁of', '▁their', '▁own', '▁people', '.']
2021-11-23 03:46:57,280 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:46:57,280 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:46:57,280 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:46:57,281 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁J ust a . ▁They ▁were ▁in ▁Gal ile e , ▁but ▁they ▁were ▁c ert ain ed ▁in ▁Gal ile e , ▁but ▁they ▁were ▁all ▁the ▁people ▁of ▁their ▁own ▁people .
2021-11-23 03:46:57,281 - INFO - joeynmt.training - Example #1
2021-11-23 03:46:57,281 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:46:57,281 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:46:57,281 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'ola']
2021-11-23 03:46:57,281 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:46:57,281 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:46:57,282 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:46:57,282 - INFO - joeynmt.training - 	Hypothesis: ▁E sc ola
2021-11-23 03:46:57,282 - INFO - joeynmt.training - Example #2
2021-11-23 03:46:57,282 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:46:57,282 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:46:57,282 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁with', '▁joy', ',', '▁and', '▁let', 'ter', ',', '▁let', 'ter', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁with', '▁each', '▁other', '.']
2021-11-23 03:46:57,282 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:46:57,283 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:46:57,283 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:46:57,283 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁with ▁joy , ▁and ▁let ter , ▁let ter ▁each ▁other , ▁and ▁let ter ▁is ▁with ▁each ▁other .
2021-11-23 03:46:57,283 - INFO - joeynmt.training - Example #3
2021-11-23 03:46:57,283 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:46:57,283 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:46:57,283 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 03:46:57,284 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:46:57,284 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:46:57,284 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:46:57,284 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 03:46:57,284 - INFO - joeynmt.training - Example #6
2021-11-23 03:46:57,284 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:46:57,284 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:46:57,285 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:46:57,285 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:46:57,285 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:46:57,285 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:46:57,285 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:46:57,285 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    73000: bleu:   7.35, loss: 84964.9531, ppl:  12.2900, duration: 151.5333s
2021-11-23 03:47:11,827 - INFO - joeynmt.training - Epoch  22, Step:    73100, Batch Loss:     2.600460, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 03:47:26,742 - INFO - joeynmt.training - Epoch  22, Step:    73200, Batch Loss:     2.445983, Tokens per Sec:     2086, Lr: 0.000100
2021-11-23 03:47:40,964 - INFO - joeynmt.training - Epoch  22, Step:    73300, Batch Loss:     2.416283, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 03:47:55,377 - INFO - joeynmt.training - Epoch  22, Step:    73400, Batch Loss:     2.316911, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 03:48:10,394 - INFO - joeynmt.training - Epoch  22, Step:    73500, Batch Loss:     2.699022, Tokens per Sec:     2062, Lr: 0.000100
2021-11-23 03:48:24,797 - INFO - joeynmt.training - Epoch  22, Step:    73600, Batch Loss:     2.294713, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 03:48:39,439 - INFO - joeynmt.training - Epoch  22, Step:    73700, Batch Loss:     2.427455, Tokens per Sec:     2120, Lr: 0.000100
2021-11-23 03:48:53,512 - INFO - joeynmt.training - Epoch  22, Step:    73800, Batch Loss:     2.513894, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 03:49:08,162 - INFO - joeynmt.training - Epoch  22, Step:    73900, Batch Loss:     2.575538, Tokens per Sec:     2208, Lr: 0.000100
2021-11-23 03:49:22,479 - INFO - joeynmt.training - Epoch  22, Step:    74000, Batch Loss:     2.582197, Tokens per Sec:     2173, Lr: 0.000100
2021-11-23 03:52:26,406 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:52:26,406 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:52:26,406 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:52:26,424 - INFO - joeynmt.training - Example #0
2021-11-23 03:52:26,424 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:52:26,424 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:52:26,424 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁They', '▁went', '▁to', '▁Jerusalem', '▁to', '▁Jerusalem', '.', '▁But', '▁they', '▁were', '▁a', '▁lar', 'ge', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁they', '▁were', '▁going', '▁to', '▁be', '▁re', 'le', 'ase', '▁the', '▁people', ',', '▁but', '▁they', '▁were', '▁all', '▁the', '▁people', '▁of', '▁their', '▁own', '▁people', '.']
2021-11-23 03:52:26,424 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:52:26,424 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:52:26,424 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:52:26,424 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁They ▁went ▁to ▁Jerusalem ▁to ▁Jerusalem . ▁But ▁they ▁were ▁a ▁lar ge ▁of ▁Gal ile e , ▁but ▁they ▁were ▁going ▁to ▁be ▁re le ase ▁the ▁people , ▁but ▁they ▁were ▁all ▁the ▁people ▁of ▁their ▁own ▁people .
2021-11-23 03:52:26,424 - INFO - joeynmt.training - Example #1
2021-11-23 03:52:26,424 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:52:26,424 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:52:26,424 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 03:52:26,424 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:52:26,424 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:52:26,424 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:52:26,424 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 03:52:26,424 - INFO - joeynmt.training - Example #2
2021-11-23 03:52:26,424 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:52:26,424 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:52:26,424 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁sa', 'ved', ',', '▁and', '▁let', 'ter', '▁with', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁one', '▁one', '.']
2021-11-23 03:52:26,424 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁sa ved , ▁and ▁let ter ▁with ▁each ▁other , ▁and ▁let ter ▁each ▁other , ▁and ▁let ter ▁is ▁one ▁one .
2021-11-23 03:52:26,425 - INFO - joeynmt.training - Example #3
2021-11-23 03:52:26,425 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:52:26,425 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:52:26,425 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁m', 'ais']
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Hypothesis: ▁m ais
2021-11-23 03:52:26,425 - INFO - joeynmt.training - Example #6
2021-11-23 03:52:26,425 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:52:26,425 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:52:26,425 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:52:26,425 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 03:52:26,425 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    74000: bleu:   7.28, loss: 84636.9141, ppl:  12.1715, duration: 183.9460s
2021-11-23 03:52:42,506 - INFO - joeynmt.training - Epoch  22, Step:    74100, Batch Loss:     2.705840, Tokens per Sec:     2080, Lr: 0.000100
2021-11-23 03:52:57,015 - INFO - joeynmt.training - Epoch  22, Step:    74200, Batch Loss:     2.438740, Tokens per Sec:     2217, Lr: 0.000100
2021-11-23 03:53:11,394 - INFO - joeynmt.training - Epoch  22, Step:    74300, Batch Loss:     2.286523, Tokens per Sec:     2097, Lr: 0.000100
2021-11-23 03:53:25,655 - INFO - joeynmt.training - Epoch  22, Step:    74400, Batch Loss:     2.529978, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 03:53:40,914 - INFO - joeynmt.training - Epoch  22, Step:    74500, Batch Loss:     2.368725, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 03:53:49,694 - INFO - joeynmt.training - Epoch  22: total training loss 8367.36
2021-11-23 03:53:49,694 - INFO - joeynmt.training - EPOCH 23
2021-11-23 03:53:56,129 - INFO - joeynmt.training - Epoch  23, Step:    74600, Batch Loss:     2.423688, Tokens per Sec:     2068, Lr: 0.000100
2021-11-23 03:54:10,676 - INFO - joeynmt.training - Epoch  23, Step:    74700, Batch Loss:     2.400988, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 03:54:25,202 - INFO - joeynmt.training - Epoch  23, Step:    74800, Batch Loss:     2.392641, Tokens per Sec:     2221, Lr: 0.000100
2021-11-23 03:54:39,600 - INFO - joeynmt.training - Epoch  23, Step:    74900, Batch Loss:     2.495219, Tokens per Sec:     2205, Lr: 0.000100
2021-11-23 03:54:54,575 - INFO - joeynmt.training - Epoch  23, Step:    75000, Batch Loss:     2.546238, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 03:57:44,409 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 03:57:44,409 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 03:57:44,410 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 03:57:44,428 - INFO - joeynmt.training - Example #0
2021-11-23 03:57:44,428 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 03:57:44,428 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 03:57:44,428 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁c', 'ert', 'ain', '▁in', '▁Jerusalem', '.', '▁He', '▁was', '▁a', '▁c', 'ru', 'cif', 'ied', '▁from', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁a', 'head', '▁of', '▁all', '▁the', '▁people', '.']
2021-11-23 03:57:44,428 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 03:57:44,428 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 03:57:44,428 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁c ert ain ▁in ▁Jerusalem . ▁He ▁was ▁a ▁c ru cif ied ▁from ▁Gal ile e , ▁but ▁he ▁was ▁a head ▁of ▁all ▁the ▁people .
2021-11-23 03:57:44,429 - INFO - joeynmt.training - Example #1
2021-11-23 03:57:44,429 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 03:57:44,429 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 03:57:44,429 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'd', 're']
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Hypothesis: ▁E d re
2021-11-23 03:57:44,429 - INFO - joeynmt.training - Example #2
2021-11-23 03:57:44,429 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 03:57:44,429 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 03:57:44,429 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', '▁a', '▁great', 'er', '▁than', 'k', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', '.']
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me ▁a ▁great er ▁than k , ▁how ▁can ▁love ▁each ▁other , ▁and ▁let ▁each ▁other .
2021-11-23 03:57:44,429 - INFO - joeynmt.training - Example #3
2021-11-23 03:57:44,429 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 03:57:44,429 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 03:57:44,429 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'u', 'as']
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 03:57:44,429 - INFO - joeynmt.training - 	Hypothesis: ▁d u as
2021-11-23 03:57:44,429 - INFO - joeynmt.training - Example #6
2021-11-23 03:57:44,430 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 03:57:44,430 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 03:57:44,430 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 03:57:44,430 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 03:57:44,430 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 03:57:44,430 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 03:57:44,430 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 03:57:44,430 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    75000: bleu:   7.31, loss: 84581.5781, ppl:  12.1516, duration: 169.8549s
2021-11-23 03:57:59,495 - INFO - joeynmt.training - Epoch  23, Step:    75100, Batch Loss:     2.460973, Tokens per Sec:     2064, Lr: 0.000100
2021-11-23 03:58:14,296 - INFO - joeynmt.training - Epoch  23, Step:    75200, Batch Loss:     2.475999, Tokens per Sec:     2052, Lr: 0.000100
2021-11-23 03:58:29,042 - INFO - joeynmt.training - Epoch  23, Step:    75300, Batch Loss:     2.820921, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 03:58:43,279 - INFO - joeynmt.training - Epoch  23, Step:    75400, Batch Loss:     2.546666, Tokens per Sec:     2203, Lr: 0.000100
2021-11-23 03:58:58,518 - INFO - joeynmt.training - Epoch  23, Step:    75500, Batch Loss:     2.621234, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 03:59:13,124 - INFO - joeynmt.training - Epoch  23, Step:    75600, Batch Loss:     2.421621, Tokens per Sec:     2235, Lr: 0.000100
2021-11-23 03:59:27,918 - INFO - joeynmt.training - Epoch  23, Step:    75700, Batch Loss:     2.392172, Tokens per Sec:     2094, Lr: 0.000100
2021-11-23 03:59:41,958 - INFO - joeynmt.training - Epoch  23, Step:    75800, Batch Loss:     2.492184, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 03:59:56,848 - INFO - joeynmt.training - Epoch  23, Step:    75900, Batch Loss:     2.516030, Tokens per Sec:     2081, Lr: 0.000100
2021-11-23 04:00:10,991 - INFO - joeynmt.training - Epoch  23, Step:    76000, Batch Loss:     2.251798, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 04:02:54,476 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:02:54,476 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:02:54,476 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:02:54,488 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 04:02:55,306 - INFO - joeynmt.helpers - delete models/baseline_multilingual/73000.ckpt
2021-11-23 04:02:55,307 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/73000.ckpt
2021-11-23 04:02:55,307 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/73000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/73000.ckpt')
2021-11-23 04:02:55,360 - INFO - joeynmt.training - Example #0
2021-11-23 04:02:55,360 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:02:55,361 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:02:55,361 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁c', 'ert', 'ain', 'ed', '▁in', '▁Jerusalem', '.', '▁But', '▁you', '▁are', '▁a', '▁c', 'ert', 'ain', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁when', '▁he', '▁was', '▁a', 'head', '▁of', '▁the', '▁people', ',', '▁they', '▁were', '▁all', '▁the', '▁fl', 'ood', '.']
2021-11-23 04:02:55,361 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:02:55,361 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:02:55,361 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:02:55,361 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁c ert ain ed ▁in ▁Jerusalem . ▁But ▁you ▁are ▁a ▁c ert ain ▁of ▁Gal ile e . ▁But ▁when ▁he ▁was ▁a head ▁of ▁the ▁people , ▁they ▁were ▁all ▁the ▁fl ood .
2021-11-23 04:02:55,362 - INFO - joeynmt.training - Example #1
2021-11-23 04:02:55,362 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:02:55,362 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:02:55,362 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'ng', 'l', 'os']
2021-11-23 04:02:55,362 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:02:55,362 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:02:55,362 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:02:55,363 - INFO - joeynmt.training - 	Hypothesis: ▁E ng l os
2021-11-23 04:02:55,363 - INFO - joeynmt.training - Example #2
2021-11-23 04:02:55,363 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:02:55,363 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:02:55,363 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁have', '▁made', '▁you', '▁to', '▁be', '▁made', '▁my', '▁body', ',', '▁and', '▁let', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', '.']
2021-11-23 04:02:55,363 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:02:55,363 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:02:55,364 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:02:55,364 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁have ▁made ▁you ▁to ▁be ▁made ▁my ▁body , ▁and ▁let ▁each ▁other , ▁and ▁let ▁each ▁other .
2021-11-23 04:02:55,364 - INFO - joeynmt.training - Example #3
2021-11-23 04:02:55,364 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:02:55,364 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:02:55,364 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 04:02:55,364 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:02:55,364 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:02:55,365 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:02:55,365 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 04:02:55,365 - INFO - joeynmt.training - Example #6
2021-11-23 04:02:55,365 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:02:55,365 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:02:55,365 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 04:02:55,365 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:02:55,365 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:02:55,366 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:02:55,366 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 04:02:55,366 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    76000: bleu:   7.69, loss: 84355.0234, ppl:  12.0706, duration: 164.3743s
2021-11-23 04:03:10,266 - INFO - joeynmt.training - Epoch  23, Step:    76100, Batch Loss:     2.347383, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 04:03:25,025 - INFO - joeynmt.training - Epoch  23, Step:    76200, Batch Loss:     2.400890, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 04:03:39,583 - INFO - joeynmt.training - Epoch  23, Step:    76300, Batch Loss:     2.682777, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 04:03:54,498 - INFO - joeynmt.training - Epoch  23, Step:    76400, Batch Loss:     2.517112, Tokens per Sec:     2039, Lr: 0.000100
2021-11-23 04:04:09,208 - INFO - joeynmt.training - Epoch  23, Step:    76500, Batch Loss:     2.262518, Tokens per Sec:     2216, Lr: 0.000100
2021-11-23 04:04:24,302 - INFO - joeynmt.training - Epoch  23, Step:    76600, Batch Loss:     2.520129, Tokens per Sec:     2101, Lr: 0.000100
2021-11-23 04:04:39,427 - INFO - joeynmt.training - Epoch  23, Step:    76700, Batch Loss:     2.404763, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 04:04:53,762 - INFO - joeynmt.training - Epoch  23, Step:    76800, Batch Loss:     2.332928, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 04:05:08,745 - INFO - joeynmt.training - Epoch  23, Step:    76900, Batch Loss:     2.576537, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 04:05:23,514 - INFO - joeynmt.training - Epoch  23, Step:    77000, Batch Loss:     2.391613, Tokens per Sec:     2190, Lr: 0.000100
2021-11-23 04:08:07,641 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:08:07,641 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:08:07,641 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:08:07,659 - INFO - joeynmt.training - Example #0
2021-11-23 04:08:07,659 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:08:07,659 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:08:07,659 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁a', '▁time', '▁you', '▁have', '▁been', '▁a', 'head', '▁of', '▁J', 'e', 'ho', 'z', 'zar', '.', '▁But', '▁you', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁your', 'self', '.']
2021-11-23 04:08:07,659 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:08:07,659 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:08:07,659 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:08:07,659 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁a ▁time ▁you ▁have ▁been ▁a head ▁of ▁J e ho z zar . ▁But ▁you ▁are ▁a head ▁of ▁Gal ile e , ▁but ▁you ▁are ▁not ▁a head ▁of ▁your self .
2021-11-23 04:08:07,659 - INFO - joeynmt.training - Example #1
2021-11-23 04:08:07,659 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:08:07,659 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:08:07,659 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 04:08:07,659 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:08:07,659 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:08:07,659 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:08:07,659 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 04:08:07,660 - INFO - joeynmt.training - Example #2
2021-11-23 04:08:07,660 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:08:07,660 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:08:07,660 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁and', '▁let', 'ter', '▁with', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁only', '▁one', '.']
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁and ▁let ter ▁with ▁each ▁other , ▁and ▁let ▁each ▁other , ▁and ▁let ter ▁is ▁only ▁one .
2021-11-23 04:08:07,660 - INFO - joeynmt.training - Example #3
2021-11-23 04:08:07,660 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:08:07,660 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:08:07,660 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 04:08:07,660 - INFO - joeynmt.training - Example #6
2021-11-23 04:08:07,660 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:08:07,660 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:08:07,660 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:08:07,660 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 04:08:07,661 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    77000: bleu:   7.54, loss: 84014.0625, ppl:  11.9497, duration: 164.1461s
2021-11-23 04:08:22,231 - INFO - joeynmt.training - Epoch  23, Step:    77100, Batch Loss:     2.394693, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 04:08:37,161 - INFO - joeynmt.training - Epoch  23, Step:    77200, Batch Loss:     2.989378, Tokens per Sec:     2095, Lr: 0.000100
2021-11-23 04:08:52,178 - INFO - joeynmt.training - Epoch  23, Step:    77300, Batch Loss:     2.442535, Tokens per Sec:     2069, Lr: 0.000100
2021-11-23 04:09:06,620 - INFO - joeynmt.training - Epoch  23, Step:    77400, Batch Loss:     2.344279, Tokens per Sec:     2209, Lr: 0.000100
2021-11-23 04:09:21,161 - INFO - joeynmt.training - Epoch  23, Step:    77500, Batch Loss:     2.398586, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 04:09:35,501 - INFO - joeynmt.training - Epoch  23, Step:    77600, Batch Loss:     2.460257, Tokens per Sec:     2248, Lr: 0.000100
2021-11-23 04:09:50,050 - INFO - joeynmt.training - Epoch  23, Step:    77700, Batch Loss:     2.342188, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 04:10:04,562 - INFO - joeynmt.training - Epoch  23, Step:    77800, Batch Loss:     2.351709, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 04:10:19,086 - INFO - joeynmt.training - Epoch  23, Step:    77900, Batch Loss:     2.255213, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 04:10:25,794 - INFO - joeynmt.training - Epoch  23: total training loss 8278.61
2021-11-23 04:10:25,794 - INFO - joeynmt.training - EPOCH 24
2021-11-23 04:10:33,847 - INFO - joeynmt.training - Epoch  24, Step:    78000, Batch Loss:     2.198226, Tokens per Sec:     2010, Lr: 0.000100
2021-11-23 04:12:48,423 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:12:48,423 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:12:48,423 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:12:48,435 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 04:12:49,245 - INFO - joeynmt.helpers - delete models/baseline_multilingual/76000.ckpt
2021-11-23 04:12:49,245 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/76000.ckpt
2021-11-23 04:12:49,246 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/76000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/76000.ckpt')
2021-11-23 04:12:49,305 - INFO - joeynmt.training - Example #0
2021-11-23 04:12:49,306 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:12:49,306 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:12:49,306 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁a', '▁time', '▁of', '▁Judah', ',', '▁from', '▁Jud', 'e', 'a', ',', '▁from', '▁Jud', 'e', 'a', ',', '▁but', '▁you', '▁are', '▁a', '▁p', 'ubl', 'ic', '.', '▁But', '▁when', '▁you', '▁were', '▁not', '▁a', 'head', '▁of', '▁all', '▁the', '▁people', '▁who', '▁are', '▁all', '▁the', '▁land', '.']
2021-11-23 04:12:49,306 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:12:49,306 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:12:49,306 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:12:49,307 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁a ▁time ▁of ▁Judah , ▁from ▁Jud e a , ▁from ▁Jud e a , ▁but ▁you ▁are ▁a ▁p ubl ic . ▁But ▁when ▁you ▁were ▁not ▁a head ▁of ▁all ▁the ▁people ▁who ▁are ▁all ▁the ▁land .
2021-11-23 04:12:49,307 - INFO - joeynmt.training - Example #1
2021-11-23 04:12:49,307 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:12:49,307 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:12:49,307 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 04:12:49,307 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:12:49,307 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:12:49,307 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:12:49,307 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 04:12:49,307 - INFO - joeynmt.training - Example #2
2021-11-23 04:12:49,308 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:12:49,308 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:12:49,308 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁how', '▁much', '▁much', '▁to', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁is', '▁one', '.']
2021-11-23 04:12:49,308 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:12:49,308 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:12:49,308 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:12:49,308 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁how ▁much ▁much ▁to ▁each ▁other , ▁and ▁let ▁each ▁other , ▁and ▁let ter ▁is ▁one .
2021-11-23 04:12:49,308 - INFO - joeynmt.training - Example #3
2021-11-23 04:12:49,308 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:12:49,309 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:12:49,309 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 04:12:49,309 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:12:49,309 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:12:49,309 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:12:49,309 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 04:12:49,309 - INFO - joeynmt.training - Example #6
2021-11-23 04:12:49,309 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:12:49,309 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:12:49,309 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 04:12:49,309 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:12:49,309 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:12:49,310 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:12:49,310 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 04:12:49,310 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    78000: bleu:   7.82, loss: 83690.7578, ppl:  11.8362, duration: 135.4629s
2021-11-23 04:13:04,343 - INFO - joeynmt.training - Epoch  24, Step:    78100, Batch Loss:     2.520229, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 04:13:18,824 - INFO - joeynmt.training - Epoch  24, Step:    78200, Batch Loss:     2.030389, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 04:13:33,106 - INFO - joeynmt.training - Epoch  24, Step:    78300, Batch Loss:     2.382517, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 04:13:47,785 - INFO - joeynmt.training - Epoch  24, Step:    78400, Batch Loss:     2.879412, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 04:14:02,411 - INFO - joeynmt.training - Epoch  24, Step:    78500, Batch Loss:     2.446986, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 04:14:17,558 - INFO - joeynmt.training - Epoch  24, Step:    78600, Batch Loss:     2.535153, Tokens per Sec:     2080, Lr: 0.000100
2021-11-23 04:14:31,943 - INFO - joeynmt.training - Epoch  24, Step:    78700, Batch Loss:     2.406771, Tokens per Sec:     2200, Lr: 0.000100
2021-11-23 04:14:45,894 - INFO - joeynmt.training - Epoch  24, Step:    78800, Batch Loss:     2.470485, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 04:15:00,676 - INFO - joeynmt.training - Epoch  24, Step:    78900, Batch Loss:     2.236645, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 04:15:14,641 - INFO - joeynmt.training - Epoch  24, Step:    79000, Batch Loss:     2.093626, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 04:17:40,767 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:17:40,767 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:17:40,767 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:17:40,778 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 04:17:41,594 - INFO - joeynmt.helpers - delete models/baseline_multilingual/78000.ckpt
2021-11-23 04:17:41,594 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/78000.ckpt
2021-11-23 04:17:41,594 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/78000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/78000.ckpt')
2021-11-23 04:17:41,650 - INFO - joeynmt.training - Example #0
2021-11-23 04:17:41,650 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:17:41,650 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:17:41,650 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁a', '▁time', '▁of', '▁J', 'e', 'us', ',', '▁you', '▁are', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁when', '▁you', '▁were', '▁p', 'ubl', 'ic', 'ed', '▁by', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁they', '▁were', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 04:17:41,650 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:17:41,651 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:17:41,651 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:17:41,651 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁a ▁time ▁of ▁J e us , ▁you ▁are ▁from ▁Gal ile e . ▁But ▁when ▁you ▁were ▁p ubl ic ed ▁by ▁the ▁people ▁of ▁Gal ile e , ▁they ▁were ▁all ▁the ▁wall s .
2021-11-23 04:17:41,651 - INFO - joeynmt.training - Example #1
2021-11-23 04:17:41,651 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:17:41,651 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:17:41,651 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 04:17:41,651 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:17:41,651 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:17:41,652 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:17:41,652 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 04:17:41,652 - INFO - joeynmt.training - Example #2
2021-11-23 04:17:41,652 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:17:41,652 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:17:41,652 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁how', '▁much', '▁much', '▁more', '▁than', 'k', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁each', '▁other', '.']
2021-11-23 04:17:41,652 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:17:41,652 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:17:41,652 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:17:41,653 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁how ▁much ▁much ▁more ▁than k ▁each ▁other , ▁and ▁let ter ▁each ▁other .
2021-11-23 04:17:41,653 - INFO - joeynmt.training - Example #3
2021-11-23 04:17:41,653 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:17:41,653 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:17:41,653 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'oc', 'ar']
2021-11-23 04:17:41,653 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:17:41,653 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:17:41,653 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:17:41,653 - INFO - joeynmt.training - 	Hypothesis: ▁s oc ar
2021-11-23 04:17:41,654 - INFO - joeynmt.training - Example #6
2021-11-23 04:17:41,654 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:17:41,654 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:17:41,654 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 04:17:41,654 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:17:41,654 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:17:41,654 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:17:41,654 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 04:17:41,654 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    79000: bleu:   7.95, loss: 83803.8047, ppl:  11.8757, duration: 147.0130s
2021-11-23 04:17:56,935 - INFO - joeynmt.training - Epoch  24, Step:    79100, Batch Loss:     2.502120, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 04:18:12,045 - INFO - joeynmt.training - Epoch  24, Step:    79200, Batch Loss:     2.529588, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 04:18:26,220 - INFO - joeynmt.training - Epoch  24, Step:    79300, Batch Loss:     2.374188, Tokens per Sec:     2215, Lr: 0.000100
2021-11-23 04:18:40,715 - INFO - joeynmt.training - Epoch  24, Step:    79400, Batch Loss:     2.317740, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 04:18:55,443 - INFO - joeynmt.training - Epoch  24, Step:    79500, Batch Loss:     2.514342, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 04:19:09,675 - INFO - joeynmt.training - Epoch  24, Step:    79600, Batch Loss:     2.357481, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 04:19:23,911 - INFO - joeynmt.training - Epoch  24, Step:    79700, Batch Loss:     2.306577, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 04:19:39,490 - INFO - joeynmt.training - Epoch  24, Step:    79800, Batch Loss:     2.629027, Tokens per Sec:     2062, Lr: 0.000100
2021-11-23 04:19:53,915 - INFO - joeynmt.training - Epoch  24, Step:    79900, Batch Loss:     2.257499, Tokens per Sec:     2110, Lr: 0.000100
2021-11-23 04:20:08,499 - INFO - joeynmt.training - Epoch  24, Step:    80000, Batch Loss:     2.466076, Tokens per Sec:     2214, Lr: 0.000100
2021-11-23 04:22:34,593 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:22:34,593 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:22:34,593 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:22:34,611 - INFO - joeynmt.training - Example #0
2021-11-23 04:22:34,611 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:22:34,611 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:22:34,611 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Jerusalem', ',', '▁and', '▁you', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁the', '▁people', ',', '▁but', '▁all', '▁the', '▁people', '▁of', '▁all', '▁the', '▁people', '▁are', '▁all', '▁the', '▁land', '.']
2021-11-23 04:22:34,611 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁Jerusalem , ▁and ▁you ▁are ▁a head ▁of ▁Gal ile e . ▁But ▁you ▁are ▁not ▁a head ▁of ▁the ▁people , ▁but ▁all ▁the ▁people ▁of ▁all ▁the ▁people ▁are ▁all ▁the ▁land .
2021-11-23 04:22:34,612 - INFO - joeynmt.training - Example #1
2021-11-23 04:22:34,612 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:22:34,612 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:22:34,612 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁g', 'ar', 'l']
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Hypothesis: ▁g ar l
2021-11-23 04:22:34,612 - INFO - joeynmt.training - Example #2
2021-11-23 04:22:34,612 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:22:34,612 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:22:34,612 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁how', '▁can', '▁be', '▁with', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁how ▁can ▁be ▁with ▁each ▁other , ▁and ▁let ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 04:22:34,612 - INFO - joeynmt.training - Example #3
2021-11-23 04:22:34,612 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:22:34,612 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:22:34,612 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:22:34,612 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:22:34,613 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:22:34,613 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 04:22:34,613 - INFO - joeynmt.training - Example #6
2021-11-23 04:22:34,613 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:22:34,613 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:22:34,613 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 04:22:34,613 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:22:34,613 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:22:34,613 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:22:34,613 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 04:22:34,613 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    80000: bleu:   7.86, loss: 83428.4141, ppl:  11.7448, duration: 146.1132s
2021-11-23 04:22:49,257 - INFO - joeynmt.training - Epoch  24, Step:    80100, Batch Loss:     2.548590, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 04:23:04,366 - INFO - joeynmt.training - Epoch  24, Step:    80200, Batch Loss:     2.645637, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 04:23:19,678 - INFO - joeynmt.training - Epoch  24, Step:    80300, Batch Loss:     2.549562, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 04:23:34,986 - INFO - joeynmt.training - Epoch  24, Step:    80400, Batch Loss:     2.332901, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 04:23:49,677 - INFO - joeynmt.training - Epoch  24, Step:    80500, Batch Loss:     2.623230, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 04:24:04,070 - INFO - joeynmt.training - Epoch  24, Step:    80600, Batch Loss:     2.513675, Tokens per Sec:     2227, Lr: 0.000100
2021-11-23 04:24:19,063 - INFO - joeynmt.training - Epoch  24, Step:    80700, Batch Loss:     2.396764, Tokens per Sec:     2074, Lr: 0.000100
2021-11-23 04:24:35,176 - INFO - joeynmt.training - Epoch  24, Step:    80800, Batch Loss:     2.458714, Tokens per Sec:     2001, Lr: 0.000100
2021-11-23 04:24:48,917 - INFO - joeynmt.training - Epoch  24, Step:    80900, Batch Loss:     2.694749, Tokens per Sec:     2222, Lr: 0.000100
2021-11-23 04:25:03,950 - INFO - joeynmt.training - Epoch  24, Step:    81000, Batch Loss:     2.081788, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 04:27:10,491 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:27:10,491 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:27:10,491 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:27:10,508 - INFO - joeynmt.training - Example #0
2021-11-23 04:27:10,509 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:27:10,509 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:27:10,509 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Judah', '.', '▁He', '▁was', '▁a', '▁p', 'ubl', 'ic', ',', '▁but', '▁he', '▁was', '▁a', '▁p', 'ubl', 'ic', '.', '▁But', '▁when', '▁he', '▁was', '▁a', 'head', '▁of', '▁all', '▁the', '▁people', ',', '▁all', '▁the', '▁people', '▁of', '▁all', '▁the', '▁har', 'vest', 's', '▁are', '▁all', '▁the', '▁har', 'vest', '.']
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁Judah . ▁He ▁was ▁a ▁p ubl ic , ▁but ▁he ▁was ▁a ▁p ubl ic . ▁But ▁when ▁he ▁was ▁a head ▁of ▁all ▁the ▁people , ▁all ▁the ▁people ▁of ▁all ▁the ▁har vest s ▁are ▁all ▁the ▁har vest .
2021-11-23 04:27:10,509 - INFO - joeynmt.training - Example #1
2021-11-23 04:27:10,509 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:27:10,509 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:27:10,509 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 04:27:10,509 - INFO - joeynmt.training - Example #2
2021-11-23 04:27:10,509 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:27:10,509 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:27:10,509 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁my', '▁body', ',', '▁and', '▁let', '▁us', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', '.']
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:27:10,509 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁my ▁body , ▁and ▁let ▁us ▁each ▁other ▁with ▁each ▁other , ▁and ▁let ▁each ▁other .
2021-11-23 04:27:10,510 - INFO - joeynmt.training - Example #3
2021-11-23 04:27:10,510 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:27:10,510 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:27:10,510 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁se', 'gu', 'nd', 'o']
2021-11-23 04:27:10,510 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:27:10,510 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:27:10,510 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:27:10,510 - INFO - joeynmt.training - 	Hypothesis: ▁se gu nd o
2021-11-23 04:27:10,510 - INFO - joeynmt.training - Example #6
2021-11-23 04:27:10,510 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:27:10,510 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:27:10,510 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 04:27:10,510 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:27:10,510 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:27:10,510 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:27:10,510 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 04:27:10,510 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    81000: bleu:   7.74, loss: 83131.8359, ppl:  11.6424, duration: 126.5595s
2021-11-23 04:27:24,903 - INFO - joeynmt.training - Epoch  24, Step:    81100, Batch Loss:     2.576479, Tokens per Sec:     2163, Lr: 0.000100
2021-11-23 04:27:39,396 - INFO - joeynmt.training - Epoch  24, Step:    81200, Batch Loss:     2.377470, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 04:27:53,250 - INFO - joeynmt.training - Epoch  24, Step:    81300, Batch Loss:     2.409718, Tokens per Sec:     2210, Lr: 0.000100
2021-11-23 04:27:58,624 - INFO - joeynmt.training - Epoch  24: total training loss 8196.16
2021-11-23 04:27:58,625 - INFO - joeynmt.training - EPOCH 25
2021-11-23 04:28:08,317 - INFO - joeynmt.training - Epoch  25, Step:    81400, Batch Loss:     2.313671, Tokens per Sec:     2094, Lr: 0.000100
2021-11-23 04:28:22,679 - INFO - joeynmt.training - Epoch  25, Step:    81500, Batch Loss:     2.508407, Tokens per Sec:     2215, Lr: 0.000100
2021-11-23 04:28:36,820 - INFO - joeynmt.training - Epoch  25, Step:    81600, Batch Loss:     2.554770, Tokens per Sec:     2209, Lr: 0.000100
2021-11-23 04:28:51,747 - INFO - joeynmt.training - Epoch  25, Step:    81700, Batch Loss:     2.229292, Tokens per Sec:     2099, Lr: 0.000100
2021-11-23 04:29:07,302 - INFO - joeynmt.training - Epoch  25, Step:    81800, Batch Loss:     2.254978, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 04:29:21,777 - INFO - joeynmt.training - Epoch  25, Step:    81900, Batch Loss:     2.371964, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 04:29:36,260 - INFO - joeynmt.training - Epoch  25, Step:    82000, Batch Loss:     2.456338, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 04:31:38,157 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:31:38,157 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:31:38,158 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:31:38,176 - INFO - joeynmt.training - Example #0
2021-11-23 04:31:38,176 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:31:38,176 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:31:38,176 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Judah', '.', '▁He', '▁was', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁he', '▁was', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁he', '▁was', '▁a', 'head', '▁of', '▁all', '▁the', '▁people', '▁who', '▁were', '▁all', '▁the', '▁g', 'round', 'ing', 'ers', '▁and', '▁all', '▁the', '▁g', 'round', '.']
2021-11-23 04:31:38,176 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:31:38,176 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:31:38,176 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:31:38,176 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁Judah . ▁He ▁was ▁a head ▁of ▁Gal ile e . ▁But ▁he ▁was ▁a head ▁of ▁Gal ile e , ▁he ▁was ▁a head ▁of ▁all ▁the ▁people ▁who ▁were ▁all ▁the ▁g round ing ers ▁and ▁all ▁the ▁g round .
2021-11-23 04:31:38,176 - INFO - joeynmt.training - Example #1
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 04:31:38,177 - INFO - joeynmt.training - Example #2
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁have', '▁made', '▁you', '▁to', '▁be', '▁made', '▁with', '▁you', ',', '▁how', '▁much', '▁much', '▁to', '▁love', '▁each', '▁other', '.']
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁have ▁made ▁you ▁to ▁be ▁made ▁with ▁you , ▁how ▁much ▁much ▁to ▁love ▁each ▁other .
2021-11-23 04:31:38,177 - INFO - joeynmt.training - Example #3
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'ada']
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:31:38,177 - INFO - joeynmt.training - 	Hypothesis: ▁c ada
2021-11-23 04:31:38,177 - INFO - joeynmt.training - Example #6
2021-11-23 04:31:38,177 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:31:38,178 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:31:38,178 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 04:31:38,178 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:31:38,178 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:31:38,178 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:31:38,178 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 04:31:38,178 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    82000: bleu:   7.95, loss: 83258.6953, ppl:  11.6861, duration: 121.9175s
2021-11-23 04:31:53,697 - INFO - joeynmt.training - Epoch  25, Step:    82100, Batch Loss:     2.207929, Tokens per Sec:     2075, Lr: 0.000100
2021-11-23 04:32:08,349 - INFO - joeynmt.training - Epoch  25, Step:    82200, Batch Loss:     2.303368, Tokens per Sec:     2185, Lr: 0.000100
2021-11-23 04:32:23,211 - INFO - joeynmt.training - Epoch  25, Step:    82300, Batch Loss:     2.223704, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 04:32:38,542 - INFO - joeynmt.training - Epoch  25, Step:    82400, Batch Loss:     2.306739, Tokens per Sec:     2085, Lr: 0.000100
2021-11-23 04:32:53,483 - INFO - joeynmt.training - Epoch  25, Step:    82500, Batch Loss:     2.268239, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 04:33:07,762 - INFO - joeynmt.training - Epoch  25, Step:    82600, Batch Loss:     2.531547, Tokens per Sec:     2217, Lr: 0.000100
2021-11-23 04:33:22,645 - INFO - joeynmt.training - Epoch  25, Step:    82700, Batch Loss:     2.355677, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 04:33:36,830 - INFO - joeynmt.training - Epoch  25, Step:    82800, Batch Loss:     2.564331, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 04:33:50,796 - INFO - joeynmt.training - Epoch  25, Step:    82900, Batch Loss:     2.113727, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 04:34:06,034 - INFO - joeynmt.training - Epoch  25, Step:    83000, Batch Loss:     2.616328, Tokens per Sec:     2001, Lr: 0.000100
2021-11-23 04:37:34,317 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:37:34,317 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:37:34,317 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:37:34,335 - INFO - joeynmt.training - Example #0
2021-11-23 04:37:34,336 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:37:34,336 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:37:34,336 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁J', 'ust', 'r', 'us', ',', '▁from', '▁Jud', 'as', ',', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁were', '▁not', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁and', '▁all', '▁who', '▁were', '▁all', '▁the', '▁fl', 'ood', '.']
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁J ust r us , ▁from ▁Jud as , ▁from ▁Gal ile e . ▁But ▁you ▁were ▁not ▁a head ▁of ▁Gal ile e , ▁and ▁all ▁who ▁were ▁all ▁the ▁fl ood .
2021-11-23 04:37:34,336 - INFO - joeynmt.training - Example #1
2021-11-23 04:37:34,336 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:37:34,336 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:37:34,336 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'sc', 'rita']
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Hypothesis: ▁E sc rita
2021-11-23 04:37:34,336 - INFO - joeynmt.training - Example #2
2021-11-23 04:37:34,336 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:37:34,336 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:37:34,336 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:37:34,336 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:37:34,337 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁how ▁can ▁love ▁each ▁other , ▁and ▁let ter ▁each ▁other ▁with ▁each ▁other .
2021-11-23 04:37:34,337 - INFO - joeynmt.training - Example #3
2021-11-23 04:37:34,337 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:37:34,337 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:37:34,337 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 04:37:34,337 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:37:34,337 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:37:34,337 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:37:34,337 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 04:37:34,337 - INFO - joeynmt.training - Example #6
2021-11-23 04:37:34,337 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:37:34,337 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:37:34,337 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 04:37:34,337 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:37:34,337 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:37:34,337 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:37:34,337 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 04:37:34,337 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    83000: bleu:   7.28, loss: 82881.7891, ppl:  11.5568, duration: 208.3027s
2021-11-23 04:37:49,943 - INFO - joeynmt.training - Epoch  25, Step:    83100, Batch Loss:     2.544569, Tokens per Sec:     2085, Lr: 0.000100
2021-11-23 04:38:03,807 - INFO - joeynmt.training - Epoch  25, Step:    83200, Batch Loss:     2.493111, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 04:38:18,427 - INFO - joeynmt.training - Epoch  25, Step:    83300, Batch Loss:     2.348648, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 04:38:33,166 - INFO - joeynmt.training - Epoch  25, Step:    83400, Batch Loss:     2.410883, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 04:38:48,002 - INFO - joeynmt.training - Epoch  25, Step:    83500, Batch Loss:     2.622481, Tokens per Sec:     2126, Lr: 0.000100
2021-11-23 04:39:02,550 - INFO - joeynmt.training - Epoch  25, Step:    83600, Batch Loss:     2.174481, Tokens per Sec:     2085, Lr: 0.000100
2021-11-23 04:39:17,781 - INFO - joeynmt.training - Epoch  25, Step:    83700, Batch Loss:     2.594677, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 04:39:32,771 - INFO - joeynmt.training - Epoch  25, Step:    83800, Batch Loss:     2.241241, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 04:39:47,469 - INFO - joeynmt.training - Epoch  25, Step:    83900, Batch Loss:     2.478660, Tokens per Sec:     2066, Lr: 0.000100
2021-11-23 04:40:01,419 - INFO - joeynmt.training - Epoch  25, Step:    84000, Batch Loss:     2.510754, Tokens per Sec:     2161, Lr: 0.000100
2021-11-23 04:42:53,000 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:42:53,000 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:42:53,000 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:42:53,012 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 04:42:53,836 - INFO - joeynmt.helpers - delete models/baseline_multilingual/79000.ckpt
2021-11-23 04:42:53,837 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/79000.ckpt
2021-11-23 04:42:53,837 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/79000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/79000.ckpt')
2021-11-23 04:42:53,897 - INFO - joeynmt.training - Example #0
2021-11-23 04:42:53,897 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:42:53,897 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:42:53,897 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Judah', ',', '▁from', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁not', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁g', 'ather', 'ing', 'ers', ',', '▁and', '▁all', '▁your', 'self', '▁are', '▁all', '▁the', '▁g', 'round', 'ing', '.']
2021-11-23 04:42:53,897 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:42:53,898 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:42:53,898 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:42:53,898 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁Judah , ▁from ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁are ▁not ▁a head ▁of ▁Gal ile e , ▁but ▁you ▁are ▁all ▁the ▁g ather ing ers , ▁and ▁all ▁your self ▁are ▁all ▁the ▁g round ing .
2021-11-23 04:42:53,898 - INFO - joeynmt.training - Example #1
2021-11-23 04:42:53,898 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:42:53,898 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:42:53,898 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'AL', '▁SC']
2021-11-23 04:42:53,898 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:42:53,898 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:42:53,899 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:42:53,899 - INFO - joeynmt.training - 	Hypothesis: ▁E AL ▁SC
2021-11-23 04:42:53,899 - INFO - joeynmt.training - Example #2
2021-11-23 04:42:53,899 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:42:53,899 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:42:53,899 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁have', '▁made', '▁my', '▁faith', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 04:42:53,899 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:42:53,899 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:42:53,900 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:42:53,900 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁have ▁made ▁my ▁faith , ▁how ▁can ▁love ▁each ▁other , ▁and ▁let ter ▁with ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 04:42:53,900 - INFO - joeynmt.training - Example #3
2021-11-23 04:42:53,900 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:42:53,900 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:42:53,900 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 04:42:53,900 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:42:53,900 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:42:53,900 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:42:53,901 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 04:42:53,901 - INFO - joeynmt.training - Example #6
2021-11-23 04:42:53,901 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:42:53,901 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:42:53,901 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 04:42:53,901 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:42:53,901 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:42:53,901 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:42:53,901 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 04:42:53,902 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    84000: bleu:   8.15, loss: 82802.1484, ppl:  11.5296, duration: 172.4821s
2021-11-23 04:43:07,732 - INFO - joeynmt.training - Epoch  25, Step:    84100, Batch Loss:     2.146211, Tokens per Sec:     2202, Lr: 0.000100
2021-11-23 04:43:22,357 - INFO - joeynmt.training - Epoch  25, Step:    84200, Batch Loss:     2.275032, Tokens per Sec:     2203, Lr: 0.000100
2021-11-23 04:43:37,376 - INFO - joeynmt.training - Epoch  25, Step:    84300, Batch Loss:     2.165301, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 04:43:51,556 - INFO - joeynmt.training - Epoch  25, Step:    84400, Batch Loss:     2.413080, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 04:44:05,970 - INFO - joeynmt.training - Epoch  25, Step:    84500, Batch Loss:     2.693538, Tokens per Sec:     2217, Lr: 0.000100
2021-11-23 04:44:21,238 - INFO - joeynmt.training - Epoch  25, Step:    84600, Batch Loss:     2.091408, Tokens per Sec:     2052, Lr: 0.000100
2021-11-23 04:44:36,135 - INFO - joeynmt.training - Epoch  25, Step:    84700, Batch Loss:     2.217680, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 04:44:39,517 - INFO - joeynmt.training - Epoch  25: total training loss 8103.27
2021-11-23 04:44:39,518 - INFO - joeynmt.training - EPOCH 26
2021-11-23 04:44:50,276 - INFO - joeynmt.training - Epoch  26, Step:    84800, Batch Loss:     2.375160, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 04:45:05,126 - INFO - joeynmt.training - Epoch  26, Step:    84900, Batch Loss:     2.447739, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 04:45:20,163 - INFO - joeynmt.training - Epoch  26, Step:    85000, Batch Loss:     2.500491, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 04:47:54,155 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:47:54,155 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:47:54,155 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:47:54,166 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 04:47:54,987 - INFO - joeynmt.helpers - delete models/baseline_multilingual/84000.ckpt
2021-11-23 04:47:54,987 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/84000.ckpt
2021-11-23 04:47:54,988 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/84000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/84000.ckpt')
2021-11-23 04:47:55,048 - INFO - joeynmt.training - Example #0
2021-11-23 04:47:55,048 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:47:55,048 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:47:55,048 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'T', 'hen', '▁you', '▁have', '▁a', '▁time', '▁from', '▁Jerusalem', '.', '▁You', '▁are', '▁a', '▁re', 'ward', '▁from', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁and', '▁all', '▁the', '▁land', '▁of', '▁all', '▁the', '▁land', '▁of', '▁all', '▁the', '▁land', '.']
2021-11-23 04:47:55,048 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:47:55,049 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:47:55,049 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:47:55,049 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" T hen ▁you ▁have ▁a ▁time ▁from ▁Jerusalem . ▁You ▁are ▁a ▁re ward ▁from ▁Gal ile e , ▁but ▁you ▁are ▁all ▁the ▁people ▁of ▁Gal ile e , ▁and ▁all ▁the ▁land ▁of ▁all ▁the ▁land ▁of ▁all ▁the ▁land .
2021-11-23 04:47:55,049 - INFO - joeynmt.training - Example #1
2021-11-23 04:47:55,049 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:47:55,049 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:47:55,049 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 04:47:55,050 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:47:55,050 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:47:55,050 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:47:55,050 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 04:47:55,050 - INFO - joeynmt.training - Example #2
2021-11-23 04:47:55,050 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:47:55,051 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:47:55,051 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', '▁with', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 04:47:55,051 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:47:55,051 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:47:55,051 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:47:55,051 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁how ▁can ▁love ▁each ▁other , ▁and ▁let ▁each ▁other ▁with ▁each ▁other ▁with ▁each ▁other .
2021-11-23 04:47:55,051 - INFO - joeynmt.training - Example #3
2021-11-23 04:47:55,052 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:47:55,052 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:47:55,052 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 04:47:55,052 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:47:55,052 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:47:55,052 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:47:55,052 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 04:47:55,052 - INFO - joeynmt.training - Example #6
2021-11-23 04:47:55,052 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:47:55,052 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:47:55,052 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 04:47:55,052 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:47:55,052 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:47:55,052 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:47:55,052 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 04:47:55,053 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    85000: bleu:   8.25, loss: 82723.5078, ppl:  11.5029, duration: 154.8892s
2021-11-23 04:48:09,850 - INFO - joeynmt.training - Epoch  26, Step:    85100, Batch Loss:     2.138264, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 04:48:24,428 - INFO - joeynmt.training - Epoch  26, Step:    85200, Batch Loss:     2.321238, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 04:48:39,433 - INFO - joeynmt.training - Epoch  26, Step:    85300, Batch Loss:     2.366717, Tokens per Sec:     2095, Lr: 0.000100
2021-11-23 04:48:54,085 - INFO - joeynmt.training - Epoch  26, Step:    85400, Batch Loss:     2.627984, Tokens per Sec:     2175, Lr: 0.000100
2021-11-23 04:49:09,120 - INFO - joeynmt.training - Epoch  26, Step:    85500, Batch Loss:     2.424166, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 04:49:24,075 - INFO - joeynmt.training - Epoch  26, Step:    85600, Batch Loss:     2.318510, Tokens per Sec:     2172, Lr: 0.000100
2021-11-23 04:49:38,750 - INFO - joeynmt.training - Epoch  26, Step:    85700, Batch Loss:     2.366409, Tokens per Sec:     2165, Lr: 0.000100
2021-11-23 04:49:53,124 - INFO - joeynmt.training - Epoch  26, Step:    85800, Batch Loss:     2.263705, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 04:50:08,430 - INFO - joeynmt.training - Epoch  26, Step:    85900, Batch Loss:     2.137356, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 04:50:22,960 - INFO - joeynmt.training - Epoch  26, Step:    86000, Batch Loss:     2.335271, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 04:52:40,675 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:52:40,676 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:52:40,676 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:52:40,692 - INFO - joeynmt.training - Example #0
2021-11-23 04:52:40,692 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:52:40,692 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:52:40,692 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Judah', ',', '▁and', '▁you', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁when', '▁you', '▁were', '▁p', 'ubl', 'ic', ',', '▁you', '▁are', '▁still', '▁a', 'head', '▁of', '▁all', '▁the', '▁st', 'ri', 'ck', '.']
2021-11-23 04:52:40,692 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:52:40,692 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:52:40,692 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁Judah , ▁and ▁you ▁are ▁a head ▁of ▁Gal ile e . ▁But ▁when ▁you ▁were ▁p ubl ic , ▁you ▁are ▁still ▁a head ▁of ▁all ▁the ▁st ri ck .
2021-11-23 04:52:40,693 - INFO - joeynmt.training - Example #1
2021-11-23 04:52:40,693 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:52:40,693 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:52:40,693 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 04:52:40,693 - INFO - joeynmt.training - Example #2
2021-11-23 04:52:40,693 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:52:40,693 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:52:40,693 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁and', '▁let', 'ter', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', '.']
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁and ▁let ter ▁each ▁other ▁with ▁each ▁other , ▁and ▁let ▁each ▁other .
2021-11-23 04:52:40,693 - INFO - joeynmt.training - Example #3
2021-11-23 04:52:40,693 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:52:40,693 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:52:40,693 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁con', 'he', 'c', 'imento']
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:52:40,693 - INFO - joeynmt.training - 	Hypothesis: ▁con he c imento
2021-11-23 04:52:40,694 - INFO - joeynmt.training - Example #6
2021-11-23 04:52:40,694 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:52:40,694 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:52:40,694 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 04:52:40,694 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:52:40,694 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:52:40,694 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:52:40,694 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 04:52:40,694 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    86000: bleu:   8.20, loss: 82502.0859, ppl:  11.4279, duration: 137.7334s
2021-11-23 04:52:55,244 - INFO - joeynmt.training - Epoch  26, Step:    86100, Batch Loss:     2.357706, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 04:53:10,205 - INFO - joeynmt.training - Epoch  26, Step:    86200, Batch Loss:     2.163328, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 04:53:23,915 - INFO - joeynmt.training - Epoch  26, Step:    86300, Batch Loss:     2.533174, Tokens per Sec:     2252, Lr: 0.000100
2021-11-23 04:53:38,912 - INFO - joeynmt.training - Epoch  26, Step:    86400, Batch Loss:     2.358324, Tokens per Sec:     2108, Lr: 0.000100
2021-11-23 04:53:53,428 - INFO - joeynmt.training - Epoch  26, Step:    86500, Batch Loss:     2.288296, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 04:54:09,313 - INFO - joeynmt.training - Epoch  26, Step:    86600, Batch Loss:     2.469939, Tokens per Sec:     2033, Lr: 0.000100
2021-11-23 04:54:23,693 - INFO - joeynmt.training - Epoch  26, Step:    86700, Batch Loss:     2.247588, Tokens per Sec:     2220, Lr: 0.000100
2021-11-23 04:54:38,181 - INFO - joeynmt.training - Epoch  26, Step:    86800, Batch Loss:     2.141430, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 04:54:52,925 - INFO - joeynmt.training - Epoch  26, Step:    86900, Batch Loss:     2.321723, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 04:55:07,504 - INFO - joeynmt.training - Epoch  26, Step:    87000, Batch Loss:     2.318726, Tokens per Sec:     2091, Lr: 0.000100
2021-11-23 04:57:45,215 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 04:57:45,215 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 04:57:45,215 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 04:57:45,226 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 04:57:46,034 - INFO - joeynmt.helpers - delete models/baseline_multilingual/85000.ckpt
2021-11-23 04:57:46,034 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/85000.ckpt
2021-11-23 04:57:46,035 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/85000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/85000.ckpt')
2021-11-23 04:57:46,095 - INFO - joeynmt.training - Example #0
2021-11-23 04:57:46,096 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 04:57:46,096 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 04:57:46,096 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁c', 'apt', 'ure', 'd', '▁by', '▁the', '▁time', '▁of', '▁Judah', '.', '▁You', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁people', '▁of', '▁all', '▁the', '▁g', 'ates', '.']
2021-11-23 04:57:46,096 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 04:57:46,096 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 04:57:46,096 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 04:57:46,097 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁c apt ure d ▁by ▁the ▁time ▁of ▁Judah . ▁You ▁are ▁a head ▁of ▁Gal ile e , ▁but ▁you ▁are ▁all ▁the ▁people ▁of ▁all ▁the ▁g ates .
2021-11-23 04:57:46,097 - INFO - joeynmt.training - Example #1
2021-11-23 04:57:46,097 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 04:57:46,097 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 04:57:46,097 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 04:57:46,097 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 04:57:46,097 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 04:57:46,098 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 04:57:46,098 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 04:57:46,098 - INFO - joeynmt.training - Example #2
2021-11-23 04:57:46,098 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 04:57:46,098 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 04:57:46,098 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁let', 'ter', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁always', '▁always', '▁always', '▁understand', 'ing', '.']
2021-11-23 04:57:46,098 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 04:57:46,099 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 04:57:46,099 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 04:57:46,099 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁how ▁can ▁love ▁each ▁other , ▁let ter ▁each ▁other ▁with ▁each ▁other , ▁always ▁always ▁always ▁understand ing .
2021-11-23 04:57:46,099 - INFO - joeynmt.training - Example #3
2021-11-23 04:57:46,099 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 04:57:46,099 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 04:57:46,099 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 04:57:46,099 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 04:57:46,100 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 04:57:46,100 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 04:57:46,100 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 04:57:46,100 - INFO - joeynmt.training - Example #6
2021-11-23 04:57:46,100 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 04:57:46,100 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 04:57:46,100 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 04:57:46,100 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 04:57:46,100 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 04:57:46,100 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 04:57:46,100 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 04:57:46,100 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    87000: bleu:   8.46, loss: 82356.9453, ppl:  11.3791, duration: 158.5956s
2021-11-23 04:58:00,973 - INFO - joeynmt.training - Epoch  26, Step:    87100, Batch Loss:     2.487959, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 04:58:15,547 - INFO - joeynmt.training - Epoch  26, Step:    87200, Batch Loss:     2.393655, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 04:58:29,330 - INFO - joeynmt.training - Epoch  26, Step:    87300, Batch Loss:     2.242012, Tokens per Sec:     2262, Lr: 0.000100
2021-11-23 04:58:43,465 - INFO - joeynmt.training - Epoch  26, Step:    87400, Batch Loss:     2.380600, Tokens per Sec:     2210, Lr: 0.000100
2021-11-23 04:58:57,896 - INFO - joeynmt.training - Epoch  26, Step:    87500, Batch Loss:     2.534860, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 04:59:12,808 - INFO - joeynmt.training - Epoch  26, Step:    87600, Batch Loss:     2.054360, Tokens per Sec:     2082, Lr: 0.000100
2021-11-23 04:59:27,698 - INFO - joeynmt.training - Epoch  26, Step:    87700, Batch Loss:     2.242192, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 04:59:41,727 - INFO - joeynmt.training - Epoch  26, Step:    87800, Batch Loss:     2.087604, Tokens per Sec:     2129, Lr: 0.000100
2021-11-23 04:59:56,146 - INFO - joeynmt.training - Epoch  26, Step:    87900, Batch Loss:     2.415825, Tokens per Sec:     2191, Lr: 0.000100
2021-11-23 05:00:10,634 - INFO - joeynmt.training - Epoch  26, Step:    88000, Batch Loss:     2.453408, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 05:02:30,185 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:02:30,185 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:02:30,185 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:02:30,202 - INFO - joeynmt.training - Example #0
2021-11-23 05:02:30,202 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:02:30,202 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:02:30,202 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁a', '▁time', '▁from', '▁Jerusalem', ',', '▁you', '▁are', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁when', '▁you', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁you', '▁are', '▁all', '▁the', '▁people', '▁of', '▁all', '▁the', '▁g', 'ate', '.']
2021-11-23 05:02:30,202 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:02:30,202 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁a ▁time ▁from ▁Jerusalem , ▁you ▁are ▁from ▁Gal ile e . ▁But ▁when ▁you ▁are ▁a head ▁of ▁Gal ile e , ▁you ▁are ▁all ▁the ▁people ▁of ▁all ▁the ▁g ate .
2021-11-23 05:02:30,203 - INFO - joeynmt.training - Example #1
2021-11-23 05:02:30,203 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:02:30,203 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:02:30,203 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 05:02:30,203 - INFO - joeynmt.training - Example #2
2021-11-23 05:02:30,203 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:02:30,203 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:02:30,203 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', '▁great', 'er', '▁than', 'k', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me ▁great er ▁than k , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 05:02:30,203 - INFO - joeynmt.training - Example #3
2021-11-23 05:02:30,203 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:02:30,203 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:02:30,203 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:02:30,203 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 05:02:30,203 - INFO - joeynmt.training - Example #6
2021-11-23 05:02:30,204 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:02:30,204 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:02:30,204 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 05:02:30,204 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:02:30,204 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:02:30,204 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:02:30,204 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 05:02:30,204 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    88000: bleu:   8.29, loss: 82076.5234, ppl:  11.2852, duration: 139.5694s
2021-11-23 05:02:45,217 - INFO - joeynmt.training - Epoch  26, Step:    88100, Batch Loss:     2.130497, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 05:02:47,013 - INFO - joeynmt.training - Epoch  26: total training loss 8029.18
2021-11-23 05:02:47,014 - INFO - joeynmt.training - EPOCH 27
2021-11-23 05:02:59,526 - INFO - joeynmt.training - Epoch  27, Step:    88200, Batch Loss:     2.263882, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 05:03:13,833 - INFO - joeynmt.training - Epoch  27, Step:    88300, Batch Loss:     2.449687, Tokens per Sec:     2238, Lr: 0.000100
2021-11-23 05:03:28,658 - INFO - joeynmt.training - Epoch  27, Step:    88400, Batch Loss:     2.394683, Tokens per Sec:     2080, Lr: 0.000100
2021-11-23 05:03:42,667 - INFO - joeynmt.training - Epoch  27, Step:    88500, Batch Loss:     2.171098, Tokens per Sec:     2173, Lr: 0.000100
2021-11-23 05:03:57,248 - INFO - joeynmt.training - Epoch  27, Step:    88600, Batch Loss:     2.452955, Tokens per Sec:     2063, Lr: 0.000100
2021-11-23 05:04:11,648 - INFO - joeynmt.training - Epoch  27, Step:    88700, Batch Loss:     2.251407, Tokens per Sec:     2210, Lr: 0.000100
2021-11-23 05:04:26,240 - INFO - joeynmt.training - Epoch  27, Step:    88800, Batch Loss:     2.367421, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 05:04:41,228 - INFO - joeynmt.training - Epoch  27, Step:    88900, Batch Loss:     2.455873, Tokens per Sec:     2133, Lr: 0.000100
2021-11-23 05:04:55,940 - INFO - joeynmt.training - Epoch  27, Step:    89000, Batch Loss:     2.201080, Tokens per Sec:     2103, Lr: 0.000100
2021-11-23 05:07:28,928 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:07:28,928 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:07:28,928 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:07:28,941 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 05:07:29,754 - INFO - joeynmt.helpers - delete models/baseline_multilingual/87000.ckpt
2021-11-23 05:07:29,754 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/87000.ckpt
2021-11-23 05:07:29,755 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/87000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/87000.ckpt')
2021-11-23 05:07:29,808 - INFO - joeynmt.training - Example #0
2021-11-23 05:07:29,809 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:07:29,809 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:07:29,809 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁They', '▁went', '▁to', '▁Jerusalem', ',', '▁and', '▁they', '▁were', '▁in', '▁Jud', 'e', 'a', '.', '▁He', '▁was', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁still', '▁follow', 'ing', '▁the', '▁people', ',', '▁but', '▁all', '▁the', '▁people', '▁of', '▁all', '▁the', '▁g', 'round', '.']
2021-11-23 05:07:29,809 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:07:29,809 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:07:29,809 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:07:29,810 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁They ▁went ▁to ▁Jerusalem , ▁and ▁they ▁were ▁in ▁Jud e a . ▁He ▁was ▁a head ▁of ▁Gal ile e , ▁but ▁he ▁was ▁still ▁follow ing ▁the ▁people , ▁but ▁all ▁the ▁people ▁of ▁all ▁the ▁g round .
2021-11-23 05:07:29,810 - INFO - joeynmt.training - Example #1
2021-11-23 05:07:29,810 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:07:29,810 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:07:29,810 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁E', 'AL', '▁SC']
2021-11-23 05:07:29,810 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:07:29,810 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:07:29,811 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:07:29,811 - INFO - joeynmt.training - 	Hypothesis: ▁E AL ▁SC
2021-11-23 05:07:29,811 - INFO - joeynmt.training - Example #2
2021-11-23 05:07:29,811 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:07:29,811 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:07:29,811 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁be', '▁made', '▁me', ',', '▁how', '▁much', '▁much', '▁to', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 05:07:29,811 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:07:29,811 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:07:29,812 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:07:29,812 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁be ▁made ▁me , ▁how ▁much ▁much ▁to ▁each ▁other , ▁and ▁let ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 05:07:29,812 - INFO - joeynmt.training - Example #3
2021-11-23 05:07:29,812 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:07:29,812 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:07:29,812 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'p', 'res', 'so']
2021-11-23 05:07:29,812 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:07:29,813 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:07:29,813 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:07:29,813 - INFO - joeynmt.training - 	Hypothesis: ▁de p res so
2021-11-23 05:07:29,813 - INFO - joeynmt.training - Example #6
2021-11-23 05:07:29,813 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:07:29,813 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:07:29,813 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 05:07:29,814 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:07:29,814 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:07:29,814 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:07:29,814 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 05:07:29,814 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    89000: bleu:   8.70, loss: 81988.8594, ppl:  11.2561, duration: 153.8736s
2021-11-23 05:07:45,531 - INFO - joeynmt.training - Epoch  27, Step:    89100, Batch Loss:     2.217233, Tokens per Sec:     2065, Lr: 0.000100
2021-11-23 05:08:00,270 - INFO - joeynmt.training - Epoch  27, Step:    89200, Batch Loss:     2.324154, Tokens per Sec:     2161, Lr: 0.000100
2021-11-23 05:08:14,090 - INFO - joeynmt.training - Epoch  27, Step:    89300, Batch Loss:     2.258567, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 05:08:28,281 - INFO - joeynmt.training - Epoch  27, Step:    89400, Batch Loss:     2.319565, Tokens per Sec:     2084, Lr: 0.000100
2021-11-23 05:08:43,460 - INFO - joeynmt.training - Epoch  27, Step:    89500, Batch Loss:     2.550499, Tokens per Sec:     2122, Lr: 0.000100
2021-11-23 05:08:57,882 - INFO - joeynmt.training - Epoch  27, Step:    89600, Batch Loss:     2.490946, Tokens per Sec:     2217, Lr: 0.000100
2021-11-23 05:09:12,664 - INFO - joeynmt.training - Epoch  27, Step:    89700, Batch Loss:     2.295849, Tokens per Sec:     2185, Lr: 0.000100
2021-11-23 05:09:28,336 - INFO - joeynmt.training - Epoch  27, Step:    89800, Batch Loss:     2.110911, Tokens per Sec:     2052, Lr: 0.000100
2021-11-23 05:09:42,479 - INFO - joeynmt.training - Epoch  27, Step:    89900, Batch Loss:     2.575662, Tokens per Sec:     2195, Lr: 0.000100
2021-11-23 05:09:57,088 - INFO - joeynmt.training - Epoch  27, Step:    90000, Batch Loss:     2.461250, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 05:11:48,234 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:11:48,235 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:11:48,235 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:11:48,246 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 05:11:49,053 - INFO - joeynmt.helpers - delete models/baseline_multilingual/89000.ckpt
2021-11-23 05:11:49,054 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/89000.ckpt
2021-11-23 05:11:49,054 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/89000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/89000.ckpt')
2021-11-23 05:11:49,115 - INFO - joeynmt.training - Example #0
2021-11-23 05:11:49,115 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:11:49,115 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:11:49,115 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁You', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Judah', ',', '▁and', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁were', '▁with', '▁the', '▁people', '▁who', '▁were', '▁follow', 'ing', '▁the', '▁other', ',', '▁and', '▁all', '▁the', '▁people', '▁were', '▁all', '▁the', '▁st', 'ood', '.']
2021-11-23 05:11:49,115 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:11:49,116 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:11:49,116 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:11:49,116 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁You ▁have ▁been ▁a ▁time ▁of ▁Judah , ▁and ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁were ▁with ▁the ▁people ▁who ▁were ▁follow ing ▁the ▁other , ▁and ▁all ▁the ▁people ▁were ▁all ▁the ▁st ood .
2021-11-23 05:11:49,116 - INFO - joeynmt.training - Example #1
2021-11-23 05:11:49,116 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:11:49,116 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:11:49,116 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 05:11:49,117 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:11:49,117 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:11:49,117 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:11:49,117 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 05:11:49,117 - INFO - joeynmt.training - Example #2
2021-11-23 05:11:49,117 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:11:49,117 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:11:49,118 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁be', '▁made', '▁me', ',', '▁how', '▁can', '▁be', '▁with', '▁you', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 05:11:49,118 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:11:49,118 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:11:49,118 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:11:49,118 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁be ▁made ▁me , ▁how ▁can ▁be ▁with ▁you , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 05:11:49,118 - INFO - joeynmt.training - Example #3
2021-11-23 05:11:49,118 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:11:49,118 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:11:49,118 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 05:11:49,118 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:11:49,119 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:11:49,119 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:11:49,119 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 05:11:49,119 - INFO - joeynmt.training - Example #6
2021-11-23 05:11:49,119 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:11:49,119 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:11:49,119 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 05:11:49,119 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:11:49,119 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:11:49,119 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:11:49,119 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 05:11:49,119 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    90000: bleu:   8.85, loss: 81693.9922, ppl:  11.1585, duration: 112.0314s
2021-11-23 05:12:03,933 - INFO - joeynmt.training - Epoch  27, Step:    90100, Batch Loss:     2.374883, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 05:12:18,005 - INFO - joeynmt.training - Epoch  27, Step:    90200, Batch Loss:     2.234923, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 05:12:32,108 - INFO - joeynmt.training - Epoch  27, Step:    90300, Batch Loss:     2.112481, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 05:12:47,155 - INFO - joeynmt.training - Epoch  27, Step:    90400, Batch Loss:     2.354057, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 05:13:01,416 - INFO - joeynmt.training - Epoch  27, Step:    90500, Batch Loss:     2.395229, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 05:13:16,274 - INFO - joeynmt.training - Epoch  27, Step:    90600, Batch Loss:     2.260770, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 05:13:31,376 - INFO - joeynmt.training - Epoch  27, Step:    90700, Batch Loss:     2.500139, Tokens per Sec:     2128, Lr: 0.000100
2021-11-23 05:13:46,267 - INFO - joeynmt.training - Epoch  27, Step:    90800, Batch Loss:     2.255504, Tokens per Sec:     2005, Lr: 0.000100
2021-11-23 05:14:01,357 - INFO - joeynmt.training - Epoch  27, Step:    90900, Batch Loss:     2.265357, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 05:14:16,196 - INFO - joeynmt.training - Epoch  27, Step:    91000, Batch Loss:     2.454472, Tokens per Sec:     2085, Lr: 0.000100
2021-11-23 05:17:17,464 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:17:17,464 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:17:17,464 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:17:17,482 - INFO - joeynmt.training - Example #0
2021-11-23 05:17:17,482 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:17:17,482 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁a', '▁time', '▁from', '▁Judah', '.', '▁He', '▁was', '▁a', '▁re', 'jo', 'ice', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁he', '▁was', '▁a', 'head', '▁of', '▁all', '▁the', '▁people', ',', '▁and', '▁all', '▁the', '▁people', '▁were', '▁all', '▁the', '▁st', 're', 'et', '.']
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁a ▁time ▁from ▁Judah . ▁He ▁was ▁a ▁re jo ice ▁from ▁Gal ile e . ▁But ▁he ▁was ▁a head ▁of ▁all ▁the ▁people , ▁and ▁all ▁the ▁people ▁were ▁all ▁the ▁st re et .
2021-11-23 05:17:17,483 - INFO - joeynmt.training - Example #1
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 05:17:17,483 - INFO - joeynmt.training - Example #2
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁with', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁let', 'ter', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁with ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁let ter ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 05:17:17,483 - INFO - joeynmt.training - Example #3
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:17:17,483 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 05:17:17,483 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:17:17,484 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:17:17,484 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:17:17,484 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 05:17:17,484 - INFO - joeynmt.training - Example #6
2021-11-23 05:17:17,484 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:17:17,484 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:17:17,484 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 05:17:17,484 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:17:17,484 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:17:17,484 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:17:17,484 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 05:17:17,484 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    91000: bleu:   8.47, loss: 81404.5156, ppl:  11.0635, duration: 181.2876s
2021-11-23 05:17:32,631 - INFO - joeynmt.training - Epoch  27, Step:    91100, Batch Loss:     2.319078, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 05:17:47,345 - INFO - joeynmt.training - Epoch  27, Step:    91200, Batch Loss:     2.197123, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 05:18:02,140 - INFO - joeynmt.training - Epoch  27, Step:    91300, Batch Loss:     2.604095, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 05:18:16,849 - INFO - joeynmt.training - Epoch  27, Step:    91400, Batch Loss:     2.153780, Tokens per Sec:     2092, Lr: 0.000100
2021-11-23 05:18:31,572 - INFO - joeynmt.training - Epoch  27, Step:    91500, Batch Loss:     2.287531, Tokens per Sec:     2193, Lr: 0.000100
2021-11-23 05:18:31,936 - INFO - joeynmt.training - Epoch  27: total training loss 7951.10
2021-11-23 05:18:31,936 - INFO - joeynmt.training - EPOCH 28
2021-11-23 05:18:45,941 - INFO - joeynmt.training - Epoch  28, Step:    91600, Batch Loss:     2.251810, Tokens per Sec:     2083, Lr: 0.000100
2021-11-23 05:19:00,274 - INFO - joeynmt.training - Epoch  28, Step:    91700, Batch Loss:     2.349056, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 05:19:14,734 - INFO - joeynmt.training - Epoch  28, Step:    91800, Batch Loss:     2.259876, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 05:19:29,395 - INFO - joeynmt.training - Epoch  28, Step:    91900, Batch Loss:     2.122904, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 05:19:44,337 - INFO - joeynmt.training - Epoch  28, Step:    92000, Batch Loss:     2.483220, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 05:21:32,826 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:21:32,826 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:21:32,826 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:21:32,842 - INFO - joeynmt.training - Example #0
2021-11-23 05:21:32,842 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:21:32,842 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:21:32,842 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁a', '▁time', '▁of', '▁J', 'e', 'us', ',', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁har', 'vest', '▁of', '▁all', '▁the', '▁har', 'vest', '.']
2021-11-23 05:21:32,842 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:21:32,842 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:21:32,842 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁a ▁time ▁of ▁J e us , ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁all ▁the ▁har vest ▁of ▁all ▁the ▁har vest .
2021-11-23 05:21:32,843 - INFO - joeynmt.training - Example #1
2021-11-23 05:21:32,843 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:21:32,843 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:21:32,843 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 05:21:32,843 - INFO - joeynmt.training - Example #2
2021-11-23 05:21:32,843 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:21:32,843 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:21:32,843 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁how', '▁much', '▁much', '▁more', '▁than', 'k', ',', '▁and', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁how ▁much ▁much ▁more ▁than k , ▁and ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 05:21:32,843 - INFO - joeynmt.training - Example #3
2021-11-23 05:21:32,843 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:21:32,843 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:21:32,843 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁v', 'ol', 'tar']
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:21:32,843 - INFO - joeynmt.training - 	Hypothesis: ▁v ol tar
2021-11-23 05:21:32,843 - INFO - joeynmt.training - Example #6
2021-11-23 05:21:32,844 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:21:32,844 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:21:32,844 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 05:21:32,844 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:21:32,844 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:21:32,844 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:21:32,844 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 05:21:32,844 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    92000: bleu:   8.72, loss: 81594.3438, ppl:  11.1257, duration: 108.5066s
2021-11-23 05:21:47,902 - INFO - joeynmt.training - Epoch  28, Step:    92100, Batch Loss:     2.231226, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 05:22:01,968 - INFO - joeynmt.training - Epoch  28, Step:    92200, Batch Loss:     2.142610, Tokens per Sec:     2180, Lr: 0.000100
2021-11-23 05:22:16,054 - INFO - joeynmt.training - Epoch  28, Step:    92300, Batch Loss:     2.564683, Tokens per Sec:     2174, Lr: 0.000100
2021-11-23 05:22:31,361 - INFO - joeynmt.training - Epoch  28, Step:    92400, Batch Loss:     2.275627, Tokens per Sec:     2071, Lr: 0.000100
2021-11-23 05:22:46,105 - INFO - joeynmt.training - Epoch  28, Step:    92500, Batch Loss:     2.551419, Tokens per Sec:     2083, Lr: 0.000100
2021-11-23 05:23:00,130 - INFO - joeynmt.training - Epoch  28, Step:    92600, Batch Loss:     2.285783, Tokens per Sec:     2231, Lr: 0.000100
2021-11-23 05:23:14,519 - INFO - joeynmt.training - Epoch  28, Step:    92700, Batch Loss:     2.289489, Tokens per Sec:     2186, Lr: 0.000100
2021-11-23 05:23:28,955 - INFO - joeynmt.training - Epoch  28, Step:    92800, Batch Loss:     2.382757, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 05:23:44,222 - INFO - joeynmt.training - Epoch  28, Step:    92900, Batch Loss:     2.332466, Tokens per Sec:     2040, Lr: 0.000100
2021-11-23 05:23:58,938 - INFO - joeynmt.training - Epoch  28, Step:    93000, Batch Loss:     2.274848, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 05:26:51,160 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:26:51,161 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:26:51,161 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:26:51,178 - INFO - joeynmt.training - Example #0
2021-11-23 05:26:51,178 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:26:51,178 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:26:51,178 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁a', '▁time', '▁of', '▁J', 'e', 'us', ',', '▁you', '▁were', '▁a', '▁c', 'ert', 'ain', '.', '▁But', '▁you', '▁were', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁and', '▁all', '▁the', '▁people', '▁were', '▁all', '▁the', '▁st', 'ood', '.']
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁a ▁time ▁of ▁J e us , ▁you ▁were ▁a ▁c ert ain . ▁But ▁you ▁were ▁follow ing ▁the ▁people ▁of ▁Gal ile e , ▁and ▁all ▁the ▁people ▁were ▁all ▁the ▁st ood .
2021-11-23 05:26:51,178 - INFO - joeynmt.training - Example #1
2021-11-23 05:26:51,178 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:26:51,178 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:26:51,178 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 05:26:51,178 - INFO - joeynmt.training - Example #2
2021-11-23 05:26:51,178 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:26:51,178 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:26:51,178 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁me', ',', '▁how', '▁much', '▁to', '▁each', '▁other', ',', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:26:51,178 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁me , ▁how ▁much ▁to ▁each ▁other , ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 05:26:51,179 - INFO - joeynmt.training - Example #3
2021-11-23 05:26:51,179 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:26:51,179 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:26:51,179 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 05:26:51,179 - INFO - joeynmt.training - Example #6
2021-11-23 05:26:51,179 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:26:51,179 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:26:51,179 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:26:51,179 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 05:26:51,179 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    93000: bleu:   8.81, loss: 81374.8203, ppl:  11.0538, duration: 172.2405s
2021-11-23 05:27:05,935 - INFO - joeynmt.training - Epoch  28, Step:    93100, Batch Loss:     2.303322, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 05:27:20,650 - INFO - joeynmt.training - Epoch  28, Step:    93200, Batch Loss:     2.502627, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 05:27:36,036 - INFO - joeynmt.training - Epoch  28, Step:    93300, Batch Loss:     2.564457, Tokens per Sec:     2029, Lr: 0.000100
2021-11-23 05:27:51,362 - INFO - joeynmt.training - Epoch  28, Step:    93400, Batch Loss:     2.408364, Tokens per Sec:     2045, Lr: 0.000100
2021-11-23 05:28:05,595 - INFO - joeynmt.training - Epoch  28, Step:    93500, Batch Loss:     2.332588, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 05:28:20,277 - INFO - joeynmt.training - Epoch  28, Step:    93600, Batch Loss:     2.122815, Tokens per Sec:     2110, Lr: 0.000100
2021-11-23 05:28:35,230 - INFO - joeynmt.training - Epoch  28, Step:    93700, Batch Loss:     2.300787, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 05:28:49,927 - INFO - joeynmt.training - Epoch  28, Step:    93800, Batch Loss:     2.336453, Tokens per Sec:     2229, Lr: 0.000100
2021-11-23 05:29:04,486 - INFO - joeynmt.training - Epoch  28, Step:    93900, Batch Loss:     2.031057, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 05:29:18,949 - INFO - joeynmt.training - Epoch  28, Step:    94000, Batch Loss:     2.427040, Tokens per Sec:     2138, Lr: 0.000100
2021-11-23 05:31:50,092 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:31:50,093 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:31:50,093 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:31:50,104 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 05:31:50,920 - INFO - joeynmt.helpers - delete models/baseline_multilingual/90000.ckpt
2021-11-23 05:31:50,920 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/90000.ckpt
2021-11-23 05:31:50,920 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/90000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/90000.ckpt')
2021-11-23 05:31:50,975 - INFO - joeynmt.training - Example #0
2021-11-23 05:31:50,976 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:31:50,976 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:31:50,976 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁going', '▁to', '▁Jerusalem', ',', '▁the', '▁time', '▁of', '▁Judah', '.', '▁He', '▁was', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁he', '▁was', '▁a', '▁follow', 'ers', ',', '▁but', '▁he', '▁was', '▁a', 'head', '▁of', '▁all', '▁the', '▁wall', '.']
2021-11-23 05:31:50,976 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:31:50,976 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:31:50,976 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:31:50,976 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁going ▁to ▁Jerusalem , ▁the ▁time ▁of ▁Judah . ▁He ▁was ▁a head ▁of ▁Gal ile e . ▁But ▁he ▁was ▁a ▁follow ers , ▁but ▁he ▁was ▁a head ▁of ▁all ▁the ▁wall .
2021-11-23 05:31:50,977 - INFO - joeynmt.training - Example #1
2021-11-23 05:31:50,977 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:31:50,977 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:31:50,977 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 05:31:50,977 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:31:50,977 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:31:50,977 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:31:50,977 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 05:31:50,978 - INFO - joeynmt.training - Example #2
2021-11-23 05:31:50,978 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:31:50,978 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:31:50,978 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁let', '▁me', '▁be', '▁made', '▁my', '▁body', ',', '▁how', '▁can', "'", 't', '▁love', '▁each', '▁other', ',', '▁and', '▁let', '▁each', '▁other', '.']
2021-11-23 05:31:50,978 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:31:50,978 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:31:50,978 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:31:50,978 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁let ▁me ▁be ▁made ▁my ▁body , ▁how ▁can ' t ▁love ▁each ▁other , ▁and ▁let ▁each ▁other .
2021-11-23 05:31:50,978 - INFO - joeynmt.training - Example #3
2021-11-23 05:31:50,979 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:31:50,979 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:31:50,979 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 05:31:50,979 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:31:50,979 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:31:50,979 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:31:50,979 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 05:31:50,979 - INFO - joeynmt.training - Example #6
2021-11-23 05:31:50,979 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:31:50,980 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:31:50,980 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 05:31:50,980 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:31:50,980 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:31:50,980 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:31:50,980 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 05:31:50,980 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    94000: bleu:   9.02, loss: 81268.3750, ppl:  11.0191, duration: 152.0306s
2021-11-23 05:32:05,972 - INFO - joeynmt.training - Epoch  28, Step:    94100, Batch Loss:     2.293795, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 05:32:20,311 - INFO - joeynmt.training - Epoch  28, Step:    94200, Batch Loss:     2.346927, Tokens per Sec:     2239, Lr: 0.000100
2021-11-23 05:32:35,470 - INFO - joeynmt.training - Epoch  28, Step:    94300, Batch Loss:     2.152900, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 05:32:50,149 - INFO - joeynmt.training - Epoch  28, Step:    94400, Batch Loss:     2.371175, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 05:33:05,023 - INFO - joeynmt.training - Epoch  28, Step:    94500, Batch Loss:     2.317108, Tokens per Sec:     2184, Lr: 0.000100
2021-11-23 05:33:20,529 - INFO - joeynmt.training - Epoch  28, Step:    94600, Batch Loss:     2.316415, Tokens per Sec:     2218, Lr: 0.000100
2021-11-23 05:33:34,978 - INFO - joeynmt.training - Epoch  28, Step:    94700, Batch Loss:     2.288253, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 05:33:49,208 - INFO - joeynmt.training - Epoch  28, Step:    94800, Batch Loss:     2.612411, Tokens per Sec:     2208, Lr: 0.000100
2021-11-23 05:34:02,903 - INFO - joeynmt.training - Epoch  28: total training loss 7881.46
2021-11-23 05:34:02,904 - INFO - joeynmt.training - EPOCH 29
2021-11-23 05:34:04,195 - INFO - joeynmt.training - Epoch  29, Step:    94900, Batch Loss:     2.510572, Tokens per Sec:     1599, Lr: 0.000100
2021-11-23 05:34:18,142 - INFO - joeynmt.training - Epoch  29, Step:    95000, Batch Loss:     2.439268, Tokens per Sec:     2244, Lr: 0.000100
2021-11-23 05:36:35,185 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:36:35,185 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:36:35,185 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:36:35,197 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 05:36:36,013 - INFO - joeynmt.helpers - delete models/baseline_multilingual/94000.ckpt
2021-11-23 05:36:36,013 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/94000.ckpt
2021-11-23 05:36:36,014 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/94000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/94000.ckpt')
2021-11-23 05:36:36,074 - INFO - joeynmt.training - Example #0
2021-11-23 05:36:36,075 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:36:36,075 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:36:36,075 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', '▁you', '▁go', '▁to', '▁Jerusalem', ',', '▁from', '▁Jud', 'e', 'a', ',', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁your', 'self', ',', '▁and', '▁all', '▁your', 'self', '▁are', '▁all', '▁your', 'self', '."']
2021-11-23 05:36:36,075 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:36:36,075 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:36:36,075 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:36:36,076 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t ▁you ▁go ▁to ▁Jerusalem , ▁from ▁Jud e a , ▁from ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁all ▁your self , ▁and ▁all ▁your self ▁are ▁all ▁your self ."
2021-11-23 05:36:36,076 - INFO - joeynmt.training - Example #1
2021-11-23 05:36:36,076 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:36:36,076 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:36:36,076 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'u', 'il', 'her', 'me']
2021-11-23 05:36:36,076 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:36:36,076 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:36:36,077 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:36:36,077 - INFO - joeynmt.training - 	Hypothesis: ▁G u il her me
2021-11-23 05:36:36,077 - INFO - joeynmt.training - Example #2
2021-11-23 05:36:36,077 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:36:36,077 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:36:36,077 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁may', '▁be', '▁made', '▁me', ',', '▁how', '▁can', '▁I', '▁have', '▁a', '▁great', 'est', 'iv', 'al', ',', '▁and', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 05:36:36,077 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:36:36,077 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:36:36,077 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:36:36,077 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁may ▁be ▁made ▁me , ▁how ▁can ▁I ▁have ▁a ▁great est iv al , ▁and ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 05:36:36,077 - INFO - joeynmt.training - Example #3
2021-11-23 05:36:36,078 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:36:36,078 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:36:36,078 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 05:36:36,078 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:36:36,078 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:36:36,078 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:36:36,078 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 05:36:36,078 - INFO - joeynmt.training - Example #6
2021-11-23 05:36:36,078 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:36:36,078 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:36:36,078 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 05:36:36,078 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:36:36,078 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:36:36,078 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:36:36,079 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 05:36:36,079 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    95000: bleu:   9.23, loss: 81118.0078, ppl:  10.9703, duration: 137.9362s
2021-11-23 05:36:51,133 - INFO - joeynmt.training - Epoch  29, Step:    95100, Batch Loss:     2.403553, Tokens per Sec:     2047, Lr: 0.000100
2021-11-23 05:37:06,025 - INFO - joeynmt.training - Epoch  29, Step:    95200, Batch Loss:     2.461500, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 05:37:21,188 - INFO - joeynmt.training - Epoch  29, Step:    95300, Batch Loss:     2.300020, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 05:37:35,581 - INFO - joeynmt.training - Epoch  29, Step:    95400, Batch Loss:     2.063712, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 05:37:50,711 - INFO - joeynmt.training - Epoch  29, Step:    95500, Batch Loss:     2.287378, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 05:38:04,955 - INFO - joeynmt.training - Epoch  29, Step:    95600, Batch Loss:     2.216112, Tokens per Sec:     2124, Lr: 0.000100
2021-11-23 05:38:18,900 - INFO - joeynmt.training - Epoch  29, Step:    95700, Batch Loss:     2.250576, Tokens per Sec:     2228, Lr: 0.000100
2021-11-23 05:38:33,621 - INFO - joeynmt.training - Epoch  29, Step:    95800, Batch Loss:     2.387640, Tokens per Sec:     2068, Lr: 0.000100
2021-11-23 05:38:48,083 - INFO - joeynmt.training - Epoch  29, Step:    95900, Batch Loss:     2.159155, Tokens per Sec:     2066, Lr: 0.000100
2021-11-23 05:39:02,194 - INFO - joeynmt.training - Epoch  29, Step:    96000, Batch Loss:     2.407362, Tokens per Sec:     2233, Lr: 0.000100
2021-11-23 05:40:46,454 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:40:46,454 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:40:46,454 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:40:46,474 - INFO - joeynmt.training - Example #0
2021-11-23 05:40:46,474 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:40:46,474 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:40:46,474 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁in', '▁Jerusalem', ',', '▁you', '▁are', '▁a', '▁c', 'ut', 'er', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁a', '▁follow', 'er', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁people', '▁of', '▁all', '▁the', '▁har', 'vest', '.']
2021-11-23 05:40:46,474 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:40:46,474 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:40:46,474 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:40:46,474 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁in ▁Jerusalem , ▁you ▁are ▁a ▁c ut er ▁of ▁Gal ile e . ▁But ▁you ▁are ▁a ▁follow er , ▁but ▁you ▁are ▁all ▁the ▁people ▁of ▁all ▁the ▁har vest .
2021-11-23 05:40:46,475 - INFO - joeynmt.training - Example #1
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁g', 'el', 'ade', 'ira']
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Hypothesis: ▁g el ade ira
2021-11-23 05:40:46,475 - INFO - joeynmt.training - Example #2
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁be', '▁made', '▁me', ',', '▁how', '▁much', '▁much', '▁to', '▁me', ',', '▁how', '▁can', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁be ▁made ▁me , ▁how ▁much ▁much ▁to ▁me , ▁how ▁can ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 05:40:46,475 - INFO - joeynmt.training - Example #3
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:40:46,475 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 05:40:46,475 - INFO - joeynmt.training - Example #6
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:40:46,475 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:40:46,476 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ix']
2021-11-23 05:40:46,476 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:40:46,476 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:40:46,476 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:40:46,476 - INFO - joeynmt.training - 	Hypothesis: ▁s ix
2021-11-23 05:40:46,476 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    96000: bleu:   8.96, loss: 81064.6250, ppl:  10.9530, duration: 104.2819s
2021-11-23 05:41:00,775 - INFO - joeynmt.training - Epoch  29, Step:    96100, Batch Loss:     2.285496, Tokens per Sec:     2268, Lr: 0.000100
2021-11-23 05:41:15,391 - INFO - joeynmt.training - Epoch  29, Step:    96200, Batch Loss:     2.167701, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 05:41:29,364 - INFO - joeynmt.training - Epoch  29, Step:    96300, Batch Loss:     2.236262, Tokens per Sec:     2222, Lr: 0.000100
2021-11-23 05:41:44,934 - INFO - joeynmt.training - Epoch  29, Step:    96400, Batch Loss:     2.094560, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 05:41:59,882 - INFO - joeynmt.training - Epoch  29, Step:    96500, Batch Loss:     2.238343, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 05:42:14,566 - INFO - joeynmt.training - Epoch  29, Step:    96600, Batch Loss:     2.118418, Tokens per Sec:     2204, Lr: 0.000100
2021-11-23 05:42:29,036 - INFO - joeynmt.training - Epoch  29, Step:    96700, Batch Loss:     2.340857, Tokens per Sec:     2261, Lr: 0.000100
2021-11-23 05:42:43,942 - INFO - joeynmt.training - Epoch  29, Step:    96800, Batch Loss:     2.319709, Tokens per Sec:     2196, Lr: 0.000100
2021-11-23 05:42:58,935 - INFO - joeynmt.training - Epoch  29, Step:    96900, Batch Loss:     2.272180, Tokens per Sec:     2052, Lr: 0.000100
2021-11-23 05:43:14,099 - INFO - joeynmt.training - Epoch  29, Step:    97000, Batch Loss:     2.399318, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 05:45:44,356 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:45:44,356 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:45:44,356 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:45:44,373 - INFO - joeynmt.training - Example #0
2021-11-23 05:45:44,374 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:45:44,374 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:45:44,374 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁a', '▁time', '▁of', '▁J', 'ul', 'i', 'us', ',', '▁you', '▁are', '▁a', '▁c', 'ert', 'ain', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁same', '▁way', '.']
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁a ▁time ▁of ▁J ul i us , ▁you ▁are ▁a ▁c ert ain . ▁But ▁you ▁are ▁follow ing ▁the ▁people , ▁but ▁you ▁are ▁all ▁the ▁same ▁way .
2021-11-23 05:45:44,374 - INFO - joeynmt.training - Example #1
2021-11-23 05:45:44,374 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:45:44,374 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:45:44,374 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 05:45:44,374 - INFO - joeynmt.training - Example #2
2021-11-23 05:45:44,374 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:45:44,374 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:45:44,374 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁ple', 'ase', ',', '▁how', '▁I', '▁have', '▁been', '▁made', ',', '▁how', '▁much', '▁more', '▁than', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '.', '▁Let', '▁each', '▁other', ',', '▁one', '▁another', '.']
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:45:44,374 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁ple ase , ▁how ▁I ▁have ▁been ▁made , ▁how ▁much ▁more ▁than ▁each ▁other , ▁love ▁each ▁other . ▁Let ▁each ▁other , ▁one ▁another .
2021-11-23 05:45:44,375 - INFO - joeynmt.training - Example #3
2021-11-23 05:45:44,375 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:45:44,375 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:45:44,375 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 05:45:44,375 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:45:44,375 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:45:44,375 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:45:44,375 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 05:45:44,375 - INFO - joeynmt.training - Example #6
2021-11-23 05:45:44,375 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:45:44,375 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:45:44,375 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 05:45:44,375 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:45:44,375 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:45:44,375 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:45:44,375 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 05:45:44,375 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    97000: bleu:   8.98, loss: 80885.3359, ppl:  10.8952, duration: 150.2756s
2021-11-23 05:45:58,894 - INFO - joeynmt.training - Epoch  29, Step:    97100, Batch Loss:     2.411789, Tokens per Sec:     2190, Lr: 0.000100
2021-11-23 05:46:13,106 - INFO - joeynmt.training - Epoch  29, Step:    97200, Batch Loss:     2.444791, Tokens per Sec:     2188, Lr: 0.000100
2021-11-23 05:46:27,600 - INFO - joeynmt.training - Epoch  29, Step:    97300, Batch Loss:     2.299596, Tokens per Sec:     2255, Lr: 0.000100
2021-11-23 05:46:41,664 - INFO - joeynmt.training - Epoch  29, Step:    97400, Batch Loss:     2.171462, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 05:46:56,214 - INFO - joeynmt.training - Epoch  29, Step:    97500, Batch Loss:     2.004788, Tokens per Sec:     2129, Lr: 0.000100
2021-11-23 05:47:11,338 - INFO - joeynmt.training - Epoch  29, Step:    97600, Batch Loss:     2.489666, Tokens per Sec:     2061, Lr: 0.000100
2021-11-23 05:47:25,828 - INFO - joeynmt.training - Epoch  29, Step:    97700, Batch Loss:     2.247240, Tokens per Sec:     2163, Lr: 0.000100
2021-11-23 05:47:40,256 - INFO - joeynmt.training - Epoch  29, Step:    97800, Batch Loss:     2.080701, Tokens per Sec:     2234, Lr: 0.000100
2021-11-23 05:47:55,209 - INFO - joeynmt.training - Epoch  29, Step:    97900, Batch Loss:     2.377440, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 05:48:10,264 - INFO - joeynmt.training - Epoch  29, Step:    98000, Batch Loss:     2.141590, Tokens per Sec:     2098, Lr: 0.000100
2021-11-23 05:50:21,305 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:50:21,305 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:50:21,305 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:50:21,317 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 05:50:22,134 - INFO - joeynmt.helpers - delete models/baseline_multilingual/95000.ckpt
2021-11-23 05:50:22,134 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/95000.ckpt
2021-11-23 05:50:22,135 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/95000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/95000.ckpt')
2021-11-23 05:50:22,192 - INFO - joeynmt.training - Example #0
2021-11-23 05:50:22,192 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:50:22,192 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:50:22,193 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁a', '▁time', '▁of', '▁Judah', ',', '▁you', '▁are', '▁a', '▁c', 'it', 'us', '.', '▁You', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁people', '▁who', '▁are', '▁all', '▁the', '▁st', 're', 'et', 's', '.']
2021-11-23 05:50:22,193 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:50:22,193 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:50:22,193 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:50:22,193 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁a ▁time ▁of ▁Judah , ▁you ▁are ▁a ▁c it us . ▁You ▁are ▁a head ▁of ▁Gal ile e , ▁but ▁you ▁are ▁all ▁the ▁people ▁who ▁are ▁all ▁the ▁st re et s .
2021-11-23 05:50:22,193 - INFO - joeynmt.training - Example #1
2021-11-23 05:50:22,194 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:50:22,194 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:50:22,194 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 05:50:22,194 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:50:22,194 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:50:22,194 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:50:22,194 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 05:50:22,194 - INFO - joeynmt.training - Example #2
2021-11-23 05:50:22,195 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:50:22,195 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:50:22,195 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 05:50:22,195 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:50:22,195 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:50:22,195 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:50:22,195 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 05:50:22,196 - INFO - joeynmt.training - Example #3
2021-11-23 05:50:22,196 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:50:22,196 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:50:22,196 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 05:50:22,196 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:50:22,196 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:50:22,196 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:50:22,197 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 05:50:22,197 - INFO - joeynmt.training - Example #6
2021-11-23 05:50:22,197 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:50:22,197 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:50:22,197 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 05:50:22,197 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:50:22,197 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:50:22,197 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:50:22,198 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 05:50:22,198 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    98000: bleu:   9.42, loss: 80440.1250, ppl:  10.7529, duration: 131.9332s
2021-11-23 05:50:36,967 - INFO - joeynmt.training - Epoch  29, Step:    98100, Batch Loss:     2.182842, Tokens per Sec:     1990, Lr: 0.000100
2021-11-23 05:50:51,863 - INFO - joeynmt.training - Epoch  29, Step:    98200, Batch Loss:     2.469002, Tokens per Sec:     2055, Lr: 0.000100
2021-11-23 05:51:03,804 - INFO - joeynmt.training - Epoch  29: total training loss 7809.55
2021-11-23 05:51:03,804 - INFO - joeynmt.training - EPOCH 30
2021-11-23 05:51:06,682 - INFO - joeynmt.training - Epoch  30, Step:    98300, Batch Loss:     2.061386, Tokens per Sec:     2053, Lr: 0.000100
2021-11-23 05:51:21,719 - INFO - joeynmt.training - Epoch  30, Step:    98400, Batch Loss:     2.409907, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 05:51:36,702 - INFO - joeynmt.training - Epoch  30, Step:    98500, Batch Loss:     2.231590, Tokens per Sec:     2240, Lr: 0.000100
2021-11-23 05:51:51,483 - INFO - joeynmt.training - Epoch  30, Step:    98600, Batch Loss:     2.437608, Tokens per Sec:     2204, Lr: 0.000100
2021-11-23 05:52:06,300 - INFO - joeynmt.training - Epoch  30, Step:    98700, Batch Loss:     2.317785, Tokens per Sec:     2200, Lr: 0.000100
2021-11-23 05:52:20,454 - INFO - joeynmt.training - Epoch  30, Step:    98800, Batch Loss:     2.407794, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 05:52:35,284 - INFO - joeynmt.training - Epoch  30, Step:    98900, Batch Loss:     2.196515, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 05:52:50,083 - INFO - joeynmt.training - Epoch  30, Step:    99000, Batch Loss:     2.292060, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 05:54:54,367 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:54:54,368 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:54:54,368 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:54:54,385 - INFO - joeynmt.training - Example #0
2021-11-23 05:54:54,385 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:54:54,385 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:54:54,385 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁in', '▁Jerusalem', ',', '▁you', '▁were', '▁a', '▁l', 'az', 'ar', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁when', '▁you', '▁were', '▁follow', 'ing', '▁the', '▁people', ',', '▁you', '▁are', '▁all', '▁the', '▁g', 'ate', ',', '▁and', '▁all', '▁the', '▁wall', 's', '▁are', '▁all', '▁the', '▁g', 'ate', '.']
2021-11-23 05:54:54,385 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:54:54,385 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:54:54,385 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:54:54,385 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁in ▁Jerusalem , ▁you ▁were ▁a ▁l az ar ▁of ▁Gal ile e . ▁But ▁when ▁you ▁were ▁follow ing ▁the ▁people , ▁you ▁are ▁all ▁the ▁g ate , ▁and ▁all ▁the ▁wall s ▁are ▁all ▁the ▁g ate .
2021-11-23 05:54:54,385 - INFO - joeynmt.training - Example #1
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 05:54:54,386 - INFO - joeynmt.training - Example #2
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁I', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁I ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 05:54:54,386 - INFO - joeynmt.training - Example #3
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'po', 'is']
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Hypothesis: ▁de po is
2021-11-23 05:54:54,386 - INFO - joeynmt.training - Example #6
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:54:54,386 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:54:54,386 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:54:54,387 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:54:54,387 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 05:54:54,387 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    99000: bleu:   9.30, loss: 80630.0000, ppl:  10.8134, duration: 124.3034s
2021-11-23 05:55:09,559 - INFO - joeynmt.training - Epoch  30, Step:    99100, Batch Loss:     2.530738, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 05:55:24,784 - INFO - joeynmt.training - Epoch  30, Step:    99200, Batch Loss:     2.325943, Tokens per Sec:     2059, Lr: 0.000100
2021-11-23 05:55:39,157 - INFO - joeynmt.training - Epoch  30, Step:    99300, Batch Loss:     2.357337, Tokens per Sec:     2165, Lr: 0.000100
2021-11-23 05:55:52,889 - INFO - joeynmt.training - Epoch  30, Step:    99400, Batch Loss:     2.315142, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 05:56:07,854 - INFO - joeynmt.training - Epoch  30, Step:    99500, Batch Loss:     2.399666, Tokens per Sec:     2095, Lr: 0.000100
2021-11-23 05:56:22,266 - INFO - joeynmt.training - Epoch  30, Step:    99600, Batch Loss:     2.307012, Tokens per Sec:     2164, Lr: 0.000100
2021-11-23 05:56:36,353 - INFO - joeynmt.training - Epoch  30, Step:    99700, Batch Loss:     2.201717, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 05:56:50,718 - INFO - joeynmt.training - Epoch  30, Step:    99800, Batch Loss:     2.446223, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 05:57:06,029 - INFO - joeynmt.training - Epoch  30, Step:    99900, Batch Loss:     2.091526, Tokens per Sec:     2071, Lr: 0.000100
2021-11-23 05:57:20,418 - INFO - joeynmt.training - Epoch  30, Step:   100000, Batch Loss:     2.145151, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 05:59:56,120 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 05:59:56,120 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 05:59:56,120 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 05:59:56,137 - INFO - joeynmt.training - Example #0
2021-11-23 05:59:56,137 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 05:59:56,137 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 05:59:56,137 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁a', '▁time', '▁from', '▁Jud', 'e', 'a', ',', '▁you', '▁were', '▁a', '▁c', 'ert', 'ain', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁were', '▁follow', 'ing', '▁the', '▁people', ',', '▁and', '▁all', '▁the', '▁people', '▁are', '▁all', '▁the', '▁g', 'round', 'ing', '.']
2021-11-23 05:59:56,137 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 05:59:56,137 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 05:59:56,137 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 05:59:56,137 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁a ▁time ▁from ▁Jud e a , ▁you ▁were ▁a ▁c ert ain ▁from ▁Gal ile e . ▁But ▁you ▁were ▁follow ing ▁the ▁people , ▁and ▁all ▁the ▁people ▁are ▁all ▁the ▁g round ing .
2021-11-23 05:59:56,137 - INFO - joeynmt.training - Example #1
2021-11-23 05:59:56,137 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 05:59:56,137 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 05:59:56,137 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 05:59:56,137 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 05:59:56,137 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 05:59:56,137 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 05:59:56,137 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 05:59:56,137 - INFO - joeynmt.training - Example #2
2021-11-23 05:59:56,137 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 05:59:56,138 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 05:59:56,138 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁be', '▁made', '▁me', '▁great', 'er', '▁than', 'k', ',', '▁how', '▁much', '▁more', '▁than', 'k', ',', '▁and', '▁love', '▁each', '▁other', ',', '▁always', '▁always', '▁always', '▁always', '▁always', '▁always', '▁always', '▁understand', 'ing', '.']
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁be ▁made ▁me ▁great er ▁than k , ▁how ▁much ▁more ▁than k , ▁and ▁love ▁each ▁other , ▁always ▁always ▁always ▁always ▁always ▁always ▁always ▁understand ing .
2021-11-23 05:59:56,138 - INFO - joeynmt.training - Example #3
2021-11-23 05:59:56,138 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 05:59:56,138 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 05:59:56,138 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁con', 'he', 'c', 'imento']
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Hypothesis: ▁con he c imento
2021-11-23 05:59:56,138 - INFO - joeynmt.training - Example #6
2021-11-23 05:59:56,138 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 05:59:56,138 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 05:59:56,138 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 05:59:56,138 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 05:59:56,138 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step   100000: bleu:   9.33, loss: 80543.6406, ppl:  10.7858, duration: 155.7198s
2021-11-23 06:00:11,402 - INFO - joeynmt.training - Epoch  30, Step:   100100, Batch Loss:     2.344766, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 06:00:26,190 - INFO - joeynmt.training - Epoch  30, Step:   100200, Batch Loss:     2.170887, Tokens per Sec:     2168, Lr: 0.000100
2021-11-23 06:00:40,849 - INFO - joeynmt.training - Epoch  30, Step:   100300, Batch Loss:     2.144134, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 06:00:56,058 - INFO - joeynmt.training - Epoch  30, Step:   100400, Batch Loss:     2.220613, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 06:01:11,026 - INFO - joeynmt.training - Epoch  30, Step:   100500, Batch Loss:     2.302321, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 06:01:25,587 - INFO - joeynmt.training - Epoch  30, Step:   100600, Batch Loss:     2.338495, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 06:01:40,631 - INFO - joeynmt.training - Epoch  30, Step:   100700, Batch Loss:     2.123938, Tokens per Sec:     2060, Lr: 0.000100
2021-11-23 06:01:55,467 - INFO - joeynmt.training - Epoch  30, Step:   100800, Batch Loss:     2.513783, Tokens per Sec:     2064, Lr: 0.000100
2021-11-23 06:02:09,755 - INFO - joeynmt.training - Epoch  30, Step:   100900, Batch Loss:     2.093839, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 06:02:24,624 - INFO - joeynmt.training - Epoch  30, Step:   101000, Batch Loss:     2.361932, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 06:04:04,702 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:04:04,702 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:04:04,702 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:04:04,719 - INFO - joeynmt.training - Example #0
2021-11-23 06:04:04,719 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:04:04,719 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:04:04,719 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', '▁let', 'ter', '▁you', '▁go', '▁to', '▁Jerusalem', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁and', '▁the', '▁other', '▁follow', 'ers', ',', '▁and', '▁all', '▁the', '▁people', '▁are', '▁all', '▁the', '▁har', 'vest', '▁of', '▁all', '▁the', '▁har', 'vest', '.']
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t ▁let ter ▁you ▁go ▁to ▁Jerusalem ▁from ▁Gal ile e . ▁But ▁the ▁people ▁of ▁Gal ile e , ▁and ▁the ▁other ▁follow ers , ▁and ▁all ▁the ▁people ▁are ▁all ▁the ▁har vest ▁of ▁all ▁the ▁har vest .
2021-11-23 06:04:04,720 - INFO - joeynmt.training - Example #1
2021-11-23 06:04:04,720 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:04:04,720 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:04:04,720 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 06:04:04,720 - INFO - joeynmt.training - Example #2
2021-11-23 06:04:04,720 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:04:04,720 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:04:04,720 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:04:04,720 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 06:04:04,720 - INFO - joeynmt.training - Example #3
2021-11-23 06:04:04,720 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:04:04,720 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:04:04,720 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁con', 'vers', 'ar']
2021-11-23 06:04:04,721 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:04:04,721 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:04:04,721 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:04:04,721 - INFO - joeynmt.training - 	Hypothesis: ▁con vers ar
2021-11-23 06:04:04,721 - INFO - joeynmt.training - Example #6
2021-11-23 06:04:04,721 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:04:04,721 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:04:04,721 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 06:04:04,721 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:04:04,721 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:04:04,721 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:04:04,721 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 06:04:04,721 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step   101000: bleu:   9.30, loss: 80249.0547, ppl:  10.6924, duration: 100.0967s
2021-11-23 06:04:19,590 - INFO - joeynmt.training - Epoch  30, Step:   101100, Batch Loss:     2.341257, Tokens per Sec:     2086, Lr: 0.000100
2021-11-23 06:04:33,673 - INFO - joeynmt.training - Epoch  30, Step:   101200, Batch Loss:     2.298440, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 06:04:48,538 - INFO - joeynmt.training - Epoch  30, Step:   101300, Batch Loss:     2.374431, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 06:05:03,202 - INFO - joeynmt.training - Epoch  30, Step:   101400, Batch Loss:     2.106349, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 06:05:17,043 - INFO - joeynmt.training - Epoch  30, Step:   101500, Batch Loss:     2.301596, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 06:05:31,752 - INFO - joeynmt.training - Epoch  30, Step:   101600, Batch Loss:     1.924690, Tokens per Sec:     2122, Lr: 0.000100
2021-11-23 06:05:41,138 - INFO - joeynmt.training - Epoch  30: total training loss 7740.35
2021-11-23 06:05:41,139 - INFO - joeynmt.training - EPOCH 31
2021-11-23 06:05:45,503 - INFO - joeynmt.training - Epoch  31, Step:   101700, Batch Loss:     2.299220, Tokens per Sec:     2104, Lr: 0.000100
2021-11-23 06:06:00,618 - INFO - joeynmt.training - Epoch  31, Step:   101800, Batch Loss:     2.499579, Tokens per Sec:     2111, Lr: 0.000100
2021-11-23 06:06:15,574 - INFO - joeynmt.training - Epoch  31, Step:   101900, Batch Loss:     2.157498, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 06:06:30,842 - INFO - joeynmt.training - Epoch  31, Step:   102000, Batch Loss:     2.305684, Tokens per Sec:     2044, Lr: 0.000100
2021-11-23 06:08:21,870 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:08:21,870 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:08:21,870 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:08:21,882 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 06:08:22,689 - INFO - joeynmt.helpers - delete models/baseline_multilingual/98000.ckpt
2021-11-23 06:08:22,689 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/98000.ckpt
2021-11-23 06:08:22,689 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/98000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/98000.ckpt')
2021-11-23 06:08:22,750 - INFO - joeynmt.training - Example #0
2021-11-23 06:08:22,750 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:08:22,750 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:08:22,750 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'T', 'hen', '▁you', '▁have', '▁been', '▁a', '▁time', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁are', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁follow', 'ers', ',', '▁but', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁over', '▁all', '▁the', '▁st', 'or', 'ies', '.']
2021-11-23 06:08:22,750 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:08:22,750 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:08:22,751 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:08:22,751 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" T hen ▁you ▁have ▁been ▁a ▁time ▁from ▁Jud e a . ▁You ▁are ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁all ▁the ▁follow ers , ▁but ▁all ▁your ▁follow ers ▁are ▁all ▁over ▁all ▁the ▁st or ies .
2021-11-23 06:08:22,751 - INFO - joeynmt.training - Example #1
2021-11-23 06:08:22,751 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:08:22,751 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:08:22,751 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁g', 'ar', 'f', 'a']
2021-11-23 06:08:22,751 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:08:22,751 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:08:22,752 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:08:22,752 - INFO - joeynmt.training - 	Hypothesis: ▁g ar f a
2021-11-23 06:08:22,752 - INFO - joeynmt.training - Example #2
2021-11-23 06:08:22,752 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:08:22,752 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:08:22,752 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁much', '▁much', '▁to', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 06:08:22,752 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:08:22,752 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:08:22,752 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:08:22,753 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁much ▁much ▁to ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 06:08:22,753 - INFO - joeynmt.training - Example #3
2021-11-23 06:08:22,753 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:08:22,753 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:08:22,753 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁con', 'st', 'ru', 'ir']
2021-11-23 06:08:22,753 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:08:22,753 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:08:22,753 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:08:22,753 - INFO - joeynmt.training - 	Hypothesis: ▁con st ru ir
2021-11-23 06:08:22,754 - INFO - joeynmt.training - Example #6
2021-11-23 06:08:22,754 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:08:22,754 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:08:22,754 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 06:08:22,754 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:08:22,754 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:08:22,754 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:08:22,754 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 06:08:22,755 - INFO - joeynmt.training - Validation result (greedy) at epoch  31, step   102000: bleu:   9.72, loss: 80105.1094, ppl:  10.6471, duration: 111.9119s
2021-11-23 06:08:36,957 - INFO - joeynmt.training - Epoch  31, Step:   102100, Batch Loss:     2.249221, Tokens per Sec:     2243, Lr: 0.000100
2021-11-23 06:08:51,948 - INFO - joeynmt.training - Epoch  31, Step:   102200, Batch Loss:     2.413178, Tokens per Sec:     2092, Lr: 0.000100
2021-11-23 06:09:06,911 - INFO - joeynmt.training - Epoch  31, Step:   102300, Batch Loss:     2.307227, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 06:09:21,646 - INFO - joeynmt.training - Epoch  31, Step:   102400, Batch Loss:     2.272842, Tokens per Sec:     2084, Lr: 0.000100
2021-11-23 06:09:35,966 - INFO - joeynmt.training - Epoch  31, Step:   102500, Batch Loss:     2.368322, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 06:09:50,739 - INFO - joeynmt.training - Epoch  31, Step:   102600, Batch Loss:     2.329473, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 06:10:05,674 - INFO - joeynmt.training - Epoch  31, Step:   102700, Batch Loss:     2.044441, Tokens per Sec:     2098, Lr: 0.000100
2021-11-23 06:10:19,818 - INFO - joeynmt.training - Epoch  31, Step:   102800, Batch Loss:     2.369971, Tokens per Sec:     2191, Lr: 0.000100
2021-11-23 06:10:34,376 - INFO - joeynmt.training - Epoch  31, Step:   102900, Batch Loss:     2.194032, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 06:10:48,962 - INFO - joeynmt.training - Epoch  31, Step:   103000, Batch Loss:     2.132082, Tokens per Sec:     2175, Lr: 0.000100
2021-11-23 06:12:38,671 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:12:38,671 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:12:38,671 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:12:38,683 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 06:12:39,494 - INFO - joeynmt.helpers - delete models/baseline_multilingual/102000.ckpt
2021-11-23 06:12:39,494 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/102000.ckpt
2021-11-23 06:12:39,495 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/102000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/102000.ckpt')
2021-11-23 06:12:39,550 - INFO - joeynmt.training - Example #0
2021-11-23 06:12:39,550 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:12:39,550 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:12:39,550 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁in', '▁the', '▁time', '▁of', '▁Judah', ',', '▁you', '▁are', '▁a', '▁c', 'ut', '▁off', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁when', '▁you', '▁were', '▁follow', 'ing', '▁the', '▁people', ',', '▁all', '▁the', '▁other', '▁people', '▁were', '▁all', '▁over', 'fl', 'ow', 'ed', '.']
2021-11-23 06:12:39,550 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:12:39,551 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:12:39,551 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:12:39,551 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁in ▁the ▁time ▁of ▁Judah , ▁you ▁are ▁a ▁c ut ▁off ▁from ▁Gal ile e . ▁But ▁when ▁you ▁were ▁follow ing ▁the ▁people , ▁all ▁the ▁other ▁people ▁were ▁all ▁over fl ow ed .
2021-11-23 06:12:39,551 - INFO - joeynmt.training - Example #1
2021-11-23 06:12:39,551 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:12:39,551 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:12:39,551 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 06:12:39,552 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:12:39,552 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:12:39,552 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:12:39,552 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 06:12:39,552 - INFO - joeynmt.training - Example #2
2021-11-23 06:12:39,552 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:12:39,553 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:12:39,553 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁be', '▁made', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 06:12:39,553 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:12:39,553 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:12:39,553 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:12:39,553 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁be ▁made ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 06:12:39,553 - INFO - joeynmt.training - Example #3
2021-11-23 06:12:39,553 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:12:39,553 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:12:39,553 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:12:39,553 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:12:39,553 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:12:39,554 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:12:39,554 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:12:39,554 - INFO - joeynmt.training - Example #6
2021-11-23 06:12:39,554 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:12:39,554 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:12:39,554 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'and']
2021-11-23 06:12:39,554 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:12:39,554 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:12:39,554 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:12:39,554 - INFO - joeynmt.training - 	Hypothesis: ▁s and
2021-11-23 06:12:39,554 - INFO - joeynmt.training - Validation result (greedy) at epoch  31, step   103000: bleu:   9.82, loss: 79959.7969, ppl:  10.6015, duration: 110.5919s
2021-11-23 06:12:54,046 - INFO - joeynmt.training - Epoch  31, Step:   103100, Batch Loss:     2.389105, Tokens per Sec:     2110, Lr: 0.000100
2021-11-23 06:13:08,586 - INFO - joeynmt.training - Epoch  31, Step:   103200, Batch Loss:     2.128635, Tokens per Sec:     2157, Lr: 0.000100
2021-11-23 06:13:23,381 - INFO - joeynmt.training - Epoch  31, Step:   103300, Batch Loss:     2.337512, Tokens per Sec:     2126, Lr: 0.000100
2021-11-23 06:13:37,819 - INFO - joeynmt.training - Epoch  31, Step:   103400, Batch Loss:     2.247309, Tokens per Sec:     2244, Lr: 0.000100
2021-11-23 06:13:52,510 - INFO - joeynmt.training - Epoch  31, Step:   103500, Batch Loss:     2.242514, Tokens per Sec:     2122, Lr: 0.000100
2021-11-23 06:14:07,381 - INFO - joeynmt.training - Epoch  31, Step:   103600, Batch Loss:     2.078453, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 06:14:21,586 - INFO - joeynmt.training - Epoch  31, Step:   103700, Batch Loss:     2.383383, Tokens per Sec:     2081, Lr: 0.000100
2021-11-23 06:14:35,866 - INFO - joeynmt.training - Epoch  31, Step:   103800, Batch Loss:     2.216314, Tokens per Sec:     2210, Lr: 0.000100
2021-11-23 06:14:50,283 - INFO - joeynmt.training - Epoch  31, Step:   103900, Batch Loss:     2.247658, Tokens per Sec:     2272, Lr: 0.000100
2021-11-23 06:15:05,301 - INFO - joeynmt.training - Epoch  31, Step:   104000, Batch Loss:     2.207395, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 06:17:43,011 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:17:43,011 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:17:43,011 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:17:43,030 - INFO - joeynmt.training - Example #0
2021-11-23 06:17:43,031 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:17:43,031 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:17:43,031 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁a', '▁time', '▁from', '▁Jud', 'e', 'a', ',', '▁you', '▁are', '▁a', '▁f', 'ive', '▁o', 'il', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁all', '▁the', '▁people', '▁are', '▁all', '▁the', '▁g', 'round', 'ing', '.']
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁a ▁time ▁from ▁Jud e a , ▁you ▁are ▁a ▁f ive ▁o il . ▁But ▁you ▁are ▁follow ing ▁the ▁people ▁of ▁Gal ile e , ▁but ▁all ▁the ▁people ▁are ▁all ▁the ▁g round ing .
2021-11-23 06:17:43,031 - INFO - joeynmt.training - Example #1
2021-11-23 06:17:43,031 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:17:43,031 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:17:43,031 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 06:17:43,031 - INFO - joeynmt.training - Example #2
2021-11-23 06:17:43,031 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:17:43,031 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:17:43,031 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁may', '▁be', '▁made', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:17:43,031 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁may ▁be ▁made ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 06:17:43,031 - INFO - joeynmt.training - Example #3
2021-11-23 06:17:43,032 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:17:43,032 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:17:43,032 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:17:43,032 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:17:43,032 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:17:43,032 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:17:43,032 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:17:43,032 - INFO - joeynmt.training - Example #6
2021-11-23 06:17:43,032 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:17:43,032 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:17:43,032 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ave']
2021-11-23 06:17:43,032 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:17:43,032 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:17:43,032 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:17:43,032 - INFO - joeynmt.training - 	Hypothesis: ▁s ave
2021-11-23 06:17:43,032 - INFO - joeynmt.training - Validation result (greedy) at epoch  31, step   104000: bleu:   9.78, loss: 79889.4766, ppl:  10.5795, duration: 157.7302s
2021-11-23 06:17:57,544 - INFO - joeynmt.training - Epoch  31, Step:   104100, Batch Loss:     2.603146, Tokens per Sec:     2138, Lr: 0.000100
2021-11-23 06:18:12,962 - INFO - joeynmt.training - Epoch  31, Step:   104200, Batch Loss:     2.430012, Tokens per Sec:     2065, Lr: 0.000100
2021-11-23 06:18:28,168 - INFO - joeynmt.training - Epoch  31, Step:   104300, Batch Loss:     2.362581, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 06:18:42,895 - INFO - joeynmt.training - Epoch  31, Step:   104400, Batch Loss:     2.124212, Tokens per Sec:     2104, Lr: 0.000100
2021-11-23 06:18:57,846 - INFO - joeynmt.training - Epoch  31, Step:   104500, Batch Loss:     2.280377, Tokens per Sec:     2078, Lr: 0.000100
2021-11-23 06:19:12,237 - INFO - joeynmt.training - Epoch  31, Step:   104600, Batch Loss:     2.243805, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 06:19:26,235 - INFO - joeynmt.training - Epoch  31, Step:   104700, Batch Loss:     2.376527, Tokens per Sec:     2161, Lr: 0.000100
2021-11-23 06:19:40,508 - INFO - joeynmt.training - Epoch  31, Step:   104800, Batch Loss:     2.005726, Tokens per Sec:     2199, Lr: 0.000100
2021-11-23 06:19:55,308 - INFO - joeynmt.training - Epoch  31, Step:   104900, Batch Loss:     2.372935, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 06:20:09,815 - INFO - joeynmt.training - Epoch  31, Step:   105000, Batch Loss:     2.350291, Tokens per Sec:     2170, Lr: 0.000100
2021-11-23 06:22:29,177 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:22:29,177 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:22:29,177 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:22:29,196 - INFO - joeynmt.training - Example #0
2021-11-23 06:22:29,196 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:22:29,196 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:22:29,196 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁a', '▁time', '▁from', '▁Jerusalem', '.', '▁You', '▁are', '▁a', '▁p', 'ubl', 'ic', '.', '▁But', '▁when', '▁you', '▁were', '▁follow', 'ing', '▁the', '▁people', ',', '▁you', '▁are', '▁follow', 'ed', '▁all', '▁the', '▁g', 'round', ',', '▁all', '▁your', '▁people', '▁are', '▁all', '▁the', '▁g', 'round', '.']
2021-11-23 06:22:29,196 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:22:29,196 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:22:29,196 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:22:29,196 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁a ▁time ▁from ▁Jerusalem . ▁You ▁are ▁a ▁p ubl ic . ▁But ▁when ▁you ▁were ▁follow ing ▁the ▁people , ▁you ▁are ▁follow ed ▁all ▁the ▁g round , ▁all ▁your ▁people ▁are ▁all ▁the ▁g round .
2021-11-23 06:22:29,196 - INFO - joeynmt.training - Example #1
2021-11-23 06:22:29,196 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:22:29,196 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:22:29,196 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 06:22:29,196 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:22:29,196 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:22:29,196 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 06:22:29,197 - INFO - joeynmt.training - Example #2
2021-11-23 06:22:29,197 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:22:29,197 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:22:29,197 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 06:22:29,197 - INFO - joeynmt.training - Example #3
2021-11-23 06:22:29,197 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:22:29,197 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:22:29,197 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:22:29,197 - INFO - joeynmt.training - Example #6
2021-11-23 06:22:29,197 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:22:29,197 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:22:29,197 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:22:29,197 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 06:22:29,198 - INFO - joeynmt.training - Validation result (greedy) at epoch  31, step   105000: bleu:   9.63, loss: 79546.8203, ppl:  10.4730, duration: 139.3823s
2021-11-23 06:22:38,126 - INFO - joeynmt.training - Epoch  31: total training loss 7679.77
2021-11-23 06:22:38,126 - INFO - joeynmt.training - EPOCH 32
2021-11-23 06:22:44,281 - INFO - joeynmt.training - Epoch  32, Step:   105100, Batch Loss:     2.263178, Tokens per Sec:     1912, Lr: 0.000100
2021-11-23 06:22:59,090 - INFO - joeynmt.training - Epoch  32, Step:   105200, Batch Loss:     2.268113, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 06:23:13,918 - INFO - joeynmt.training - Epoch  32, Step:   105300, Batch Loss:     2.160515, Tokens per Sec:     2186, Lr: 0.000100
2021-11-23 06:23:28,411 - INFO - joeynmt.training - Epoch  32, Step:   105400, Batch Loss:     2.212368, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 06:23:42,764 - INFO - joeynmt.training - Epoch  32, Step:   105500, Batch Loss:     2.219987, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 06:23:57,523 - INFO - joeynmt.training - Epoch  32, Step:   105600, Batch Loss:     2.360609, Tokens per Sec:     2090, Lr: 0.000100
2021-11-23 06:24:12,321 - INFO - joeynmt.training - Epoch  32, Step:   105700, Batch Loss:     2.358350, Tokens per Sec:     2194, Lr: 0.000100
2021-11-23 06:24:27,432 - INFO - joeynmt.training - Epoch  32, Step:   105800, Batch Loss:     2.338416, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 06:24:42,215 - INFO - joeynmt.training - Epoch  32, Step:   105900, Batch Loss:     2.146814, Tokens per Sec:     2194, Lr: 0.000100
2021-11-23 06:24:56,361 - INFO - joeynmt.training - Epoch  32, Step:   106000, Batch Loss:     2.102755, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 06:26:53,377 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:26:53,377 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:26:53,377 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:26:53,399 - INFO - joeynmt.training - Example #0
2021-11-23 06:26:53,399 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:26:53,399 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:26:53,399 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁going', '▁to', '▁Jerusalem', ',', '▁you', '▁were', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁was', '▁follow', 'ing', '▁the', '▁people', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁the', '▁people', '▁and', '▁all', '▁the', '▁g', 'ates', '.']
2021-11-23 06:26:53,399 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:26:53,399 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:26:53,399 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:26:53,399 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁going ▁to ▁Jerusalem , ▁you ▁were ▁a head ▁of ▁Gal ile e . ▁He ▁was ▁follow ing ▁the ▁people , ▁but ▁he ▁was ▁follow ing ▁all ▁the ▁people ▁and ▁all ▁the ▁g ates .
2021-11-23 06:26:53,399 - INFO - joeynmt.training - Example #1
2021-11-23 06:26:53,399 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:26:53,399 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:26:53,399 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 06:26:53,399 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:26:53,399 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:26:53,399 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:26:53,399 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 06:26:53,399 - INFO - joeynmt.training - Example #2
2021-11-23 06:26:53,400 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:26:53,400 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:26:53,400 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁much', '▁to', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁always', '▁one', '▁with', '▁each', '▁other', '.']
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁much ▁to ▁each ▁other , ▁love ▁each ▁other , ▁always ▁one ▁with ▁each ▁other .
2021-11-23 06:26:53,400 - INFO - joeynmt.training - Example #3
2021-11-23 06:26:53,400 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:26:53,400 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:26:53,400 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁con', 'st', 'ru', 'ir']
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Hypothesis: ▁con st ru ir
2021-11-23 06:26:53,400 - INFO - joeynmt.training - Example #6
2021-11-23 06:26:53,400 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:26:53,400 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:26:53,400 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:26:53,400 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 06:26:53,400 - INFO - joeynmt.training - Validation result (greedy) at epoch  32, step   106000: bleu:   9.58, loss: 79855.8906, ppl:  10.5690, duration: 117.0387s
2021-11-23 06:27:07,911 - INFO - joeynmt.training - Epoch  32, Step:   106100, Batch Loss:     2.437407, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 06:27:22,666 - INFO - joeynmt.training - Epoch  32, Step:   106200, Batch Loss:     2.180209, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 06:27:38,054 - INFO - joeynmt.training - Epoch  32, Step:   106300, Batch Loss:     2.362937, Tokens per Sec:     2059, Lr: 0.000100
2021-11-23 06:27:53,478 - INFO - joeynmt.training - Epoch  32, Step:   106400, Batch Loss:     2.217505, Tokens per Sec:     2074, Lr: 0.000100
2021-11-23 06:28:08,413 - INFO - joeynmt.training - Epoch  32, Step:   106500, Batch Loss:     2.236343, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 06:28:23,108 - INFO - joeynmt.training - Epoch  32, Step:   106600, Batch Loss:     2.198611, Tokens per Sec:     2201, Lr: 0.000100
2021-11-23 06:28:38,072 - INFO - joeynmt.training - Epoch  32, Step:   106700, Batch Loss:     2.243711, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 06:28:52,706 - INFO - joeynmt.training - Epoch  32, Step:   106800, Batch Loss:     2.119455, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 06:29:06,922 - INFO - joeynmt.training - Epoch  32, Step:   106900, Batch Loss:     2.291794, Tokens per Sec:     2199, Lr: 0.000100
2021-11-23 06:29:20,874 - INFO - joeynmt.training - Epoch  32, Step:   107000, Batch Loss:     2.223539, Tokens per Sec:     2185, Lr: 0.000100
2021-11-23 06:31:00,904 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:31:00,904 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:31:00,904 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:31:00,917 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 06:31:01,721 - INFO - joeynmt.helpers - delete models/baseline_multilingual/103000.ckpt
2021-11-23 06:31:01,721 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/103000.ckpt
2021-11-23 06:31:01,722 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/103000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/103000.ckpt')
2021-11-23 06:31:01,781 - INFO - joeynmt.training - Example #0
2021-11-23 06:31:01,782 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:31:01,782 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:31:01,782 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁there', ',', '▁you', '▁were', '▁a', '▁time', '▁from', '▁Gal', 'ile', 'e', '.', '▁He', '▁was', '▁with', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁follow', 'ed', '▁all', '▁the', '▁people', ',', '▁and', '▁all', '▁the', '▁people', '▁of', '▁all', '▁the', '▁g', 'round', 'ed', '.']
2021-11-23 06:31:01,782 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:31:01,782 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:31:01,783 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:31:01,783 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁there , ▁you ▁were ▁a ▁time ▁from ▁Gal ile e . ▁He ▁was ▁with ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁was ▁follow ed ▁all ▁the ▁people , ▁and ▁all ▁the ▁people ▁of ▁all ▁the ▁g round ed .
2021-11-23 06:31:01,783 - INFO - joeynmt.training - Example #1
2021-11-23 06:31:01,783 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:31:01,783 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:31:01,783 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 06:31:01,783 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:31:01,784 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:31:01,784 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:31:01,784 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 06:31:01,784 - INFO - joeynmt.training - Example #2
2021-11-23 06:31:01,784 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:31:01,784 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:31:01,784 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 06:31:01,785 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:31:01,785 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:31:01,785 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:31:01,785 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 06:31:01,785 - INFO - joeynmt.training - Example #3
2021-11-23 06:31:01,785 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:31:01,786 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:31:01,786 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:31:01,786 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:31:01,786 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:31:01,786 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:31:01,786 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:31:01,786 - INFO - joeynmt.training - Example #6
2021-11-23 06:31:01,786 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:31:01,787 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:31:01,787 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 06:31:01,787 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:31:01,787 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:31:01,787 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:31:01,787 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 06:31:01,788 - INFO - joeynmt.training - Validation result (greedy) at epoch  32, step   107000: bleu:  10.20, loss: 79353.8438, ppl:  10.4135, duration: 100.9134s
2021-11-23 06:31:15,896 - INFO - joeynmt.training - Epoch  32, Step:   107100, Batch Loss:     2.218951, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 06:31:30,455 - INFO - joeynmt.training - Epoch  32, Step:   107200, Batch Loss:     2.445730, Tokens per Sec:     2130, Lr: 0.000100
2021-11-23 06:31:44,754 - INFO - joeynmt.training - Epoch  32, Step:   107300, Batch Loss:     2.482204, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 06:31:59,474 - INFO - joeynmt.training - Epoch  32, Step:   107400, Batch Loss:     2.232002, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 06:32:14,225 - INFO - joeynmt.training - Epoch  32, Step:   107500, Batch Loss:     2.228401, Tokens per Sec:     2085, Lr: 0.000100
2021-11-23 06:32:28,922 - INFO - joeynmt.training - Epoch  32, Step:   107600, Batch Loss:     2.063621, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 06:32:43,062 - INFO - joeynmt.training - Epoch  32, Step:   107700, Batch Loss:     2.343298, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 06:32:58,032 - INFO - joeynmt.training - Epoch  32, Step:   107800, Batch Loss:     2.055342, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 06:33:12,658 - INFO - joeynmt.training - Epoch  32, Step:   107900, Batch Loss:     2.227122, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 06:33:27,448 - INFO - joeynmt.training - Epoch  32, Step:   108000, Batch Loss:     2.081983, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 06:35:20,648 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:35:20,648 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:35:20,648 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:35:20,666 - INFO - joeynmt.training - Example #0
2021-11-23 06:35:20,666 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:35:20,666 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:35:20,666 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁af', 'raid', '▁of', '▁Judah', ',', '▁you', '▁are', '▁a', '▁fe', 'llow', 'ship', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', ',', '▁but', '▁all', '▁the', '▁people', '▁are', '▁all', '▁the', '▁st', 'ood', '.']
2021-11-23 06:35:20,666 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:35:20,666 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:35:20,666 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁af raid ▁of ▁Judah , ▁you ▁are ▁a ▁fe llow ship ▁from ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁people , ▁but ▁all ▁the ▁people ▁are ▁all ▁the ▁st ood .
2021-11-23 06:35:20,667 - INFO - joeynmt.training - Example #1
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'u', 'il', 'her', 'me']
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Hypothesis: ▁G u il her me
2021-11-23 06:35:20,667 - INFO - joeynmt.training - Example #2
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁much', '▁to', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁much ▁to ▁love ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 06:35:20,667 - INFO - joeynmt.training - Example #3
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:35:20,667 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:35:20,667 - INFO - joeynmt.training - Example #6
2021-11-23 06:35:20,667 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:35:20,668 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:35:20,668 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 06:35:20,668 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:35:20,668 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:35:20,668 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:35:20,668 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 06:35:20,668 - INFO - joeynmt.training - Validation result (greedy) at epoch  32, step   108000: bleu:  10.04, loss: 79300.1875, ppl:  10.3970, duration: 113.2194s
2021-11-23 06:35:34,909 - INFO - joeynmt.training - Epoch  32, Step:   108100, Batch Loss:     2.355592, Tokens per Sec:     2174, Lr: 0.000100
2021-11-23 06:35:49,545 - INFO - joeynmt.training - Epoch  32, Step:   108200, Batch Loss:     2.281118, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 06:36:04,375 - INFO - joeynmt.training - Epoch  32, Step:   108300, Batch Loss:     2.269368, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 06:36:19,234 - INFO - joeynmt.training - Epoch  32, Step:   108400, Batch Loss:     2.105974, Tokens per Sec:     2093, Lr: 0.000100
2021-11-23 06:36:26,239 - INFO - joeynmt.training - Epoch  32: total training loss 7615.33
2021-11-23 06:36:26,240 - INFO - joeynmt.training - EPOCH 33
2021-11-23 06:36:34,180 - INFO - joeynmt.training - Epoch  33, Step:   108500, Batch Loss:     2.233807, Tokens per Sec:     2049, Lr: 0.000100
2021-11-23 06:36:48,427 - INFO - joeynmt.training - Epoch  33, Step:   108600, Batch Loss:     2.305729, Tokens per Sec:     2227, Lr: 0.000100
2021-11-23 06:37:03,034 - INFO - joeynmt.training - Epoch  33, Step:   108700, Batch Loss:     2.321124, Tokens per Sec:     2221, Lr: 0.000100
2021-11-23 06:37:18,165 - INFO - joeynmt.training - Epoch  33, Step:   108800, Batch Loss:     2.312185, Tokens per Sec:     2055, Lr: 0.000100
2021-11-23 06:37:32,965 - INFO - joeynmt.training - Epoch  33, Step:   108900, Batch Loss:     2.116949, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 06:37:47,650 - INFO - joeynmt.training - Epoch  33, Step:   109000, Batch Loss:     2.120030, Tokens per Sec:     2175, Lr: 0.000100
2021-11-23 06:39:36,884 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:39:36,884 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:39:36,884 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:39:36,901 - INFO - joeynmt.training - Example #0
2021-11-23 06:39:36,901 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:39:36,901 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:39:36,901 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Judah', '.', '▁You', '▁have', '▁been', '▁with', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁when', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁the', '▁people', ',', '▁all', '▁the', '▁people', '▁were', '▁all', '▁over', '▁all', '▁the', '▁g', 'round', 'ing', '.']
2021-11-23 06:39:36,901 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:39:36,901 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:39:36,901 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁a ▁time ▁of ▁Judah . ▁You ▁have ▁been ▁with ▁the ▁people ▁of ▁Gal ile e . ▁But ▁when ▁he ▁was ▁follow ing ▁all ▁the ▁people , ▁all ▁the ▁people ▁were ▁all ▁over ▁all ▁the ▁g round ing .
2021-11-23 06:39:36,902 - INFO - joeynmt.training - Example #1
2021-11-23 06:39:36,902 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:39:36,902 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:39:36,902 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'o', 'vern', 'ador']
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Hypothesis: ▁G o vern ador
2021-11-23 06:39:36,902 - INFO - joeynmt.training - Example #2
2021-11-23 06:39:36,902 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:39:36,902 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:39:36,902 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 06:39:36,902 - INFO - joeynmt.training - Example #3
2021-11-23 06:39:36,902 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:39:36,902 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:39:36,902 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:39:36,902 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:39:36,902 - INFO - joeynmt.training - Example #6
2021-11-23 06:39:36,903 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:39:36,903 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:39:36,903 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 06:39:36,903 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:39:36,903 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:39:36,903 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:39:36,903 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 06:39:36,903 - INFO - joeynmt.training - Validation result (greedy) at epoch  33, step   109000: bleu:  10.07, loss: 79275.1094, ppl:  10.3893, duration: 109.2529s
2021-11-23 06:39:51,088 - INFO - joeynmt.training - Epoch  33, Step:   109100, Batch Loss:     2.062974, Tokens per Sec:     2165, Lr: 0.000100
2021-11-23 06:40:05,735 - INFO - joeynmt.training - Epoch  33, Step:   109200, Batch Loss:     2.199772, Tokens per Sec:     2086, Lr: 0.000100
2021-11-23 06:40:20,819 - INFO - joeynmt.training - Epoch  33, Step:   109300, Batch Loss:     2.101680, Tokens per Sec:     2094, Lr: 0.000100
2021-11-23 06:40:34,629 - INFO - joeynmt.training - Epoch  33, Step:   109400, Batch Loss:     2.415494, Tokens per Sec:     2193, Lr: 0.000100
2021-11-23 06:40:49,461 - INFO - joeynmt.training - Epoch  33, Step:   109500, Batch Loss:     2.311957, Tokens per Sec:     2098, Lr: 0.000100
2021-11-23 06:41:04,091 - INFO - joeynmt.training - Epoch  33, Step:   109600, Batch Loss:     2.276013, Tokens per Sec:     2199, Lr: 0.000100
2021-11-23 06:41:18,255 - INFO - joeynmt.training - Epoch  33, Step:   109700, Batch Loss:     2.240337, Tokens per Sec:     2130, Lr: 0.000100
2021-11-23 06:41:33,174 - INFO - joeynmt.training - Epoch  33, Step:   109800, Batch Loss:     1.980417, Tokens per Sec:     2072, Lr: 0.000100
2021-11-23 06:41:48,629 - INFO - joeynmt.training - Epoch  33, Step:   109900, Batch Loss:     2.101972, Tokens per Sec:     2060, Lr: 0.000100
2021-11-23 06:42:02,794 - INFO - joeynmt.training - Epoch  33, Step:   110000, Batch Loss:     2.214899, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 06:44:07,232 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:44:07,232 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:44:07,232 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:44:07,249 - INFO - joeynmt.training - Example #0
2021-11-23 06:44:07,249 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:44:07,250 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:44:07,250 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'o', '▁you', '▁have', '▁been', '▁a', '▁time', '▁of', '▁Judah', ',', '▁and', '▁you', '▁are', '▁a', '▁follow', 'er', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁follow', 'ers', ',', '▁and', '▁all', '▁who', '▁are', '▁all', '▁the', '▁wall', 's', '▁of', '▁all', '▁the', '▁g', 'ate', '.']
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S o ▁you ▁have ▁been ▁a ▁time ▁of ▁Judah , ▁and ▁you ▁are ▁a ▁follow er ▁of ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁follow ers , ▁and ▁all ▁who ▁are ▁all ▁the ▁wall s ▁of ▁all ▁the ▁g ate .
2021-11-23 06:44:07,250 - INFO - joeynmt.training - Example #1
2021-11-23 06:44:07,250 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:44:07,250 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:44:07,250 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 06:44:07,250 - INFO - joeynmt.training - Example #2
2021-11-23 06:44:07,250 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:44:07,250 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:44:07,250 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁may', '▁be', '▁made', '▁me', '▁great', 'er', '▁than', 'k', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '.']
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:44:07,250 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁may ▁be ▁made ▁me ▁great er ▁than k , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other .
2021-11-23 06:44:07,250 - INFO - joeynmt.training - Example #3
2021-11-23 06:44:07,250 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:44:07,251 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:44:07,251 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:44:07,251 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:44:07,251 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:44:07,251 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:44:07,251 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:44:07,251 - INFO - joeynmt.training - Example #6
2021-11-23 06:44:07,251 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:44:07,251 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:44:07,251 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 06:44:07,251 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:44:07,251 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:44:07,251 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:44:07,251 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 06:44:07,251 - INFO - joeynmt.training - Validation result (greedy) at epoch  33, step   110000: bleu:  10.18, loss: 79265.2500, ppl:  10.3863, duration: 124.4568s
2021-11-23 06:44:22,961 - INFO - joeynmt.training - Epoch  33, Step:   110100, Batch Loss:     2.192757, Tokens per Sec:     2088, Lr: 0.000100
2021-11-23 06:44:38,800 - INFO - joeynmt.training - Epoch  33, Step:   110200, Batch Loss:     2.196277, Tokens per Sec:     2033, Lr: 0.000100
2021-11-23 06:44:53,395 - INFO - joeynmt.training - Epoch  33, Step:   110300, Batch Loss:     2.203309, Tokens per Sec:     2208, Lr: 0.000100
2021-11-23 06:45:08,187 - INFO - joeynmt.training - Epoch  33, Step:   110400, Batch Loss:     2.310707, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 06:45:21,942 - INFO - joeynmt.training - Epoch  33, Step:   110500, Batch Loss:     2.365900, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 06:45:36,216 - INFO - joeynmt.training - Epoch  33, Step:   110600, Batch Loss:     2.119683, Tokens per Sec:     2248, Lr: 0.000100
2021-11-23 06:45:51,570 - INFO - joeynmt.training - Epoch  33, Step:   110700, Batch Loss:     2.417255, Tokens per Sec:     2061, Lr: 0.000100
2021-11-23 06:46:06,077 - INFO - joeynmt.training - Epoch  33, Step:   110800, Batch Loss:     2.090227, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 06:46:20,619 - INFO - joeynmt.training - Epoch  33, Step:   110900, Batch Loss:     2.070451, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 06:46:35,177 - INFO - joeynmt.training - Epoch  33, Step:   111000, Batch Loss:     2.632443, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 06:48:29,295 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:48:29,295 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:48:29,295 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:48:29,307 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 06:48:30,125 - INFO - joeynmt.helpers - delete models/baseline_multilingual/107000.ckpt
2021-11-23 06:48:30,125 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/107000.ckpt
2021-11-23 06:48:30,126 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/107000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/107000.ckpt')
2021-11-23 06:48:30,179 - INFO - joeynmt.training - Example #0
2021-11-23 06:48:30,179 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:48:30,179 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:48:30,180 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'e', 'll', '▁you', ',', '▁you', '▁have', '▁been', '▁a', '▁time', '▁from', '▁Jud', 'e', 'a', '.', '▁But', '▁you', '▁are', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁who', '▁are', '▁all', '▁who', '▁are', '▁all', '▁the', '▁poor', '.']
2021-11-23 06:48:30,180 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:48:30,180 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:48:30,180 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:48:30,180 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W e ll ▁you , ▁you ▁have ▁been ▁a ▁time ▁from ▁Jud e a . ▁But ▁you ▁are ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁all ▁who ▁are ▁all ▁who ▁are ▁all ▁the ▁poor .
2021-11-23 06:48:30,180 - INFO - joeynmt.training - Example #1
2021-11-23 06:48:30,180 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:48:30,180 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:48:30,180 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 06:48:30,180 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:48:30,180 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:48:30,180 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:48:30,180 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 06:48:30,180 - INFO - joeynmt.training - Example #2
2021-11-23 06:48:30,180 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:48:30,180 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:48:30,180 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁always', '▁only', '▁one', '▁another', '.']
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other , ▁always ▁only ▁one ▁another .
2021-11-23 06:48:30,181 - INFO - joeynmt.training - Example #3
2021-11-23 06:48:30,181 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:48:30,181 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:48:30,181 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:48:30,181 - INFO - joeynmt.training - Example #6
2021-11-23 06:48:30,181 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:48:30,181 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:48:30,181 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:48:30,181 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 06:48:30,182 - INFO - joeynmt.training - Validation result (greedy) at epoch  33, step   111000: bleu:  10.22, loss: 79048.1250, ppl:  10.3199, duration: 115.0041s
2021-11-23 06:48:45,454 - INFO - joeynmt.training - Epoch  33, Step:   111100, Batch Loss:     2.367295, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 06:49:00,130 - INFO - joeynmt.training - Epoch  33, Step:   111200, Batch Loss:     2.158230, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 06:49:14,145 - INFO - joeynmt.training - Epoch  33, Step:   111300, Batch Loss:     2.182587, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 06:49:29,131 - INFO - joeynmt.training - Epoch  33, Step:   111400, Batch Loss:     2.144841, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 06:49:43,530 - INFO - joeynmt.training - Epoch  33, Step:   111500, Batch Loss:     2.347754, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 06:49:58,197 - INFO - joeynmt.training - Epoch  33, Step:   111600, Batch Loss:     2.391351, Tokens per Sec:     2091, Lr: 0.000100
2021-11-23 06:50:13,085 - INFO - joeynmt.training - Epoch  33, Step:   111700, Batch Loss:     2.262179, Tokens per Sec:     2128, Lr: 0.000100
2021-11-23 06:50:27,558 - INFO - joeynmt.training - Epoch  33, Step:   111800, Batch Loss:     2.019515, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 06:50:32,606 - INFO - joeynmt.training - Epoch  33: total training loss 7549.00
2021-11-23 06:50:32,607 - INFO - joeynmt.training - EPOCH 34
2021-11-23 06:50:41,471 - INFO - joeynmt.training - Epoch  34, Step:   111900, Batch Loss:     2.243687, Tokens per Sec:     2211, Lr: 0.000100
2021-11-23 06:50:56,370 - INFO - joeynmt.training - Epoch  34, Step:   112000, Batch Loss:     2.229109, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 06:52:45,873 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:52:45,873 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:52:45,873 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:52:45,886 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 06:52:46,701 - INFO - joeynmt.helpers - delete models/baseline_multilingual/111000.ckpt
2021-11-23 06:52:46,701 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/111000.ckpt
2021-11-23 06:52:46,701 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/111000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/111000.ckpt')
2021-11-23 06:52:46,760 - INFO - joeynmt.training - Example #0
2021-11-23 06:52:46,761 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:52:46,761 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:52:46,761 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'T', 'here', 'fore', '▁you', '▁have', '▁been', '▁a', '▁time', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁are', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁follow', 'ing', '▁all', '▁the', '▁people', ',', '▁and', '▁all', '▁the', '▁wall', 's', '▁are', '▁all', '▁the', '▁st', 're', 'et', 's', '.']
2021-11-23 06:52:46,761 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:52:46,761 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:52:46,761 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:52:46,762 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" T here fore ▁you ▁have ▁been ▁a ▁time ▁from ▁Jud e a . ▁You ▁are ▁follow ing ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁follow ing ▁all ▁the ▁people , ▁and ▁all ▁the ▁wall s ▁are ▁all ▁the ▁st re et s .
2021-11-23 06:52:46,762 - INFO - joeynmt.training - Example #1
2021-11-23 06:52:46,762 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:52:46,762 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:52:46,762 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 06:52:46,762 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:52:46,762 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:52:46,762 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:52:46,763 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 06:52:46,763 - INFO - joeynmt.training - Example #2
2021-11-23 06:52:46,763 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:52:46,763 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:52:46,763 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', ',', '▁always', '▁one', '▁another', '.']
2021-11-23 06:52:46,763 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:52:46,763 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:52:46,764 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:52:46,764 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other , ▁always ▁one ▁another .
2021-11-23 06:52:46,764 - INFO - joeynmt.training - Example #3
2021-11-23 06:52:46,764 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:52:46,764 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:52:46,764 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:52:46,764 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:52:46,764 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:52:46,764 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:52:46,764 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:52:46,764 - INFO - joeynmt.training - Example #6
2021-11-23 06:52:46,764 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:52:46,764 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:52:46,765 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 06:52:46,765 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:52:46,765 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:52:46,765 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:52:46,765 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 06:52:46,765 - INFO - joeynmt.training - Validation result (greedy) at epoch  34, step   112000: bleu:  10.46, loss: 78820.0859, ppl:  10.2507, duration: 110.3947s
2021-11-23 06:53:01,439 - INFO - joeynmt.training - Epoch  34, Step:   112100, Batch Loss:     2.195598, Tokens per Sec:     2040, Lr: 0.000100
2021-11-23 06:53:16,501 - INFO - joeynmt.training - Epoch  34, Step:   112200, Batch Loss:     2.379243, Tokens per Sec:     2178, Lr: 0.000100
2021-11-23 06:53:30,406 - INFO - joeynmt.training - Epoch  34, Step:   112300, Batch Loss:     2.380784, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 06:53:44,990 - INFO - joeynmt.training - Epoch  34, Step:   112400, Batch Loss:     2.055786, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 06:53:59,710 - INFO - joeynmt.training - Epoch  34, Step:   112500, Batch Loss:     2.155544, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 06:54:14,948 - INFO - joeynmt.training - Epoch  34, Step:   112600, Batch Loss:     2.246258, Tokens per Sec:     2095, Lr: 0.000100
2021-11-23 06:54:28,778 - INFO - joeynmt.training - Epoch  34, Step:   112700, Batch Loss:     2.241126, Tokens per Sec:     2190, Lr: 0.000100
2021-11-23 06:54:44,052 - INFO - joeynmt.training - Epoch  34, Step:   112800, Batch Loss:     2.467498, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 06:54:58,948 - INFO - joeynmt.training - Epoch  34, Step:   112900, Batch Loss:     2.273704, Tokens per Sec:     2110, Lr: 0.000100
2021-11-23 06:55:13,362 - INFO - joeynmt.training - Epoch  34, Step:   113000, Batch Loss:     2.061962, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 06:57:00,652 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 06:57:00,652 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 06:57:00,652 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 06:57:00,670 - INFO - joeynmt.training - Example #0
2021-11-23 06:57:00,670 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 06:57:00,670 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 06:57:00,670 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Jud', 'e', 'a', ',', '▁you', '▁were', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁whole', '▁whole', '▁land', '.']
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Jud e a , ▁you ▁were ▁from ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁all ▁the ▁whole ▁whole ▁land .
2021-11-23 06:57:00,670 - INFO - joeynmt.training - Example #1
2021-11-23 06:57:00,670 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 06:57:00,670 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 06:57:00,670 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 06:57:00,670 - INFO - joeynmt.training - Example #2
2021-11-23 06:57:00,670 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 06:57:00,670 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 06:57:00,670 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 06:57:00,670 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 06:57:00,671 - INFO - joeynmt.training - Example #3
2021-11-23 06:57:00,671 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 06:57:00,671 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 06:57:00,671 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 06:57:00,671 - INFO - joeynmt.training - Example #6
2021-11-23 06:57:00,671 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 06:57:00,671 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 06:57:00,671 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 06:57:00,671 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 06:57:00,671 - INFO - joeynmt.training - Validation result (greedy) at epoch  34, step   113000: bleu:  10.41, loss: 78924.6562, ppl:  10.2824, duration: 107.3093s
2021-11-23 06:57:14,986 - INFO - joeynmt.training - Epoch  34, Step:   113100, Batch Loss:     2.413098, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 06:57:30,229 - INFO - joeynmt.training - Epoch  34, Step:   113200, Batch Loss:     2.026216, Tokens per Sec:     2039, Lr: 0.000100
2021-11-23 06:57:44,669 - INFO - joeynmt.training - Epoch  34, Step:   113300, Batch Loss:     2.098912, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 06:57:59,472 - INFO - joeynmt.training - Epoch  34, Step:   113400, Batch Loss:     2.392827, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 06:58:14,240 - INFO - joeynmt.training - Epoch  34, Step:   113500, Batch Loss:     2.260211, Tokens per Sec:     2095, Lr: 0.000100
2021-11-23 06:58:28,411 - INFO - joeynmt.training - Epoch  34, Step:   113600, Batch Loss:     2.153312, Tokens per Sec:     2173, Lr: 0.000100
2021-11-23 06:58:43,381 - INFO - joeynmt.training - Epoch  34, Step:   113700, Batch Loss:     1.964184, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 06:58:57,759 - INFO - joeynmt.training - Epoch  34, Step:   113800, Batch Loss:     2.402168, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 06:59:12,906 - INFO - joeynmt.training - Epoch  34, Step:   113900, Batch Loss:     2.216068, Tokens per Sec:     2097, Lr: 0.000100
2021-11-23 06:59:27,953 - INFO - joeynmt.training - Epoch  34, Step:   114000, Batch Loss:     2.523950, Tokens per Sec:     2051, Lr: 0.000100
2021-11-23 07:00:57,725 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:00:57,725 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:00:57,726 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:00:57,738 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 07:00:58,554 - INFO - joeynmt.helpers - delete models/baseline_multilingual/112000.ckpt
2021-11-23 07:00:58,555 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/112000.ckpt
2021-11-23 07:00:58,555 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/112000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/112000.ckpt')
2021-11-23 07:00:58,609 - INFO - joeynmt.training - Example #0
2021-11-23 07:00:58,609 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:00:58,609 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:00:58,609 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁f', 'av', 'or', '▁of', '▁the', '▁time', '▁of', '▁J', 'ul', 'us', '.', '▁You', '▁are', '▁follow', 'ing', '▁the', '▁follow', 'ers', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁all', '▁the', '▁follow', 'ers', '▁of', '▁your', '▁follow', 'ers', '.']
2021-11-23 07:00:58,609 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:00:58,609 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:00:58,610 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:00:58,610 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁f av or ▁of ▁the ▁time ▁of ▁J ul us . ▁You ▁are ▁follow ing ▁the ▁follow ers ▁of ▁Gal ile e , ▁but ▁you ▁are ▁all ▁the ▁follow ers ▁of ▁your ▁follow ers .
2021-11-23 07:00:58,610 - INFO - joeynmt.training - Example #1
2021-11-23 07:00:58,610 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:00:58,610 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:00:58,610 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:00:58,610 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:00:58,611 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:00:58,611 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:00:58,611 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:00:58,611 - INFO - joeynmt.training - Example #2
2021-11-23 07:00:58,611 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:00:58,611 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:00:58,612 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁made', '▁my', '▁faith', ',', '▁how', '▁can', '▁be', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 07:00:58,612 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:00:58,612 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:00:58,612 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:00:58,612 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁made ▁my ▁faith , ▁how ▁can ▁be ▁with ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 07:00:58,612 - INFO - joeynmt.training - Example #3
2021-11-23 07:00:58,612 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:00:58,613 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:00:58,613 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'entro']
2021-11-23 07:00:58,613 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:00:58,613 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:00:58,613 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:00:58,613 - INFO - joeynmt.training - 	Hypothesis: ▁d entro
2021-11-23 07:00:58,613 - INFO - joeynmt.training - Example #6
2021-11-23 07:00:58,613 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:00:58,614 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:00:58,614 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 07:00:58,614 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:00:58,614 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:00:58,614 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:00:58,614 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 07:00:58,615 - INFO - joeynmt.training - Validation result (greedy) at epoch  34, step   114000: bleu:  10.60, loss: 78827.6797, ppl:  10.2530, duration: 90.6611s
2021-11-23 07:01:13,692 - INFO - joeynmt.training - Epoch  34, Step:   114100, Batch Loss:     2.111793, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 07:01:29,442 - INFO - joeynmt.training - Epoch  34, Step:   114200, Batch Loss:     2.216280, Tokens per Sec:     2063, Lr: 0.000100
2021-11-23 07:01:44,340 - INFO - joeynmt.training - Epoch  34, Step:   114300, Batch Loss:     2.117556, Tokens per Sec:     2186, Lr: 0.000100
2021-11-23 07:01:59,100 - INFO - joeynmt.training - Epoch  34, Step:   114400, Batch Loss:     2.403310, Tokens per Sec:     2256, Lr: 0.000100
2021-11-23 07:02:14,106 - INFO - joeynmt.training - Epoch  34, Step:   114500, Batch Loss:     2.265488, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 07:02:28,472 - INFO - joeynmt.training - Epoch  34, Step:   114600, Batch Loss:     2.192287, Tokens per Sec:     2203, Lr: 0.000100
2021-11-23 07:02:43,700 - INFO - joeynmt.training - Epoch  34, Step:   114700, Batch Loss:     2.230567, Tokens per Sec:     2057, Lr: 0.000100
2021-11-23 07:02:58,164 - INFO - joeynmt.training - Epoch  34, Step:   114800, Batch Loss:     2.036159, Tokens per Sec:     2103, Lr: 0.000100
2021-11-23 07:03:11,926 - INFO - joeynmt.training - Epoch  34, Step:   114900, Batch Loss:     2.352641, Tokens per Sec:     2163, Lr: 0.000100
2021-11-23 07:03:26,200 - INFO - joeynmt.training - Epoch  34, Step:   115000, Batch Loss:     2.215585, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 07:05:08,886 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:05:08,887 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:05:08,887 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:05:08,903 - INFO - joeynmt.training - Example #0
2021-11-23 07:05:08,903 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:05:08,903 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:05:08,903 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁going', '▁to', '▁Jerusalem', ',', '▁the', '▁time', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁the', '▁people', ',', '▁and', '▁all', '▁the', '▁wall', 's', '▁were', '▁all', '▁the', '▁sh', 'ip', 'p', 'ed', '.']
2021-11-23 07:05:08,903 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:05:08,903 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:05:08,903 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁going ▁to ▁Jerusalem , ▁the ▁time ▁of ▁Gal ile e . ▁But ▁you ▁follow ed ▁the ▁follow ers , ▁but ▁he ▁was ▁follow ing ▁all ▁the ▁people , ▁and ▁all ▁the ▁wall s ▁were ▁all ▁the ▁sh ip p ed .
2021-11-23 07:05:08,904 - INFO - joeynmt.training - Example #1
2021-11-23 07:05:08,904 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:05:08,904 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:05:08,904 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 07:05:08,904 - INFO - joeynmt.training - Example #2
2021-11-23 07:05:08,904 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:05:08,904 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:05:08,904 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', 'er', '▁than', 'ks', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great er ▁than ks , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 07:05:08,904 - INFO - joeynmt.training - Example #3
2021-11-23 07:05:08,904 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:05:08,904 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:05:08,904 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'po', 'is']
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:05:08,904 - INFO - joeynmt.training - 	Hypothesis: ▁de po is
2021-11-23 07:05:08,905 - INFO - joeynmt.training - Example #6
2021-11-23 07:05:08,905 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:05:08,905 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:05:08,905 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'leep']
2021-11-23 07:05:08,905 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:05:08,905 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:05:08,905 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:05:08,905 - INFO - joeynmt.training - 	Hypothesis: ▁s leep
2021-11-23 07:05:08,905 - INFO - joeynmt.training - Validation result (greedy) at epoch  34, step   115000: bleu:  10.32, loss: 78500.3125, ppl:  10.1543, duration: 102.7040s
2021-11-23 07:05:23,161 - INFO - joeynmt.training - Epoch  34, Step:   115100, Batch Loss:     2.207745, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 07:05:38,344 - INFO - joeynmt.training - Epoch  34, Step:   115200, Batch Loss:     2.088043, Tokens per Sec:     2086, Lr: 0.000100
2021-11-23 07:05:41,977 - INFO - joeynmt.training - Epoch  34: total training loss 7492.93
2021-11-23 07:05:41,978 - INFO - joeynmt.training - EPOCH 35
2021-11-23 07:05:52,627 - INFO - joeynmt.training - Epoch  35, Step:   115300, Batch Loss:     2.211169, Tokens per Sec:     2218, Lr: 0.000100
2021-11-23 07:06:06,999 - INFO - joeynmt.training - Epoch  35, Step:   115400, Batch Loss:     2.320904, Tokens per Sec:     2209, Lr: 0.000100
2021-11-23 07:06:21,553 - INFO - joeynmt.training - Epoch  35, Step:   115500, Batch Loss:     2.441489, Tokens per Sec:     2210, Lr: 0.000100
2021-11-23 07:06:37,075 - INFO - joeynmt.training - Epoch  35, Step:   115600, Batch Loss:     2.493564, Tokens per Sec:     2066, Lr: 0.000100
2021-11-23 07:06:51,366 - INFO - joeynmt.training - Epoch  35, Step:   115700, Batch Loss:     2.187582, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 07:07:05,889 - INFO - joeynmt.training - Epoch  35, Step:   115800, Batch Loss:     2.129373, Tokens per Sec:     2065, Lr: 0.000100
2021-11-23 07:07:20,595 - INFO - joeynmt.training - Epoch  35, Step:   115900, Batch Loss:     2.023631, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 07:07:35,746 - INFO - joeynmt.training - Epoch  35, Step:   116000, Batch Loss:     2.198735, Tokens per Sec:     2070, Lr: 0.000100
2021-11-23 07:09:37,543 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:09:37,543 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:09:37,543 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:09:37,562 - INFO - joeynmt.training - Example #0
2021-11-23 07:09:37,563 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:09:37,563 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:09:37,563 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁a', '▁time', '▁from', '▁Jud', 'e', 'a', ',', '▁you', '▁are', '▁a', 'head', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', ',', '▁but', '▁all', '▁the', '▁people', '▁are', '▁all', '▁the', '▁sh', 'are', '.']
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁a ▁time ▁from ▁Jud e a , ▁you ▁are ▁a head ▁of ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁people , ▁but ▁all ▁the ▁people ▁are ▁all ▁the ▁sh are .
2021-11-23 07:09:37,563 - INFO - joeynmt.training - Example #1
2021-11-23 07:09:37,563 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:09:37,563 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:09:37,563 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:09:37,563 - INFO - joeynmt.training - Example #2
2021-11-23 07:09:37,563 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:09:37,563 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:09:37,563 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁good', '▁and', '▁faith', 'ful', 'ness', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:09:37,563 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁good ▁and ▁faith ful ness , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 07:09:37,564 - INFO - joeynmt.training - Example #3
2021-11-23 07:09:37,564 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:09:37,564 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:09:37,564 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 07:09:37,564 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:09:37,564 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:09:37,564 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:09:37,564 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 07:09:37,564 - INFO - joeynmt.training - Example #6
2021-11-23 07:09:37,564 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:09:37,564 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:09:37,564 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 07:09:37,564 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:09:37,564 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:09:37,564 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:09:37,564 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 07:09:37,564 - INFO - joeynmt.training - Validation result (greedy) at epoch  35, step   116000: bleu:  10.57, loss: 78433.0469, ppl:  10.1342, duration: 121.8182s
2021-11-23 07:09:52,990 - INFO - joeynmt.training - Epoch  35, Step:   116100, Batch Loss:     2.031001, Tokens per Sec:     2124, Lr: 0.000100
2021-11-23 07:10:07,034 - INFO - joeynmt.training - Epoch  35, Step:   116200, Batch Loss:     2.035506, Tokens per Sec:     2198, Lr: 0.000100
2021-11-23 07:10:21,802 - INFO - joeynmt.training - Epoch  35, Step:   116300, Batch Loss:     2.101629, Tokens per Sec:     2034, Lr: 0.000100
2021-11-23 07:10:36,418 - INFO - joeynmt.training - Epoch  35, Step:   116400, Batch Loss:     2.076149, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 07:10:51,364 - INFO - joeynmt.training - Epoch  35, Step:   116500, Batch Loss:     2.102533, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 07:11:05,946 - INFO - joeynmt.training - Epoch  35, Step:   116600, Batch Loss:     2.139045, Tokens per Sec:     2095, Lr: 0.000100
2021-11-23 07:11:21,564 - INFO - joeynmt.training - Epoch  35, Step:   116700, Batch Loss:     2.304217, Tokens per Sec:     2018, Lr: 0.000100
2021-11-23 07:11:36,796 - INFO - joeynmt.training - Epoch  35, Step:   116800, Batch Loss:     2.013775, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 07:11:51,423 - INFO - joeynmt.training - Epoch  35, Step:   116900, Batch Loss:     2.015332, Tokens per Sec:     2210, Lr: 0.000100
2021-11-23 07:12:05,945 - INFO - joeynmt.training - Epoch  35, Step:   117000, Batch Loss:     2.126411, Tokens per Sec:     2170, Lr: 0.000100
2021-11-23 07:14:26,844 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:14:26,844 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:14:26,844 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:14:26,861 - INFO - joeynmt.training - Example #0
2021-11-23 07:14:26,861 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:14:26,861 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:14:26,861 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁a', '▁time', '▁from', '▁Jud', 'e', 'a', ',', '▁you', '▁are', '▁the', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁follow', 'ers', ',', '▁but', '▁all', '▁who', '▁are', '▁all', '▁who', '▁are', '▁all', 'ow', 'ing', '▁to', '▁the', '▁sh', 'ame', '.']
2021-11-23 07:14:26,861 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:14:26,861 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:14:26,861 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:14:26,861 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁a ▁time ▁from ▁Jud e a , ▁you ▁are ▁the ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁follow ers , ▁but ▁all ▁who ▁are ▁all ▁who ▁are ▁all ow ing ▁to ▁the ▁sh ame .
2021-11-23 07:14:26,861 - INFO - joeynmt.training - Example #1
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:14:26,862 - INFO - joeynmt.training - Example #2
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁may', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁may ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 07:14:26,862 - INFO - joeynmt.training - Example #3
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'cl', 'us', 'ão']
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:14:26,862 - INFO - joeynmt.training - 	Hypothesis: ▁de cl us ão
2021-11-23 07:14:26,862 - INFO - joeynmt.training - Example #6
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:14:26,862 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 07:14:26,863 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:14:26,863 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:14:26,863 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:14:26,863 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 07:14:26,863 - INFO - joeynmt.training - Validation result (greedy) at epoch  35, step   117000: bleu:  10.41, loss: 78483.9844, ppl:  10.1494, duration: 140.9174s
2021-11-23 07:14:41,206 - INFO - joeynmt.training - Epoch  35, Step:   117100, Batch Loss:     2.155785, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 07:14:55,236 - INFO - joeynmt.training - Epoch  35, Step:   117200, Batch Loss:     2.239309, Tokens per Sec:     2202, Lr: 0.000100
2021-11-23 07:15:09,622 - INFO - joeynmt.training - Epoch  35, Step:   117300, Batch Loss:     2.279950, Tokens per Sec:     2303, Lr: 0.000100
2021-11-23 07:15:23,734 - INFO - joeynmt.training - Epoch  35, Step:   117400, Batch Loss:     2.051227, Tokens per Sec:     2215, Lr: 0.000100
2021-11-23 07:15:38,362 - INFO - joeynmt.training - Epoch  35, Step:   117500, Batch Loss:     2.380473, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 07:15:53,161 - INFO - joeynmt.training - Epoch  35, Step:   117600, Batch Loss:     2.137653, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 07:16:07,641 - INFO - joeynmt.training - Epoch  35, Step:   117700, Batch Loss:     2.045007, Tokens per Sec:     2230, Lr: 0.000100
2021-11-23 07:16:22,624 - INFO - joeynmt.training - Epoch  35, Step:   117800, Batch Loss:     2.286886, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 07:16:36,990 - INFO - joeynmt.training - Epoch  35, Step:   117900, Batch Loss:     2.686237, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 07:16:51,477 - INFO - joeynmt.training - Epoch  35, Step:   118000, Batch Loss:     2.155545, Tokens per Sec:     2158, Lr: 0.000100
2021-11-23 07:19:01,003 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:19:01,003 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:19:01,003 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:19:01,015 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 07:19:01,819 - INFO - joeynmt.helpers - delete models/baseline_multilingual/114000.ckpt
2021-11-23 07:19:01,819 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/114000.ckpt
2021-11-23 07:19:01,820 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/114000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/114000.ckpt')
2021-11-23 07:19:01,880 - INFO - joeynmt.training - Example #0
2021-11-23 07:19:01,881 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:19:01,881 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:19:01,881 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Judah', ',', '▁you', '▁were', '▁c', 'ert', 'ain', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁and', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁the', '▁people', ',', '▁and', '▁all', '▁the', '▁whole', '▁whole', '▁whole', '▁whole', '▁land', '.']
2021-11-23 07:19:01,881 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:19:01,881 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:19:01,881 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:19:01,882 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Judah , ▁you ▁were ▁c ert ain ed ▁from ▁Gal ile e . ▁But ▁you ▁follow ed ▁the ▁follow ers , ▁and ▁he ▁was ▁follow ing ▁all ▁the ▁people , ▁and ▁all ▁the ▁whole ▁whole ▁whole ▁whole ▁land .
2021-11-23 07:19:01,882 - INFO - joeynmt.training - Example #1
2021-11-23 07:19:01,882 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:19:01,882 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:19:01,882 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:19:01,882 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:19:01,882 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:19:01,882 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:19:01,883 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:19:01,883 - INFO - joeynmt.training - Example #2
2021-11-23 07:19:01,883 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:19:01,883 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:19:01,883 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', 'est', ',', '▁how', '▁can', '▁I', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 07:19:01,883 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:19:01,883 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:19:01,883 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:19:01,883 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great est , ▁how ▁can ▁I ▁love ▁each ▁other , ▁and ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 07:19:01,884 - INFO - joeynmt.training - Example #3
2021-11-23 07:19:01,884 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:19:01,884 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:19:01,884 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'pe', 'nd', 'o']
2021-11-23 07:19:01,884 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:19:01,884 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:19:01,884 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:19:01,884 - INFO - joeynmt.training - 	Hypothesis: ▁de pe nd o
2021-11-23 07:19:01,884 - INFO - joeynmt.training - Example #6
2021-11-23 07:19:01,884 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:19:01,884 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:19:01,884 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 07:19:01,884 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:19:01,884 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:19:01,885 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:19:01,885 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 07:19:01,885 - INFO - joeynmt.training - Validation result (greedy) at epoch  35, step   118000: bleu:  10.85, loss: 78190.7422, ppl:  10.0619, duration: 130.4077s
2021-11-23 07:19:16,250 - INFO - joeynmt.training - Epoch  35, Step:   118100, Batch Loss:     2.009771, Tokens per Sec:     2218, Lr: 0.000100
2021-11-23 07:19:30,973 - INFO - joeynmt.training - Epoch  35, Step:   118200, Batch Loss:     2.207163, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 07:19:46,511 - INFO - joeynmt.training - Epoch  35, Step:   118300, Batch Loss:     2.093831, Tokens per Sec:     2075, Lr: 0.000100
2021-11-23 07:20:01,228 - INFO - joeynmt.training - Epoch  35, Step:   118400, Batch Loss:     1.977699, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 07:20:15,781 - INFO - joeynmt.training - Epoch  35, Step:   118500, Batch Loss:     2.166414, Tokens per Sec:     2120, Lr: 0.000100
2021-11-23 07:20:30,711 - INFO - joeynmt.training - Epoch  35, Step:   118600, Batch Loss:     2.337956, Tokens per Sec:     2063, Lr: 0.000100
2021-11-23 07:20:32,882 - INFO - joeynmt.training - Epoch  35: total training loss 7429.33
2021-11-23 07:20:32,882 - INFO - joeynmt.training - EPOCH 36
2021-11-23 07:20:45,230 - INFO - joeynmt.training - Epoch  36, Step:   118700, Batch Loss:     2.033188, Tokens per Sec:     2034, Lr: 0.000100
2021-11-23 07:20:59,964 - INFO - joeynmt.training - Epoch  36, Step:   118800, Batch Loss:     2.156731, Tokens per Sec:     2049, Lr: 0.000100
2021-11-23 07:21:14,754 - INFO - joeynmt.training - Epoch  36, Step:   118900, Batch Loss:     2.094404, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 07:21:29,862 - INFO - joeynmt.training - Epoch  36, Step:   119000, Batch Loss:     2.175300, Tokens per Sec:     2095, Lr: 0.000100
2021-11-23 07:23:49,510 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:23:49,510 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:23:49,511 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:23:49,527 - INFO - joeynmt.training - Example #0
2021-11-23 07:23:49,527 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:23:49,527 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:23:49,527 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁time', ',', '▁you', '▁were', '▁f', 'ree', '▁from', '▁Gal', 'ile', 'e', '.', '▁He', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁the', '▁people', '▁and', '▁all', '▁the', '▁whole', '▁whole', '▁land', '.']
2021-11-23 07:23:49,527 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:23:49,527 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁time , ▁you ▁were ▁f ree ▁from ▁Gal ile e . ▁He ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁was ▁follow ing ▁all ▁the ▁people ▁and ▁all ▁the ▁whole ▁whole ▁land .
2021-11-23 07:23:49,528 - INFO - joeynmt.training - Example #1
2021-11-23 07:23:49,528 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:23:49,528 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:23:49,528 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:23:49,528 - INFO - joeynmt.training - Example #2
2021-11-23 07:23:49,528 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:23:49,528 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:23:49,528 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 07:23:49,528 - INFO - joeynmt.training - Example #3
2021-11-23 07:23:49,528 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:23:49,528 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:23:49,528 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁con', 'st', 'ru', 'ir']
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:23:49,528 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:23:49,529 - INFO - joeynmt.training - 	Hypothesis: ▁con st ru ir
2021-11-23 07:23:49,529 - INFO - joeynmt.training - Example #6
2021-11-23 07:23:49,529 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:23:49,529 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:23:49,529 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 07:23:49,529 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:23:49,529 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:23:49,529 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:23:49,529 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 07:23:49,529 - INFO - joeynmt.training - Validation result (greedy) at epoch  36, step   119000: bleu:  10.62, loss: 78020.7656, ppl:  10.0116, duration: 139.6662s
2021-11-23 07:24:04,460 - INFO - joeynmt.training - Epoch  36, Step:   119100, Batch Loss:     2.379568, Tokens per Sec:     2067, Lr: 0.000100
2021-11-23 07:24:20,350 - INFO - joeynmt.training - Epoch  36, Step:   119200, Batch Loss:     2.284178, Tokens per Sec:     2090, Lr: 0.000100
2021-11-23 07:24:34,643 - INFO - joeynmt.training - Epoch  36, Step:   119300, Batch Loss:     2.045828, Tokens per Sec:     2111, Lr: 0.000100
2021-11-23 07:24:49,315 - INFO - joeynmt.training - Epoch  36, Step:   119400, Batch Loss:     2.131568, Tokens per Sec:     2211, Lr: 0.000100
2021-11-23 07:25:04,110 - INFO - joeynmt.training - Epoch  36, Step:   119500, Batch Loss:     1.913785, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 07:25:18,311 - INFO - joeynmt.training - Epoch  36, Step:   119600, Batch Loss:     1.911740, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 07:25:33,037 - INFO - joeynmt.training - Epoch  36, Step:   119700, Batch Loss:     2.070194, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 07:25:47,383 - INFO - joeynmt.training - Epoch  36, Step:   119800, Batch Loss:     2.029050, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 07:26:02,322 - INFO - joeynmt.training - Epoch  36, Step:   119900, Batch Loss:     1.938975, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 07:26:17,316 - INFO - joeynmt.training - Epoch  36, Step:   120000, Batch Loss:     2.247720, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 07:28:19,164 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:28:19,164 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:28:19,164 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:28:19,182 - INFO - joeynmt.training - Example #0
2021-11-23 07:28:19,182 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:28:19,182 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:28:19,182 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁a', '▁time', '▁from', '▁Jud', 'e', 'a', ',', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', ',', '▁and', '▁all', '▁who', '▁are', '▁all', '▁the', '▁st', 'ood', '.']
2021-11-23 07:28:19,182 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:28:19,182 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:28:19,182 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:28:19,182 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁a ▁time ▁from ▁Jud e a , ▁you ▁are ▁follow ing ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁are ▁follow ing , ▁and ▁all ▁who ▁are ▁all ▁the ▁st ood .
2021-11-23 07:28:19,182 - INFO - joeynmt.training - Example #1
2021-11-23 07:28:19,182 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:28:19,182 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:28:19,182 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:28:19,182 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:28:19,182 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:28:19,182 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:28:19,182 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:28:19,183 - INFO - joeynmt.training - Example #2
2021-11-23 07:28:19,183 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:28:19,183 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:28:19,183 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 07:28:19,183 - INFO - joeynmt.training - Example #3
2021-11-23 07:28:19,183 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:28:19,183 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:28:19,183 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁des', 'en', 'v', 'ol', 'ver']
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Hypothesis: ▁des en v ol ver
2021-11-23 07:28:19,183 - INFO - joeynmt.training - Example #6
2021-11-23 07:28:19,183 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:28:19,183 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:28:19,183 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ave']
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:28:19,183 - INFO - joeynmt.training - 	Hypothesis: ▁s ave
2021-11-23 07:28:19,184 - INFO - joeynmt.training - Validation result (greedy) at epoch  36, step   120000: bleu:  10.52, loss: 78330.0156, ppl:  10.1034, duration: 121.8666s
2021-11-23 07:28:34,369 - INFO - joeynmt.training - Epoch  36, Step:   120100, Batch Loss:     2.229719, Tokens per Sec:     2032, Lr: 0.000100
2021-11-23 07:28:49,185 - INFO - joeynmt.training - Epoch  36, Step:   120200, Batch Loss:     2.245245, Tokens per Sec:     2063, Lr: 0.000100
2021-11-23 07:29:03,415 - INFO - joeynmt.training - Epoch  36, Step:   120300, Batch Loss:     2.176883, Tokens per Sec:     2294, Lr: 0.000100
2021-11-23 07:29:18,777 - INFO - joeynmt.training - Epoch  36, Step:   120400, Batch Loss:     1.999631, Tokens per Sec:     2065, Lr: 0.000100
2021-11-23 07:29:33,232 - INFO - joeynmt.training - Epoch  36, Step:   120500, Batch Loss:     2.119922, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 07:29:48,519 - INFO - joeynmt.training - Epoch  36, Step:   120600, Batch Loss:     1.952129, Tokens per Sec:     2104, Lr: 0.000100
2021-11-23 07:30:03,457 - INFO - joeynmt.training - Epoch  36, Step:   120700, Batch Loss:     2.179574, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 07:30:18,165 - INFO - joeynmt.training - Epoch  36, Step:   120800, Batch Loss:     2.229629, Tokens per Sec:     2094, Lr: 0.000100
2021-11-23 07:30:32,135 - INFO - joeynmt.training - Epoch  36, Step:   120900, Batch Loss:     2.068849, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 07:30:47,114 - INFO - joeynmt.training - Epoch  36, Step:   121000, Batch Loss:     2.071037, Tokens per Sec:     2071, Lr: 0.000100
2021-11-23 07:32:44,816 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:32:44,816 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:32:44,816 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:32:44,834 - INFO - joeynmt.training - Example #0
2021-11-23 07:32:44,834 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:32:44,834 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:32:44,834 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'op', 'h', 'ile', '▁you', ',', '▁you', '▁have', '▁been', '▁a', '▁time', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁follow', 'ing', '▁all', '▁the', '▁people', '▁of', '▁all', '▁the', '▁sh', 'ip', '.']
2021-11-23 07:32:44,834 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:32:44,834 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:32:44,834 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:32:44,834 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t op h ile ▁you , ▁you ▁have ▁been ▁a ▁time ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁follow ing ▁all ▁the ▁people ▁of ▁all ▁the ▁sh ip .
2021-11-23 07:32:44,834 - INFO - joeynmt.training - Example #1
2021-11-23 07:32:44,834 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:32:44,834 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:32:44,834 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:32:44,834 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:32:44,834 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:32:44,834 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:32:44,834 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:32:44,834 - INFO - joeynmt.training - Example #2
2021-11-23 07:32:44,834 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:32:44,834 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:32:44,834 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', ',', '▁one', '▁another', '▁is', '▁one', '▁another', '.']
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other , ▁one ▁another ▁is ▁one ▁another .
2021-11-23 07:32:44,835 - INFO - joeynmt.training - Example #3
2021-11-23 07:32:44,835 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:32:44,835 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:32:44,835 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'pe', 'nd', 'ência']
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Hypothesis: ▁de pe nd ência
2021-11-23 07:32:44,835 - INFO - joeynmt.training - Example #6
2021-11-23 07:32:44,835 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:32:44,835 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:32:44,835 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'um', 'mer']
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:32:44,835 - INFO - joeynmt.training - 	Hypothesis: ▁s um mer
2021-11-23 07:32:44,835 - INFO - joeynmt.training - Validation result (greedy) at epoch  36, step   121000: bleu:  10.42, loss: 78100.6328, ppl:  10.0352, duration: 117.7208s
2021-11-23 07:32:59,726 - INFO - joeynmt.training - Epoch  36, Step:   121100, Batch Loss:     2.197133, Tokens per Sec:     2062, Lr: 0.000100
2021-11-23 07:33:14,534 - INFO - joeynmt.training - Epoch  36, Step:   121200, Batch Loss:     1.971622, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 07:33:29,314 - INFO - joeynmt.training - Epoch  36, Step:   121300, Batch Loss:     1.922883, Tokens per Sec:     2046, Lr: 0.000100
2021-11-23 07:33:43,481 - INFO - joeynmt.training - Epoch  36, Step:   121400, Batch Loss:     2.331313, Tokens per Sec:     2248, Lr: 0.000100
2021-11-23 07:33:57,833 - INFO - joeynmt.training - Epoch  36, Step:   121500, Batch Loss:     1.919440, Tokens per Sec:     2210, Lr: 0.000100
2021-11-23 07:34:13,563 - INFO - joeynmt.training - Epoch  36, Step:   121600, Batch Loss:     2.472042, Tokens per Sec:     2041, Lr: 0.000100
2021-11-23 07:34:28,481 - INFO - joeynmt.training - Epoch  36, Step:   121700, Batch Loss:     2.177952, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 07:34:43,195 - INFO - joeynmt.training - Epoch  36, Step:   121800, Batch Loss:     1.942214, Tokens per Sec:     2065, Lr: 0.000100
2021-11-23 07:34:58,336 - INFO - joeynmt.training - Epoch  36, Step:   121900, Batch Loss:     1.917115, Tokens per Sec:     2128, Lr: 0.000100
2021-11-23 07:35:13,161 - INFO - joeynmt.training - Epoch  36, Step:   122000, Batch Loss:     2.364197, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 07:37:19,117 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:37:19,117 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:37:19,117 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:37:19,130 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 07:37:19,939 - INFO - joeynmt.helpers - delete models/baseline_multilingual/118000.ckpt
2021-11-23 07:37:19,940 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/118000.ckpt
2021-11-23 07:37:19,940 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/118000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/118000.ckpt')
2021-11-23 07:37:19,993 - INFO - joeynmt.training - Example #0
2021-11-23 07:37:19,994 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:37:19,994 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:37:19,994 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Jud', 'e', 'a', ',', '▁you', '▁were', '▁c', 'ert', 'ain', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁when', '▁you', '▁were', '▁follow', 'ing', '▁the', '▁people', ',', '▁all', '▁the', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁sh', 'ame', '.']
2021-11-23 07:37:19,994 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:37:19,994 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:37:19,994 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:37:19,994 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Jud e a , ▁you ▁were ▁c ert ain ed ▁from ▁Gal ile e . ▁But ▁when ▁you ▁were ▁follow ing ▁the ▁people , ▁all ▁the ▁follow ers ▁are ▁all ▁the ▁sh ame .
2021-11-23 07:37:19,995 - INFO - joeynmt.training - Example #1
2021-11-23 07:37:19,995 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:37:19,995 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:37:19,995 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:37:19,995 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:37:19,995 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:37:19,995 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:37:19,995 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:37:19,996 - INFO - joeynmt.training - Example #2
2021-11-23 07:37:19,996 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:37:19,996 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:37:19,996 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', 'er', '▁than', 'k', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 07:37:19,996 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:37:19,996 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:37:19,996 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:37:19,996 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great er ▁than k , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 07:37:19,997 - INFO - joeynmt.training - Example #3
2021-11-23 07:37:19,997 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:37:19,997 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:37:19,997 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁con', 'st', 'ru', 'ir']
2021-11-23 07:37:19,997 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:37:19,997 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:37:19,997 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:37:19,997 - INFO - joeynmt.training - 	Hypothesis: ▁con st ru ir
2021-11-23 07:37:19,997 - INFO - joeynmt.training - Example #6
2021-11-23 07:37:19,997 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:37:19,997 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:37:19,997 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 07:37:19,997 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:37:19,997 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:37:19,998 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:37:19,998 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 07:37:19,998 - INFO - joeynmt.training - Validation result (greedy) at epoch  36, step   122000: bleu:  10.99, loss: 77573.8984, ppl:   9.8803, duration: 126.8360s
2021-11-23 07:37:20,564 - INFO - joeynmt.training - Epoch  36: total training loss 7373.09
2021-11-23 07:37:20,565 - INFO - joeynmt.training - EPOCH 37
2021-11-23 07:37:35,108 - INFO - joeynmt.training - Epoch  37, Step:   122100, Batch Loss:     2.272179, Tokens per Sec:     2077, Lr: 0.000100
2021-11-23 07:37:50,296 - INFO - joeynmt.training - Epoch  37, Step:   122200, Batch Loss:     2.267767, Tokens per Sec:     2097, Lr: 0.000100
2021-11-23 07:38:05,471 - INFO - joeynmt.training - Epoch  37, Step:   122300, Batch Loss:     2.180974, Tokens per Sec:     2074, Lr: 0.000100
2021-11-23 07:38:20,264 - INFO - joeynmt.training - Epoch  37, Step:   122400, Batch Loss:     2.052266, Tokens per Sec:     2212, Lr: 0.000100
2021-11-23 07:38:35,612 - INFO - joeynmt.training - Epoch  37, Step:   122500, Batch Loss:     2.208884, Tokens per Sec:     2093, Lr: 0.000100
2021-11-23 07:38:50,486 - INFO - joeynmt.training - Epoch  37, Step:   122600, Batch Loss:     2.233307, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 07:39:04,908 - INFO - joeynmt.training - Epoch  37, Step:   122700, Batch Loss:     2.128491, Tokens per Sec:     2268, Lr: 0.000100
2021-11-23 07:39:19,786 - INFO - joeynmt.training - Epoch  37, Step:   122800, Batch Loss:     2.448930, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 07:39:34,815 - INFO - joeynmt.training - Epoch  37, Step:   122900, Batch Loss:     2.072822, Tokens per Sec:     2094, Lr: 0.000100
2021-11-23 07:39:49,606 - INFO - joeynmt.training - Epoch  37, Step:   123000, Batch Loss:     2.119257, Tokens per Sec:     2047, Lr: 0.000100
2021-11-23 07:41:50,999 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:41:50,999 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:41:50,999 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:41:51,017 - INFO - joeynmt.training - Example #0
2021-11-23 07:41:51,017 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:41:51,017 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:41:51,017 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁have', '▁been', '▁f', 'av', 'or', '▁of', '▁the', '▁time', '▁of', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁the', '▁people', ',', '▁and', '▁all', '▁the', '▁wall', 's', '▁were', '▁all', '▁the', '▁sh', 'ip', '.']
2021-11-23 07:41:51,017 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:41:51,017 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁have ▁been ▁f av or ▁of ▁the ▁time ▁of ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁he ▁was ▁follow ing ▁all ▁the ▁people , ▁and ▁all ▁the ▁wall s ▁were ▁all ▁the ▁sh ip .
2021-11-23 07:41:51,018 - INFO - joeynmt.training - Example #1
2021-11-23 07:41:51,018 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:41:51,018 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:41:51,018 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:41:51,018 - INFO - joeynmt.training - Example #2
2021-11-23 07:41:51,018 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:41:51,018 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:41:51,018 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 07:41:51,018 - INFO - joeynmt.training - Example #3
2021-11-23 07:41:51,018 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:41:51,018 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:41:51,018 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'p', 'res', 'ent', 'ação']
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:41:51,018 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:41:51,019 - INFO - joeynmt.training - 	Hypothesis: ▁de p res ent ação
2021-11-23 07:41:51,019 - INFO - joeynmt.training - Example #6
2021-11-23 07:41:51,019 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:41:51,019 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:41:51,019 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'and', 'als']
2021-11-23 07:41:51,019 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:41:51,019 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:41:51,019 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:41:51,019 - INFO - joeynmt.training - 	Hypothesis: ▁s and als
2021-11-23 07:41:51,019 - INFO - joeynmt.training - Validation result (greedy) at epoch  37, step   123000: bleu:  10.76, loss: 77851.5625, ppl:   9.9617, duration: 121.4129s
2021-11-23 07:42:05,994 - INFO - joeynmt.training - Epoch  37, Step:   123100, Batch Loss:     2.007480, Tokens per Sec:     2081, Lr: 0.000100
2021-11-23 07:42:20,534 - INFO - joeynmt.training - Epoch  37, Step:   123200, Batch Loss:     2.082954, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 07:42:35,063 - INFO - joeynmt.training - Epoch  37, Step:   123300, Batch Loss:     2.294492, Tokens per Sec:     2188, Lr: 0.000100
2021-11-23 07:42:50,557 - INFO - joeynmt.training - Epoch  37, Step:   123400, Batch Loss:     2.168578, Tokens per Sec:     1989, Lr: 0.000100
2021-11-23 07:43:04,811 - INFO - joeynmt.training - Epoch  37, Step:   123500, Batch Loss:     2.018671, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 07:43:18,816 - INFO - joeynmt.training - Epoch  37, Step:   123600, Batch Loss:     2.290420, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 07:43:33,515 - INFO - joeynmt.training - Epoch  37, Step:   123700, Batch Loss:     2.201469, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 07:43:48,411 - INFO - joeynmt.training - Epoch  37, Step:   123800, Batch Loss:     2.321334, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 07:44:03,206 - INFO - joeynmt.training - Epoch  37, Step:   123900, Batch Loss:     2.019752, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 07:44:17,573 - INFO - joeynmt.training - Epoch  37, Step:   124000, Batch Loss:     2.209203, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 07:46:21,592 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:46:21,592 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:46:21,592 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:46:21,613 - INFO - joeynmt.training - Example #0
2021-11-23 07:46:21,613 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:46:21,613 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:46:21,613 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'op', 'ed', '▁you', ',', '▁a', '▁time', '▁of', '▁J', 'ul', 'us', ',', '▁and', '▁you', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁when', '▁you', '▁are', '▁follow', 'ing', '▁all', '▁the', '▁people', ',', '▁all', '▁the', '▁whole', '▁land', '.']
2021-11-23 07:46:21,613 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:46:21,613 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:46:21,613 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:46:21,613 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t op ed ▁you , ▁a ▁time ▁of ▁J ul us , ▁and ▁you ▁follow ed ▁the ▁people ▁of ▁Gal ile e . ▁But ▁when ▁you ▁are ▁follow ing ▁all ▁the ▁people , ▁all ▁the ▁whole ▁land .
2021-11-23 07:46:21,613 - INFO - joeynmt.training - Example #1
2021-11-23 07:46:21,613 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:46:21,613 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:46:21,613 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:46:21,613 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:46:21,613 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:46:21,613 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:46:21,613 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:46:21,613 - INFO - joeynmt.training - Example #2
2021-11-23 07:46:21,614 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:46:21,614 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:46:21,614 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', 'er', '▁than', 'ks', ',', '▁how', '▁much', '▁to', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁one', '▁another', '.']
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great er ▁than ks , ▁how ▁much ▁to ▁each ▁other , ▁love ▁each ▁other , ▁one ▁another .
2021-11-23 07:46:21,614 - INFO - joeynmt.training - Example #3
2021-11-23 07:46:21,614 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:46:21,614 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:46:21,614 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'fe', 'ito']
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Hypothesis: ▁de fe ito
2021-11-23 07:46:21,614 - INFO - joeynmt.training - Example #6
2021-11-23 07:46:21,614 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:46:21,614 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:46:21,614 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:46:21,614 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 07:46:21,614 - INFO - joeynmt.training - Validation result (greedy) at epoch  37, step   124000: bleu:  10.90, loss: 77769.8828, ppl:   9.9377, duration: 124.0413s
2021-11-23 07:46:36,028 - INFO - joeynmt.training - Epoch  37, Step:   124100, Batch Loss:     2.508108, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 07:46:51,474 - INFO - joeynmt.training - Epoch  37, Step:   124200, Batch Loss:     2.050792, Tokens per Sec:     2005, Lr: 0.000100
2021-11-23 07:47:06,538 - INFO - joeynmt.training - Epoch  37, Step:   124300, Batch Loss:     2.085013, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 07:47:21,239 - INFO - joeynmt.training - Epoch  37, Step:   124400, Batch Loss:     2.150334, Tokens per Sec:     2175, Lr: 0.000100
2021-11-23 07:47:35,894 - INFO - joeynmt.training - Epoch  37, Step:   124500, Batch Loss:     2.219538, Tokens per Sec:     2133, Lr: 0.000100
2021-11-23 07:47:49,856 - INFO - joeynmt.training - Epoch  37, Step:   124600, Batch Loss:     2.036244, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 07:48:04,978 - INFO - joeynmt.training - Epoch  37, Step:   124700, Batch Loss:     2.072669, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 07:48:20,344 - INFO - joeynmt.training - Epoch  37, Step:   124800, Batch Loss:     2.320684, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 07:48:34,829 - INFO - joeynmt.training - Epoch  37, Step:   124900, Batch Loss:     2.045370, Tokens per Sec:     2180, Lr: 0.000100
2021-11-23 07:48:49,916 - INFO - joeynmt.training - Epoch  37, Step:   125000, Batch Loss:     2.135210, Tokens per Sec:     2073, Lr: 0.000100
2021-11-23 07:51:09,239 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:51:09,239 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:51:09,239 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:51:09,252 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 07:51:10,053 - INFO - joeynmt.helpers - delete models/baseline_multilingual/122000.ckpt
2021-11-23 07:51:10,053 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/122000.ckpt
2021-11-23 07:51:10,053 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/122000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/122000.ckpt')
2021-11-23 07:51:10,096 - INFO - joeynmt.training - Example #0
2021-11-23 07:51:10,096 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:51:10,096 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:51:10,096 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'op', 'ed', '▁you', ',', '▁and', '▁you', '▁were', '▁f', 'at', 'che', 'd', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁are', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁follow', 'ing', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 07:51:10,096 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:51:10,096 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:51:10,097 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:51:10,097 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t op ed ▁you , ▁and ▁you ▁were ▁f at che d ▁from ▁Jud e a . ▁You ▁are ▁follow ing ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁follow ing ▁all ▁the ▁wall s .
2021-11-23 07:51:10,097 - INFO - joeynmt.training - Example #1
2021-11-23 07:51:10,097 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:51:10,097 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:51:10,097 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:51:10,097 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:51:10,097 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:51:10,097 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:51:10,097 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:51:10,097 - INFO - joeynmt.training - Example #2
2021-11-23 07:51:10,098 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:51:10,098 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:51:10,098 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', 'er', '▁than', 'k', ',', '▁how', '▁much', '▁to', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 07:51:10,098 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:51:10,098 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:51:10,098 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:51:10,098 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great er ▁than k , ▁how ▁much ▁to ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 07:51:10,098 - INFO - joeynmt.training - Example #3
2021-11-23 07:51:10,098 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:51:10,098 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:51:10,098 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'fe', 'ito']
2021-11-23 07:51:10,098 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:51:10,099 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:51:10,099 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:51:10,099 - INFO - joeynmt.training - 	Hypothesis: ▁de fe ito
2021-11-23 07:51:10,099 - INFO - joeynmt.training - Example #6
2021-11-23 07:51:10,099 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:51:10,099 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:51:10,099 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 07:51:10,099 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:51:10,099 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:51:10,099 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:51:10,099 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 07:51:10,100 - INFO - joeynmt.training - Validation result (greedy) at epoch  37, step   125000: bleu:  11.13, loss: 77537.4531, ppl:   9.8697, duration: 140.1827s
2021-11-23 07:51:25,382 - INFO - joeynmt.training - Epoch  37, Step:   125100, Batch Loss:     2.348484, Tokens per Sec:     2021, Lr: 0.000100
2021-11-23 07:51:39,915 - INFO - joeynmt.training - Epoch  37, Step:   125200, Batch Loss:     1.975959, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 07:51:54,799 - INFO - joeynmt.training - Epoch  37, Step:   125300, Batch Loss:     2.220429, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 07:52:08,918 - INFO - joeynmt.training - Epoch  37: total training loss 7325.70
2021-11-23 07:52:08,918 - INFO - joeynmt.training - EPOCH 38
2021-11-23 07:52:10,109 - INFO - joeynmt.training - Epoch  38, Step:   125400, Batch Loss:     2.038559, Tokens per Sec:     1679, Lr: 0.000100
2021-11-23 07:52:24,710 - INFO - joeynmt.training - Epoch  38, Step:   125500, Batch Loss:     2.147956, Tokens per Sec:     2198, Lr: 0.000100
2021-11-23 07:52:40,491 - INFO - joeynmt.training - Epoch  38, Step:   125600, Batch Loss:     2.053313, Tokens per Sec:     2080, Lr: 0.000100
2021-11-23 07:52:55,207 - INFO - joeynmt.training - Epoch  38, Step:   125700, Batch Loss:     2.380267, Tokens per Sec:     2126, Lr: 0.000100
2021-11-23 07:53:09,960 - INFO - joeynmt.training - Epoch  38, Step:   125800, Batch Loss:     2.086668, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 07:53:24,603 - INFO - joeynmt.training - Epoch  38, Step:   125900, Batch Loss:     1.933662, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 07:53:39,361 - INFO - joeynmt.training - Epoch  38, Step:   126000, Batch Loss:     2.252949, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 07:56:04,188 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 07:56:04,189 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 07:56:04,189 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 07:56:04,207 - INFO - joeynmt.training - Example #0
2021-11-23 07:56:04,207 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 07:56:04,207 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 07:56:04,207 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁there', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁of', '▁Jud', 'e', 'a', ',', '▁you', '▁were', '▁with', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', ',', '▁but', '▁all', '▁who', '▁are', '▁follow', 'ing', '▁their', '▁follow', 'ers', '.']
2021-11-23 07:56:04,207 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 07:56:04,207 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 07:56:04,207 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 07:56:04,207 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁there , ▁you ▁were ▁f av or ▁of ▁Jud e a , ▁you ▁were ▁with ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁people , ▁but ▁all ▁who ▁are ▁follow ing ▁their ▁follow ers .
2021-11-23 07:56:04,207 - INFO - joeynmt.training - Example #1
2021-11-23 07:56:04,207 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 07:56:04,207 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 07:56:04,207 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 07:56:04,207 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 07:56:04,207 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 07:56:04,207 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 07:56:04,207 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 07:56:04,207 - INFO - joeynmt.training - Example #2
2021-11-23 07:56:04,207 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 07:56:04,207 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 07:56:04,207 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁my', '▁faith', 'ful', 'ness', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁each', '▁other', ',', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 07:56:04,207 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁my ▁faith ful ness , ▁how ▁can ▁love ▁each ▁other , ▁each ▁other , ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 07:56:04,208 - INFO - joeynmt.training - Example #3
2021-11-23 07:56:04,208 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 07:56:04,208 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 07:56:04,208 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'po', 'is']
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Hypothesis: ▁de po is
2021-11-23 07:56:04,208 - INFO - joeynmt.training - Example #6
2021-11-23 07:56:04,208 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 07:56:04,208 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 07:56:04,208 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 07:56:04,208 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 07:56:04,208 - INFO - joeynmt.training - Validation result (greedy) at epoch  38, step   126000: bleu:  10.96, loss: 77647.8047, ppl:   9.9019, duration: 144.8467s
2021-11-23 07:56:18,819 - INFO - joeynmt.training - Epoch  38, Step:   126100, Batch Loss:     2.242846, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 07:56:33,395 - INFO - joeynmt.training - Epoch  38, Step:   126200, Batch Loss:     2.242963, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 07:56:48,028 - INFO - joeynmt.training - Epoch  38, Step:   126300, Batch Loss:     1.985597, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 07:57:02,106 - INFO - joeynmt.training - Epoch  38, Step:   126400, Batch Loss:     2.164756, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 07:57:17,289 - INFO - joeynmt.training - Epoch  38, Step:   126500, Batch Loss:     1.992183, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 07:57:32,774 - INFO - joeynmt.training - Epoch  38, Step:   126600, Batch Loss:     2.076431, Tokens per Sec:     2020, Lr: 0.000100
2021-11-23 07:57:47,363 - INFO - joeynmt.training - Epoch  38, Step:   126700, Batch Loss:     2.016069, Tokens per Sec:     2098, Lr: 0.000100
2021-11-23 07:58:02,427 - INFO - joeynmt.training - Epoch  38, Step:   126800, Batch Loss:     2.195793, Tokens per Sec:     2043, Lr: 0.000100
2021-11-23 07:58:17,127 - INFO - joeynmt.training - Epoch  38, Step:   126900, Batch Loss:     1.884537, Tokens per Sec:     2157, Lr: 0.000100
2021-11-23 07:58:31,988 - INFO - joeynmt.training - Epoch  38, Step:   127000, Batch Loss:     2.200205, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 08:00:46,666 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:00:46,666 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:00:46,666 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:00:46,679 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 08:00:47,492 - INFO - joeynmt.helpers - delete models/baseline_multilingual/125000.ckpt
2021-11-23 08:00:47,492 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/125000.ckpt
2021-11-23 08:00:47,492 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/125000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/125000.ckpt')
2021-11-23 08:00:47,538 - INFO - joeynmt.training - Example #0
2021-11-23 08:00:47,538 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:00:47,538 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:00:47,538 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁have', '▁been', '▁f', 'av', 'or', '▁of', '▁Judah', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁follow', 'ing', '▁all', '▁the', '▁follow', 'ers', ',', '▁but', '▁all', '▁the', '▁whole', '▁leaders', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 08:00:47,538 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:00:47,539 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:00:47,539 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:00:47,539 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁have ▁been ▁f av or ▁of ▁Judah . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁follow ing ▁all ▁the ▁follow ers , ▁but ▁all ▁the ▁whole ▁leaders ▁are ▁all ow ed .
2021-11-23 08:00:47,539 - INFO - joeynmt.training - Example #1
2021-11-23 08:00:47,539 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:00:47,539 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:00:47,539 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 08:00:47,539 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:00:47,540 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:00:47,540 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:00:47,540 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 08:00:47,540 - INFO - joeynmt.training - Example #2
2021-11-23 08:00:47,540 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:00:47,540 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:00:47,540 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁a', '▁good', '▁thing', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 08:00:47,540 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:00:47,541 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:00:47,541 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:00:47,541 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁a ▁good ▁thing , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 08:00:47,541 - INFO - joeynmt.training - Example #3
2021-11-23 08:00:47,541 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:00:47,541 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:00:47,541 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁con', 'st', 'ru', 'ir']
2021-11-23 08:00:47,541 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:00:47,542 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:00:47,542 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:00:47,542 - INFO - joeynmt.training - 	Hypothesis: ▁con st ru ir
2021-11-23 08:00:47,542 - INFO - joeynmt.training - Example #6
2021-11-23 08:00:47,542 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:00:47,542 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:00:47,542 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 08:00:47,542 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:00:47,542 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:00:47,543 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:00:47,543 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 08:00:47,543 - INFO - joeynmt.training - Validation result (greedy) at epoch  38, step   127000: bleu:  11.14, loss: 77419.3203, ppl:   9.8353, duration: 135.5547s
2021-11-23 08:01:02,965 - INFO - joeynmt.training - Epoch  38, Step:   127100, Batch Loss:     2.024993, Tokens per Sec:     2094, Lr: 0.000100
2021-11-23 08:01:17,506 - INFO - joeynmt.training - Epoch  38, Step:   127200, Batch Loss:     2.144005, Tokens per Sec:     2045, Lr: 0.000100
2021-11-23 08:01:32,169 - INFO - joeynmt.training - Epoch  38, Step:   127300, Batch Loss:     2.288251, Tokens per Sec:     2186, Lr: 0.000100
2021-11-23 08:01:47,163 - INFO - joeynmt.training - Epoch  38, Step:   127400, Batch Loss:     1.826559, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 08:02:02,047 - INFO - joeynmt.training - Epoch  38, Step:   127500, Batch Loss:     1.794338, Tokens per Sec:     2101, Lr: 0.000100
2021-11-23 08:02:16,428 - INFO - joeynmt.training - Epoch  38, Step:   127600, Batch Loss:     2.048014, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 08:02:30,594 - INFO - joeynmt.training - Epoch  38, Step:   127700, Batch Loss:     2.220321, Tokens per Sec:     2221, Lr: 0.000100
2021-11-23 08:02:45,376 - INFO - joeynmt.training - Epoch  38, Step:   127800, Batch Loss:     2.106380, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 08:03:00,245 - INFO - joeynmt.training - Epoch  38, Step:   127900, Batch Loss:     2.231457, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 08:03:15,885 - INFO - joeynmt.training - Epoch  38, Step:   128000, Batch Loss:     2.189860, Tokens per Sec:     2101, Lr: 0.000100
2021-11-23 08:05:31,195 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:05:31,196 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:05:31,196 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:05:31,214 - INFO - joeynmt.training - Example #0
2021-11-23 08:05:31,214 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:05:31,215 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:05:31,215 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁af', 'raid', '▁of', '▁Jud', 'e', 'a', ',', '▁you', '▁are', '▁going', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁are', '▁follow', 'ing', '▁the', '▁follow', 'ers', ',', '▁but', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁whole', '▁leaders', '.']
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁af raid ▁of ▁Jud e a , ▁you ▁are ▁going ▁from ▁Gal ile e . ▁You ▁are ▁follow ing ▁the ▁follow ers , ▁but ▁all ▁your ▁follow ers ▁are ▁all ▁the ▁whole ▁leaders .
2021-11-23 08:05:31,215 - INFO - joeynmt.training - Example #1
2021-11-23 08:05:31,215 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:05:31,215 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:05:31,215 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'u', 'il', 'her', 'me']
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Hypothesis: ▁G u il her me
2021-11-23 08:05:31,215 - INFO - joeynmt.training - Example #2
2021-11-23 08:05:31,215 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:05:31,215 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:05:31,215 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁a', '▁great', 'er', '▁than', '▁each', '▁other', ',', '▁how', '▁love', '▁each', '▁other', ',', '▁always', '▁have', '▁one', '▁another', '.']
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:05:31,215 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁a ▁great er ▁than ▁each ▁other , ▁how ▁love ▁each ▁other , ▁always ▁have ▁one ▁another .
2021-11-23 08:05:31,216 - INFO - joeynmt.training - Example #3
2021-11-23 08:05:31,216 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:05:31,216 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:05:31,216 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:05:31,216 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:05:31,216 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:05:31,216 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:05:31,216 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:05:31,216 - INFO - joeynmt.training - Example #6
2021-11-23 08:05:31,216 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:05:31,216 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:05:31,216 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 08:05:31,216 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:05:31,216 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:05:31,216 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:05:31,216 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 08:05:31,216 - INFO - joeynmt.training - Validation result (greedy) at epoch  38, step   128000: bleu:  10.94, loss: 77289.7344, ppl:   9.7978, duration: 135.3307s
2021-11-23 08:05:46,096 - INFO - joeynmt.training - Epoch  38, Step:   128100, Batch Loss:     2.129278, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 08:06:00,381 - INFO - joeynmt.training - Epoch  38, Step:   128200, Batch Loss:     2.117149, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 08:06:15,029 - INFO - joeynmt.training - Epoch  38, Step:   128300, Batch Loss:     2.241998, Tokens per Sec:     2185, Lr: 0.000100
2021-11-23 08:06:29,490 - INFO - joeynmt.training - Epoch  38, Step:   128400, Batch Loss:     2.308851, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 08:06:44,796 - INFO - joeynmt.training - Epoch  38, Step:   128500, Batch Loss:     2.265412, Tokens per Sec:     2085, Lr: 0.000100
2021-11-23 08:06:59,204 - INFO - joeynmt.training - Epoch  38, Step:   128600, Batch Loss:     2.086817, Tokens per Sec:     2185, Lr: 0.000100
2021-11-23 08:07:13,541 - INFO - joeynmt.training - Epoch  38, Step:   128700, Batch Loss:     2.137834, Tokens per Sec:     2244, Lr: 0.000100
2021-11-23 08:07:25,242 - INFO - joeynmt.training - Epoch  38: total training loss 7266.56
2021-11-23 08:07:25,242 - INFO - joeynmt.training - EPOCH 39
2021-11-23 08:07:27,918 - INFO - joeynmt.training - Epoch  39, Step:   128800, Batch Loss:     2.060704, Tokens per Sec:     1940, Lr: 0.000100
2021-11-23 08:07:42,033 - INFO - joeynmt.training - Epoch  39, Step:   128900, Batch Loss:     2.284694, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 08:07:55,936 - INFO - joeynmt.training - Epoch  39, Step:   129000, Batch Loss:     1.921289, Tokens per Sec:     2258, Lr: 0.000100
2021-11-23 08:09:47,197 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:09:47,197 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:09:47,197 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:09:47,216 - INFO - joeynmt.training - Example #0
2021-11-23 08:09:47,217 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:09:47,217 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:09:47,217 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁the', '▁time', '▁of', '▁Judah', ',', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁follow', 'ers', ',', '▁and', '▁all', '▁the', '▁people', '▁are', '▁all', '▁the', '▁sh', 'ame', '.']
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁the ▁time ▁of ▁Judah , ▁you ▁are ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁follow ers , ▁and ▁all ▁the ▁people ▁are ▁all ▁the ▁sh ame .
2021-11-23 08:09:47,217 - INFO - joeynmt.training - Example #1
2021-11-23 08:09:47,217 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:09:47,217 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:09:47,217 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 08:09:47,217 - INFO - joeynmt.training - Example #2
2021-11-23 08:09:47,217 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:09:47,217 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:09:47,217 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁a', '▁great', 'est', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:09:47,217 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:09:47,218 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁a ▁great est , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 08:09:47,218 - INFO - joeynmt.training - Example #3
2021-11-23 08:09:47,218 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:09:47,218 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:09:47,218 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁des', 'en', 'v', 'ol', 'ver']
2021-11-23 08:09:47,218 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:09:47,218 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:09:47,218 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:09:47,218 - INFO - joeynmt.training - 	Hypothesis: ▁des en v ol ver
2021-11-23 08:09:47,218 - INFO - joeynmt.training - Example #6
2021-11-23 08:09:47,218 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:09:47,218 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:09:47,218 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ave']
2021-11-23 08:09:47,218 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:09:47,218 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:09:47,218 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:09:47,218 - INFO - joeynmt.training - 	Hypothesis: ▁s ave
2021-11-23 08:09:47,218 - INFO - joeynmt.training - Validation result (greedy) at epoch  39, step   129000: bleu:  11.12, loss: 77120.9766, ppl:   9.7491, duration: 111.2819s
2021-11-23 08:10:01,846 - INFO - joeynmt.training - Epoch  39, Step:   129100, Batch Loss:     2.363520, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 08:10:15,894 - INFO - joeynmt.training - Epoch  39, Step:   129200, Batch Loss:     2.007219, Tokens per Sec:     2231, Lr: 0.000100
2021-11-23 08:10:30,251 - INFO - joeynmt.training - Epoch  39, Step:   129300, Batch Loss:     1.973550, Tokens per Sec:     2226, Lr: 0.000100
2021-11-23 08:10:44,358 - INFO - joeynmt.training - Epoch  39, Step:   129400, Batch Loss:     2.213193, Tokens per Sec:     2172, Lr: 0.000100
2021-11-23 08:10:58,522 - INFO - joeynmt.training - Epoch  39, Step:   129500, Batch Loss:     2.216233, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 08:11:12,862 - INFO - joeynmt.training - Epoch  39, Step:   129600, Batch Loss:     2.262313, Tokens per Sec:     2255, Lr: 0.000100
2021-11-23 08:11:28,505 - INFO - joeynmt.training - Epoch  39, Step:   129700, Batch Loss:     1.914057, Tokens per Sec:     1987, Lr: 0.000100
2021-11-23 08:11:42,612 - INFO - joeynmt.training - Epoch  39, Step:   129800, Batch Loss:     2.023946, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 08:11:57,504 - INFO - joeynmt.training - Epoch  39, Step:   129900, Batch Loss:     2.103229, Tokens per Sec:     2158, Lr: 0.000100
2021-11-23 08:12:12,731 - INFO - joeynmt.training - Epoch  39, Step:   130000, Batch Loss:     2.065739, Tokens per Sec:     2085, Lr: 0.000100
2021-11-23 08:14:08,174 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:14:08,174 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:14:08,174 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:14:08,186 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 08:14:08,994 - INFO - joeynmt.helpers - delete models/baseline_multilingual/127000.ckpt
2021-11-23 08:14:08,994 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/127000.ckpt
2021-11-23 08:14:08,995 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/127000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/127000.ckpt')
2021-11-23 08:14:09,037 - INFO - joeynmt.training - Example #0
2021-11-23 08:14:09,037 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:14:09,037 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:14:09,037 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Judah', ',', '▁you', '▁were', '▁with', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁and', '▁all', '▁the', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁him', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁over', '▁the', '▁land', '.']
2021-11-23 08:14:09,037 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:14:09,037 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:14:09,037 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:14:09,038 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Judah , ▁you ▁were ▁with ▁Gal ile e . ▁But ▁you ▁follow ed ▁the ▁follow ers , ▁and ▁all ▁the ▁follow ers ▁are ▁follow ing ▁him , ▁and ▁all ▁your ▁follow ers ▁are ▁all ▁over ▁the ▁land .
2021-11-23 08:14:09,038 - INFO - joeynmt.training - Example #1
2021-11-23 08:14:09,038 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:14:09,038 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:14:09,038 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'u', 'il', 'her', 'me']
2021-11-23 08:14:09,038 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:14:09,038 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:14:09,038 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:14:09,038 - INFO - joeynmt.training - 	Hypothesis: ▁G u il her me
2021-11-23 08:14:09,038 - INFO - joeynmt.training - Example #2
2021-11-23 08:14:09,039 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:14:09,039 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:14:09,039 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', 'er', '▁than', 'k', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 08:14:09,039 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:14:09,039 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:14:09,039 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:14:09,039 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great er ▁than k , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 08:14:09,039 - INFO - joeynmt.training - Example #3
2021-11-23 08:14:09,039 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:14:09,039 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:14:09,039 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'po', 'is']
2021-11-23 08:14:09,039 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:14:09,039 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:14:09,039 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:14:09,040 - INFO - joeynmt.training - 	Hypothesis: ▁de po is
2021-11-23 08:14:09,040 - INFO - joeynmt.training - Example #6
2021-11-23 08:14:09,040 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:14:09,040 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:14:09,040 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'ave']
2021-11-23 08:14:09,040 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:14:09,040 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:14:09,040 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:14:09,040 - INFO - joeynmt.training - 	Hypothesis: ▁s ave
2021-11-23 08:14:09,040 - INFO - joeynmt.training - Validation result (greedy) at epoch  39, step   130000: bleu:  11.30, loss: 77250.2031, ppl:   9.7863, duration: 116.3086s
2021-11-23 08:14:23,858 - INFO - joeynmt.training - Epoch  39, Step:   130100, Batch Loss:     2.087143, Tokens per Sec:     2086, Lr: 0.000100
2021-11-23 08:14:38,184 - INFO - joeynmt.training - Epoch  39, Step:   130200, Batch Loss:     2.038436, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 08:14:52,819 - INFO - joeynmt.training - Epoch  39, Step:   130300, Batch Loss:     1.859439, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 08:15:07,858 - INFO - joeynmt.training - Epoch  39, Step:   130400, Batch Loss:     2.305031, Tokens per Sec:     2098, Lr: 0.000100
2021-11-23 08:15:22,502 - INFO - joeynmt.training - Epoch  39, Step:   130500, Batch Loss:     2.323121, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 08:15:37,115 - INFO - joeynmt.training - Epoch  39, Step:   130600, Batch Loss:     2.146578, Tokens per Sec:     2170, Lr: 0.000100
2021-11-23 08:15:52,472 - INFO - joeynmt.training - Epoch  39, Step:   130700, Batch Loss:     2.310503, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 08:16:06,614 - INFO - joeynmt.training - Epoch  39, Step:   130800, Batch Loss:     1.788621, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 08:16:21,346 - INFO - joeynmt.training - Epoch  39, Step:   130900, Batch Loss:     1.996639, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 08:16:36,260 - INFO - joeynmt.training - Epoch  39, Step:   131000, Batch Loss:     2.091547, Tokens per Sec:     2071, Lr: 0.000100
2021-11-23 08:18:22,767 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:18:22,767 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:18:22,767 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:18:22,779 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 08:18:23,580 - INFO - joeynmt.helpers - delete models/baseline_multilingual/130000.ckpt
2021-11-23 08:18:23,581 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/130000.ckpt
2021-11-23 08:18:23,581 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/130000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/130000.ckpt')
2021-11-23 08:18:23,641 - INFO - joeynmt.training - Example #0
2021-11-23 08:18:23,641 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:18:23,641 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:18:23,641 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁in', '▁Jerusalem', ',', '▁you', '▁were', '▁in', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁the', '▁other', '▁people', '▁and', '▁all', '▁the', '▁whole', '▁land', '.']
2021-11-23 08:18:23,641 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:18:23,641 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:18:23,642 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:18:23,642 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁in ▁Jerusalem , ▁you ▁were ▁in ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁was ▁follow ing ▁all ▁the ▁other ▁people ▁and ▁all ▁the ▁whole ▁land .
2021-11-23 08:18:23,642 - INFO - joeynmt.training - Example #1
2021-11-23 08:18:23,642 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:18:23,642 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:18:23,642 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 08:18:23,642 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:18:23,642 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:18:23,643 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:18:23,643 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 08:18:23,643 - INFO - joeynmt.training - Example #2
2021-11-23 08:18:23,643 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:18:23,643 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:18:23,643 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', 'est', ',', '▁how', '▁much', '▁I', '▁am', '▁with', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 08:18:23,644 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:18:23,644 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:18:23,644 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:18:23,644 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great est , ▁how ▁much ▁I ▁am ▁with ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 08:18:23,644 - INFO - joeynmt.training - Example #3
2021-11-23 08:18:23,644 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:18:23,644 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:18:23,644 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:18:23,644 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:18:23,644 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:18:23,644 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:18:23,645 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:18:23,645 - INFO - joeynmt.training - Example #6
2021-11-23 08:18:23,645 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:18:23,645 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:18:23,645 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 08:18:23,645 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:18:23,645 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:18:23,645 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:18:23,645 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 08:18:23,645 - INFO - joeynmt.training - Validation result (greedy) at epoch  39, step   131000: bleu:  11.49, loss: 77177.9453, ppl:   9.7655, duration: 107.3848s
2021-11-23 08:18:38,342 - INFO - joeynmt.training - Epoch  39, Step:   131100, Batch Loss:     1.965920, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 08:18:53,245 - INFO - joeynmt.training - Epoch  39, Step:   131200, Batch Loss:     1.752185, Tokens per Sec:     2140, Lr: 0.000100
2021-11-23 08:19:08,302 - INFO - joeynmt.training - Epoch  39, Step:   131300, Batch Loss:     2.244168, Tokens per Sec:     2083, Lr: 0.000100
2021-11-23 08:19:23,055 - INFO - joeynmt.training - Epoch  39, Step:   131400, Batch Loss:     2.016301, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 08:19:37,202 - INFO - joeynmt.training - Epoch  39, Step:   131500, Batch Loss:     2.013650, Tokens per Sec:     2228, Lr: 0.000100
2021-11-23 08:19:52,782 - INFO - joeynmt.training - Epoch  39, Step:   131600, Batch Loss:     2.022265, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 08:20:07,041 - INFO - joeynmt.training - Epoch  39, Step:   131700, Batch Loss:     1.902405, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 08:20:21,334 - INFO - joeynmt.training - Epoch  39, Step:   131800, Batch Loss:     2.069815, Tokens per Sec:     2184, Lr: 0.000100
2021-11-23 08:20:37,247 - INFO - joeynmt.training - Epoch  39, Step:   131900, Batch Loss:     2.186814, Tokens per Sec:     2130, Lr: 0.000100
2021-11-23 08:20:52,045 - INFO - joeynmt.training - Epoch  39, Step:   132000, Batch Loss:     2.107638, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 08:23:01,179 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:23:01,179 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:23:01,179 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:23:01,199 - INFO - joeynmt.training - Example #0
2021-11-23 08:23:01,199 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:23:01,199 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:23:01,199 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Judah', ',', '▁you', '▁were', '▁with', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁the', '▁people', ',', '▁and', '▁all', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁and', '▁all', '▁the', '▁wall', 's', '▁were', '▁all', '▁over', 'w', 'he', 'l', '.']
2021-11-23 08:23:01,199 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:23:01,199 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:23:01,199 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:23:01,199 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Judah , ▁you ▁were ▁with ▁Gal ile e . ▁But ▁you ▁follow ed ▁the ▁people , ▁and ▁all ▁the ▁people ▁of ▁Gal ile e , ▁and ▁all ▁the ▁wall s ▁were ▁all ▁over w he l .
2021-11-23 08:23:01,199 - INFO - joeynmt.training - Example #1
2021-11-23 08:23:01,199 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:23:01,199 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:23:01,199 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 08:23:01,199 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:23:01,199 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 08:23:01,200 - INFO - joeynmt.training - Example #2
2021-11-23 08:23:01,200 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:23:01,200 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:23:01,200 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁I', '▁make', '▁you', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁I ▁make ▁you ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 08:23:01,200 - INFO - joeynmt.training - Example #3
2021-11-23 08:23:01,200 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:23:01,200 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:23:01,200 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:23:01,200 - INFO - joeynmt.training - Example #6
2021-11-23 08:23:01,200 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:23:01,200 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:23:01,200 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:23:01,200 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 08:23:01,201 - INFO - joeynmt.training - Validation result (greedy) at epoch  39, step   132000: bleu:  10.97, loss: 76838.8516, ppl:   9.6682, duration: 129.1556s
2021-11-23 08:23:15,388 - INFO - joeynmt.training - Epoch  39, Step:   132100, Batch Loss:     2.326934, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 08:23:25,575 - INFO - joeynmt.training - Epoch  39: total training loss 7212.61
2021-11-23 08:23:25,575 - INFO - joeynmt.training - EPOCH 40
2021-11-23 08:23:29,956 - INFO - joeynmt.training - Epoch  40, Step:   132200, Batch Loss:     2.303038, Tokens per Sec:     2083, Lr: 0.000100
2021-11-23 08:23:44,534 - INFO - joeynmt.training - Epoch  40, Step:   132300, Batch Loss:     2.073197, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 08:23:59,266 - INFO - joeynmt.training - Epoch  40, Step:   132400, Batch Loss:     2.191704, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 08:24:13,962 - INFO - joeynmt.training - Epoch  40, Step:   132500, Batch Loss:     1.939798, Tokens per Sec:     2063, Lr: 0.000100
2021-11-23 08:24:29,011 - INFO - joeynmt.training - Epoch  40, Step:   132600, Batch Loss:     1.856192, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 08:24:43,291 - INFO - joeynmt.training - Epoch  40, Step:   132700, Batch Loss:     2.154412, Tokens per Sec:     2235, Lr: 0.000100
2021-11-23 08:24:57,630 - INFO - joeynmt.training - Epoch  40, Step:   132800, Batch Loss:     2.023807, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 08:25:11,930 - INFO - joeynmt.training - Epoch  40, Step:   132900, Batch Loss:     2.324056, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 08:25:27,010 - INFO - joeynmt.training - Epoch  40, Step:   133000, Batch Loss:     2.011990, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 08:27:30,293 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:27:30,294 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:27:30,294 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:27:30,312 - INFO - joeynmt.training - Example #0
2021-11-23 08:27:30,312 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:27:30,312 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:27:30,312 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Jud', 'e', 'a', ',', '▁you', '▁were', '▁going', '▁to', '▁Gal', 'ile', 'e', '.', '▁You', '▁are', '▁follow', 'ing', '▁the', '▁follow', 'ers', ',', '▁but', '▁all', '▁who', '▁are', '▁follow', 'ing', '▁your', '▁follow', 'ers', '.']
2021-11-23 08:27:30,312 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:27:30,312 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:27:30,312 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:27:30,312 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Jud e a , ▁you ▁were ▁going ▁to ▁Gal ile e . ▁You ▁are ▁follow ing ▁the ▁follow ers , ▁but ▁all ▁who ▁are ▁follow ing ▁your ▁follow ers .
2021-11-23 08:27:30,312 - INFO - joeynmt.training - Example #1
2021-11-23 08:27:30,312 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:27:30,312 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:27:30,312 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 08:27:30,312 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:27:30,312 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:27:30,312 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:27:30,312 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 08:27:30,312 - INFO - joeynmt.training - Example #2
2021-11-23 08:27:30,312 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:27:30,312 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:27:30,313 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 08:27:30,313 - INFO - joeynmt.training - Example #3
2021-11-23 08:27:30,313 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:27:30,313 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:27:30,313 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'pe', 'nd', 'o']
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Hypothesis: ▁de pe nd o
2021-11-23 08:27:30,313 - INFO - joeynmt.training - Example #6
2021-11-23 08:27:30,313 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:27:30,313 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:27:30,313 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:27:30,313 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 08:27:30,313 - INFO - joeynmt.training - Validation result (greedy) at epoch  40, step   133000: bleu:  11.45, loss: 76927.7266, ppl:   9.6936, duration: 123.3029s
2021-11-23 08:27:44,774 - INFO - joeynmt.training - Epoch  40, Step:   133100, Batch Loss:     2.165736, Tokens per Sec:     2198, Lr: 0.000100
2021-11-23 08:27:59,486 - INFO - joeynmt.training - Epoch  40, Step:   133200, Batch Loss:     1.956562, Tokens per Sec:     2091, Lr: 0.000100
2021-11-23 08:28:14,740 - INFO - joeynmt.training - Epoch  40, Step:   133300, Batch Loss:     2.163465, Tokens per Sec:     2069, Lr: 0.000100
2021-11-23 08:28:30,179 - INFO - joeynmt.training - Epoch  40, Step:   133400, Batch Loss:     2.075714, Tokens per Sec:     2004, Lr: 0.000100
2021-11-23 08:28:44,441 - INFO - joeynmt.training - Epoch  40, Step:   133500, Batch Loss:     1.814240, Tokens per Sec:     2221, Lr: 0.000100
2021-11-23 08:28:59,312 - INFO - joeynmt.training - Epoch  40, Step:   133600, Batch Loss:     2.119886, Tokens per Sec:     2068, Lr: 0.000100
2021-11-23 08:29:14,030 - INFO - joeynmt.training - Epoch  40, Step:   133700, Batch Loss:     2.086739, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 08:29:28,623 - INFO - joeynmt.training - Epoch  40, Step:   133800, Batch Loss:     2.147122, Tokens per Sec:     2172, Lr: 0.000100
2021-11-23 08:29:42,298 - INFO - joeynmt.training - Epoch  40, Step:   133900, Batch Loss:     2.010025, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 08:29:56,983 - INFO - joeynmt.training - Epoch  40, Step:   134000, Batch Loss:     2.027720, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 08:32:17,344 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:32:17,344 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:32:17,344 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:32:17,355 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 08:32:18,175 - INFO - joeynmt.helpers - delete models/baseline_multilingual/131000.ckpt
2021-11-23 08:32:18,176 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/131000.ckpt
2021-11-23 08:32:18,176 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/131000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/131000.ckpt')
2021-11-23 08:32:18,229 - INFO - joeynmt.training - Example #0
2021-11-23 08:32:18,230 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:32:18,230 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:32:18,230 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Judah', ',', '▁you', '▁were', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁one', '▁who', '▁follow', 'ed', '▁all', '▁the', '▁people', ',', '▁and', '▁all', '▁the', '▁wall', 's', '▁are', '▁all', '▁the', '▁sh', 'ip', 'p', 'ed', '.']
2021-11-23 08:32:18,230 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:32:18,230 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:32:18,230 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:32:18,231 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Judah , ▁you ▁were ▁follow ing ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁are ▁follow ing ▁the ▁one ▁who ▁follow ed ▁all ▁the ▁people , ▁and ▁all ▁the ▁wall s ▁are ▁all ▁the ▁sh ip p ed .
2021-11-23 08:32:18,231 - INFO - joeynmt.training - Example #1
2021-11-23 08:32:18,231 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:32:18,231 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:32:18,231 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 08:32:18,231 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:32:18,231 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:32:18,231 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:32:18,232 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 08:32:18,232 - INFO - joeynmt.training - Example #2
2021-11-23 08:32:18,232 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:32:18,232 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:32:18,232 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁I', '▁have', '▁the', '▁end', '▁of', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 08:32:18,232 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:32:18,232 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:32:18,233 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:32:18,233 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁I ▁have ▁the ▁end ▁of ▁each ▁other , ▁and ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 08:32:18,233 - INFO - joeynmt.training - Example #3
2021-11-23 08:32:18,233 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:32:18,233 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:32:18,233 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:32:18,233 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:32:18,234 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:32:18,234 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:32:18,234 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:32:18,234 - INFO - joeynmt.training - Example #6
2021-11-23 08:32:18,234 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:32:18,234 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:32:18,234 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 08:32:18,234 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:32:18,235 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:32:18,235 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:32:18,235 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 08:32:18,235 - INFO - joeynmt.training - Validation result (greedy) at epoch  40, step   134000: bleu:  11.54, loss: 76673.5000, ppl:   9.6211, duration: 141.2517s
2021-11-23 08:32:33,095 - INFO - joeynmt.training - Epoch  40, Step:   134100, Batch Loss:     2.268949, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 08:32:47,499 - INFO - joeynmt.training - Epoch  40, Step:   134200, Batch Loss:     2.033096, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 08:33:02,904 - INFO - joeynmt.training - Epoch  40, Step:   134300, Batch Loss:     2.046378, Tokens per Sec:     2037, Lr: 0.000100
2021-11-23 08:33:17,367 - INFO - joeynmt.training - Epoch  40, Step:   134400, Batch Loss:     2.279116, Tokens per Sec:     2212, Lr: 0.000100
2021-11-23 08:33:32,708 - INFO - joeynmt.training - Epoch  40, Step:   134500, Batch Loss:     2.186270, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 08:33:47,957 - INFO - joeynmt.training - Epoch  40, Step:   134600, Batch Loss:     2.129510, Tokens per Sec:     2046, Lr: 0.000100
2021-11-23 08:34:02,194 - INFO - joeynmt.training - Epoch  40, Step:   134700, Batch Loss:     2.074898, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 08:34:16,411 - INFO - joeynmt.training - Epoch  40, Step:   134800, Batch Loss:     2.036774, Tokens per Sec:     2267, Lr: 0.000100
2021-11-23 08:34:30,943 - INFO - joeynmt.training - Epoch  40, Step:   134900, Batch Loss:     2.352669, Tokens per Sec:     2080, Lr: 0.000100
2021-11-23 08:34:46,278 - INFO - joeynmt.training - Epoch  40, Step:   135000, Batch Loss:     2.356177, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 08:36:27,990 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:36:27,990 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:36:27,990 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:36:28,002 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 08:36:28,807 - INFO - joeynmt.helpers - delete models/baseline_multilingual/134000.ckpt
2021-11-23 08:36:28,807 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/134000.ckpt
2021-11-23 08:36:28,808 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/134000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/134000.ckpt')
2021-11-23 08:36:28,866 - INFO - joeynmt.training - Example #0
2021-11-23 08:36:28,866 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:36:28,867 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:36:28,867 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Judah', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁from', '▁Gal', 'ile', 'e', '.', '▁He', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁the', '▁g', 'round', '.']
2021-11-23 08:36:28,867 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:36:28,867 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:36:28,867 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:36:28,867 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Judah , ▁you ▁were ▁f av or ▁from ▁Gal ile e . ▁He ▁follow ed ▁the ▁people , ▁but ▁he ▁was ▁follow ing ▁all ▁his ▁follow ers ▁and ▁all ▁the ▁g round .
2021-11-23 08:36:28,868 - INFO - joeynmt.training - Example #1
2021-11-23 08:36:28,868 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:36:28,868 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:36:28,868 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 08:36:28,868 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:36:28,868 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:36:28,868 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:36:28,868 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 08:36:28,869 - INFO - joeynmt.training - Example #2
2021-11-23 08:36:28,869 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:36:28,869 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:36:28,869 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 08:36:28,869 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:36:28,869 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:36:28,869 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:36:28,869 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 08:36:28,869 - INFO - joeynmt.training - Example #3
2021-11-23 08:36:28,869 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:36:28,869 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:36:28,869 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:36:28,870 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:36:28,870 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:36:28,870 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:36:28,870 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:36:28,870 - INFO - joeynmt.training - Example #6
2021-11-23 08:36:28,870 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:36:28,870 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:36:28,870 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 08:36:28,870 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:36:28,870 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:36:28,870 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:36:28,870 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 08:36:28,871 - INFO - joeynmt.training - Validation result (greedy) at epoch  40, step   135000: bleu:  11.59, loss: 76457.2969, ppl:   9.5599, duration: 102.5918s
2021-11-23 08:36:43,883 - INFO - joeynmt.training - Epoch  40, Step:   135100, Batch Loss:     1.924081, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 08:36:58,733 - INFO - joeynmt.training - Epoch  40, Step:   135200, Batch Loss:     2.205394, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 08:37:13,080 - INFO - joeynmt.training - Epoch  40, Step:   135300, Batch Loss:     1.964278, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 08:37:27,150 - INFO - joeynmt.training - Epoch  40, Step:   135400, Batch Loss:     2.214493, Tokens per Sec:     2212, Lr: 0.000100
2021-11-23 08:37:41,335 - INFO - joeynmt.training - Epoch  40, Step:   135500, Batch Loss:     2.147472, Tokens per Sec:     2175, Lr: 0.000100
2021-11-23 08:37:50,092 - INFO - joeynmt.training - Epoch  40: total training loss 7163.03
2021-11-23 08:37:50,092 - INFO - joeynmt.training - EPOCH 41
2021-11-23 08:37:55,552 - INFO - joeynmt.training - Epoch  41, Step:   135600, Batch Loss:     1.970818, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 08:38:10,372 - INFO - joeynmt.training - Epoch  41, Step:   135700, Batch Loss:     2.281051, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 08:38:24,466 - INFO - joeynmt.training - Epoch  41, Step:   135800, Batch Loss:     1.920285, Tokens per Sec:     2126, Lr: 0.000100
2021-11-23 08:38:39,850 - INFO - joeynmt.training - Epoch  41, Step:   135900, Batch Loss:     1.902416, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 08:38:55,228 - INFO - joeynmt.training - Epoch  41, Step:   136000, Batch Loss:     1.980997, Tokens per Sec:     2081, Lr: 0.000100
2021-11-23 08:40:35,304 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:40:35,304 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:40:35,304 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:40:35,322 - INFO - joeynmt.training - Example #0
2021-11-23 08:40:35,322 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:40:35,322 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:40:35,322 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁going', '▁to', '▁be', '▁a', '▁time', '▁of', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁follow', 'ed', '▁all', '▁the', '▁people', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁all', '▁over', 'fl', 'ow', 'ed', '.']
2021-11-23 08:40:35,322 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:40:35,322 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:40:35,322 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:40:35,322 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁going ▁to ▁be ▁a ▁time ▁of ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁follow ed ▁all ▁the ▁people , ▁and ▁all ▁his ▁follow ers ▁are ▁all ▁over fl ow ed .
2021-11-23 08:40:35,322 - INFO - joeynmt.training - Example #1
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 08:40:35,323 - INFO - joeynmt.training - Example #2
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 08:40:35,323 - INFO - joeynmt.training - Example #3
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:40:35,323 - INFO - joeynmt.training - Example #6
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:40:35,323 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'and', 'als']
2021-11-23 08:40:35,323 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:40:35,324 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:40:35,324 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:40:35,324 - INFO - joeynmt.training - 	Hypothesis: ▁s and als
2021-11-23 08:40:35,324 - INFO - joeynmt.training - Validation result (greedy) at epoch  41, step   136000: bleu:  11.34, loss: 76828.2969, ppl:   9.6652, duration: 100.0952s
2021-11-23 08:40:49,951 - INFO - joeynmt.training - Epoch  41, Step:   136100, Batch Loss:     2.033208, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 08:41:05,235 - INFO - joeynmt.training - Epoch  41, Step:   136200, Batch Loss:     1.847862, Tokens per Sec:     2037, Lr: 0.000100
2021-11-23 08:41:20,054 - INFO - joeynmt.training - Epoch  41, Step:   136300, Batch Loss:     1.914027, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 08:41:34,357 - INFO - joeynmt.training - Epoch  41, Step:   136400, Batch Loss:     2.160789, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 08:41:48,534 - INFO - joeynmt.training - Epoch  41, Step:   136500, Batch Loss:     2.337777, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 08:42:03,513 - INFO - joeynmt.training - Epoch  41, Step:   136600, Batch Loss:     2.133105, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 08:42:18,128 - INFO - joeynmt.training - Epoch  41, Step:   136700, Batch Loss:     2.005197, Tokens per Sec:     2251, Lr: 0.000100
2021-11-23 08:42:33,033 - INFO - joeynmt.training - Epoch  41, Step:   136800, Batch Loss:     1.983504, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 08:42:47,726 - INFO - joeynmt.training - Epoch  41, Step:   136900, Batch Loss:     2.146874, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 08:43:02,304 - INFO - joeynmt.training - Epoch  41, Step:   137000, Batch Loss:     2.140468, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 08:44:52,797 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:44:52,797 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:44:52,797 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:44:52,814 - INFO - joeynmt.training - Example #0
2021-11-23 08:44:52,814 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:44:52,814 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:44:52,814 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁in', '▁Jerusalem', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁all', '▁the', '▁one', '▁who', '▁were', '▁going', '▁to', '▁sp', 'read', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 08:44:52,814 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:44:52,814 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁in ▁Jerusalem , ▁you ▁were ▁f av or ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁all ▁the ▁one ▁who ▁were ▁going ▁to ▁sp read ▁all ▁the ▁wall s .
2021-11-23 08:44:52,815 - INFO - joeynmt.training - Example #1
2021-11-23 08:44:52,815 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:44:52,815 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:44:52,815 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 08:44:52,815 - INFO - joeynmt.training - Example #2
2021-11-23 08:44:52,815 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:44:52,815 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:44:52,815 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 08:44:52,815 - INFO - joeynmt.training - Example #3
2021-11-23 08:44:52,815 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:44:52,815 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:44:52,815 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:44:52,815 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:44:52,816 - INFO - joeynmt.training - Example #6
2021-11-23 08:44:52,816 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:44:52,816 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:44:52,816 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 08:44:52,816 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:44:52,816 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:44:52,816 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:44:52,816 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 08:44:52,816 - INFO - joeynmt.training - Validation result (greedy) at epoch  41, step   137000: bleu:  11.58, loss: 76611.7578, ppl:   9.6036, duration: 110.5116s
2021-11-23 08:45:07,310 - INFO - joeynmt.training - Epoch  41, Step:   137100, Batch Loss:     1.915063, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 08:45:22,279 - INFO - joeynmt.training - Epoch  41, Step:   137200, Batch Loss:     2.059247, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 08:45:36,584 - INFO - joeynmt.training - Epoch  41, Step:   137300, Batch Loss:     2.040532, Tokens per Sec:     2182, Lr: 0.000100
2021-11-23 08:45:51,053 - INFO - joeynmt.training - Epoch  41, Step:   137400, Batch Loss:     2.229703, Tokens per Sec:     2110, Lr: 0.000100
2021-11-23 08:46:05,635 - INFO - joeynmt.training - Epoch  41, Step:   137500, Batch Loss:     2.259777, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 08:46:21,045 - INFO - joeynmt.training - Epoch  41, Step:   137600, Batch Loss:     2.303946, Tokens per Sec:     2019, Lr: 0.000100
2021-11-23 08:46:35,797 - INFO - joeynmt.training - Epoch  41, Step:   137700, Batch Loss:     2.116452, Tokens per Sec:     2133, Lr: 0.000100
2021-11-23 08:46:50,162 - INFO - joeynmt.training - Epoch  41, Step:   137800, Batch Loss:     2.217082, Tokens per Sec:     2203, Lr: 0.000100
2021-11-23 08:47:04,841 - INFO - joeynmt.training - Epoch  41, Step:   137900, Batch Loss:     2.135589, Tokens per Sec:     2172, Lr: 0.000100
2021-11-23 08:47:19,466 - INFO - joeynmt.training - Epoch  41, Step:   138000, Batch Loss:     2.067980, Tokens per Sec:     2120, Lr: 0.000100
2021-11-23 08:49:14,753 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:49:14,753 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:49:14,753 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:49:14,765 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 08:49:15,579 - INFO - joeynmt.helpers - delete models/baseline_multilingual/135000.ckpt
2021-11-23 08:49:15,579 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/135000.ckpt
2021-11-23 08:49:15,580 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/135000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/135000.ckpt')
2021-11-23 08:49:15,633 - INFO - joeynmt.training - Example #0
2021-11-23 08:49:15,634 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:49:15,634 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:49:15,634 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Jud', 'e', 'a', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁and', '▁all', '▁the', '▁follow', 'ers', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁over', '▁the', '▁land', '.']
2021-11-23 08:49:15,634 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:49:15,634 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:49:15,635 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:49:15,635 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Jud e a , ▁you ▁were ▁f av or ▁from ▁Gal ile e . ▁But ▁you ▁follow ed ▁the ▁follow ers , ▁and ▁all ▁the ▁follow ers ▁of ▁your ▁follow ers ▁are ▁all ▁over ▁the ▁land .
2021-11-23 08:49:15,635 - INFO - joeynmt.training - Example #1
2021-11-23 08:49:15,635 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:49:15,635 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:49:15,635 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 08:49:15,635 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:49:15,635 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:49:15,636 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:49:15,636 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 08:49:15,636 - INFO - joeynmt.training - Example #2
2021-11-23 08:49:15,636 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:49:15,636 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:49:15,636 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', ',', '▁always', '▁have', '▁one', '▁one', '▁another', '.']
2021-11-23 08:49:15,637 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:49:15,637 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:49:15,637 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:49:15,637 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁and ▁love ▁each ▁other , ▁always ▁have ▁one ▁one ▁another .
2021-11-23 08:49:15,637 - INFO - joeynmt.training - Example #3
2021-11-23 08:49:15,637 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:49:15,637 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:49:15,638 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:49:15,638 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:49:15,638 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:49:15,638 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:49:15,638 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:49:15,638 - INFO - joeynmt.training - Example #6
2021-11-23 08:49:15,638 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:49:15,638 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:49:15,639 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 08:49:15,639 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:49:15,639 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:49:15,639 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:49:15,639 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 08:49:15,639 - INFO - joeynmt.training - Validation result (greedy) at epoch  41, step   138000: bleu:  11.68, loss: 76372.4844, ppl:   9.5360, duration: 116.1734s
2021-11-23 08:49:30,382 - INFO - joeynmt.training - Epoch  41, Step:   138100, Batch Loss:     2.038021, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 08:49:44,802 - INFO - joeynmt.training - Epoch  41, Step:   138200, Batch Loss:     2.142125, Tokens per Sec:     2211, Lr: 0.000100
2021-11-23 08:50:00,011 - INFO - joeynmt.training - Epoch  41, Step:   138300, Batch Loss:     2.065192, Tokens per Sec:     2082, Lr: 0.000100
2021-11-23 08:50:14,495 - INFO - joeynmt.training - Epoch  41, Step:   138400, Batch Loss:     2.084356, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 08:50:28,810 - INFO - joeynmt.training - Epoch  41, Step:   138500, Batch Loss:     2.221812, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 08:50:42,912 - INFO - joeynmt.training - Epoch  41, Step:   138600, Batch Loss:     2.127402, Tokens per Sec:     2224, Lr: 0.000100
2021-11-23 08:50:57,745 - INFO - joeynmt.training - Epoch  41, Step:   138700, Batch Loss:     2.257773, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 08:51:11,851 - INFO - joeynmt.training - Epoch  41, Step:   138800, Batch Loss:     2.114053, Tokens per Sec:     2196, Lr: 0.000100
2021-11-23 08:51:26,422 - INFO - joeynmt.training - Epoch  41, Step:   138900, Batch Loss:     1.967427, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 08:51:33,718 - INFO - joeynmt.training - Epoch  41: total training loss 7111.00
2021-11-23 08:51:33,719 - INFO - joeynmt.training - EPOCH 42
2021-11-23 08:51:41,811 - INFO - joeynmt.training - Epoch  42, Step:   139000, Batch Loss:     1.992481, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 08:53:25,824 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:53:25,825 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:53:25,825 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:53:25,844 - INFO - joeynmt.training - Example #0
2021-11-23 08:53:25,844 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:53:25,844 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:53:25,844 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Jud', 'e', 'a', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁but', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁har', 'vest', '▁of', '▁your', '▁follow', 'ers', '.']
2021-11-23 08:53:25,844 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:53:25,844 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Jud e a , ▁you ▁were ▁f av or ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁follow ers , ▁but ▁all ▁your ▁follow ers ▁are ▁all ▁the ▁har vest ▁of ▁your ▁follow ers .
2021-11-23 08:53:25,845 - INFO - joeynmt.training - Example #1
2021-11-23 08:53:25,845 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:53:25,845 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:53:25,845 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'u', 'il', 'her', 'me']
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Hypothesis: ▁G u il her me
2021-11-23 08:53:25,845 - INFO - joeynmt.training - Example #2
2021-11-23 08:53:25,845 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:53:25,845 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:53:25,845 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁one', '▁another', '.']
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other , ▁one ▁another .
2021-11-23 08:53:25,845 - INFO - joeynmt.training - Example #3
2021-11-23 08:53:25,845 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:53:25,845 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:53:25,845 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:53:25,845 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:53:25,846 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:53:25,846 - INFO - joeynmt.training - Example #6
2021-11-23 08:53:25,846 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:53:25,846 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:53:25,846 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 08:53:25,846 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:53:25,846 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:53:25,846 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:53:25,846 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 08:53:25,846 - INFO - joeynmt.training - Validation result (greedy) at epoch  42, step   139000: bleu:  11.59, loss: 76390.9375, ppl:   9.5412, duration: 104.0343s
2021-11-23 08:53:40,436 - INFO - joeynmt.training - Epoch  42, Step:   139100, Batch Loss:     2.011327, Tokens per Sec:     2222, Lr: 0.000100
2021-11-23 08:53:56,104 - INFO - joeynmt.training - Epoch  42, Step:   139200, Batch Loss:     2.222680, Tokens per Sec:     2078, Lr: 0.000100
2021-11-23 08:54:11,214 - INFO - joeynmt.training - Epoch  42, Step:   139300, Batch Loss:     2.079947, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 08:54:26,006 - INFO - joeynmt.training - Epoch  42, Step:   139400, Batch Loss:     1.950974, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 08:54:40,193 - INFO - joeynmt.training - Epoch  42, Step:   139500, Batch Loss:     2.001484, Tokens per Sec:     2072, Lr: 0.000100
2021-11-23 08:54:54,866 - INFO - joeynmt.training - Epoch  42, Step:   139600, Batch Loss:     2.034079, Tokens per Sec:     2216, Lr: 0.000100
2021-11-23 08:55:08,893 - INFO - joeynmt.training - Epoch  42, Step:   139700, Batch Loss:     1.968983, Tokens per Sec:     2164, Lr: 0.000100
2021-11-23 08:55:23,870 - INFO - joeynmt.training - Epoch  42, Step:   139800, Batch Loss:     2.060284, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 08:55:38,824 - INFO - joeynmt.training - Epoch  42, Step:   139900, Batch Loss:     2.139406, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 08:55:52,737 - INFO - joeynmt.training - Epoch  42, Step:   140000, Batch Loss:     2.188601, Tokens per Sec:     2198, Lr: 0.000100
2021-11-23 08:57:55,768 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 08:57:55,768 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 08:57:55,768 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 08:57:55,779 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 08:57:56,590 - INFO - joeynmt.helpers - delete models/baseline_multilingual/138000.ckpt
2021-11-23 08:57:56,591 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/138000.ckpt
2021-11-23 08:57:56,591 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/138000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/138000.ckpt')
2021-11-23 08:57:56,649 - INFO - joeynmt.training - Example #0
2021-11-23 08:57:56,649 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 08:57:56,650 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 08:57:56,650 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Jud', 'e', 'a', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁he', '▁was', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 08:57:56,650 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 08:57:56,650 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 08:57:56,650 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 08:57:56,650 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Jud e a , ▁you ▁were ▁f av or ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁he ▁was ▁follow ed ▁all ▁his ▁follow ers ▁and ▁all ▁the ▁wall s .
2021-11-23 08:57:56,650 - INFO - joeynmt.training - Example #1
2021-11-23 08:57:56,651 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 08:57:56,651 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 08:57:56,651 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 08:57:56,651 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 08:57:56,651 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 08:57:56,651 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 08:57:56,651 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 08:57:56,652 - INFO - joeynmt.training - Example #2
2021-11-23 08:57:56,652 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 08:57:56,652 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 08:57:56,652 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 08:57:56,652 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 08:57:56,652 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 08:57:56,652 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 08:57:56,653 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 08:57:56,653 - INFO - joeynmt.training - Example #3
2021-11-23 08:57:56,653 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 08:57:56,653 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 08:57:56,653 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 08:57:56,653 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 08:57:56,653 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 08:57:56,653 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 08:57:56,654 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 08:57:56,654 - INFO - joeynmt.training - Example #6
2021-11-23 08:57:56,654 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 08:57:56,654 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 08:57:56,654 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 08:57:56,654 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 08:57:56,654 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 08:57:56,654 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 08:57:56,655 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 08:57:56,655 - INFO - joeynmt.training - Validation result (greedy) at epoch  42, step   140000: bleu:  11.83, loss: 76346.2891, ppl:   9.5286, duration: 123.9180s
2021-11-23 08:58:10,559 - INFO - joeynmt.training - Epoch  42, Step:   140100, Batch Loss:     2.014311, Tokens per Sec:     2257, Lr: 0.000100
2021-11-23 08:58:25,641 - INFO - joeynmt.training - Epoch  42, Step:   140200, Batch Loss:     1.994488, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 08:58:40,723 - INFO - joeynmt.training - Epoch  42, Step:   140300, Batch Loss:     2.020754, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 08:58:55,610 - INFO - joeynmt.training - Epoch  42, Step:   140400, Batch Loss:     2.227023, Tokens per Sec:     2067, Lr: 0.000100
2021-11-23 08:59:09,717 - INFO - joeynmt.training - Epoch  42, Step:   140500, Batch Loss:     2.143352, Tokens per Sec:     2182, Lr: 0.000100
2021-11-23 08:59:24,705 - INFO - joeynmt.training - Epoch  42, Step:   140600, Batch Loss:     2.247205, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 08:59:39,033 - INFO - joeynmt.training - Epoch  42, Step:   140700, Batch Loss:     2.082443, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 08:59:53,246 - INFO - joeynmt.training - Epoch  42, Step:   140800, Batch Loss:     1.965450, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 09:00:07,570 - INFO - joeynmt.training - Epoch  42, Step:   140900, Batch Loss:     1.959120, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 09:00:22,247 - INFO - joeynmt.training - Epoch  42, Step:   141000, Batch Loss:     2.256125, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 09:02:10,535 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:02:10,535 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:02:10,535 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:02:10,548 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 09:02:11,360 - INFO - joeynmt.helpers - delete models/baseline_multilingual/140000.ckpt
2021-11-23 09:02:11,361 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/140000.ckpt
2021-11-23 09:02:11,361 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/140000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/140000.ckpt')
2021-11-23 09:02:11,413 - INFO - joeynmt.training - Example #0
2021-11-23 09:02:11,414 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:02:11,414 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:02:11,414 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Judah', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁him', ',', '▁but', '▁all', '▁the', '▁people', '▁are', '▁follow', 'ing', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁har', 'vest', '.']
2021-11-23 09:02:11,414 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:02:11,414 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:02:11,414 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:02:11,414 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Judah , ▁you ▁were ▁f av or ▁from ▁Gal ile e . ▁But ▁you ▁follow ed ▁him , ▁but ▁all ▁the ▁people ▁are ▁follow ing ▁your ▁follow ers , ▁and ▁all ▁your ▁follow ers ▁are ▁all ▁the ▁har vest .
2021-11-23 09:02:11,415 - INFO - joeynmt.training - Example #1
2021-11-23 09:02:11,415 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:02:11,415 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:02:11,415 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:02:11,415 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:02:11,415 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:02:11,415 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:02:11,415 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:02:11,415 - INFO - joeynmt.training - Example #2
2021-11-23 09:02:11,415 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:02:11,415 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:02:11,416 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '.']
2021-11-23 09:02:11,416 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:02:11,416 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:02:11,416 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:02:11,416 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one .
2021-11-23 09:02:11,416 - INFO - joeynmt.training - Example #3
2021-11-23 09:02:11,416 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:02:11,416 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:02:11,416 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 09:02:11,416 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:02:11,416 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:02:11,417 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:02:11,417 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 09:02:11,417 - INFO - joeynmt.training - Example #6
2021-11-23 09:02:11,417 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:02:11,417 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:02:11,417 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:02:11,417 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:02:11,417 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:02:11,417 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:02:11,417 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:02:11,418 - INFO - joeynmt.training - Validation result (greedy) at epoch  42, step   141000: bleu:  11.92, loss: 76325.1484, ppl:   9.5226, duration: 109.1704s
2021-11-23 09:02:25,858 - INFO - joeynmt.training - Epoch  42, Step:   141100, Batch Loss:     2.164262, Tokens per Sec:     2178, Lr: 0.000100
2021-11-23 09:02:40,059 - INFO - joeynmt.training - Epoch  42, Step:   141200, Batch Loss:     2.240488, Tokens per Sec:     2173, Lr: 0.000100
2021-11-23 09:02:54,524 - INFO - joeynmt.training - Epoch  42, Step:   141300, Batch Loss:     2.122957, Tokens per Sec:     2090, Lr: 0.000100
2021-11-23 09:03:09,898 - INFO - joeynmt.training - Epoch  42, Step:   141400, Batch Loss:     1.924001, Tokens per Sec:     2054, Lr: 0.000100
2021-11-23 09:03:24,748 - INFO - joeynmt.training - Epoch  42, Step:   141500, Batch Loss:     2.114737, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 09:03:38,977 - INFO - joeynmt.training - Epoch  42, Step:   141600, Batch Loss:     2.104964, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 09:03:54,275 - INFO - joeynmt.training - Epoch  42, Step:   141700, Batch Loss:     2.092422, Tokens per Sec:     2165, Lr: 0.000100
2021-11-23 09:04:08,989 - INFO - joeynmt.training - Epoch  42, Step:   141800, Batch Loss:     1.842369, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 09:04:23,418 - INFO - joeynmt.training - Epoch  42, Step:   141900, Batch Loss:     1.955081, Tokens per Sec:     2201, Lr: 0.000100
2021-11-23 09:04:39,062 - INFO - joeynmt.training - Epoch  42, Step:   142000, Batch Loss:     2.001851, Tokens per Sec:     2021, Lr: 0.000100
2021-11-23 09:06:25,439 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:06:25,440 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:06:25,440 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:06:25,453 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 09:06:26,275 - INFO - joeynmt.helpers - delete models/baseline_multilingual/141000.ckpt
2021-11-23 09:06:26,276 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/141000.ckpt
2021-11-23 09:06:26,276 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/141000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/141000.ckpt')
2021-11-23 09:06:26,339 - INFO - joeynmt.training - Example #0
2021-11-23 09:06:26,339 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:06:26,339 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:06:26,339 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Judah', ',', '▁you', '▁were', '▁filled', '▁with', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁the', '▁people', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁your', '▁follow', 'ers', '.']
2021-11-23 09:06:26,339 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:06:26,339 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:06:26,340 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:06:26,340 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Judah , ▁you ▁were ▁filled ▁with ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁follow ed ▁the ▁people , ▁and ▁all ▁your ▁follow ers ▁are ▁all ▁your ▁follow ers .
2021-11-23 09:06:26,340 - INFO - joeynmt.training - Example #1
2021-11-23 09:06:26,340 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:06:26,340 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:06:26,340 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:06:26,340 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:06:26,341 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:06:26,341 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:06:26,341 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:06:26,341 - INFO - joeynmt.training - Example #2
2021-11-23 09:06:26,341 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:06:26,341 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:06:26,341 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', '.']
2021-11-23 09:06:26,342 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:06:26,342 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:06:26,342 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:06:26,342 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other .
2021-11-23 09:06:26,342 - INFO - joeynmt.training - Example #3
2021-11-23 09:06:26,342 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:06:26,342 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:06:26,343 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁per', 'ce', 'ber']
2021-11-23 09:06:26,343 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:06:26,343 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:06:26,343 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:06:26,343 - INFO - joeynmt.training - 	Hypothesis: ▁per ce ber
2021-11-23 09:06:26,343 - INFO - joeynmt.training - Example #6
2021-11-23 09:06:26,343 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:06:26,344 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:06:26,344 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:06:26,344 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:06:26,344 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:06:26,344 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:06:26,344 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:06:26,344 - INFO - joeynmt.training - Validation result (greedy) at epoch  42, step   142000: bleu:  11.97, loss: 75793.8828, ppl:   9.3744, duration: 107.2822s
2021-11-23 09:06:41,399 - INFO - joeynmt.training - Epoch  42, Step:   142100, Batch Loss:     2.022853, Tokens per Sec:     2097, Lr: 0.000100
2021-11-23 09:06:55,978 - INFO - joeynmt.training - Epoch  42, Step:   142200, Batch Loss:     2.169970, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 09:07:10,379 - INFO - joeynmt.training - Epoch  42, Step:   142300, Batch Loss:     2.104291, Tokens per Sec:     2165, Lr: 0.000100
2021-11-23 09:07:16,514 - INFO - joeynmt.training - Epoch  42: total training loss 7063.25
2021-11-23 09:07:16,515 - INFO - joeynmt.training - EPOCH 43
2021-11-23 09:07:25,850 - INFO - joeynmt.training - Epoch  43, Step:   142400, Batch Loss:     2.241639, Tokens per Sec:     2081, Lr: 0.000100
2021-11-23 09:07:41,222 - INFO - joeynmt.training - Epoch  43, Step:   142500, Batch Loss:     1.932799, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 09:07:55,693 - INFO - joeynmt.training - Epoch  43, Step:   142600, Batch Loss:     1.963687, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 09:08:10,294 - INFO - joeynmt.training - Epoch  43, Step:   142700, Batch Loss:     2.161207, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 09:08:24,767 - INFO - joeynmt.training - Epoch  43, Step:   142800, Batch Loss:     2.162210, Tokens per Sec:     2189, Lr: 0.000100
2021-11-23 09:08:39,372 - INFO - joeynmt.training - Epoch  43, Step:   142900, Batch Loss:     1.978144, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 09:08:53,335 - INFO - joeynmt.training - Epoch  43, Step:   143000, Batch Loss:     2.059977, Tokens per Sec:     2182, Lr: 0.000100
2021-11-23 09:10:59,332 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:10:59,332 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:10:59,332 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:10:59,344 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 09:11:00,161 - INFO - joeynmt.helpers - delete models/baseline_multilingual/142000.ckpt
2021-11-23 09:11:00,162 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/142000.ckpt
2021-11-23 09:11:00,162 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/142000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/142000.ckpt')
2021-11-23 09:11:00,218 - INFO - joeynmt.training - Example #0
2021-11-23 09:11:00,218 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:11:00,218 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:11:00,218 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁arri', 'ved', ',', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Judah', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁the', '▁people', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁all', '▁over', '▁the', '▁wall', 's', '.']
2021-11-23 09:11:00,218 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:11:00,219 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:11:00,219 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:11:00,219 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁arri ved , ▁you ▁were ▁af raid ▁of ▁Judah . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁was ▁follow ing ▁all ▁the ▁people , ▁and ▁all ▁his ▁follow ers ▁are ▁all ▁over ▁the ▁wall s .
2021-11-23 09:11:00,219 - INFO - joeynmt.training - Example #1
2021-11-23 09:11:00,219 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:11:00,219 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:11:00,220 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 09:11:00,220 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:11:00,220 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:11:00,220 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:11:00,220 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 09:11:00,220 - INFO - joeynmt.training - Example #2
2021-11-23 09:11:00,220 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:11:00,221 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:11:00,221 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 09:11:00,221 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:11:00,221 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:11:00,221 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:11:00,221 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other ▁with ▁each ▁other , ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 09:11:00,221 - INFO - joeynmt.training - Example #3
2021-11-23 09:11:00,222 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:11:00,222 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:11:00,222 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁per', 'ce', 'ber']
2021-11-23 09:11:00,222 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:11:00,222 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:11:00,222 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:11:00,222 - INFO - joeynmt.training - 	Hypothesis: ▁per ce ber
2021-11-23 09:11:00,222 - INFO - joeynmt.training - Example #6
2021-11-23 09:11:00,222 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:11:00,222 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:11:00,222 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:11:00,222 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:11:00,222 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:11:00,222 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:11:00,222 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:11:00,223 - INFO - joeynmt.training - Validation result (greedy) at epoch  43, step   143000: bleu:  12.14, loss: 76078.2109, ppl:   9.4535, duration: 126.8871s
2021-11-23 09:11:15,474 - INFO - joeynmt.training - Epoch  43, Step:   143100, Batch Loss:     2.112474, Tokens per Sec:     2062, Lr: 0.000100
2021-11-23 09:11:30,021 - INFO - joeynmt.training - Epoch  43, Step:   143200, Batch Loss:     2.123039, Tokens per Sec:     2202, Lr: 0.000100
2021-11-23 09:11:44,722 - INFO - joeynmt.training - Epoch  43, Step:   143300, Batch Loss:     2.224610, Tokens per Sec:     2215, Lr: 0.000100
2021-11-23 09:11:59,710 - INFO - joeynmt.training - Epoch  43, Step:   143400, Batch Loss:     2.125908, Tokens per Sec:     2035, Lr: 0.000100
2021-11-23 09:12:14,075 - INFO - joeynmt.training - Epoch  43, Step:   143500, Batch Loss:     1.953920, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 09:12:28,808 - INFO - joeynmt.training - Epoch  43, Step:   143600, Batch Loss:     2.157431, Tokens per Sec:     2122, Lr: 0.000100
2021-11-23 09:12:42,794 - INFO - joeynmt.training - Epoch  43, Step:   143700, Batch Loss:     1.957789, Tokens per Sec:     2196, Lr: 0.000100
2021-11-23 09:12:57,695 - INFO - joeynmt.training - Epoch  43, Step:   143800, Batch Loss:     2.499528, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 09:13:12,122 - INFO - joeynmt.training - Epoch  43, Step:   143900, Batch Loss:     2.224152, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 09:13:27,226 - INFO - joeynmt.training - Epoch  43, Step:   144000, Batch Loss:     1.944751, Tokens per Sec:     2200, Lr: 0.000100
2021-11-23 09:15:34,136 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:15:34,136 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:15:34,136 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:15:34,149 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 09:15:34,951 - INFO - joeynmt.helpers - delete models/baseline_multilingual/143000.ckpt
2021-11-23 09:15:34,951 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/143000.ckpt
2021-11-23 09:15:34,951 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/143000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/143000.ckpt')
2021-11-23 09:15:35,009 - INFO - joeynmt.training - Example #0
2021-11-23 09:15:35,009 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:15:35,009 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:15:35,010 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', ',', '▁you', '▁were', '▁f', 'ight', 'ing', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁follow', 'ing', '▁all', '▁your', '▁follow', 'ers', '.']
2021-11-23 09:15:35,010 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:15:35,010 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:15:35,010 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:15:35,010 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid , ▁you ▁were ▁f ight ing ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁follow ing ▁all ▁your ▁follow ers .
2021-11-23 09:15:35,010 - INFO - joeynmt.training - Example #1
2021-11-23 09:15:35,010 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:15:35,010 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:15:35,010 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:15:35,011 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:15:35,011 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:15:35,011 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:15:35,011 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:15:35,011 - INFO - joeynmt.training - Example #2
2021-11-23 09:15:35,011 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:15:35,011 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:15:35,011 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁much', '▁I', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁always', '▁have', '▁one', '▁one', '.']
2021-11-23 09:15:35,011 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:15:35,011 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:15:35,012 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:15:35,012 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁much ▁I ▁love ▁each ▁other , ▁love ▁each ▁other , ▁always ▁have ▁one ▁one .
2021-11-23 09:15:35,012 - INFO - joeynmt.training - Example #3
2021-11-23 09:15:35,012 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:15:35,012 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:15:35,012 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 09:15:35,012 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:15:35,012 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:15:35,012 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:15:35,012 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 09:15:35,013 - INFO - joeynmt.training - Example #6
2021-11-23 09:15:35,013 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:15:35,013 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:15:35,013 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:15:35,013 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:15:35,013 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:15:35,013 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:15:35,013 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:15:35,013 - INFO - joeynmt.training - Validation result (greedy) at epoch  43, step   144000: bleu:  12.14, loss: 76072.2031, ppl:   9.4518, duration: 127.7868s
2021-11-23 09:15:50,140 - INFO - joeynmt.training - Epoch  43, Step:   144100, Batch Loss:     2.095815, Tokens per Sec:     2218, Lr: 0.000100
2021-11-23 09:16:04,501 - INFO - joeynmt.training - Epoch  43, Step:   144200, Batch Loss:     1.863134, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 09:16:18,005 - INFO - joeynmt.training - Epoch  43, Step:   144300, Batch Loss:     2.097802, Tokens per Sec:     2174, Lr: 0.000100
2021-11-23 09:16:32,872 - INFO - joeynmt.training - Epoch  43, Step:   144400, Batch Loss:     2.190921, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 09:16:47,802 - INFO - joeynmt.training - Epoch  43, Step:   144500, Batch Loss:     1.893066, Tokens per Sec:     2170, Lr: 0.000100
2021-11-23 09:17:02,588 - INFO - joeynmt.training - Epoch  43, Step:   144600, Batch Loss:     2.047801, Tokens per Sec:     2097, Lr: 0.000100
2021-11-23 09:17:16,722 - INFO - joeynmt.training - Epoch  43, Step:   144700, Batch Loss:     2.141217, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 09:17:32,432 - INFO - joeynmt.training - Epoch  43, Step:   144800, Batch Loss:     2.126092, Tokens per Sec:     1966, Lr: 0.000100
2021-11-23 09:17:47,753 - INFO - joeynmt.training - Epoch  43, Step:   144900, Batch Loss:     2.169796, Tokens per Sec:     1995, Lr: 0.000100
2021-11-23 09:18:02,044 - INFO - joeynmt.training - Epoch  43, Step:   145000, Batch Loss:     2.097739, Tokens per Sec:     2233, Lr: 0.000100
2021-11-23 09:19:58,846 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:19:58,846 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:19:58,846 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:19:58,859 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 09:19:59,668 - INFO - joeynmt.helpers - delete models/baseline_multilingual/144000.ckpt
2021-11-23 09:19:59,668 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/144000.ckpt
2021-11-23 09:19:59,669 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/144000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/144000.ckpt')
2021-11-23 09:19:59,722 - INFO - joeynmt.training - Example #0
2021-11-23 09:19:59,723 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:19:59,723 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:19:59,723 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Jud', 'e', 'a', ',', '▁you', '▁were', '▁going', '▁from', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁the', '▁one', '▁who', '▁follow', 'ed', '▁him', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁sh', 'ip', 'p', 'ed', '.']
2021-11-23 09:19:59,723 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:19:59,723 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:19:59,723 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:19:59,724 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Jud e a , ▁you ▁were ▁going ▁from ▁Gal ile e . ▁But ▁you ▁follow ed ▁the ▁one ▁who ▁follow ed ▁him , ▁and ▁all ▁your ▁follow ers ▁are ▁all ▁the ▁sh ip p ed .
2021-11-23 09:19:59,724 - INFO - joeynmt.training - Example #1
2021-11-23 09:19:59,724 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:19:59,724 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:19:59,724 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'u', 'il', 'her', 'me']
2021-11-23 09:19:59,724 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:19:59,724 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:19:59,725 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:19:59,725 - INFO - joeynmt.training - 	Hypothesis: ▁G u il her me
2021-11-23 09:19:59,725 - INFO - joeynmt.training - Example #2
2021-11-23 09:19:59,725 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:19:59,725 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:19:59,725 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 09:19:59,725 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:19:59,726 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:19:59,726 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:19:59,726 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁love ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 09:19:59,726 - INFO - joeynmt.training - Example #3
2021-11-23 09:19:59,726 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:19:59,726 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:19:59,726 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 09:19:59,727 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:19:59,727 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:19:59,727 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:19:59,727 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 09:19:59,727 - INFO - joeynmt.training - Example #6
2021-11-23 09:19:59,727 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:19:59,727 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:19:59,728 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁s', 'el', 'f']
2021-11-23 09:19:59,728 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:19:59,728 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:19:59,728 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:19:59,728 - INFO - joeynmt.training - 	Hypothesis: ▁s el f
2021-11-23 09:19:59,728 - INFO - joeynmt.training - Validation result (greedy) at epoch  43, step   145000: bleu:  12.16, loss: 75791.9375, ppl:   9.3739, duration: 117.6841s
2021-11-23 09:20:13,979 - INFO - joeynmt.training - Epoch  43, Step:   145100, Batch Loss:     2.195163, Tokens per Sec:     2162, Lr: 0.000100
2021-11-23 09:20:27,924 - INFO - joeynmt.training - Epoch  43, Step:   145200, Batch Loss:     1.865862, Tokens per Sec:     2211, Lr: 0.000100
2021-11-23 09:20:43,409 - INFO - joeynmt.training - Epoch  43, Step:   145300, Batch Loss:     2.074655, Tokens per Sec:     2056, Lr: 0.000100
2021-11-23 09:20:58,306 - INFO - joeynmt.training - Epoch  43, Step:   145400, Batch Loss:     2.048843, Tokens per Sec:     2200, Lr: 0.000100
2021-11-23 09:21:12,869 - INFO - joeynmt.training - Epoch  43, Step:   145500, Batch Loss:     1.955683, Tokens per Sec:     2126, Lr: 0.000100
2021-11-23 09:21:27,683 - INFO - joeynmt.training - Epoch  43, Step:   145600, Batch Loss:     2.016059, Tokens per Sec:     2200, Lr: 0.000100
2021-11-23 09:21:43,117 - INFO - joeynmt.training - Epoch  43, Step:   145700, Batch Loss:     2.418600, Tokens per Sec:     2027, Lr: 0.000100
2021-11-23 09:21:46,951 - INFO - joeynmt.training - Epoch  43: total training loss 7015.16
2021-11-23 09:21:46,952 - INFO - joeynmt.training - EPOCH 44
2021-11-23 09:21:57,934 - INFO - joeynmt.training - Epoch  44, Step:   145800, Batch Loss:     1.974423, Tokens per Sec:     2068, Lr: 0.000100
2021-11-23 09:22:13,108 - INFO - joeynmt.training - Epoch  44, Step:   145900, Batch Loss:     1.930683, Tokens per Sec:     2021, Lr: 0.000100
2021-11-23 09:22:27,877 - INFO - joeynmt.training - Epoch  44, Step:   146000, Batch Loss:     1.949740, Tokens per Sec:     2110, Lr: 0.000100
2021-11-23 09:24:29,935 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:24:29,936 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:24:29,936 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:24:29,947 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 09:24:30,751 - INFO - joeynmt.helpers - delete models/baseline_multilingual/145000.ckpt
2021-11-23 09:24:30,752 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/145000.ckpt
2021-11-23 09:24:30,752 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/145000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/145000.ckpt')
2021-11-23 09:24:30,811 - INFO - joeynmt.training - Example #0
2021-11-23 09:24:30,811 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:24:30,811 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:24:30,812 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁time', ',', '▁you', '▁were', '▁f', 'ive', '▁o', "'", 'cl', 'ock', 'ing', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁follow', 'ing', '▁your', '▁follow', 'ers', '.']
2021-11-23 09:24:30,812 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:24:30,812 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:24:30,812 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:24:30,812 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁time , ▁you ▁were ▁f ive ▁o ' cl ock ing ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁follow ing ▁your ▁follow ers .
2021-11-23 09:24:30,812 - INFO - joeynmt.training - Example #1
2021-11-23 09:24:30,813 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:24:30,813 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:24:30,813 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:24:30,813 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:24:30,813 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:24:30,813 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:24:30,813 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:24:30,813 - INFO - joeynmt.training - Example #2
2021-11-23 09:24:30,814 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:24:30,814 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:24:30,814 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 09:24:30,814 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:24:30,814 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:24:30,814 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:24:30,814 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 09:24:30,815 - INFO - joeynmt.training - Example #3
2021-11-23 09:24:30,815 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:24:30,815 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:24:30,815 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 09:24:30,815 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:24:30,815 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:24:30,815 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:24:30,815 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 09:24:30,816 - INFO - joeynmt.training - Example #6
2021-11-23 09:24:30,816 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:24:30,816 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:24:30,816 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 09:24:30,816 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:24:30,816 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:24:30,816 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:24:30,816 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 09:24:30,817 - INFO - joeynmt.training - Validation result (greedy) at epoch  44, step   146000: bleu:  12.34, loss: 75864.7031, ppl:   9.3941, duration: 122.9398s
2021-11-23 09:24:45,506 - INFO - joeynmt.training - Epoch  44, Step:   146100, Batch Loss:     2.129632, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 09:25:01,067 - INFO - joeynmt.training - Epoch  44, Step:   146200, Batch Loss:     2.081137, Tokens per Sec:     2110, Lr: 0.000100
2021-11-23 09:25:16,115 - INFO - joeynmt.training - Epoch  44, Step:   146300, Batch Loss:     2.149671, Tokens per Sec:     2071, Lr: 0.000100
2021-11-23 09:25:30,922 - INFO - joeynmt.training - Epoch  44, Step:   146400, Batch Loss:     1.977640, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 09:25:45,926 - INFO - joeynmt.training - Epoch  44, Step:   146500, Batch Loss:     2.550813, Tokens per Sec:     2184, Lr: 0.000100
2021-11-23 09:26:00,705 - INFO - joeynmt.training - Epoch  44, Step:   146600, Batch Loss:     1.938724, Tokens per Sec:     2233, Lr: 0.000100
2021-11-23 09:26:14,997 - INFO - joeynmt.training - Epoch  44, Step:   146700, Batch Loss:     2.246791, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 09:26:29,418 - INFO - joeynmt.training - Epoch  44, Step:   146800, Batch Loss:     2.068189, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 09:26:43,869 - INFO - joeynmt.training - Epoch  44, Step:   146900, Batch Loss:     1.902546, Tokens per Sec:     2195, Lr: 0.000100
2021-11-23 09:26:57,429 - INFO - joeynmt.training - Epoch  44, Step:   147000, Batch Loss:     2.002511, Tokens per Sec:     2182, Lr: 0.000100
2021-11-23 09:28:49,547 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:28:49,548 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:28:49,548 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:28:49,565 - INFO - joeynmt.training - Example #0
2021-11-23 09:28:49,565 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:28:49,565 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:28:49,565 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁were', '▁count', 'ed', '▁by', '▁Jud', 'e', 'a', '▁and', '▁was', '▁filled', '▁with', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁over', 'w', 'he', 'l', 'med', '.']
2021-11-23 09:28:49,565 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:28:49,565 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:28:49,565 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:28:49,565 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁were ▁count ed ▁by ▁Jud e a ▁and ▁was ▁filled ▁with ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁follow ed ▁the ▁follow ers , ▁and ▁all ▁your ▁follow ers ▁are ▁all ▁over w he l med .
2021-11-23 09:28:49,565 - INFO - joeynmt.training - Example #1
2021-11-23 09:28:49,565 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:28:49,565 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:28:49,565 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 09:28:49,565 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:28:49,565 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 09:28:49,566 - INFO - joeynmt.training - Example #2
2021-11-23 09:28:49,566 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:28:49,566 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:28:49,566 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 09:28:49,566 - INFO - joeynmt.training - Example #3
2021-11-23 09:28:49,566 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:28:49,566 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:28:49,566 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'u', 'pl', 'a']
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Hypothesis: ▁d u pl a
2021-11-23 09:28:49,566 - INFO - joeynmt.training - Example #6
2021-11-23 09:28:49,566 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:28:49,566 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:28:49,566 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:28:49,566 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 09:28:49,567 - INFO - joeynmt.training - Validation result (greedy) at epoch  44, step   147000: bleu:  12.24, loss: 75767.2031, ppl:   9.3671, duration: 112.1371s
2021-11-23 09:29:03,126 - INFO - joeynmt.training - Epoch  44, Step:   147100, Batch Loss:     2.223089, Tokens per Sec:     2204, Lr: 0.000100
2021-11-23 09:29:17,481 - INFO - joeynmt.training - Epoch  44, Step:   147200, Batch Loss:     2.095131, Tokens per Sec:     2058, Lr: 0.000100
2021-11-23 09:29:31,676 - INFO - joeynmt.training - Epoch  44, Step:   147300, Batch Loss:     1.833609, Tokens per Sec:     2178, Lr: 0.000100
2021-11-23 09:29:46,364 - INFO - joeynmt.training - Epoch  44, Step:   147400, Batch Loss:     2.189269, Tokens per Sec:     2195, Lr: 0.000100
2021-11-23 09:30:00,408 - INFO - joeynmt.training - Epoch  44, Step:   147500, Batch Loss:     1.974516, Tokens per Sec:     2174, Lr: 0.000100
2021-11-23 09:30:15,383 - INFO - joeynmt.training - Epoch  44, Step:   147600, Batch Loss:     2.189966, Tokens per Sec:     2239, Lr: 0.000100
2021-11-23 09:30:30,039 - INFO - joeynmt.training - Epoch  44, Step:   147700, Batch Loss:     1.970941, Tokens per Sec:     2140, Lr: 0.000100
2021-11-23 09:30:44,823 - INFO - joeynmt.training - Epoch  44, Step:   147800, Batch Loss:     1.904374, Tokens per Sec:     2092, Lr: 0.000100
2021-11-23 09:30:59,359 - INFO - joeynmt.training - Epoch  44, Step:   147900, Batch Loss:     2.069268, Tokens per Sec:     2172, Lr: 0.000100
2021-11-23 09:31:14,309 - INFO - joeynmt.training - Epoch  44, Step:   148000, Batch Loss:     2.265221, Tokens per Sec:     2133, Lr: 0.000100
2021-11-23 09:33:15,800 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:33:15,800 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:33:15,800 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:33:15,817 - INFO - joeynmt.training - Example #0
2021-11-23 09:33:15,817 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:33:15,817 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:33:15,817 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁were', '▁count', 'ry', 'ing', ',', '▁and', '▁Jud', 'as', '▁was', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁him', ',', '▁but', '▁all', '▁the', '▁people', '▁follow', 'ed', '▁him', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁all', '▁over', 'w', 'he', 'l', '.']
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁were ▁count ry ing , ▁and ▁Jud as ▁was ▁from ▁Gal ile e . ▁You ▁follow ed ▁him , ▁but ▁all ▁the ▁people ▁follow ed ▁him , ▁and ▁all ▁his ▁follow ers ▁were ▁all ▁over w he l .
2021-11-23 09:33:15,818 - INFO - joeynmt.training - Example #1
2021-11-23 09:33:15,818 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:33:15,818 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:33:15,818 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:33:15,818 - INFO - joeynmt.training - Example #2
2021-11-23 09:33:15,818 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:33:15,818 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:33:15,818 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other ▁with ▁each ▁other , ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 09:33:15,818 - INFO - joeynmt.training - Example #3
2021-11-23 09:33:15,818 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:33:15,818 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:33:15,818 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁c', 'er', 'to']
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:33:15,818 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:33:15,819 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:33:15,819 - INFO - joeynmt.training - 	Hypothesis: ▁c er to
2021-11-23 09:33:15,819 - INFO - joeynmt.training - Example #6
2021-11-23 09:33:15,819 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:33:15,819 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:33:15,819 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:33:15,819 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:33:15,819 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:33:15,819 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:33:15,819 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:33:15,819 - INFO - joeynmt.training - Validation result (greedy) at epoch  44, step   148000: bleu:  12.31, loss: 75660.1484, ppl:   9.3375, duration: 121.5099s
2021-11-23 09:33:30,686 - INFO - joeynmt.training - Epoch  44, Step:   148100, Batch Loss:     1.996833, Tokens per Sec:     2135, Lr: 0.000100
2021-11-23 09:33:45,917 - INFO - joeynmt.training - Epoch  44, Step:   148200, Batch Loss:     2.192211, Tokens per Sec:     2119, Lr: 0.000100
2021-11-23 09:34:00,545 - INFO - joeynmt.training - Epoch  44, Step:   148300, Batch Loss:     2.077779, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 09:34:14,923 - INFO - joeynmt.training - Epoch  44, Step:   148400, Batch Loss:     2.144361, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 09:34:30,035 - INFO - joeynmt.training - Epoch  44, Step:   148500, Batch Loss:     2.107739, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 09:34:44,966 - INFO - joeynmt.training - Epoch  44, Step:   148600, Batch Loss:     2.011521, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 09:34:59,753 - INFO - joeynmt.training - Epoch  44, Step:   148700, Batch Loss:     2.151614, Tokens per Sec:     2124, Lr: 0.000100
2021-11-23 09:35:14,586 - INFO - joeynmt.training - Epoch  44, Step:   148800, Batch Loss:     1.704741, Tokens per Sec:     2065, Lr: 0.000100
2021-11-23 09:35:29,785 - INFO - joeynmt.training - Epoch  44, Step:   148900, Batch Loss:     2.063465, Tokens per Sec:     2038, Lr: 0.000100
2021-11-23 09:35:44,639 - INFO - joeynmt.training - Epoch  44, Step:   149000, Batch Loss:     2.003139, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 09:37:36,967 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:37:36,967 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:37:36,967 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:37:36,986 - INFO - joeynmt.training - Example #0
2021-11-23 09:37:36,986 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:37:36,986 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:37:36,986 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁time', ',', '▁you', '▁were', '▁count', 'ry', 'ing', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁follow', 'ed', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 09:37:36,986 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:37:36,986 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:37:36,986 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁time , ▁you ▁were ▁count ry ing ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁was ▁follow ed ▁all ▁the ▁wall s .
2021-11-23 09:37:36,987 - INFO - joeynmt.training - Example #1
2021-11-23 09:37:36,987 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:37:36,987 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:37:36,987 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:37:36,987 - INFO - joeynmt.training - Example #2
2021-11-23 09:37:36,987 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:37:36,987 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:37:36,987 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 09:37:36,987 - INFO - joeynmt.training - Example #3
2021-11-23 09:37:36,987 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:37:36,987 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:37:36,987 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'fe', 'ito']
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:37:36,987 - INFO - joeynmt.training - 	Hypothesis: ▁de fe ito
2021-11-23 09:37:36,987 - INFO - joeynmt.training - Example #6
2021-11-23 09:37:36,988 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:37:36,988 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:37:36,988 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:37:36,988 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:37:36,988 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:37:36,988 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:37:36,988 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:37:36,988 - INFO - joeynmt.training - Validation result (greedy) at epoch  44, step   149000: bleu:  12.10, loss: 75536.7969, ppl:   9.3035, duration: 112.3483s
2021-11-23 09:37:51,434 - INFO - joeynmt.training - Epoch  44, Step:   149100, Batch Loss:     2.127995, Tokens per Sec:     2219, Lr: 0.000100
2021-11-23 09:37:53,739 - INFO - joeynmt.training - Epoch  44: total training loss 6971.93
2021-11-23 09:37:53,740 - INFO - joeynmt.training - EPOCH 45
2021-11-23 09:38:05,454 - INFO - joeynmt.training - Epoch  45, Step:   149200, Batch Loss:     1.948446, Tokens per Sec:     2297, Lr: 0.000100
2021-11-23 09:38:20,110 - INFO - joeynmt.training - Epoch  45, Step:   149300, Batch Loss:     1.937674, Tokens per Sec:     2104, Lr: 0.000100
2021-11-23 09:38:34,182 - INFO - joeynmt.training - Epoch  45, Step:   149400, Batch Loss:     2.381248, Tokens per Sec:     2191, Lr: 0.000100
2021-11-23 09:38:48,748 - INFO - joeynmt.training - Epoch  45, Step:   149500, Batch Loss:     1.892351, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 09:39:04,549 - INFO - joeynmt.training - Epoch  45, Step:   149600, Batch Loss:     2.031731, Tokens per Sec:     2062, Lr: 0.000100
2021-11-23 09:39:18,108 - INFO - joeynmt.training - Epoch  45, Step:   149700, Batch Loss:     1.861671, Tokens per Sec:     2184, Lr: 0.000100
2021-11-23 09:39:33,793 - INFO - joeynmt.training - Epoch  45, Step:   149800, Batch Loss:     2.114937, Tokens per Sec:     2064, Lr: 0.000100
2021-11-23 09:39:48,512 - INFO - joeynmt.training - Epoch  45, Step:   149900, Batch Loss:     1.885531, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 09:40:02,950 - INFO - joeynmt.training - Epoch  45, Step:   150000, Batch Loss:     2.018161, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 09:42:06,618 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:42:06,618 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:42:06,619 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:42:06,636 - INFO - joeynmt.training - Example #0
2021-11-23 09:42:06,636 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:42:06,636 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:42:06,636 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁there', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁of', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 09:42:06,636 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:42:06,636 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁there , ▁you ▁were ▁f av or ▁of ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁follow ed ▁all ▁his ▁follow ers ▁and ▁all ▁the ▁wall s .
2021-11-23 09:42:06,637 - INFO - joeynmt.training - Example #1
2021-11-23 09:42:06,637 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:42:06,637 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:42:06,637 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:42:06,637 - INFO - joeynmt.training - Example #2
2021-11-23 09:42:06,637 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:42:06,637 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:42:06,637 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 09:42:06,637 - INFO - joeynmt.training - Example #3
2021-11-23 09:42:06,637 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:42:06,637 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:42:06,637 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'ista']
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:42:06,637 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:42:06,638 - INFO - joeynmt.training - 	Hypothesis: ▁d er v ista
2021-11-23 09:42:06,638 - INFO - joeynmt.training - Example #6
2021-11-23 09:42:06,638 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:42:06,638 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:42:06,638 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:42:06,638 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:42:06,638 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:42:06,638 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:42:06,638 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:42:06,638 - INFO - joeynmt.training - Validation result (greedy) at epoch  45, step   150000: bleu:  11.96, loss: 75548.7422, ppl:   9.3068, duration: 123.6877s
2021-11-23 09:42:20,366 - INFO - joeynmt.training - Epoch  45, Step:   150100, Batch Loss:     2.176608, Tokens per Sec:     2235, Lr: 0.000100
2021-11-23 09:42:34,314 - INFO - joeynmt.training - Epoch  45, Step:   150200, Batch Loss:     2.145984, Tokens per Sec:     2126, Lr: 0.000100
2021-11-23 09:42:48,822 - INFO - joeynmt.training - Epoch  45, Step:   150300, Batch Loss:     2.065178, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 09:43:03,752 - INFO - joeynmt.training - Epoch  45, Step:   150400, Batch Loss:     1.877161, Tokens per Sec:     2074, Lr: 0.000100
2021-11-23 09:43:19,158 - INFO - joeynmt.training - Epoch  45, Step:   150500, Batch Loss:     1.735481, Tokens per Sec:     2051, Lr: 0.000100
2021-11-23 09:43:34,916 - INFO - joeynmt.training - Epoch  45, Step:   150600, Batch Loss:     1.980784, Tokens per Sec:     1994, Lr: 0.000100
2021-11-23 09:43:49,272 - INFO - joeynmt.training - Epoch  45, Step:   150700, Batch Loss:     2.069858, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 09:44:03,502 - INFO - joeynmt.training - Epoch  45, Step:   150800, Batch Loss:     2.020073, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 09:44:18,503 - INFO - joeynmt.training - Epoch  45, Step:   150900, Batch Loss:     1.904998, Tokens per Sec:     2104, Lr: 0.000100
2021-11-23 09:44:33,091 - INFO - joeynmt.training - Epoch  45, Step:   151000, Batch Loss:     1.954022, Tokens per Sec:     2182, Lr: 0.000100
2021-11-23 09:46:43,940 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:46:43,940 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:46:43,940 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:46:43,957 - INFO - joeynmt.training - Example #0
2021-11-23 09:46:43,958 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:46:43,958 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:46:43,958 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁af', 'raid', '▁of', '▁Judah', ',', '▁you', '▁follow', 'ed', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁one', '▁of', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁sh', 'atter', 'ed', '.']
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁af raid ▁of ▁Judah , ▁you ▁follow ed ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁one ▁of ▁your ▁follow ers , ▁and ▁all ▁your ▁follow ers ▁are ▁all ▁the ▁sh atter ed .
2021-11-23 09:46:43,958 - INFO - joeynmt.training - Example #1
2021-11-23 09:46:43,958 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:46:43,958 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:46:43,958 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:46:43,958 - INFO - joeynmt.training - Example #2
2021-11-23 09:46:43,958 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:46:43,958 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:46:43,958 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:46:43,958 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 09:46:43,959 - INFO - joeynmt.training - Example #3
2021-11-23 09:46:43,959 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:46:43,959 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:46:43,959 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁C', 'AR', 'T', 'AR']
2021-11-23 09:46:43,959 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:46:43,959 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:46:43,959 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:46:43,959 - INFO - joeynmt.training - 	Hypothesis: ▁C AR T AR
2021-11-23 09:46:43,959 - INFO - joeynmt.training - Example #6
2021-11-23 09:46:43,959 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:46:43,959 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:46:43,959 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:46:43,959 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:46:43,959 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:46:43,959 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:46:43,959 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:46:43,959 - INFO - joeynmt.training - Validation result (greedy) at epoch  45, step   151000: bleu:  12.30, loss: 75502.1875, ppl:   9.2940, duration: 130.8679s
2021-11-23 09:46:59,076 - INFO - joeynmt.training - Epoch  45, Step:   151100, Batch Loss:     2.143291, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 09:47:13,575 - INFO - joeynmt.training - Epoch  45, Step:   151200, Batch Loss:     2.222978, Tokens per Sec:     2124, Lr: 0.000100
2021-11-23 09:47:28,336 - INFO - joeynmt.training - Epoch  45, Step:   151300, Batch Loss:     2.056388, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 09:47:42,432 - INFO - joeynmt.training - Epoch  45, Step:   151400, Batch Loss:     2.432164, Tokens per Sec:     2198, Lr: 0.000100
2021-11-23 09:47:56,789 - INFO - joeynmt.training - Epoch  45, Step:   151500, Batch Loss:     1.976899, Tokens per Sec:     2200, Lr: 0.000100
2021-11-23 09:48:11,652 - INFO - joeynmt.training - Epoch  45, Step:   151600, Batch Loss:     1.890849, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 09:48:26,693 - INFO - joeynmt.training - Epoch  45, Step:   151700, Batch Loss:     1.977091, Tokens per Sec:     2018, Lr: 0.000100
2021-11-23 09:48:41,717 - INFO - joeynmt.training - Epoch  45, Step:   151800, Batch Loss:     1.854110, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 09:48:56,583 - INFO - joeynmt.training - Epoch  45, Step:   151900, Batch Loss:     2.138052, Tokens per Sec:     2196, Lr: 0.000100
2021-11-23 09:49:10,863 - INFO - joeynmt.training - Epoch  45, Step:   152000, Batch Loss:     2.170138, Tokens per Sec:     2236, Lr: 0.000100
2021-11-23 09:51:14,913 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:51:14,914 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:51:14,914 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:51:14,925 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 09:51:15,734 - INFO - joeynmt.helpers - delete models/baseline_multilingual/146000.ckpt
2021-11-23 09:51:15,734 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/146000.ckpt
2021-11-23 09:51:15,735 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/146000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/146000.ckpt')
2021-11-23 09:51:15,788 - INFO - joeynmt.training - Example #0
2021-11-23 09:51:15,788 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:51:15,788 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:51:15,788 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁there', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁of', '▁Judah', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁all', '▁over', 'w', 'he', 'l', 'm', '.']
2021-11-23 09:51:15,788 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:51:15,789 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:51:15,789 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:51:15,789 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁there , ▁you ▁were ▁f av or ▁of ▁Judah . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁follow ed ▁all ▁his ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁all ▁over w he l m .
2021-11-23 09:51:15,789 - INFO - joeynmt.training - Example #1
2021-11-23 09:51:15,789 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:51:15,789 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:51:15,789 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:51:15,789 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:51:15,789 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:51:15,789 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:51:15,790 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:51:15,790 - INFO - joeynmt.training - Example #2
2021-11-23 09:51:15,790 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:51:15,790 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:51:15,790 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁you', '▁have', '▁a', 'ct', 'u', 'ally', '▁faith', 'ful', '▁work', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 09:51:15,790 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:51:15,790 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:51:15,790 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:51:15,790 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁you ▁have ▁a ct u ally ▁faith ful ▁work ▁with ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 09:51:15,791 - INFO - joeynmt.training - Example #3
2021-11-23 09:51:15,791 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:51:15,791 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:51:15,791 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 09:51:15,791 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:51:15,791 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:51:15,791 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:51:15,791 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 09:51:15,791 - INFO - joeynmt.training - Example #6
2021-11-23 09:51:15,791 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:51:15,792 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:51:15,792 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:51:15,792 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:51:15,792 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:51:15,792 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:51:15,792 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:51:15,792 - INFO - joeynmt.training - Validation result (greedy) at epoch  45, step   152000: bleu:  12.51, loss: 74941.2891, ppl:   9.1414, duration: 124.9292s
2021-11-23 09:51:31,087 - INFO - joeynmt.training - Epoch  45, Step:   152100, Batch Loss:     2.367423, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 09:51:45,794 - INFO - joeynmt.training - Epoch  45, Step:   152200, Batch Loss:     1.926583, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 09:52:00,047 - INFO - joeynmt.training - Epoch  45, Step:   152300, Batch Loss:     1.846001, Tokens per Sec:     2200, Lr: 0.000100
2021-11-23 09:52:14,737 - INFO - joeynmt.training - Epoch  45, Step:   152400, Batch Loss:     1.940413, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 09:52:29,627 - INFO - joeynmt.training - Epoch  45, Step:   152500, Batch Loss:     2.230038, Tokens per Sec:     2165, Lr: 0.000100
2021-11-23 09:52:30,215 - INFO - joeynmt.training - Epoch  45: total training loss 6927.01
2021-11-23 09:52:30,216 - INFO - joeynmt.training - EPOCH 46
2021-11-23 09:52:44,033 - INFO - joeynmt.training - Epoch  46, Step:   152600, Batch Loss:     1.863863, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 09:52:59,198 - INFO - joeynmt.training - Epoch  46, Step:   152700, Batch Loss:     2.078133, Tokens per Sec:     2079, Lr: 0.000100
2021-11-23 09:53:14,000 - INFO - joeynmt.training - Epoch  46, Step:   152800, Batch Loss:     1.987274, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 09:53:28,467 - INFO - joeynmt.training - Epoch  46, Step:   152900, Batch Loss:     1.970615, Tokens per Sec:     2193, Lr: 0.000100
2021-11-23 09:53:42,576 - INFO - joeynmt.training - Epoch  46, Step:   153000, Batch Loss:     2.052842, Tokens per Sec:     2193, Lr: 0.000100
2021-11-23 09:55:53,166 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 09:55:53,167 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 09:55:53,167 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 09:55:53,184 - INFO - joeynmt.training - Example #0
2021-11-23 09:55:53,185 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 09:55:53,185 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 09:55:53,185 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁and', '▁you', '▁are', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁follow', 'ing', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁sc', 'atter', 'ed', '.']
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁have ▁been ▁count ed , ▁and ▁you ▁are ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁follow ing ▁your ▁follow ers , ▁and ▁all ▁your ▁follow ers ▁are ▁all ▁the ▁sc atter ed .
2021-11-23 09:55:53,185 - INFO - joeynmt.training - Example #1
2021-11-23 09:55:53,185 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 09:55:53,185 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 09:55:53,185 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 09:55:53,185 - INFO - joeynmt.training - Example #2
2021-11-23 09:55:53,185 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 09:55:53,185 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 09:55:53,185 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 09:55:53,185 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 09:55:53,186 - INFO - joeynmt.training - Example #3
2021-11-23 09:55:53,186 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 09:55:53,186 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 09:55:53,186 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'oso']
2021-11-23 09:55:53,186 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 09:55:53,186 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 09:55:53,186 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 09:55:53,186 - INFO - joeynmt.training - 	Hypothesis: ▁d er v oso
2021-11-23 09:55:53,186 - INFO - joeynmt.training - Example #6
2021-11-23 09:55:53,186 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 09:55:53,186 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 09:55:53,186 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 09:55:53,186 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 09:55:53,186 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 09:55:53,186 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 09:55:53,186 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 09:55:53,186 - INFO - joeynmt.training - Validation result (greedy) at epoch  46, step   153000: bleu:  12.42, loss: 75319.2422, ppl:   9.2440, duration: 130.6096s
2021-11-23 09:56:08,296 - INFO - joeynmt.training - Epoch  46, Step:   153100, Batch Loss:     2.014965, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 09:56:22,898 - INFO - joeynmt.training - Epoch  46, Step:   153200, Batch Loss:     2.010765, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 09:56:37,352 - INFO - joeynmt.training - Epoch  46, Step:   153300, Batch Loss:     1.932534, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 09:56:52,686 - INFO - joeynmt.training - Epoch  46, Step:   153400, Batch Loss:     1.887730, Tokens per Sec:     2088, Lr: 0.000100
2021-11-23 09:57:07,377 - INFO - joeynmt.training - Epoch  46, Step:   153500, Batch Loss:     1.991642, Tokens per Sec:     2060, Lr: 0.000100
2021-11-23 09:57:21,741 - INFO - joeynmt.training - Epoch  46, Step:   153600, Batch Loss:     1.954218, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 09:57:36,621 - INFO - joeynmt.training - Epoch  46, Step:   153700, Batch Loss:     2.143935, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 09:57:51,064 - INFO - joeynmt.training - Epoch  46, Step:   153800, Batch Loss:     1.891018, Tokens per Sec:     2204, Lr: 0.000100
2021-11-23 09:58:05,095 - INFO - joeynmt.training - Epoch  46, Step:   153900, Batch Loss:     1.887251, Tokens per Sec:     2185, Lr: 0.000100
2021-11-23 09:58:20,057 - INFO - joeynmt.training - Epoch  46, Step:   154000, Batch Loss:     1.949323, Tokens per Sec:     2133, Lr: 0.000100
2021-11-23 10:00:05,719 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:00:05,719 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:00:05,719 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:00:05,736 - INFO - joeynmt.training - Example #0
2021-11-23 10:00:05,736 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:00:05,736 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:00:05,736 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁time', ',', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁one', '▁of', '▁the', '▁people', '▁follow', 'ed', '▁him', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁all', '▁over', 'c', 'ome', '.']
2021-11-23 10:00:05,736 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:00:05,736 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:00:05,736 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:00:05,736 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁time , ▁you ▁were ▁count ed ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁one ▁of ▁the ▁people ▁follow ed ▁him , ▁and ▁all ▁his ▁follow ers ▁were ▁all ▁over c ome .
2021-11-23 10:00:05,736 - INFO - joeynmt.training - Example #1
2021-11-23 10:00:05,736 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:00:05,736 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:00:05,736 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:00:05,736 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:00:05,737 - INFO - joeynmt.training - Example #2
2021-11-23 10:00:05,737 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:00:05,737 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:00:05,737 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', 'e', 'ver', ',', '▁love', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁with', '▁one', '▁another', '.']
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how e ver , ▁love ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁with ▁one ▁another .
2021-11-23 10:00:05,737 - INFO - joeynmt.training - Example #3
2021-11-23 10:00:05,737 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:00:05,737 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:00:05,737 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 10:00:05,737 - INFO - joeynmt.training - Example #6
2021-11-23 10:00:05,737 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:00:05,737 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:00:05,737 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:00:05,737 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:00:05,738 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 10:00:05,738 - INFO - joeynmt.training - Validation result (greedy) at epoch  46, step   154000: bleu:  12.50, loss: 75342.9844, ppl:   9.2505, duration: 105.6800s
2021-11-23 10:00:20,231 - INFO - joeynmt.training - Epoch  46, Step:   154100, Batch Loss:     1.993874, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 10:00:34,775 - INFO - joeynmt.training - Epoch  46, Step:   154200, Batch Loss:     1.996740, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 10:00:49,635 - INFO - joeynmt.training - Epoch  46, Step:   154300, Batch Loss:     1.989772, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 10:01:04,182 - INFO - joeynmt.training - Epoch  46, Step:   154400, Batch Loss:     1.813784, Tokens per Sec:     2220, Lr: 0.000100
2021-11-23 10:01:18,347 - INFO - joeynmt.training - Epoch  46, Step:   154500, Batch Loss:     1.980900, Tokens per Sec:     2210, Lr: 0.000100
2021-11-23 10:01:32,572 - INFO - joeynmt.training - Epoch  46, Step:   154600, Batch Loss:     1.793643, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 10:01:47,110 - INFO - joeynmt.training - Epoch  46, Step:   154700, Batch Loss:     1.926172, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 10:02:01,585 - INFO - joeynmt.training - Epoch  46, Step:   154800, Batch Loss:     2.153598, Tokens per Sec:     2179, Lr: 0.000100
2021-11-23 10:02:16,144 - INFO - joeynmt.training - Epoch  46, Step:   154900, Batch Loss:     2.178897, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 10:02:31,166 - INFO - joeynmt.training - Epoch  46, Step:   155000, Batch Loss:     2.103297, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 10:04:53,989 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:04:53,989 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:04:53,989 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:04:54,008 - INFO - joeynmt.training - Example #0
2021-11-23 10:04:54,008 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:04:54,008 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:04:54,008 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'L', 'ook', ',', '▁you', '▁are', '▁per', 'se', 'c', 'ut', 'ed', '▁by', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁follow', 'ing', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁over', 'w', 'he', 'l', '.']
2021-11-23 10:04:54,008 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:04:54,008 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:04:54,008 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:04:54,008 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" L ook , ▁you ▁are ▁per se c ut ed ▁by ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁follow ing ▁your ▁follow ers , ▁and ▁all ▁your ▁follow ers ▁are ▁all ▁over w he l .
2021-11-23 10:04:54,008 - INFO - joeynmt.training - Example #1
2021-11-23 10:04:54,008 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:04:54,008 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:04:54,008 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:04:54,008 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:04:54,008 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:04:54,008 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:04:54,008 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:04:54,008 - INFO - joeynmt.training - Example #2
2021-11-23 10:04:54,008 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:04:54,009 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:04:54,009 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 10:04:54,009 - INFO - joeynmt.training - Example #3
2021-11-23 10:04:54,009 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:04:54,009 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:04:54,009 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 10:04:54,009 - INFO - joeynmt.training - Example #6
2021-11-23 10:04:54,009 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:04:54,009 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:04:54,009 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:04:54,009 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 10:04:54,009 - INFO - joeynmt.training - Validation result (greedy) at epoch  46, step   155000: bleu:  12.48, loss: 75047.1953, ppl:   9.1700, duration: 142.8426s
2021-11-23 10:05:09,426 - INFO - joeynmt.training - Epoch  46, Step:   155100, Batch Loss:     2.060099, Tokens per Sec:     2227, Lr: 0.000100
2021-11-23 10:05:24,814 - INFO - joeynmt.training - Epoch  46, Step:   155200, Batch Loss:     2.118467, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 10:05:39,291 - INFO - joeynmt.training - Epoch  46, Step:   155300, Batch Loss:     1.993159, Tokens per Sec:     2101, Lr: 0.000100
2021-11-23 10:05:53,964 - INFO - joeynmt.training - Epoch  46, Step:   155400, Batch Loss:     1.814386, Tokens per Sec:     2088, Lr: 0.000100
2021-11-23 10:06:08,105 - INFO - joeynmt.training - Epoch  46, Step:   155500, Batch Loss:     2.067650, Tokens per Sec:     2189, Lr: 0.000100
2021-11-23 10:06:23,153 - INFO - joeynmt.training - Epoch  46, Step:   155600, Batch Loss:     1.775661, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 10:06:38,648 - INFO - joeynmt.training - Epoch  46, Step:   155700, Batch Loss:     1.732576, Tokens per Sec:     2078, Lr: 0.000100
2021-11-23 10:06:53,934 - INFO - joeynmt.training - Epoch  46, Step:   155800, Batch Loss:     1.830818, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 10:07:07,117 - INFO - joeynmt.training - Epoch  46: total training loss 6882.55
2021-11-23 10:07:07,118 - INFO - joeynmt.training - EPOCH 47
2021-11-23 10:07:07,965 - INFO - joeynmt.training - Epoch  47, Step:   155900, Batch Loss:     2.018108, Tokens per Sec:     1932, Lr: 0.000100
2021-11-23 10:07:22,372 - INFO - joeynmt.training - Epoch  47, Step:   156000, Batch Loss:     2.158167, Tokens per Sec:     2214, Lr: 0.000100
2021-11-23 10:08:53,872 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:08:53,872 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:08:53,872 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:08:53,884 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 10:08:54,682 - INFO - joeynmt.helpers - delete models/baseline_multilingual/152000.ckpt
2021-11-23 10:08:54,683 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/152000.ckpt
2021-11-23 10:08:54,683 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/152000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/152000.ckpt')
2021-11-23 10:08:54,740 - INFO - joeynmt.training - Example #0
2021-11-23 10:08:54,740 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:08:54,740 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:08:54,740 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁in', '▁Jerusalem', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁but', '▁one', '▁of', '▁the', '▁other', '▁people', ',', '▁and', '▁all', '▁the', '▁follow', 'ers', '▁were', '▁all', '▁over', '▁the', '▁sh', 'ip', 'p', '.']
2021-11-23 10:08:54,740 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:08:54,741 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:08:54,741 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:08:54,741 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁in ▁Jerusalem , ▁you ▁were ▁f av or ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁follow ers , ▁but ▁one ▁of ▁the ▁other ▁people , ▁and ▁all ▁the ▁follow ers ▁were ▁all ▁over ▁the ▁sh ip p .
2021-11-23 10:08:54,741 - INFO - joeynmt.training - Example #1
2021-11-23 10:08:54,741 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:08:54,741 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:08:54,741 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:08:54,741 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:08:54,741 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:08:54,742 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:08:54,742 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:08:54,742 - INFO - joeynmt.training - Example #2
2021-11-23 10:08:54,742 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:08:54,742 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:08:54,742 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁tell', 'ing', '▁each', '▁other', '.']
2021-11-23 10:08:54,742 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:08:54,742 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:08:54,743 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:08:54,743 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁tell ing ▁each ▁other .
2021-11-23 10:08:54,743 - INFO - joeynmt.training - Example #3
2021-11-23 10:08:54,743 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:08:54,743 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:08:54,743 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'so']
2021-11-23 10:08:54,743 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:08:54,743 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:08:54,743 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:08:54,744 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur so
2021-11-23 10:08:54,744 - INFO - joeynmt.training - Example #6
2021-11-23 10:08:54,744 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:08:54,744 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:08:54,744 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 10:08:54,744 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:08:54,744 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:08:54,744 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:08:54,744 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 10:08:54,745 - INFO - joeynmt.training - Validation result (greedy) at epoch  47, step   156000: bleu:  12.84, loss: 75051.4219, ppl:   9.1712, duration: 92.3726s
2021-11-23 10:09:09,530 - INFO - joeynmt.training - Epoch  47, Step:   156100, Batch Loss:     1.983163, Tokens per Sec:     2188, Lr: 0.000100
2021-11-23 10:09:24,356 - INFO - joeynmt.training - Epoch  47, Step:   156200, Batch Loss:     1.947226, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 10:09:39,080 - INFO - joeynmt.training - Epoch  47, Step:   156300, Batch Loss:     1.753926, Tokens per Sec:     2080, Lr: 0.000100
2021-11-23 10:09:53,830 - INFO - joeynmt.training - Epoch  47, Step:   156400, Batch Loss:     1.769258, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 10:10:08,005 - INFO - joeynmt.training - Epoch  47, Step:   156500, Batch Loss:     1.770635, Tokens per Sec:     2223, Lr: 0.000100
2021-11-23 10:10:22,469 - INFO - joeynmt.training - Epoch  47, Step:   156600, Batch Loss:     2.032465, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 10:10:36,814 - INFO - joeynmt.training - Epoch  47, Step:   156700, Batch Loss:     2.090088, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 10:10:51,912 - INFO - joeynmt.training - Epoch  47, Step:   156800, Batch Loss:     1.828263, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 10:11:06,958 - INFO - joeynmt.training - Epoch  47, Step:   156900, Batch Loss:     2.115109, Tokens per Sec:     2157, Lr: 0.000100
2021-11-23 10:11:21,613 - INFO - joeynmt.training - Epoch  47, Step:   157000, Batch Loss:     1.904157, Tokens per Sec:     2173, Lr: 0.000100
2021-11-23 10:13:13,604 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:13:13,604 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:13:13,604 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:13:13,616 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 10:13:14,423 - INFO - joeynmt.helpers - delete models/baseline_multilingual/156000.ckpt
2021-11-23 10:13:14,423 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/156000.ckpt
2021-11-23 10:13:14,424 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/156000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/156000.ckpt')
2021-11-23 10:13:14,478 - INFO - joeynmt.training - Example #0
2021-11-23 10:13:14,478 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:13:14,478 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:13:14,478 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁have', '▁been', '▁count', 'ed', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁the', '▁people', '▁of', '▁the', '▁whole', '▁har', 'vest', '.']
2021-11-23 10:13:14,478 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:13:14,478 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:13:14,479 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:13:14,479 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁have ▁been ▁count ed ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁was ▁follow ing ▁all ▁his ▁follow ers ▁and ▁all ▁the ▁people ▁of ▁the ▁whole ▁har vest .
2021-11-23 10:13:14,479 - INFO - joeynmt.training - Example #1
2021-11-23 10:13:14,479 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:13:14,479 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:13:14,479 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:13:14,479 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:13:14,480 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:13:14,480 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:13:14,480 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:13:14,480 - INFO - joeynmt.training - Example #2
2021-11-23 10:13:14,480 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:13:14,480 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:13:14,481 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁and', '▁tell', '▁me', '▁what', '▁is', '▁true', '.']
2021-11-23 10:13:14,481 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:13:14,481 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:13:14,481 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:13:14,481 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁and ▁tell ▁me ▁what ▁is ▁true .
2021-11-23 10:13:14,481 - INFO - joeynmt.training - Example #3
2021-11-23 10:13:14,481 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:13:14,481 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:13:14,482 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 10:13:14,482 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:13:14,482 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:13:14,482 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:13:14,482 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 10:13:14,482 - INFO - joeynmt.training - Example #6
2021-11-23 10:13:14,482 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:13:14,482 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:13:14,482 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:13:14,482 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:13:14,482 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:13:14,482 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:13:14,482 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:13:14,482 - INFO - joeynmt.training - Validation result (greedy) at epoch  47, step   157000: bleu:  12.84, loss: 75001.0000, ppl:   9.1575, duration: 112.8693s
2021-11-23 10:13:29,347 - INFO - joeynmt.training - Epoch  47, Step:   157100, Batch Loss:     2.107352, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 10:13:43,812 - INFO - joeynmt.training - Epoch  47, Step:   157200, Batch Loss:     1.873992, Tokens per Sec:     2157, Lr: 0.000100
2021-11-23 10:13:58,559 - INFO - joeynmt.training - Epoch  47, Step:   157300, Batch Loss:     1.928821, Tokens per Sec:     2075, Lr: 0.000100
2021-11-23 10:14:12,797 - INFO - joeynmt.training - Epoch  47, Step:   157400, Batch Loss:     1.819678, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 10:14:27,053 - INFO - joeynmt.training - Epoch  47, Step:   157500, Batch Loss:     1.838303, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 10:14:41,493 - INFO - joeynmt.training - Epoch  47, Step:   157600, Batch Loss:     2.002379, Tokens per Sec:     2173, Lr: 0.000100
2021-11-23 10:14:56,616 - INFO - joeynmt.training - Epoch  47, Step:   157700, Batch Loss:     2.336097, Tokens per Sec:     2059, Lr: 0.000100
2021-11-23 10:15:11,886 - INFO - joeynmt.training - Epoch  47, Step:   157800, Batch Loss:     2.042223, Tokens per Sec:     2069, Lr: 0.000100
2021-11-23 10:15:26,601 - INFO - joeynmt.training - Epoch  47, Step:   157900, Batch Loss:     2.095146, Tokens per Sec:     2224, Lr: 0.000100
2021-11-23 10:15:41,830 - INFO - joeynmt.training - Epoch  47, Step:   158000, Batch Loss:     2.124501, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 10:17:24,544 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:17:24,544 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:17:24,544 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:17:24,557 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 10:17:25,368 - INFO - joeynmt.helpers - delete models/baseline_multilingual/157000.ckpt
2021-11-23 10:17:25,369 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/157000.ckpt
2021-11-23 10:17:25,369 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/157000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/157000.ckpt')
2021-11-23 10:17:25,427 - INFO - joeynmt.training - Example #0
2021-11-23 10:17:25,427 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:17:25,427 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:17:25,428 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁were', '▁count', 'ry', 'ing', '▁for', '▁Jerusalem', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 10:17:25,428 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:17:25,428 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:17:25,428 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:17:25,428 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁were ▁count ry ing ▁for ▁Jerusalem . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁was ▁follow ing ▁all ▁his ▁follow ers ▁and ▁all ▁the ▁wall s .
2021-11-23 10:17:25,428 - INFO - joeynmt.training - Example #1
2021-11-23 10:17:25,428 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:17:25,428 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:17:25,429 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 10:17:25,429 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:17:25,429 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:17:25,429 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:17:25,429 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 10:17:25,429 - INFO - joeynmt.training - Example #2
2021-11-23 10:17:25,429 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:17:25,429 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:17:25,429 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁we', '▁have', '▁the', '▁end', '▁of', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 10:17:25,429 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:17:25,429 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:17:25,430 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:17:25,430 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁we ▁have ▁the ▁end ▁of ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 10:17:25,430 - INFO - joeynmt.training - Example #3
2021-11-23 10:17:25,430 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:17:25,430 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:17:25,430 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'oso']
2021-11-23 10:17:25,430 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:17:25,430 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:17:25,430 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:17:25,430 - INFO - joeynmt.training - 	Hypothesis: ▁d er v oso
2021-11-23 10:17:25,431 - INFO - joeynmt.training - Example #6
2021-11-23 10:17:25,431 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:17:25,431 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:17:25,431 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:17:25,431 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:17:25,431 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:17:25,431 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:17:25,431 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:17:25,431 - INFO - joeynmt.training - Validation result (greedy) at epoch  47, step   158000: bleu:  12.99, loss: 74601.0078, ppl:   9.0500, duration: 103.6005s
2021-11-23 10:17:40,162 - INFO - joeynmt.training - Epoch  47, Step:   158100, Batch Loss:     1.867285, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 10:17:54,630 - INFO - joeynmt.training - Epoch  47, Step:   158200, Batch Loss:     2.123602, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 10:18:09,566 - INFO - joeynmt.training - Epoch  47, Step:   158300, Batch Loss:     2.110140, Tokens per Sec:     2100, Lr: 0.000100
2021-11-23 10:18:24,465 - INFO - joeynmt.training - Epoch  47, Step:   158400, Batch Loss:     1.895676, Tokens per Sec:     2055, Lr: 0.000100
2021-11-23 10:18:40,003 - INFO - joeynmt.training - Epoch  47, Step:   158500, Batch Loss:     1.787271, Tokens per Sec:     2039, Lr: 0.000100
2021-11-23 10:18:54,686 - INFO - joeynmt.training - Epoch  47, Step:   158600, Batch Loss:     2.306979, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 10:19:09,706 - INFO - joeynmt.training - Epoch  47, Step:   158700, Batch Loss:     1.824548, Tokens per Sec:     2133, Lr: 0.000100
2021-11-23 10:19:23,507 - INFO - joeynmt.training - Epoch  47, Step:   158800, Batch Loss:     2.240025, Tokens per Sec:     2222, Lr: 0.000100
2021-11-23 10:19:37,953 - INFO - joeynmt.training - Epoch  47, Step:   158900, Batch Loss:     2.246467, Tokens per Sec:     2236, Lr: 0.000100
2021-11-23 10:19:52,724 - INFO - joeynmt.training - Epoch  47, Step:   159000, Batch Loss:     2.012184, Tokens per Sec:     2033, Lr: 0.000100
2021-11-23 10:21:46,602 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:21:46,602 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:21:46,602 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:21:46,618 - INFO - joeynmt.training - Example #0
2021-11-23 10:21:46,619 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:21:46,619 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:21:46,619 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁f', 'ive', '▁tim', 'es', '▁of', '▁Jud', 'e', 'a', ',', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁over', 'w', 'he', 'l', '.']
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁f ive ▁tim es ▁of ▁Jud e a , ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁follow ed ▁the ▁follow ers , ▁and ▁all ▁your ▁follow ers ▁are ▁all ▁over w he l .
2021-11-23 10:21:46,619 - INFO - joeynmt.training - Example #1
2021-11-23 10:21:46,619 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:21:46,619 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:21:46,619 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'u', 'il', 'her', 'me']
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Hypothesis: ▁G u il her me
2021-11-23 10:21:46,619 - INFO - joeynmt.training - Example #2
2021-11-23 10:21:46,619 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:21:46,619 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:21:46,619 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:21:46,619 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:21:46,620 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 10:21:46,620 - INFO - joeynmt.training - Example #3
2021-11-23 10:21:46,620 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:21:46,620 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:21:46,620 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 10:21:46,620 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:21:46,620 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:21:46,620 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:21:46,620 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 10:21:46,620 - INFO - joeynmt.training - Example #6
2021-11-23 10:21:46,620 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:21:46,620 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:21:46,620 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 10:21:46,620 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:21:46,620 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:21:46,620 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:21:46,620 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 10:21:46,620 - INFO - joeynmt.training - Validation result (greedy) at epoch  47, step   159000: bleu:  12.67, loss: 74621.1953, ppl:   9.0554, duration: 113.8957s
2021-11-23 10:22:00,693 - INFO - joeynmt.training - Epoch  47, Step:   159100, Batch Loss:     2.062585, Tokens per Sec:     2133, Lr: 0.000100
2021-11-23 10:22:15,151 - INFO - joeynmt.training - Epoch  47, Step:   159200, Batch Loss:     2.059416, Tokens per Sec:     2232, Lr: 0.000100
2021-11-23 10:22:27,169 - INFO - joeynmt.training - Epoch  47: total training loss 6833.13
2021-11-23 10:22:27,169 - INFO - joeynmt.training - EPOCH 48
2021-11-23 10:22:29,599 - INFO - joeynmt.training - Epoch  48, Step:   159300, Batch Loss:     1.819535, Tokens per Sec:     2028, Lr: 0.000100
2021-11-23 10:22:44,133 - INFO - joeynmt.training - Epoch  48, Step:   159400, Batch Loss:     1.686960, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 10:22:58,791 - INFO - joeynmt.training - Epoch  48, Step:   159500, Batch Loss:     2.216527, Tokens per Sec:     2184, Lr: 0.000100
2021-11-23 10:23:12,528 - INFO - joeynmt.training - Epoch  48, Step:   159600, Batch Loss:     2.077405, Tokens per Sec:     2205, Lr: 0.000100
2021-11-23 10:23:27,380 - INFO - joeynmt.training - Epoch  48, Step:   159700, Batch Loss:     1.907200, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 10:23:41,894 - INFO - joeynmt.training - Epoch  48, Step:   159800, Batch Loss:     1.935113, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 10:23:56,967 - INFO - joeynmt.training - Epoch  48, Step:   159900, Batch Loss:     2.006357, Tokens per Sec:     2104, Lr: 0.000100
2021-11-23 10:24:11,077 - INFO - joeynmt.training - Epoch  48, Step:   160000, Batch Loss:     2.017689, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 10:26:05,133 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:26:05,133 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:26:05,133 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:26:05,150 - INFO - joeynmt.training - Example #0
2021-11-23 10:26:05,150 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:26:05,150 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:26:05,150 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁time', ',', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁was', '▁follow', 'ing', '▁the', '▁one', '▁who', '▁had', '▁been', '▁follow', 'ing', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 10:26:05,150 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:26:05,150 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:26:05,150 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁time , ▁you ▁were ▁count ed ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁was ▁follow ing ▁the ▁one ▁who ▁had ▁been ▁follow ing ▁his ▁follow ers ▁and ▁all ▁his ▁follow ers .
2021-11-23 10:26:05,151 - INFO - joeynmt.training - Example #1
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:26:05,151 - INFO - joeynmt.training - Example #2
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 10:26:05,151 - INFO - joeynmt.training - Example #3
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:26:05,151 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 10:26:05,151 - INFO - joeynmt.training - Example #6
2021-11-23 10:26:05,151 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:26:05,152 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:26:05,152 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:26:05,152 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:26:05,152 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:26:05,152 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:26:05,152 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:26:05,152 - INFO - joeynmt.training - Validation result (greedy) at epoch  48, step   160000: bleu:  12.73, loss: 74761.8516, ppl:   9.0931, duration: 114.0738s
2021-11-23 10:26:20,207 - INFO - joeynmt.training - Epoch  48, Step:   160100, Batch Loss:     1.641289, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 10:26:34,636 - INFO - joeynmt.training - Epoch  48, Step:   160200, Batch Loss:     2.049601, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 10:26:49,325 - INFO - joeynmt.training - Epoch  48, Step:   160300, Batch Loss:     2.328332, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 10:27:03,521 - INFO - joeynmt.training - Epoch  48, Step:   160400, Batch Loss:     2.049866, Tokens per Sec:     2225, Lr: 0.000100
2021-11-23 10:27:18,860 - INFO - joeynmt.training - Epoch  48, Step:   160500, Batch Loss:     2.004337, Tokens per Sec:     2067, Lr: 0.000100
2021-11-23 10:27:33,218 - INFO - joeynmt.training - Epoch  48, Step:   160600, Batch Loss:     1.915450, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 10:27:48,898 - INFO - joeynmt.training - Epoch  48, Step:   160700, Batch Loss:     1.917930, Tokens per Sec:     2068, Lr: 0.000100
2021-11-23 10:28:03,662 - INFO - joeynmt.training - Epoch  48, Step:   160800, Batch Loss:     1.947406, Tokens per Sec:     2084, Lr: 0.000100
2021-11-23 10:28:18,350 - INFO - joeynmt.training - Epoch  48, Step:   160900, Batch Loss:     1.690915, Tokens per Sec:     2236, Lr: 0.000100
2021-11-23 10:28:32,590 - INFO - joeynmt.training - Epoch  48, Step:   161000, Batch Loss:     1.891151, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 10:30:23,153 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:30:23,153 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:30:23,153 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:30:23,170 - INFO - joeynmt.training - Example #0
2021-11-23 10:30:23,170 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:30:23,170 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:30:23,170 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁there', ',', '▁you', '▁were', '▁n', 'um', 'ber', '▁of', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁one', '▁who', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 10:30:23,170 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:30:23,170 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:30:23,170 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:30:23,170 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁there , ▁you ▁were ▁n um ber ▁of ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁you ▁are ▁follow ing ▁the ▁one ▁who ▁follow ed ▁all ▁his ▁follow ers .
2021-11-23 10:30:23,170 - INFO - joeynmt.training - Example #1
2021-11-23 10:30:23,170 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:30:23,170 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:30:23,170 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:30:23,170 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:30:23,170 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:30:23,170 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:30:23,170 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:30:23,170 - INFO - joeynmt.training - Example #2
2021-11-23 10:30:23,170 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:30:23,171 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:30:23,171 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', 'er', '▁than', 'k', ',', '▁how', 'e', 'ver', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁understand', 'ing', '.']
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great er ▁than k , ▁how e ver , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁understand ing .
2021-11-23 10:30:23,171 - INFO - joeynmt.training - Example #3
2021-11-23 10:30:23,171 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:30:23,171 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:30:23,171 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 10:30:23,171 - INFO - joeynmt.training - Example #6
2021-11-23 10:30:23,171 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:30:23,171 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:30:23,171 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:30:23,171 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:30:23,171 - INFO - joeynmt.training - Validation result (greedy) at epoch  48, step   161000: bleu:  12.61, loss: 74624.4297, ppl:   9.0563, duration: 110.5812s
2021-11-23 10:30:38,266 - INFO - joeynmt.training - Epoch  48, Step:   161100, Batch Loss:     1.734635, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 10:30:53,055 - INFO - joeynmt.training - Epoch  48, Step:   161200, Batch Loss:     2.353016, Tokens per Sec:     2190, Lr: 0.000100
2021-11-23 10:31:07,187 - INFO - joeynmt.training - Epoch  48, Step:   161300, Batch Loss:     2.039740, Tokens per Sec:     2309, Lr: 0.000100
2021-11-23 10:31:21,710 - INFO - joeynmt.training - Epoch  48, Step:   161400, Batch Loss:     1.927260, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 10:31:36,740 - INFO - joeynmt.training - Epoch  48, Step:   161500, Batch Loss:     2.060428, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 10:31:51,726 - INFO - joeynmt.training - Epoch  48, Step:   161600, Batch Loss:     1.852298, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 10:32:06,886 - INFO - joeynmt.training - Epoch  48, Step:   161700, Batch Loss:     1.984591, Tokens per Sec:     2069, Lr: 0.000100
2021-11-23 10:32:21,252 - INFO - joeynmt.training - Epoch  48, Step:   161800, Batch Loss:     1.821411, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 10:32:36,573 - INFO - joeynmt.training - Epoch  48, Step:   161900, Batch Loss:     1.824326, Tokens per Sec:     2077, Lr: 0.000100
2021-11-23 10:32:51,384 - INFO - joeynmt.training - Epoch  48, Step:   162000, Batch Loss:     2.051161, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 10:34:33,654 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:34:33,654 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:34:33,654 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:34:33,666 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 10:34:34,474 - INFO - joeynmt.helpers - delete models/baseline_multilingual/158000.ckpt
2021-11-23 10:34:34,474 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/158000.ckpt
2021-11-23 10:34:34,474 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/158000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/158000.ckpt')
2021-11-23 10:34:34,531 - INFO - joeynmt.training - Example #0
2021-11-23 10:34:34,531 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:34:34,531 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:34:34,531 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁per', 'se', 'c', 'ut', 'ed', ',', '▁you', '▁were', '▁cir', 'c', 'um', 'c', 'ised', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 10:34:34,531 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:34:34,532 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:34:34,532 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:34:34,532 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁per se c ut ed , ▁you ▁were ▁cir c um c ised ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁the ▁wall s .
2021-11-23 10:34:34,532 - INFO - joeynmt.training - Example #1
2021-11-23 10:34:34,532 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:34:34,532 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:34:34,533 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 10:34:34,533 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:34:34,533 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:34:34,533 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:34:34,533 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 10:34:34,533 - INFO - joeynmt.training - Example #2
2021-11-23 10:34:34,533 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:34:34,534 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:34:34,534 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁I', '▁have', '▁the', '▁end', '▁of', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 10:34:34,534 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:34:34,534 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:34:34,534 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:34:34,534 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁I ▁have ▁the ▁end ▁of ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 10:34:34,534 - INFO - joeynmt.training - Example #3
2021-11-23 10:34:34,535 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:34:34,535 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:34:34,535 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 10:34:34,535 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:34:34,535 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:34:34,535 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:34:34,535 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 10:34:34,535 - INFO - joeynmt.training - Example #6
2021-11-23 10:34:34,536 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:34:34,536 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:34:34,536 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:34:34,536 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:34:34,536 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:34:34,536 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:34:34,536 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:34:34,537 - INFO - joeynmt.training - Validation result (greedy) at epoch  48, step   162000: bleu:  13.17, loss: 74547.8125, ppl:   9.0358, duration: 103.1518s
2021-11-23 10:34:49,190 - INFO - joeynmt.training - Epoch  48, Step:   162100, Batch Loss:     2.122527, Tokens per Sec:     2143, Lr: 0.000100
2021-11-23 10:35:03,167 - INFO - joeynmt.training - Epoch  48, Step:   162200, Batch Loss:     2.170415, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 10:35:18,467 - INFO - joeynmt.training - Epoch  48, Step:   162300, Batch Loss:     1.900631, Tokens per Sec:     2057, Lr: 0.000100
2021-11-23 10:35:32,705 - INFO - joeynmt.training - Epoch  48, Step:   162400, Batch Loss:     1.913813, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 10:35:47,472 - INFO - joeynmt.training - Epoch  48, Step:   162500, Batch Loss:     1.913856, Tokens per Sec:     2201, Lr: 0.000100
2021-11-23 10:36:01,278 - INFO - joeynmt.training - Epoch  48, Step:   162600, Batch Loss:     1.757002, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 10:36:11,233 - INFO - joeynmt.training - Epoch  48: total training loss 6799.65
2021-11-23 10:36:11,233 - INFO - joeynmt.training - EPOCH 49
2021-11-23 10:36:15,495 - INFO - joeynmt.training - Epoch  49, Step:   162700, Batch Loss:     1.955148, Tokens per Sec:     2206, Lr: 0.000100
2021-11-23 10:36:29,906 - INFO - joeynmt.training - Epoch  49, Step:   162800, Batch Loss:     2.015832, Tokens per Sec:     2101, Lr: 0.000100
2021-11-23 10:36:44,699 - INFO - joeynmt.training - Epoch  49, Step:   162900, Batch Loss:     2.113690, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 10:36:59,218 - INFO - joeynmt.training - Epoch  49, Step:   163000, Batch Loss:     1.912793, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 10:39:12,165 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:39:12,165 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:39:12,165 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:39:12,184 - INFO - joeynmt.training - Example #0
2021-11-23 10:39:12,184 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:39:12,184 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:39:12,184 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁there', ',', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁there , ▁you ▁were ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁other ▁follow ers , ▁and ▁all ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 10:39:12,185 - INFO - joeynmt.training - Example #1
2021-11-23 10:39:12,185 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:39:12,185 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:39:12,185 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:39:12,185 - INFO - joeynmt.training - Example #2
2021-11-23 10:39:12,185 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:39:12,185 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:39:12,185 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁one', '▁another', '▁another', '.']
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:39:12,185 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁each ▁other , ▁one ▁another ▁another .
2021-11-23 10:39:12,185 - INFO - joeynmt.training - Example #3
2021-11-23 10:39:12,185 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:39:12,185 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:39:12,185 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'fe', 'ito']
2021-11-23 10:39:12,186 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:39:12,186 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:39:12,186 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:39:12,186 - INFO - joeynmt.training - 	Hypothesis: ▁de fe ito
2021-11-23 10:39:12,186 - INFO - joeynmt.training - Example #6
2021-11-23 10:39:12,186 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:39:12,186 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:39:12,186 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:39:12,186 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:39:12,186 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:39:12,186 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:39:12,186 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:39:12,186 - INFO - joeynmt.training - Validation result (greedy) at epoch  49, step   163000: bleu:  13.12, loss: 74810.1797, ppl:   9.1061, duration: 132.9677s
2021-11-23 10:39:27,858 - INFO - joeynmt.training - Epoch  49, Step:   163100, Batch Loss:     2.260554, Tokens per Sec:     2038, Lr: 0.000100
2021-11-23 10:39:42,441 - INFO - joeynmt.training - Epoch  49, Step:   163200, Batch Loss:     2.036977, Tokens per Sec:     2140, Lr: 0.000100
2021-11-23 10:39:57,117 - INFO - joeynmt.training - Epoch  49, Step:   163300, Batch Loss:     1.759690, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 10:40:12,365 - INFO - joeynmt.training - Epoch  49, Step:   163400, Batch Loss:     1.992839, Tokens per Sec:     2070, Lr: 0.000100
2021-11-23 10:40:27,300 - INFO - joeynmt.training - Epoch  49, Step:   163500, Batch Loss:     1.943073, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 10:40:42,607 - INFO - joeynmt.training - Epoch  49, Step:   163600, Batch Loss:     2.112241, Tokens per Sec:     2188, Lr: 0.000100
2021-11-23 10:40:57,758 - INFO - joeynmt.training - Epoch  49, Step:   163700, Batch Loss:     1.759971, Tokens per Sec:     2056, Lr: 0.000100
2021-11-23 10:41:12,194 - INFO - joeynmt.training - Epoch  49, Step:   163800, Batch Loss:     2.147526, Tokens per Sec:     2091, Lr: 0.000100
2021-11-23 10:41:27,494 - INFO - joeynmt.training - Epoch  49, Step:   163900, Batch Loss:     2.157371, Tokens per Sec:     2057, Lr: 0.000100
2021-11-23 10:41:41,842 - INFO - joeynmt.training - Epoch  49, Step:   164000, Batch Loss:     1.781484, Tokens per Sec:     2190, Lr: 0.000100
2021-11-23 10:43:22,526 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:43:22,526 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:43:22,527 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:43:22,543 - INFO - joeynmt.training - Example #0
2021-11-23 10:43:22,543 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:43:22,543 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:43:22,543 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'op', 'h', 'ile', '▁you', '▁were', '▁count', 'ry', 'ing', '▁for', '▁Jerusalem', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁the', '▁follow', 'ers', '.']
2021-11-23 10:43:22,543 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:43:22,543 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:43:22,543 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:43:22,543 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t op h ile ▁you ▁were ▁count ry ing ▁for ▁Jerusalem . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁follow ed ▁all ▁his ▁follow ers ▁and ▁the ▁follow ers .
2021-11-23 10:43:22,543 - INFO - joeynmt.training - Example #1
2021-11-23 10:43:22,543 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:43:22,543 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:43:22,543 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:43:22,543 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:43:22,543 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:43:22,543 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:43:22,543 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:43:22,543 - INFO - joeynmt.training - Example #2
2021-11-23 10:43:22,544 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:43:22,544 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:43:22,544 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', 'est', '▁and', '▁comple', 't', 'ely', '▁comple', 't', 'ely', '▁comple', 't', 'ely', ',', '▁how', 'e', 'ver', '▁love', '▁each', '▁other', ',', '▁have', '▁one', '▁another', ':']
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great est ▁and ▁comple t ely ▁comple t ely ▁comple t ely , ▁how e ver ▁love ▁each ▁other , ▁have ▁one ▁another :
2021-11-23 10:43:22,544 - INFO - joeynmt.training - Example #3
2021-11-23 10:43:22,544 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:43:22,544 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:43:22,544 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'u', 'as']
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Hypothesis: ▁d u as
2021-11-23 10:43:22,544 - INFO - joeynmt.training - Example #6
2021-11-23 10:43:22,544 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:43:22,544 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:43:22,544 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:43:22,544 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:43:22,544 - INFO - joeynmt.training - Validation result (greedy) at epoch  49, step   164000: bleu:  12.94, loss: 74570.7969, ppl:   9.0419, duration: 100.7017s
2021-11-23 10:43:36,690 - INFO - joeynmt.training - Epoch  49, Step:   164100, Batch Loss:     2.407795, Tokens per Sec:     2231, Lr: 0.000100
2021-11-23 10:43:50,924 - INFO - joeynmt.training - Epoch  49, Step:   164200, Batch Loss:     2.196073, Tokens per Sec:     2172, Lr: 0.000100
2021-11-23 10:44:05,860 - INFO - joeynmt.training - Epoch  49, Step:   164300, Batch Loss:     1.875706, Tokens per Sec:     2066, Lr: 0.000100
2021-11-23 10:44:20,450 - INFO - joeynmt.training - Epoch  49, Step:   164400, Batch Loss:     2.232785, Tokens per Sec:     2212, Lr: 0.000100
2021-11-23 10:44:34,389 - INFO - joeynmt.training - Epoch  49, Step:   164500, Batch Loss:     1.848783, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 10:44:50,629 - INFO - joeynmt.training - Epoch  49, Step:   164600, Batch Loss:     1.975065, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 10:45:04,963 - INFO - joeynmt.training - Epoch  49, Step:   164700, Batch Loss:     2.008207, Tokens per Sec:     2208, Lr: 0.000100
2021-11-23 10:45:19,328 - INFO - joeynmt.training - Epoch  49, Step:   164800, Batch Loss:     1.967402, Tokens per Sec:     2283, Lr: 0.000100
2021-11-23 10:45:33,039 - INFO - joeynmt.training - Epoch  49, Step:   164900, Batch Loss:     2.152897, Tokens per Sec:     2211, Lr: 0.000100
2021-11-23 10:45:47,361 - INFO - joeynmt.training - Epoch  49, Step:   165000, Batch Loss:     2.116476, Tokens per Sec:     2250, Lr: 0.000100
2021-11-23 10:47:33,457 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:47:33,457 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:47:33,457 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:47:33,469 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 10:47:34,296 - INFO - joeynmt.helpers - delete models/baseline_multilingual/162000.ckpt
2021-11-23 10:47:34,297 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/162000.ckpt
2021-11-23 10:47:34,297 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/162000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/162000.ckpt')
2021-11-23 10:47:34,354 - INFO - joeynmt.training - Example #0
2021-11-23 10:47:34,355 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:47:34,355 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:47:34,355 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁count', 'ry', ',', '▁you', '▁were', '▁count', 'ing', '▁the', '▁time', '▁of', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 10:47:34,355 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:47:34,355 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:47:34,356 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:47:34,356 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁count ry , ▁you ▁were ▁count ing ▁the ▁time ▁of ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁the ▁wall s .
2021-11-23 10:47:34,356 - INFO - joeynmt.training - Example #1
2021-11-23 10:47:34,356 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:47:34,356 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:47:34,356 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:47:34,356 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:47:34,356 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:47:34,357 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:47:34,357 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:47:34,357 - INFO - joeynmt.training - Example #2
2021-11-23 10:47:34,357 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:47:34,357 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:47:34,357 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁one', '▁another', ',', '▁tell', 'ing', '▁me', '▁what', '▁is', '▁mean', 'ing', '.']
2021-11-23 10:47:34,358 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:47:34,358 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:47:34,358 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:47:34,358 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁love ▁each ▁other ▁with ▁each ▁other , ▁one ▁another , ▁tell ing ▁me ▁what ▁is ▁mean ing .
2021-11-23 10:47:34,358 - INFO - joeynmt.training - Example #3
2021-11-23 10:47:34,358 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:47:34,358 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:47:34,358 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'oso']
2021-11-23 10:47:34,358 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:47:34,358 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:47:34,359 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:47:34,359 - INFO - joeynmt.training - 	Hypothesis: ▁d er v oso
2021-11-23 10:47:34,359 - INFO - joeynmt.training - Example #6
2021-11-23 10:47:34,359 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:47:34,359 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:47:34,359 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:47:34,359 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:47:34,359 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:47:34,359 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:47:34,359 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:47:34,359 - INFO - joeynmt.training - Validation result (greedy) at epoch  49, step   165000: bleu:  13.53, loss: 74240.3984, ppl:   8.9541, duration: 106.9982s
2021-11-23 10:47:48,824 - INFO - joeynmt.training - Epoch  49, Step:   165100, Batch Loss:     1.912777, Tokens per Sec:     2090, Lr: 0.000100
2021-11-23 10:48:03,201 - INFO - joeynmt.training - Epoch  49, Step:   165200, Batch Loss:     1.803557, Tokens per Sec:     2275, Lr: 0.000100
2021-11-23 10:48:17,110 - INFO - joeynmt.training - Epoch  49, Step:   165300, Batch Loss:     1.630086, Tokens per Sec:     2133, Lr: 0.000100
2021-11-23 10:48:31,052 - INFO - joeynmt.training - Epoch  49, Step:   165400, Batch Loss:     2.166152, Tokens per Sec:     2157, Lr: 0.000100
2021-11-23 10:48:46,132 - INFO - joeynmt.training - Epoch  49, Step:   165500, Batch Loss:     2.006058, Tokens per Sec:     2082, Lr: 0.000100
2021-11-23 10:49:01,016 - INFO - joeynmt.training - Epoch  49, Step:   165600, Batch Loss:     2.100015, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 10:49:16,174 - INFO - joeynmt.training - Epoch  49, Step:   165700, Batch Loss:     2.193219, Tokens per Sec:     2122, Lr: 0.000100
2021-11-23 10:49:30,534 - INFO - joeynmt.training - Epoch  49, Step:   165800, Batch Loss:     1.926671, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 10:49:45,050 - INFO - joeynmt.training - Epoch  49, Step:   165900, Batch Loss:     2.238486, Tokens per Sec:     2078, Lr: 0.000100
2021-11-23 10:50:00,090 - INFO - joeynmt.training - Epoch  49, Step:   166000, Batch Loss:     1.744704, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 10:52:03,915 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:52:03,915 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:52:03,915 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:52:03,933 - INFO - joeynmt.training - Example #0
2021-11-23 10:52:03,933 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:52:03,933 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:52:03,933 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁were', '▁count', 'ed', '▁by', '▁Jud', 'as', '▁and', '▁f', 'ast', 'ing', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁and', '▁the', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁har', 'vest', '.']
2021-11-23 10:52:03,933 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:52:03,933 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:52:03,933 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:52:03,933 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁were ▁count ed ▁by ▁Jud as ▁and ▁f ast ing ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁and ▁the ▁whole ▁whole ▁whole ▁whole ▁whole ▁whole ▁whole ▁whole ▁har vest .
2021-11-23 10:52:03,933 - INFO - joeynmt.training - Example #1
2021-11-23 10:52:03,933 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:52:03,933 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:52:03,933 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ra', 'nde']
2021-11-23 10:52:03,933 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:52:03,933 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:52:03,933 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:52:03,933 - INFO - joeynmt.training - 	Hypothesis: ▁G ra nde
2021-11-23 10:52:03,933 - INFO - joeynmt.training - Example #2
2021-11-23 10:52:03,933 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:52:03,934 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:52:03,934 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 10:52:03,934 - INFO - joeynmt.training - Example #3
2021-11-23 10:52:03,934 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:52:03,934 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:52:03,934 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁de', 'po', 'is']
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Hypothesis: ▁de po is
2021-11-23 10:52:03,934 - INFO - joeynmt.training - Example #6
2021-11-23 10:52:03,934 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:52:03,934 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:52:03,934 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:52:03,934 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:52:03,934 - INFO - joeynmt.training - Validation result (greedy) at epoch  49, step   166000: bleu:  13.08, loss: 74175.8828, ppl:   8.9371, duration: 123.8439s
2021-11-23 10:52:12,926 - INFO - joeynmt.training - Epoch  49: total training loss 6751.55
2021-11-23 10:52:12,927 - INFO - joeynmt.training - EPOCH 50
2021-11-23 10:52:18,993 - INFO - joeynmt.training - Epoch  50, Step:   166100, Batch Loss:     2.136784, Tokens per Sec:     2033, Lr: 0.000100
2021-11-23 10:52:33,455 - INFO - joeynmt.training - Epoch  50, Step:   166200, Batch Loss:     2.001312, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 10:52:48,289 - INFO - joeynmt.training - Epoch  50, Step:   166300, Batch Loss:     2.087591, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 10:53:03,210 - INFO - joeynmt.training - Epoch  50, Step:   166400, Batch Loss:     2.287807, Tokens per Sec:     2073, Lr: 0.000100
2021-11-23 10:53:18,142 - INFO - joeynmt.training - Epoch  50, Step:   166500, Batch Loss:     2.050683, Tokens per Sec:     2159, Lr: 0.000100
2021-11-23 10:53:33,158 - INFO - joeynmt.training - Epoch  50, Step:   166600, Batch Loss:     1.837075, Tokens per Sec:     2190, Lr: 0.000100
2021-11-23 10:53:47,865 - INFO - joeynmt.training - Epoch  50, Step:   166700, Batch Loss:     2.047974, Tokens per Sec:     2056, Lr: 0.000100
2021-11-23 10:54:02,572 - INFO - joeynmt.training - Epoch  50, Step:   166800, Batch Loss:     2.110870, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 10:54:16,999 - INFO - joeynmt.training - Epoch  50, Step:   166900, Batch Loss:     2.087079, Tokens per Sec:     2111, Lr: 0.000100
2021-11-23 10:54:31,652 - INFO - joeynmt.training - Epoch  50, Step:   167000, Batch Loss:     1.997889, Tokens per Sec:     2175, Lr: 0.000100
2021-11-23 10:56:13,736 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 10:56:13,736 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 10:56:13,736 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 10:56:13,753 - INFO - joeynmt.training - Example #0
2021-11-23 10:56:13,753 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 10:56:13,753 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 10:56:13,753 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁are', '▁count', 'ed', '▁by', '▁Jud', 'e', 'a', ',', '▁and', '▁you', '▁are', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁but', '▁he', '▁is', '▁follow', 'ed', '▁that', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁the', '▁wall', 's', '.']
2021-11-23 10:56:13,753 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 10:56:13,753 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 10:56:13,753 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 10:56:13,753 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁are ▁count ed ▁by ▁Jud e a , ▁and ▁you ▁are ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁follow ers , ▁but ▁he ▁is ▁follow ed ▁that ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁the ▁wall s .
2021-11-23 10:56:13,753 - INFO - joeynmt.training - Example #1
2021-11-23 10:56:13,753 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 10:56:13,753 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 10:56:13,753 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 10:56:13,753 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 10:56:13,753 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 10:56:13,754 - INFO - joeynmt.training - Example #2
2021-11-23 10:56:13,754 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 10:56:13,754 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 10:56:13,754 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁work', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '.']
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other , ▁work ▁with ▁each ▁other , ▁and ▁love ▁each ▁other .
2021-11-23 10:56:13,754 - INFO - joeynmt.training - Example #3
2021-11-23 10:56:13,754 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 10:56:13,754 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 10:56:13,754 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 10:56:13,754 - INFO - joeynmt.training - Example #6
2021-11-23 10:56:13,754 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 10:56:13,754 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 10:56:13,754 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 10:56:13,754 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 10:56:13,755 - INFO - joeynmt.training - Validation result (greedy) at epoch  50, step   167000: bleu:  13.01, loss: 74551.1484, ppl:   9.0367, duration: 102.1018s
2021-11-23 10:56:28,188 - INFO - joeynmt.training - Epoch  50, Step:   167100, Batch Loss:     1.735057, Tokens per Sec:     2198, Lr: 0.000100
2021-11-23 10:56:42,623 - INFO - joeynmt.training - Epoch  50, Step:   167200, Batch Loss:     1.882673, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 10:56:57,485 - INFO - joeynmt.training - Epoch  50, Step:   167300, Batch Loss:     2.052403, Tokens per Sec:     2253, Lr: 0.000100
2021-11-23 10:57:12,461 - INFO - joeynmt.training - Epoch  50, Step:   167400, Batch Loss:     1.952887, Tokens per Sec:     2131, Lr: 0.000100
2021-11-23 10:57:26,687 - INFO - joeynmt.training - Epoch  50, Step:   167500, Batch Loss:     2.190442, Tokens per Sec:     2117, Lr: 0.000100
2021-11-23 10:57:41,419 - INFO - joeynmt.training - Epoch  50, Step:   167600, Batch Loss:     2.128506, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 10:57:56,129 - INFO - joeynmt.training - Epoch  50, Step:   167700, Batch Loss:     2.030882, Tokens per Sec:     2157, Lr: 0.000100
2021-11-23 10:58:10,966 - INFO - joeynmt.training - Epoch  50, Step:   167800, Batch Loss:     1.786355, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 10:58:25,848 - INFO - joeynmt.training - Epoch  50, Step:   167900, Batch Loss:     1.827655, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 10:58:40,541 - INFO - joeynmt.training - Epoch  50, Step:   168000, Batch Loss:     1.951786, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 11:00:41,929 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:00:41,929 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:00:41,929 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:00:41,946 - INFO - joeynmt.training - Example #0
2021-11-23 11:00:41,946 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁were', '▁count', 'ry', 'ing', ',', '▁and', '▁you', '▁were', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁follow', 'ers', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁the', '▁wall', 's', '▁and', '▁the', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁har', 'vest', '.']
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁were ▁count ry ing , ▁and ▁you ▁were ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁follow ers , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁the ▁wall s ▁and ▁the ▁whole ▁whole ▁whole ▁whole ▁whole ▁whole ▁whole ▁whole ▁har vest .
2021-11-23 11:00:41,947 - INFO - joeynmt.training - Example #1
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:00:41,947 - INFO - joeynmt.training - Example #2
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:00:41,947 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 11:00:41,947 - INFO - joeynmt.training - Example #3
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:00:41,947 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:00:41,948 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 11:00:41,948 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:00:41,948 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:00:41,948 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:00:41,948 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 11:00:41,948 - INFO - joeynmt.training - Example #6
2021-11-23 11:00:41,948 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:00:41,948 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:00:41,948 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 11:00:41,948 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:00:41,948 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:00:41,948 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:00:41,948 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 11:00:41,948 - INFO - joeynmt.training - Validation result (greedy) at epoch  50, step   168000: bleu:  13.45, loss: 74248.8281, ppl:   8.9564, duration: 121.4069s
2021-11-23 11:00:57,002 - INFO - joeynmt.training - Epoch  50, Step:   168100, Batch Loss:     1.897893, Tokens per Sec:     2071, Lr: 0.000100
2021-11-23 11:01:11,617 - INFO - joeynmt.training - Epoch  50, Step:   168200, Batch Loss:     2.076135, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 11:01:26,262 - INFO - joeynmt.training - Epoch  50, Step:   168300, Batch Loss:     2.044381, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 11:01:39,886 - INFO - joeynmt.training - Epoch  50, Step:   168400, Batch Loss:     2.025043, Tokens per Sec:     2253, Lr: 0.000100
2021-11-23 11:01:54,135 - INFO - joeynmt.training - Epoch  50, Step:   168500, Batch Loss:     1.967467, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 11:02:09,394 - INFO - joeynmt.training - Epoch  50, Step:   168600, Batch Loss:     2.420854, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 11:02:23,626 - INFO - joeynmt.training - Epoch  50, Step:   168700, Batch Loss:     1.918344, Tokens per Sec:     2237, Lr: 0.000100
2021-11-23 11:02:38,135 - INFO - joeynmt.training - Epoch  50, Step:   168800, Batch Loss:     2.269257, Tokens per Sec:     2203, Lr: 0.000100
2021-11-23 11:02:52,320 - INFO - joeynmt.training - Epoch  50, Step:   168900, Batch Loss:     1.815730, Tokens per Sec:     2181, Lr: 0.000100
2021-11-23 11:03:06,778 - INFO - joeynmt.training - Epoch  50, Step:   169000, Batch Loss:     2.056555, Tokens per Sec:     2198, Lr: 0.000100
2021-11-23 11:05:20,952 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:05:20,952 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:05:20,952 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:05:20,970 - INFO - joeynmt.training - Example #0
2021-11-23 11:05:20,970 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:05:20,970 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:05:20,970 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁count', 'ry', ',', '▁you', '▁were', '▁f', 'at', 'ten', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁one', '▁who', '▁follow', 'ed', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 11:05:20,970 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:05:20,970 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:05:20,970 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:05:20,970 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁count ry , ▁you ▁were ▁f at ten ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁one ▁who ▁follow ed ▁his ▁follow ers ▁and ▁all ▁his ▁follow ers .
2021-11-23 11:05:20,970 - INFO - joeynmt.training - Example #1
2021-11-23 11:05:20,970 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:05:20,970 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:05:20,970 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:05:20,970 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:05:20,970 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:05:20,971 - INFO - joeynmt.training - Example #2
2021-11-23 11:05:20,971 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:05:20,971 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:05:20,971 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', 'est', ',', '▁how', '▁can', '▁I', '▁have', '▁the', '▁end', '▁of', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great est , ▁how ▁can ▁I ▁have ▁the ▁end ▁of ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 11:05:20,971 - INFO - joeynmt.training - Example #3
2021-11-23 11:05:20,971 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:05:20,971 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:05:20,971 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'm', 'inar']
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Hypothesis: ▁d er m inar
2021-11-23 11:05:20,971 - INFO - joeynmt.training - Example #6
2021-11-23 11:05:20,971 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:05:20,971 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:05:20,971 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:05:20,971 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 11:05:20,972 - INFO - joeynmt.training - Validation result (greedy) at epoch  50, step   169000: bleu:  13.05, loss: 73919.5938, ppl:   8.8697, duration: 134.1936s
2021-11-23 11:05:36,186 - INFO - joeynmt.training - Epoch  50, Step:   169100, Batch Loss:     1.831326, Tokens per Sec:     2010, Lr: 0.000100
2021-11-23 11:05:51,310 - INFO - joeynmt.training - Epoch  50, Step:   169200, Batch Loss:     1.946447, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 11:06:05,372 - INFO - joeynmt.training - Epoch  50, Step:   169300, Batch Loss:     2.013465, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 11:06:20,685 - INFO - joeynmt.training - Epoch  50, Step:   169400, Batch Loss:     1.845592, Tokens per Sec:     2036, Lr: 0.000100
2021-11-23 11:06:28,160 - INFO - joeynmt.training - Epoch  50: total training loss 6716.65
2021-11-23 11:06:28,160 - INFO - joeynmt.training - EPOCH 51
2021-11-23 11:06:35,117 - INFO - joeynmt.training - Epoch  51, Step:   169500, Batch Loss:     2.115030, Tokens per Sec:     2268, Lr: 0.000100
2021-11-23 11:06:50,026 - INFO - joeynmt.training - Epoch  51, Step:   169600, Batch Loss:     1.903012, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 11:07:04,351 - INFO - joeynmt.training - Epoch  51, Step:   169700, Batch Loss:     1.942877, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 11:07:18,777 - INFO - joeynmt.training - Epoch  51, Step:   169800, Batch Loss:     1.832748, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 11:07:33,730 - INFO - joeynmt.training - Epoch  51, Step:   169900, Batch Loss:     1.792122, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 11:07:48,190 - INFO - joeynmt.training - Epoch  51, Step:   170000, Batch Loss:     2.060471, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 11:09:54,156 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:09:54,156 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:09:54,156 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:09:54,174 - INFO - joeynmt.training - Example #0
2021-11-23 11:09:54,174 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:09:54,174 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:09:54,174 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁f', 'av', 'or', ',', '▁you', '▁were', '▁f', 'av', 'or', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁the', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁whole', '▁har', 'vest', '.']
2021-11-23 11:09:54,174 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:09:54,174 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:09:54,174 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:09:54,174 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁f av or , ▁you ▁were ▁f av or ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁the ▁whole ▁whole ▁whole ▁whole ▁whole ▁whole ▁whole ▁whole ▁har vest .
2021-11-23 11:09:54,174 - INFO - joeynmt.training - Example #1
2021-11-23 11:09:54,174 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:09:54,175 - INFO - joeynmt.training - Example #2
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 11:09:54,175 - INFO - joeynmt.training - Example #3
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'u', 'pl', 'a']
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Hypothesis: ▁d u pl a
2021-11-23 11:09:54,175 - INFO - joeynmt.training - Example #6
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:09:54,175 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:09:54,175 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:09:54,176 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:09:54,176 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 11:09:54,176 - INFO - joeynmt.training - Validation result (greedy) at epoch  51, step   170000: bleu:  12.81, loss: 74377.1719, ppl:   8.9904, duration: 125.9854s
2021-11-23 11:10:09,087 - INFO - joeynmt.training - Epoch  51, Step:   170100, Batch Loss:     2.160822, Tokens per Sec:     2038, Lr: 0.000100
2021-11-23 11:10:23,591 - INFO - joeynmt.training - Epoch  51, Step:   170200, Batch Loss:     2.139562, Tokens per Sec:     2218, Lr: 0.000100
2021-11-23 11:10:38,346 - INFO - joeynmt.training - Epoch  51, Step:   170300, Batch Loss:     1.902786, Tokens per Sec:     2157, Lr: 0.000100
2021-11-23 11:10:52,816 - INFO - joeynmt.training - Epoch  51, Step:   170400, Batch Loss:     1.772309, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 11:11:07,806 - INFO - joeynmt.training - Epoch  51, Step:   170500, Batch Loss:     2.007508, Tokens per Sec:     2046, Lr: 0.000100
2021-11-23 11:11:21,252 - INFO - joeynmt.training - Epoch  51, Step:   170600, Batch Loss:     2.143230, Tokens per Sec:     2205, Lr: 0.000100
2021-11-23 11:11:36,229 - INFO - joeynmt.training - Epoch  51, Step:   170700, Batch Loss:     1.923561, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 11:11:50,290 - INFO - joeynmt.training - Epoch  51, Step:   170800, Batch Loss:     2.140454, Tokens per Sec:     2232, Lr: 0.000100
2021-11-23 11:12:05,676 - INFO - joeynmt.training - Epoch  51, Step:   170900, Batch Loss:     1.842731, Tokens per Sec:     2092, Lr: 0.000100
2021-11-23 11:12:20,054 - INFO - joeynmt.training - Epoch  51, Step:   171000, Batch Loss:     2.469422, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 11:14:12,815 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:14:12,815 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:14:12,815 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:14:12,835 - INFO - joeynmt.training - Example #0
2021-11-23 11:14:12,835 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:14:12,835 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:14:12,835 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁were', '▁count', 'ry', ',', '▁and', '▁you', '▁were', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁you', '▁are', '▁follow', 'ing', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 11:14:12,835 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁were ▁count ry , ▁and ▁you ▁were ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁you ▁are ▁follow ing ▁your ▁follow ers , ▁and ▁all ▁your ▁follow ers ▁are ▁sc atter ed .
2021-11-23 11:14:12,836 - INFO - joeynmt.training - Example #1
2021-11-23 11:14:12,836 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:14:12,836 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:14:12,836 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 11:14:12,836 - INFO - joeynmt.training - Example #2
2021-11-23 11:14:12,836 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:14:12,836 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:14:12,836 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁work', '▁with', '▁each', '▁other', ',', '▁one', '▁another', '.']
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other , ▁and ▁work ▁with ▁each ▁other , ▁one ▁another .
2021-11-23 11:14:12,836 - INFO - joeynmt.training - Example #3
2021-11-23 11:14:12,836 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:14:12,836 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:14:12,836 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'oso']
2021-11-23 11:14:12,836 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:14:12,837 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:14:12,837 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:14:12,837 - INFO - joeynmt.training - 	Hypothesis: ▁d er v oso
2021-11-23 11:14:12,837 - INFO - joeynmt.training - Example #6
2021-11-23 11:14:12,837 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:14:12,837 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:14:12,837 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁1', '00']
2021-11-23 11:14:12,837 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:14:12,837 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:14:12,837 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:14:12,837 - INFO - joeynmt.training - 	Hypothesis: ▁1 00
2021-11-23 11:14:12,837 - INFO - joeynmt.training - Validation result (greedy) at epoch  51, step   171000: bleu:  12.89, loss: 74120.7969, ppl:   8.9226, duration: 112.7824s
2021-11-23 11:14:27,373 - INFO - joeynmt.training - Epoch  51, Step:   171100, Batch Loss:     2.070796, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 11:14:42,039 - INFO - joeynmt.training - Epoch  51, Step:   171200, Batch Loss:     2.016730, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 11:14:56,563 - INFO - joeynmt.training - Epoch  51, Step:   171300, Batch Loss:     2.094235, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 11:15:11,006 - INFO - joeynmt.training - Epoch  51, Step:   171400, Batch Loss:     2.082809, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 11:15:25,493 - INFO - joeynmt.training - Epoch  51, Step:   171500, Batch Loss:     1.991483, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 11:15:40,853 - INFO - joeynmt.training - Epoch  51, Step:   171600, Batch Loss:     2.091085, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 11:15:55,646 - INFO - joeynmt.training - Epoch  51, Step:   171700, Batch Loss:     2.486994, Tokens per Sec:     2185, Lr: 0.000100
2021-11-23 11:16:10,846 - INFO - joeynmt.training - Epoch  51, Step:   171800, Batch Loss:     1.910850, Tokens per Sec:     2051, Lr: 0.000100
2021-11-23 11:16:25,763 - INFO - joeynmt.training - Epoch  51, Step:   171900, Batch Loss:     1.838862, Tokens per Sec:     2130, Lr: 0.000100
2021-11-23 11:16:40,332 - INFO - joeynmt.training - Epoch  51, Step:   172000, Batch Loss:     2.114373, Tokens per Sec:     2220, Lr: 0.000100
2021-11-23 11:18:28,828 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:18:28,829 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:18:28,829 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:18:28,841 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 11:18:31,093 - INFO - joeynmt.helpers - delete models/baseline_multilingual/165000.ckpt
2021-11-23 11:18:31,093 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/165000.ckpt
2021-11-23 11:18:31,094 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/165000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/165000.ckpt')
2021-11-23 11:18:31,174 - INFO - joeynmt.training - Example #0
2021-11-23 11:18:31,175 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:18:31,175 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:18:31,175 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'e', 'll', ',', '▁you', '▁have', '▁been', '▁f', 'av', 'or', '▁of', '▁Jud', 'e', 'a', ',', '▁and', '▁you', '▁are', '▁filled', '▁with', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁he', '▁is', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 11:18:31,175 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:18:31,175 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:18:31,175 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:18:31,176 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W e ll , ▁you ▁have ▁been ▁f av or ▁of ▁Jud e a , ▁and ▁you ▁are ▁filled ▁with ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁he ▁is ▁follow ed ▁all ▁his ▁follow ers ▁and ▁all ▁his ▁follow ers .
2021-11-23 11:18:31,176 - INFO - joeynmt.training - Example #1
2021-11-23 11:18:31,176 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:18:31,176 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:18:31,176 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:18:31,176 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:18:31,176 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:18:31,176 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:18:31,177 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:18:31,177 - INFO - joeynmt.training - Example #2
2021-11-23 11:18:31,177 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:18:31,177 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:18:31,177 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁can', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 11:18:31,177 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:18:31,177 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:18:31,178 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:18:31,178 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁can ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 11:18:31,178 - INFO - joeynmt.training - Example #3
2021-11-23 11:18:31,178 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:18:31,178 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:18:31,178 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'oso']
2021-11-23 11:18:31,178 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:18:31,179 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:18:31,179 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:18:31,179 - INFO - joeynmt.training - 	Hypothesis: ▁d er v oso
2021-11-23 11:18:31,179 - INFO - joeynmt.training - Example #6
2021-11-23 11:18:31,179 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:18:31,179 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:18:31,179 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 11:18:31,179 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:18:31,180 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:18:31,180 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:18:31,180 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 11:18:31,180 - INFO - joeynmt.training - Validation result (greedy) at epoch  51, step   172000: bleu:  13.59, loss: 73696.8359, ppl:   8.8116, duration: 110.8479s
2021-11-23 11:18:46,128 - INFO - joeynmt.training - Epoch  51, Step:   172100, Batch Loss:     2.211980, Tokens per Sec:     2175, Lr: 0.000100
2021-11-23 11:19:00,642 - INFO - joeynmt.training - Epoch  51, Step:   172200, Batch Loss:     1.913987, Tokens per Sec:     2165, Lr: 0.000100
2021-11-23 11:19:14,500 - INFO - joeynmt.training - Epoch  51, Step:   172300, Batch Loss:     2.100187, Tokens per Sec:     2200, Lr: 0.000100
2021-11-23 11:19:29,346 - INFO - joeynmt.training - Epoch  51, Step:   172400, Batch Loss:     1.899179, Tokens per Sec:     2090, Lr: 0.000100
2021-11-23 11:19:44,041 - INFO - joeynmt.training - Epoch  51, Step:   172500, Batch Loss:     1.778775, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 11:19:58,995 - INFO - joeynmt.training - Epoch  51, Step:   172600, Batch Loss:     1.847040, Tokens per Sec:     2061, Lr: 0.000100
2021-11-23 11:20:14,140 - INFO - joeynmt.training - Epoch  51, Step:   172700, Batch Loss:     2.086474, Tokens per Sec:     2196, Lr: 0.000100
2021-11-23 11:20:29,923 - INFO - joeynmt.training - Epoch  51, Step:   172800, Batch Loss:     2.038961, Tokens per Sec:     2058, Lr: 0.000100
2021-11-23 11:20:35,372 - INFO - joeynmt.training - Epoch  51: total training loss 6676.33
2021-11-23 11:20:35,373 - INFO - joeynmt.training - EPOCH 52
2021-11-23 11:20:44,078 - INFO - joeynmt.training - Epoch  52, Step:   172900, Batch Loss:     1.809147, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 11:20:58,997 - INFO - joeynmt.training - Epoch  52, Step:   173000, Batch Loss:     1.832778, Tokens per Sec:     2168, Lr: 0.000100
2021-11-23 11:22:39,262 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:22:39,263 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:22:39,263 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:22:39,279 - INFO - joeynmt.training - Example #0
2021-11-23 11:22:39,279 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:22:39,279 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:22:39,279 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁have', '▁been', '▁count', 'ed', '▁by', '▁Jud', 'e', 'a', '▁and', '▁the', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁people', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 11:22:39,279 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:22:39,279 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:22:39,279 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁have ▁been ▁count ed ▁by ▁Jud e a ▁and ▁the ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁people ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁all ow ed .
2021-11-23 11:22:39,280 - INFO - joeynmt.training - Example #1
2021-11-23 11:22:39,280 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:22:39,280 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:22:39,280 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:22:39,280 - INFO - joeynmt.training - Example #2
2021-11-23 11:22:39,280 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:22:39,280 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:22:39,280 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 11:22:39,280 - INFO - joeynmt.training - Example #3
2021-11-23 11:22:39,280 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:22:39,280 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:22:39,280 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'oso']
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:22:39,280 - INFO - joeynmt.training - 	Hypothesis: ▁d er v oso
2021-11-23 11:22:39,281 - INFO - joeynmt.training - Example #6
2021-11-23 11:22:39,281 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:22:39,281 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:22:39,281 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 11:22:39,281 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:22:39,281 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:22:39,281 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:22:39,281 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 11:22:39,281 - INFO - joeynmt.training - Validation result (greedy) at epoch  52, step   173000: bleu:  13.46, loss: 73984.4922, ppl:   8.8867, duration: 100.2838s
2021-11-23 11:22:54,287 - INFO - joeynmt.training - Epoch  52, Step:   173100, Batch Loss:     2.165868, Tokens per Sec:     2081, Lr: 0.000100
2021-11-23 11:23:09,099 - INFO - joeynmt.training - Epoch  52, Step:   173200, Batch Loss:     1.921042, Tokens per Sec:     2213, Lr: 0.000100
2021-11-23 11:23:23,393 - INFO - joeynmt.training - Epoch  52, Step:   173300, Batch Loss:     1.866731, Tokens per Sec:     2193, Lr: 0.000100
2021-11-23 11:23:38,774 - INFO - joeynmt.training - Epoch  52, Step:   173400, Batch Loss:     2.251381, Tokens per Sec:     2181, Lr: 0.000100
2021-11-23 11:23:53,416 - INFO - joeynmt.training - Epoch  52, Step:   173500, Batch Loss:     1.777801, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 11:24:07,428 - INFO - joeynmt.training - Epoch  52, Step:   173600, Batch Loss:     1.773284, Tokens per Sec:     2219, Lr: 0.000100
2021-11-23 11:24:22,078 - INFO - joeynmt.training - Epoch  52, Step:   173700, Batch Loss:     2.017076, Tokens per Sec:     2201, Lr: 0.000100
2021-11-23 11:24:36,939 - INFO - joeynmt.training - Epoch  52, Step:   173800, Batch Loss:     1.938195, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 11:24:51,207 - INFO - joeynmt.training - Epoch  52, Step:   173900, Batch Loss:     2.244473, Tokens per Sec:     2191, Lr: 0.000100
2021-11-23 11:25:05,688 - INFO - joeynmt.training - Epoch  52, Step:   174000, Batch Loss:     1.971251, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 11:27:02,008 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:27:02,008 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:27:02,008 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:27:02,028 - INFO - joeynmt.training - Example #0
2021-11-23 11:27:02,028 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:27:02,028 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:27:02,029 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁are', '▁count', 'ry', ',', '▁and', '▁you', '▁are', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁are ▁count ry , ▁and ▁you ▁are ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 11:27:02,029 - INFO - joeynmt.training - Example #1
2021-11-23 11:27:02,029 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:27:02,029 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:27:02,029 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:27:02,029 - INFO - joeynmt.training - Example #2
2021-11-23 11:27:02,029 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:27:02,029 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:27:02,029 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', '▁by', '▁each', '▁other', ',', '▁how', 'e', 'ver', ',', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁be', '▁with', '▁one', '▁another', '.']
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:27:02,029 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy ▁by ▁each ▁other , ▁how e ver , ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁be ▁with ▁one ▁another .
2021-11-23 11:27:02,029 - INFO - joeynmt.training - Example #3
2021-11-23 11:27:02,029 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:27:02,029 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:27:02,030 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'oso']
2021-11-23 11:27:02,030 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:27:02,030 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:27:02,030 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:27:02,030 - INFO - joeynmt.training - 	Hypothesis: ▁d er v oso
2021-11-23 11:27:02,030 - INFO - joeynmt.training - Example #6
2021-11-23 11:27:02,030 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:27:02,030 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:27:02,030 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '5']
2021-11-23 11:27:02,030 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:27:02,030 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:27:02,030 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:27:02,030 - INFO - joeynmt.training - 	Hypothesis: ▁5 5
2021-11-23 11:27:02,030 - INFO - joeynmt.training - Validation result (greedy) at epoch  52, step   174000: bleu:  13.42, loss: 74121.8125, ppl:   8.9228, duration: 116.3417s
2021-11-23 11:27:16,485 - INFO - joeynmt.training - Epoch  52, Step:   174100, Batch Loss:     1.654511, Tokens per Sec:     2080, Lr: 0.000100
2021-11-23 11:27:31,613 - INFO - joeynmt.training - Epoch  52, Step:   174200, Batch Loss:     2.230017, Tokens per Sec:     2120, Lr: 0.000100
2021-11-23 11:27:47,156 - INFO - joeynmt.training - Epoch  52, Step:   174300, Batch Loss:     2.010617, Tokens per Sec:     2209, Lr: 0.000100
2021-11-23 11:28:01,308 - INFO - joeynmt.training - Epoch  52, Step:   174400, Batch Loss:     1.737542, Tokens per Sec:     2158, Lr: 0.000100
2021-11-23 11:28:16,181 - INFO - joeynmt.training - Epoch  52, Step:   174500, Batch Loss:     1.866902, Tokens per Sec:     2181, Lr: 0.000100
2021-11-23 11:28:30,778 - INFO - joeynmt.training - Epoch  52, Step:   174600, Batch Loss:     2.149527, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 11:28:44,464 - INFO - joeynmt.training - Epoch  52, Step:   174700, Batch Loss:     1.639711, Tokens per Sec:     2148, Lr: 0.000100
2021-11-23 11:28:59,380 - INFO - joeynmt.training - Epoch  52, Step:   174800, Batch Loss:     1.904359, Tokens per Sec:     2072, Lr: 0.000100
2021-11-23 11:29:14,712 - INFO - joeynmt.training - Epoch  52, Step:   174900, Batch Loss:     2.022881, Tokens per Sec:     2031, Lr: 0.000100
2021-11-23 11:29:29,373 - INFO - joeynmt.training - Epoch  52, Step:   175000, Batch Loss:     1.772524, Tokens per Sec:     2090, Lr: 0.000100
2021-11-23 11:31:20,599 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:31:20,599 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:31:20,599 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:31:20,617 - INFO - joeynmt.training - Example #0
2021-11-23 11:31:20,618 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:31:20,618 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:31:20,618 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'L', 'et', '▁you', '▁have', '▁been', '▁f', 'av', 'or', '▁of', '▁Jud', 'e', 'a', '▁and', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁sc', 'atter', 'ed', '.']
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" L et ▁you ▁have ▁been ▁f av or ▁of ▁Jud e a ▁and ▁the ▁people ▁of ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁all ▁the ▁sc atter ed .
2021-11-23 11:31:20,618 - INFO - joeynmt.training - Example #1
2021-11-23 11:31:20,618 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:31:20,618 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:31:20,618 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:31:20,618 - INFO - joeynmt.training - Example #2
2021-11-23 11:31:20,618 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:31:20,618 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:31:20,618 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁joy', '▁by', '▁faith', 'ful', 'ness', ',', '▁how', '▁love', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:31:20,618 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁joy ▁by ▁faith ful ness , ▁how ▁love ▁each ▁other , ▁work ▁with ▁one ▁another .
2021-11-23 11:31:20,619 - INFO - joeynmt.training - Example #3
2021-11-23 11:31:20,619 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:31:20,619 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:31:20,619 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'oso']
2021-11-23 11:31:20,619 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:31:20,619 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:31:20,619 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:31:20,619 - INFO - joeynmt.training - 	Hypothesis: ▁d er v oso
2021-11-23 11:31:20,619 - INFO - joeynmt.training - Example #6
2021-11-23 11:31:20,619 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:31:20,619 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:31:20,619 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '5']
2021-11-23 11:31:20,619 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:31:20,619 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:31:20,619 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:31:20,619 - INFO - joeynmt.training - 	Hypothesis: ▁5 5
2021-11-23 11:31:20,619 - INFO - joeynmt.training - Validation result (greedy) at epoch  52, step   175000: bleu:  13.43, loss: 74009.5938, ppl:   8.8933, duration: 111.2458s
2021-11-23 11:31:35,933 - INFO - joeynmt.training - Epoch  52, Step:   175100, Batch Loss:     1.789547, Tokens per Sec:     2133, Lr: 0.000100
2021-11-23 11:31:50,350 - INFO - joeynmt.training - Epoch  52, Step:   175200, Batch Loss:     1.979195, Tokens per Sec:     2180, Lr: 0.000100
2021-11-23 11:32:05,211 - INFO - joeynmt.training - Epoch  52, Step:   175300, Batch Loss:     1.928119, Tokens per Sec:     2087, Lr: 0.000100
2021-11-23 11:32:20,818 - INFO - joeynmt.training - Epoch  52, Step:   175400, Batch Loss:     2.302155, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 11:32:35,125 - INFO - joeynmt.training - Epoch  52, Step:   175500, Batch Loss:     1.668140, Tokens per Sec:     2216, Lr: 0.000100
2021-11-23 11:32:49,952 - INFO - joeynmt.training - Epoch  52, Step:   175600, Batch Loss:     1.949232, Tokens per Sec:     2139, Lr: 0.000100
2021-11-23 11:33:04,062 - INFO - joeynmt.training - Epoch  52, Step:   175700, Batch Loss:     2.238259, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 11:33:18,206 - INFO - joeynmt.training - Epoch  52, Step:   175800, Batch Loss:     1.971456, Tokens per Sec:     2153, Lr: 0.000100
2021-11-23 11:33:33,350 - INFO - joeynmt.training - Epoch  52, Step:   175900, Batch Loss:     1.930811, Tokens per Sec:     2035, Lr: 0.000100
2021-11-23 11:33:47,874 - INFO - joeynmt.training - Epoch  52, Step:   176000, Batch Loss:     2.048519, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 11:35:33,491 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:35:33,492 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:35:33,492 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:35:33,515 - INFO - joeynmt.training - Example #0
2021-11-23 11:35:33,515 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:35:33,515 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:35:33,515 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'and', '▁you', ',', '▁for', '▁you', '▁are', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁you', '▁are', '▁follow', 'ing', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 11:35:33,515 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:35:33,515 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t and ▁you , ▁for ▁you ▁are ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁you ▁are ▁follow ing ▁your ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 11:35:33,516 - INFO - joeynmt.training - Example #1
2021-11-23 11:35:33,516 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:35:33,516 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:35:33,516 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:35:33,516 - INFO - joeynmt.training - Example #2
2021-11-23 11:35:33,516 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:35:33,516 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:35:33,516 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', ',', '▁how', '▁to', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy , ▁how ▁to ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 11:35:33,516 - INFO - joeynmt.training - Example #3
2021-11-23 11:35:33,516 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:35:33,516 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:35:33,516 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'rit', 'ar']
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:35:33,516 - INFO - joeynmt.training - 	Hypothesis: ▁D es c rit ar
2021-11-23 11:35:33,517 - INFO - joeynmt.training - Example #6
2021-11-23 11:35:33,517 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:35:33,517 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:35:33,517 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 11:35:33,517 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:35:33,517 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:35:33,517 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:35:33,517 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 11:35:33,517 - INFO - joeynmt.training - Validation result (greedy) at epoch  52, step   176000: bleu:  13.43, loss: 73527.0000, ppl:   8.7675, duration: 105.6430s
2021-11-23 11:35:48,155 - INFO - joeynmt.training - Epoch  52, Step:   176100, Batch Loss:     1.831327, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 11:36:02,447 - INFO - joeynmt.training - Epoch  52, Step:   176200, Batch Loss:     2.411060, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 11:36:06,386 - INFO - joeynmt.training - Epoch  52: total training loss 6634.32
2021-11-23 11:36:06,386 - INFO - joeynmt.training - EPOCH 53
2021-11-23 11:36:17,182 - INFO - joeynmt.training - Epoch  53, Step:   176300, Batch Loss:     1.720078, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 11:36:32,277 - INFO - joeynmt.training - Epoch  53, Step:   176400, Batch Loss:     2.023066, Tokens per Sec:     2060, Lr: 0.000100
2021-11-23 11:36:46,862 - INFO - joeynmt.training - Epoch  53, Step:   176500, Batch Loss:     1.779981, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 11:37:01,190 - INFO - joeynmt.training - Epoch  53, Step:   176600, Batch Loss:     1.765338, Tokens per Sec:     2123, Lr: 0.000100
2021-11-23 11:37:16,382 - INFO - joeynmt.training - Epoch  53, Step:   176700, Batch Loss:     2.043455, Tokens per Sec:     2111, Lr: 0.000100
2021-11-23 11:37:31,091 - INFO - joeynmt.training - Epoch  53, Step:   176800, Batch Loss:     1.816887, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 11:37:45,566 - INFO - joeynmt.training - Epoch  53, Step:   176900, Batch Loss:     1.950419, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 11:38:00,540 - INFO - joeynmt.training - Epoch  53, Step:   177000, Batch Loss:     1.855018, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 11:40:01,168 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:40:01,168 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:40:01,168 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:40:01,186 - INFO - joeynmt.training - Example #0
2021-11-23 11:40:01,186 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:40:01,186 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:40:01,186 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'op', '▁you', ',', '▁for', '▁you', '▁were', '▁f', 'av', 'or', '▁of', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁people', '▁follow', 'ed', '▁him', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁sc', 'atter', 'ed', '.']
2021-11-23 11:40:01,186 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t op ▁you , ▁for ▁you ▁were ▁f av or ▁of ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁people ▁follow ed ▁him , ▁and ▁all ▁his ▁follow ers ▁are ▁all ▁the ▁sc atter ed .
2021-11-23 11:40:01,187 - INFO - joeynmt.training - Example #1
2021-11-23 11:40:01,187 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:40:01,187 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:40:01,187 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:40:01,187 - INFO - joeynmt.training - Example #2
2021-11-23 11:40:01,187 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:40:01,187 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:40:01,187 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other , ▁work ▁with ▁one ▁another .
2021-11-23 11:40:01,187 - INFO - joeynmt.training - Example #3
2021-11-23 11:40:01,187 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:40:01,187 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:40:01,187 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'so']
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:40:01,187 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:40:01,188 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:40:01,188 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur so
2021-11-23 11:40:01,188 - INFO - joeynmt.training - Example #6
2021-11-23 11:40:01,188 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:40:01,188 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:40:01,188 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 11:40:01,188 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:40:01,188 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:40:01,188 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:40:01,188 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 11:40:01,188 - INFO - joeynmt.training - Validation result (greedy) at epoch  53, step   177000: bleu:  13.57, loss: 73906.5391, ppl:   8.8663, duration: 120.6471s
2021-11-23 11:40:15,787 - INFO - joeynmt.training - Epoch  53, Step:   177100, Batch Loss:     2.025519, Tokens per Sec:     2212, Lr: 0.000100
2021-11-23 11:40:30,231 - INFO - joeynmt.training - Epoch  53, Step:   177200, Batch Loss:     1.978704, Tokens per Sec:     2136, Lr: 0.000100
2021-11-23 11:40:44,555 - INFO - joeynmt.training - Epoch  53, Step:   177300, Batch Loss:     1.901950, Tokens per Sec:     2142, Lr: 0.000100
2021-11-23 11:40:58,970 - INFO - joeynmt.training - Epoch  53, Step:   177400, Batch Loss:     1.812528, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 11:41:14,830 - INFO - joeynmt.training - Epoch  53, Step:   177500, Batch Loss:     1.844761, Tokens per Sec:     2059, Lr: 0.000100
2021-11-23 11:41:29,088 - INFO - joeynmt.training - Epoch  53, Step:   177600, Batch Loss:     2.027387, Tokens per Sec:     2231, Lr: 0.000100
2021-11-23 11:41:43,346 - INFO - joeynmt.training - Epoch  53, Step:   177700, Batch Loss:     1.913934, Tokens per Sec:     2158, Lr: 0.000100
2021-11-23 11:41:58,132 - INFO - joeynmt.training - Epoch  53, Step:   177800, Batch Loss:     2.161507, Tokens per Sec:     2067, Lr: 0.000100
2021-11-23 11:42:12,573 - INFO - joeynmt.training - Epoch  53, Step:   177900, Batch Loss:     1.974799, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 11:42:27,126 - INFO - joeynmt.training - Epoch  53, Step:   178000, Batch Loss:     2.111468, Tokens per Sec:     2189, Lr: 0.000100
2021-11-23 11:44:27,715 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:44:27,715 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:44:27,715 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:44:27,736 - INFO - joeynmt.training - Example #0
2021-11-23 11:44:27,736 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:44:27,736 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:44:27,736 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁f', 'av', 'or', ',', '▁you', '▁f', 'av', 'or', '▁of', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁sc', 'atter', 'ed', '.']
2021-11-23 11:44:27,736 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:44:27,736 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:44:27,736 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:44:27,736 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁f av or , ▁you ▁f av or ▁of ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁the ▁sc atter ed .
2021-11-23 11:44:27,736 - INFO - joeynmt.training - Example #1
2021-11-23 11:44:27,736 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:44:27,736 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:44:27,736 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:44:27,736 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:44:27,736 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:44:27,736 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:44:27,736 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:44:27,736 - INFO - joeynmt.training - Example #2
2021-11-23 11:44:27,737 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:44:27,737 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:44:27,737 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁joy', '▁by', '▁each', '▁other', ',', '▁how', 'e', 'ver', '▁love', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁joy ▁by ▁each ▁other , ▁how e ver ▁love ▁each ▁other , ▁work ▁with ▁one ▁another .
2021-11-23 11:44:27,737 - INFO - joeynmt.training - Example #3
2021-11-23 11:44:27,737 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:44:27,737 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:44:27,737 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 11:44:27,737 - INFO - joeynmt.training - Example #6
2021-11-23 11:44:27,737 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:44:27,737 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:44:27,737 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:44:27,737 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 11:44:27,737 - INFO - joeynmt.training - Validation result (greedy) at epoch  53, step   178000: bleu:  13.33, loss: 74037.1953, ppl:   8.9006, duration: 120.6110s
2021-11-23 11:44:42,699 - INFO - joeynmt.training - Epoch  53, Step:   178100, Batch Loss:     2.097301, Tokens per Sec:     2112, Lr: 0.000100
2021-11-23 11:44:57,442 - INFO - joeynmt.training - Epoch  53, Step:   178200, Batch Loss:     1.961330, Tokens per Sec:     2195, Lr: 0.000100
2021-11-23 11:45:12,597 - INFO - joeynmt.training - Epoch  53, Step:   178300, Batch Loss:     1.867716, Tokens per Sec:     2218, Lr: 0.000100
2021-11-23 11:45:26,748 - INFO - joeynmt.training - Epoch  53, Step:   178400, Batch Loss:     2.057166, Tokens per Sec:     2080, Lr: 0.000100
2021-11-23 11:45:41,467 - INFO - joeynmt.training - Epoch  53, Step:   178500, Batch Loss:     1.827107, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 11:45:56,685 - INFO - joeynmt.training - Epoch  53, Step:   178600, Batch Loss:     2.048529, Tokens per Sec:     2052, Lr: 0.000100
2021-11-23 11:46:11,274 - INFO - joeynmt.training - Epoch  53, Step:   178700, Batch Loss:     2.006946, Tokens per Sec:     2124, Lr: 0.000100
2021-11-23 11:46:25,964 - INFO - joeynmt.training - Epoch  53, Step:   178800, Batch Loss:     1.963396, Tokens per Sec:     2109, Lr: 0.000100
2021-11-23 11:46:40,312 - INFO - joeynmt.training - Epoch  53, Step:   178900, Batch Loss:     2.061173, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 11:46:54,615 - INFO - joeynmt.training - Epoch  53, Step:   179000, Batch Loss:     1.932836, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 11:49:05,877 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:49:05,877 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:49:05,877 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:49:05,888 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 11:49:06,756 - INFO - joeynmt.helpers - delete models/baseline_multilingual/172000.ckpt
2021-11-23 11:49:06,756 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/172000.ckpt
2021-11-23 11:49:06,757 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/172000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/172000.ckpt')
2021-11-23 11:49:06,811 - INFO - joeynmt.training - Example #0
2021-11-23 11:49:06,812 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:49:06,812 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:49:06,812 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁and', '▁you', '▁are', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 11:49:06,812 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:49:06,812 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:49:06,812 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:49:06,813 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁have ▁been ▁count ed , ▁and ▁you ▁are ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁follow ed ▁all ▁his ▁follow ers ▁and ▁all ▁his ▁follow ers .
2021-11-23 11:49:06,813 - INFO - joeynmt.training - Example #1
2021-11-23 11:49:06,813 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:49:06,813 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:49:06,813 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:49:06,813 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:49:06,813 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:49:06,814 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:49:06,814 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:49:06,814 - INFO - joeynmt.training - Example #2
2021-11-23 11:49:06,814 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:49:06,814 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:49:06,814 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 11:49:06,814 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:49:06,815 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:49:06,815 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:49:06,815 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 11:49:06,815 - INFO - joeynmt.training - Example #3
2021-11-23 11:49:06,815 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:49:06,815 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:49:06,815 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'so']
2021-11-23 11:49:06,816 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:49:06,816 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:49:06,816 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:49:06,816 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur so
2021-11-23 11:49:06,816 - INFO - joeynmt.training - Example #6
2021-11-23 11:49:06,816 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:49:06,816 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:49:06,817 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 11:49:06,817 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:49:06,817 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:49:06,817 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:49:06,817 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 11:49:06,817 - INFO - joeynmt.training - Validation result (greedy) at epoch  53, step   179000: bleu:  13.68, loss: 73578.4531, ppl:   8.7808, duration: 132.2020s
2021-11-23 11:49:21,451 - INFO - joeynmt.training - Epoch  53, Step:   179100, Batch Loss:     1.890214, Tokens per Sec:     2165, Lr: 0.000100
2021-11-23 11:49:36,391 - INFO - joeynmt.training - Epoch  53, Step:   179200, Batch Loss:     1.954484, Tokens per Sec:     2132, Lr: 0.000100
2021-11-23 11:49:50,647 - INFO - joeynmt.training - Epoch  53, Step:   179300, Batch Loss:     1.879352, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 11:50:05,257 - INFO - joeynmt.training - Epoch  53, Step:   179400, Batch Loss:     1.962780, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 11:50:20,158 - INFO - joeynmt.training - Epoch  53, Step:   179500, Batch Loss:     1.839397, Tokens per Sec:     2171, Lr: 0.000100
2021-11-23 11:50:34,597 - INFO - joeynmt.training - Epoch  53, Step:   179600, Batch Loss:     2.161873, Tokens per Sec:     2147, Lr: 0.000100
2021-11-23 11:50:37,059 - INFO - joeynmt.training - Epoch  53: total training loss 6603.12
2021-11-23 11:50:37,059 - INFO - joeynmt.training - EPOCH 54
2021-11-23 11:50:48,623 - INFO - joeynmt.training - Epoch  54, Step:   179700, Batch Loss:     1.981338, Tokens per Sec:     2145, Lr: 0.000100
2021-11-23 11:51:03,371 - INFO - joeynmt.training - Epoch  54, Step:   179800, Batch Loss:     1.732368, Tokens per Sec:     2110, Lr: 0.000100
2021-11-23 11:51:18,483 - INFO - joeynmt.training - Epoch  54, Step:   179900, Batch Loss:     2.046530, Tokens per Sec:     1973, Lr: 0.000100
2021-11-23 11:51:33,302 - INFO - joeynmt.training - Epoch  54, Step:   180000, Batch Loss:     2.023550, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 11:53:16,783 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:53:16,784 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:53:16,784 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:53:16,795 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 11:53:17,599 - INFO - joeynmt.helpers - delete models/baseline_multilingual/179000.ckpt
2021-11-23 11:53:17,599 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/179000.ckpt
2021-11-23 11:53:17,600 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/179000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/179000.ckpt')
2021-11-23 11:53:17,656 - INFO - joeynmt.training - Example #0
2021-11-23 11:53:17,656 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:53:17,656 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:53:17,656 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'op', 'e', ',', '▁you', '▁are', '▁count', 'ed', '▁by', '▁Jud', 'e', 'a', ',', '▁and', '▁you', '▁are', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 11:53:17,657 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:53:17,657 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:53:17,657 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:53:17,657 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t op e , ▁you ▁are ▁count ed ▁by ▁Jud e a , ▁and ▁you ▁are ▁the ▁people ▁of ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 11:53:17,657 - INFO - joeynmt.training - Example #1
2021-11-23 11:53:17,657 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:53:17,658 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:53:17,658 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 11:53:17,658 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:53:17,658 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:53:17,658 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:53:17,658 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 11:53:17,658 - INFO - joeynmt.training - Example #2
2021-11-23 11:53:17,658 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:53:17,659 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:53:17,659 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 11:53:17,659 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:53:17,659 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:53:17,659 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:53:17,659 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 11:53:17,659 - INFO - joeynmt.training - Example #3
2021-11-23 11:53:17,660 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:53:17,660 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:53:17,660 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 11:53:17,660 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:53:17,660 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:53:17,660 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:53:17,660 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 11:53:17,660 - INFO - joeynmt.training - Example #6
2021-11-23 11:53:17,661 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:53:17,661 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:53:17,661 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '00']
2021-11-23 11:53:17,661 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:53:17,661 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:53:17,661 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:53:17,661 - INFO - joeynmt.training - 	Hypothesis: ▁5 00
2021-11-23 11:53:17,661 - INFO - joeynmt.training - Validation result (greedy) at epoch  54, step   180000: bleu:  13.97, loss: 73645.6797, ppl:   8.7983, duration: 104.3583s
2021-11-23 11:53:32,506 - INFO - joeynmt.training - Epoch  54, Step:   180100, Batch Loss:     1.930238, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 11:53:46,676 - INFO - joeynmt.training - Epoch  54, Step:   180200, Batch Loss:     2.009318, Tokens per Sec:     2170, Lr: 0.000100
2021-11-23 11:54:01,126 - INFO - joeynmt.training - Epoch  54, Step:   180300, Batch Loss:     1.922080, Tokens per Sec:     2198, Lr: 0.000100
2021-11-23 11:54:15,747 - INFO - joeynmt.training - Epoch  54, Step:   180400, Batch Loss:     1.968591, Tokens per Sec:     2167, Lr: 0.000100
2021-11-23 11:54:30,367 - INFO - joeynmt.training - Epoch  54, Step:   180500, Batch Loss:     1.911492, Tokens per Sec:     2115, Lr: 0.000100
2021-11-23 11:54:45,700 - INFO - joeynmt.training - Epoch  54, Step:   180600, Batch Loss:     1.960037, Tokens per Sec:     2113, Lr: 0.000100
2021-11-23 11:55:00,617 - INFO - joeynmt.training - Epoch  54, Step:   180700, Batch Loss:     2.367866, Tokens per Sec:     2130, Lr: 0.000100
2021-11-23 11:55:14,737 - INFO - joeynmt.training - Epoch  54, Step:   180800, Batch Loss:     1.964762, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 11:55:29,193 - INFO - joeynmt.training - Epoch  54, Step:   180900, Batch Loss:     1.820265, Tokens per Sec:     2183, Lr: 0.000100
2021-11-23 11:55:44,034 - INFO - joeynmt.training - Epoch  54, Step:   181000, Batch Loss:     1.717634, Tokens per Sec:     2169, Lr: 0.000100
2021-11-23 11:57:45,286 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 11:57:45,286 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 11:57:45,286 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 11:57:45,303 - INFO - joeynmt.training - Example #0
2021-11-23 11:57:45,303 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 11:57:45,303 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 11:57:45,303 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'op', '▁you', ',', '▁you', '▁are', '▁count', 'ed', '▁by', '▁Jud', 'as', '▁and', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 11:57:45,303 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 11:57:45,303 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 11:57:45,303 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 11:57:45,303 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t op ▁you , ▁you ▁are ▁count ed ▁by ▁Jud as ▁and ▁the ▁people ▁of ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 11:57:45,303 - INFO - joeynmt.training - Example #1
2021-11-23 11:57:45,303 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 11:57:45,303 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 11:57:45,303 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 11:57:45,303 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 11:57:45,303 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 11:57:45,303 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 11:57:45,303 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 11:57:45,303 - INFO - joeynmt.training - Example #2
2021-11-23 11:57:45,303 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 11:57:45,303 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 11:57:45,303 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 11:57:45,303 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 11:57:45,304 - INFO - joeynmt.training - Example #3
2021-11-23 11:57:45,304 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 11:57:45,304 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 11:57:45,304 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'so']
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur so
2021-11-23 11:57:45,304 - INFO - joeynmt.training - Example #6
2021-11-23 11:57:45,304 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 11:57:45,304 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 11:57:45,304 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '00']
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 11:57:45,304 - INFO - joeynmt.training - 	Hypothesis: ▁5 00
2021-11-23 11:57:45,304 - INFO - joeynmt.training - Validation result (greedy) at epoch  54, step   181000: bleu:  13.48, loss: 73522.1172, ppl:   8.7662, duration: 121.2701s
2021-11-23 11:57:59,521 - INFO - joeynmt.training - Epoch  54, Step:   181100, Batch Loss:     1.929543, Tokens per Sec:     2213, Lr: 0.000100
2021-11-23 11:58:13,686 - INFO - joeynmt.training - Epoch  54, Step:   181200, Batch Loss:     1.727530, Tokens per Sec:     2209, Lr: 0.000100
2021-11-23 11:58:27,763 - INFO - joeynmt.training - Epoch  54, Step:   181300, Batch Loss:     2.132744, Tokens per Sec:     2161, Lr: 0.000100
2021-11-23 11:58:42,563 - INFO - joeynmt.training - Epoch  54, Step:   181400, Batch Loss:     1.837953, Tokens per Sec:     2116, Lr: 0.000100
2021-11-23 11:58:57,093 - INFO - joeynmt.training - Epoch  54, Step:   181500, Batch Loss:     1.950002, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 11:59:12,678 - INFO - joeynmt.training - Epoch  54, Step:   181600, Batch Loss:     1.826310, Tokens per Sec:     2036, Lr: 0.000100
2021-11-23 11:59:27,304 - INFO - joeynmt.training - Epoch  54, Step:   181700, Batch Loss:     2.006818, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 11:59:41,658 - INFO - joeynmt.training - Epoch  54, Step:   181800, Batch Loss:     2.098200, Tokens per Sec:     2275, Lr: 0.000100
2021-11-23 11:59:56,406 - INFO - joeynmt.training - Epoch  54, Step:   181900, Batch Loss:     2.151618, Tokens per Sec:     2166, Lr: 0.000100
2021-11-23 12:00:11,774 - INFO - joeynmt.training - Epoch  54, Step:   182000, Batch Loss:     1.862206, Tokens per Sec:     2076, Lr: 0.000100
2021-11-23 12:02:10,796 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:02:10,798 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:02:10,798 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:02:10,817 - INFO - joeynmt.training - Example #0
2021-11-23 12:02:10,817 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:02:10,817 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:02:10,817 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'op', 's', '▁you', '▁were', '▁count', 'ing', '▁the', '▁time', '▁of', '▁Jud', 'e', 'a', '▁and', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', '▁are', '▁all', '▁the', '▁wall', 's', '.']
2021-11-23 12:02:10,817 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:02:10,817 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:02:10,817 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:02:10,817 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t op s ▁you ▁were ▁count ing ▁the ▁time ▁of ▁Jud e a ▁and ▁the ▁people ▁of ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁other ▁follow ers ▁are ▁all ▁the ▁wall s .
2021-11-23 12:02:10,817 - INFO - joeynmt.training - Example #1
2021-11-23 12:02:10,817 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:02:10,817 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:02:10,817 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:02:10,817 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:02:10,817 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:02:10,817 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:02:10,817 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:02:10,817 - INFO - joeynmt.training - Example #2
2021-11-23 12:02:10,817 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:02:10,817 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:02:10,817 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 12:02:10,818 - INFO - joeynmt.training - Example #3
2021-11-23 12:02:10,818 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:02:10,818 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:02:10,818 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 12:02:10,818 - INFO - joeynmt.training - Example #6
2021-11-23 12:02:10,818 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:02:10,818 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:02:10,818 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:02:10,818 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 12:02:10,818 - INFO - joeynmt.training - Validation result (greedy) at epoch  54, step   182000: bleu:  13.64, loss: 73317.1016, ppl:   8.7133, duration: 119.0437s
2021-11-23 12:02:26,145 - INFO - joeynmt.training - Epoch  54, Step:   182100, Batch Loss:     1.735940, Tokens per Sec:     2032, Lr: 0.000100
2021-11-23 12:02:40,480 - INFO - joeynmt.training - Epoch  54, Step:   182200, Batch Loss:     1.745696, Tokens per Sec:     2212, Lr: 0.000100
2021-11-23 12:02:55,144 - INFO - joeynmt.training - Epoch  54, Step:   182300, Batch Loss:     1.950195, Tokens per Sec:     2163, Lr: 0.000100
2021-11-23 12:03:09,911 - INFO - joeynmt.training - Epoch  54, Step:   182400, Batch Loss:     1.940732, Tokens per Sec:     2149, Lr: 0.000100
2021-11-23 12:03:23,754 - INFO - joeynmt.training - Epoch  54, Step:   182500, Batch Loss:     1.929457, Tokens per Sec:     2267, Lr: 0.000100
2021-11-23 12:03:38,515 - INFO - joeynmt.training - Epoch  54, Step:   182600, Batch Loss:     1.500212, Tokens per Sec:     2127, Lr: 0.000100
2021-11-23 12:03:54,012 - INFO - joeynmt.training - Epoch  54, Step:   182700, Batch Loss:     1.947148, Tokens per Sec:     2038, Lr: 0.000100
2021-11-23 12:04:08,875 - INFO - joeynmt.training - Epoch  54, Step:   182800, Batch Loss:     1.987372, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 12:04:23,562 - INFO - joeynmt.training - Epoch  54, Step:   182900, Batch Loss:     2.007881, Tokens per Sec:     2158, Lr: 0.000100
2021-11-23 12:04:37,792 - INFO - joeynmt.training - Epoch  54, Step:   183000, Batch Loss:     1.860015, Tokens per Sec:     2225, Lr: 0.000100
2021-11-23 12:06:36,179 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:06:36,179 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:06:36,179 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:06:36,192 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 12:06:37,112 - INFO - joeynmt.helpers - delete models/baseline_multilingual/180000.ckpt
2021-11-23 12:06:37,113 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/180000.ckpt
2021-11-23 12:06:37,113 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/180000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/180000.ckpt')
2021-11-23 12:06:37,168 - INFO - joeynmt.training - Example #0
2021-11-23 12:06:37,168 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:06:37,168 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:06:37,168 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁are', '▁count', 'ing', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 12:06:37,169 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:06:37,169 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:06:37,169 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:06:37,169 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁are ▁count ing ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 12:06:37,169 - INFO - joeynmt.training - Example #1
2021-11-23 12:06:37,169 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:06:37,170 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:06:37,170 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:06:37,170 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:06:37,170 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:06:37,170 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:06:37,170 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:06:37,170 - INFO - joeynmt.training - Example #2
2021-11-23 12:06:37,171 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:06:37,171 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:06:37,171 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁the', '▁end', '▁of', '▁love', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '.']
2021-11-23 12:06:37,171 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:06:37,171 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:06:37,171 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:06:37,171 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁the ▁end ▁of ▁love ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one .
2021-11-23 12:06:37,172 - INFO - joeynmt.training - Example #3
2021-11-23 12:06:37,172 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:06:37,172 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:06:37,172 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'ista']
2021-11-23 12:06:37,172 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:06:37,172 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:06:37,172 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:06:37,172 - INFO - joeynmt.training - 	Hypothesis: ▁d er v ista
2021-11-23 12:06:37,173 - INFO - joeynmt.training - Example #6
2021-11-23 12:06:37,173 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:06:37,173 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:06:37,173 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '00']
2021-11-23 12:06:37,173 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:06:37,173 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:06:37,173 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:06:37,173 - INFO - joeynmt.training - 	Hypothesis: ▁5 00
2021-11-23 12:06:37,174 - INFO - joeynmt.training - Validation result (greedy) at epoch  54, step   183000: bleu:  14.14, loss: 73204.9453, ppl:   8.6845, duration: 119.3812s
2021-11-23 12:06:37,915 - INFO - joeynmt.training - Epoch  54: total training loss 6563.42
2021-11-23 12:06:37,915 - INFO - joeynmt.training - EPOCH 55
2021-11-23 12:06:52,140 - INFO - joeynmt.training - Epoch  55, Step:   183100, Batch Loss:     1.928236, Tokens per Sec:     2088, Lr: 0.000100
2021-11-23 12:07:07,780 - INFO - joeynmt.training - Epoch  55, Step:   183200, Batch Loss:     1.795652, Tokens per Sec:     2078, Lr: 0.000100
2021-11-23 12:07:22,585 - INFO - joeynmt.training - Epoch  55, Step:   183300, Batch Loss:     1.953546, Tokens per Sec:     2060, Lr: 0.000100
2021-11-23 12:07:37,489 - INFO - joeynmt.training - Epoch  55, Step:   183400, Batch Loss:     1.863575, Tokens per Sec:     2120, Lr: 0.000100
2021-11-23 12:07:51,965 - INFO - joeynmt.training - Epoch  55, Step:   183500, Batch Loss:     1.788082, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 12:08:06,477 - INFO - joeynmt.training - Epoch  55, Step:   183600, Batch Loss:     1.893553, Tokens per Sec:     2158, Lr: 0.000100
2021-11-23 12:08:21,014 - INFO - joeynmt.training - Epoch  55, Step:   183700, Batch Loss:     1.741060, Tokens per Sec:     2098, Lr: 0.000100
2021-11-23 12:08:35,643 - INFO - joeynmt.training - Epoch  55, Step:   183800, Batch Loss:     1.824184, Tokens per Sec:     2076, Lr: 0.000100
2021-11-23 12:08:50,701 - INFO - joeynmt.training - Epoch  55, Step:   183900, Batch Loss:     1.935032, Tokens per Sec:     2141, Lr: 0.000100
2021-11-23 12:09:05,243 - INFO - joeynmt.training - Epoch  55, Step:   184000, Batch Loss:     2.012143, Tokens per Sec:     2207, Lr: 0.000100
2021-11-23 12:10:52,669 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:10:52,669 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:10:52,669 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:10:52,685 - INFO - joeynmt.training - Example #0
2021-11-23 12:10:52,686 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:10:52,686 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:10:52,686 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁are', '▁count', 'ed', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁the', '▁wall', 's', '.']
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁are ▁count ed ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁the ▁wall s .
2021-11-23 12:10:52,686 - INFO - joeynmt.training - Example #1
2021-11-23 12:10:52,686 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:10:52,686 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:10:52,686 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:10:52,686 - INFO - joeynmt.training - Example #2
2021-11-23 12:10:52,686 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:10:52,686 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:10:52,686 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:10:52,686 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:10:52,687 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 12:10:52,687 - INFO - joeynmt.training - Example #3
2021-11-23 12:10:52,687 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:10:52,687 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:10:52,687 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'oso']
2021-11-23 12:10:52,687 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:10:52,687 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:10:52,687 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:10:52,687 - INFO - joeynmt.training - 	Hypothesis: ▁d er v oso
2021-11-23 12:10:52,687 - INFO - joeynmt.training - Example #6
2021-11-23 12:10:52,687 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:10:52,687 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:10:52,687 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '00']
2021-11-23 12:10:52,687 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:10:52,687 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:10:52,687 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:10:52,687 - INFO - joeynmt.training - 	Hypothesis: ▁5 00
2021-11-23 12:10:52,687 - INFO - joeynmt.training - Validation result (greedy) at epoch  55, step   184000: bleu:  14.13, loss: 73656.2812, ppl:   8.8010, duration: 107.4440s
2021-11-23 12:11:08,101 - INFO - joeynmt.training - Epoch  55, Step:   184100, Batch Loss:     1.760106, Tokens per Sec:     2124, Lr: 0.000100
2021-11-23 12:11:23,486 - INFO - joeynmt.training - Epoch  55, Step:   184200, Batch Loss:     2.028330, Tokens per Sec:     2185, Lr: 0.000100
2021-11-23 12:11:37,902 - INFO - joeynmt.training - Epoch  55, Step:   184300, Batch Loss:     1.959320, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 12:11:52,219 - INFO - joeynmt.training - Epoch  55, Step:   184400, Batch Loss:     2.083534, Tokens per Sec:     2213, Lr: 0.000100
2021-11-23 12:12:06,892 - INFO - joeynmt.training - Epoch  55, Step:   184500, Batch Loss:     1.730026, Tokens per Sec:     2128, Lr: 0.000100
2021-11-23 12:12:21,173 - INFO - joeynmt.training - Epoch  55, Step:   184600, Batch Loss:     1.861053, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 12:12:35,413 - INFO - joeynmt.training - Epoch  55, Step:   184700, Batch Loss:     1.750243, Tokens per Sec:     2182, Lr: 0.000100
2021-11-23 12:12:51,160 - INFO - joeynmt.training - Epoch  55, Step:   184800, Batch Loss:     1.711640, Tokens per Sec:     2077, Lr: 0.000100
2021-11-23 12:13:05,584 - INFO - joeynmt.training - Epoch  55, Step:   184900, Batch Loss:     1.837150, Tokens per Sec:     2129, Lr: 0.000100
2021-11-23 12:13:20,188 - INFO - joeynmt.training - Epoch  55, Step:   185000, Batch Loss:     1.982954, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 12:15:01,894 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:15:01,894 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:15:01,894 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:15:01,906 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 12:15:02,904 - INFO - joeynmt.helpers - delete models/baseline_multilingual/183000.ckpt
2021-11-23 12:15:02,905 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/183000.ckpt
2021-11-23 12:15:02,905 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/183000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/183000.ckpt')
2021-11-23 12:15:02,960 - INFO - joeynmt.training - Example #0
2021-11-23 12:15:02,960 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:15:02,961 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:15:02,961 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'L', 'et', '▁you', '▁have', '▁been', '▁f', 'av', 'or', '▁of', '▁Jud', 'as', ',', '▁and', '▁you', '▁are', '▁follow', 'ing', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁But', '▁you', '▁follow', 'ed', '▁one', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 12:15:02,961 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:15:02,961 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:15:02,961 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:15:02,961 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" L et ▁you ▁have ▁been ▁f av or ▁of ▁Jud as , ▁and ▁you ▁are ▁follow ing ▁the ▁people ▁of ▁Gal ile e . ▁But ▁you ▁follow ed ▁one , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 12:15:02,961 - INFO - joeynmt.training - Example #1
2021-11-23 12:15:02,962 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:15:02,962 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:15:02,962 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:15:02,962 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:15:02,962 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:15:02,962 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:15:02,962 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:15:02,963 - INFO - joeynmt.training - Example #2
2021-11-23 12:15:02,963 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:15:02,963 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:15:02,963 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁hap', 'p', 'y', '▁to', '▁ple', 'ase', '▁the', '▁end', '▁of', '▁the', '▁end', '▁of', '▁love', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 12:15:02,963 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:15:02,963 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:15:02,963 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:15:02,963 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁hap p y ▁to ▁ple ase ▁the ▁end ▁of ▁the ▁end ▁of ▁love ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 12:15:02,964 - INFO - joeynmt.training - Example #3
2021-11-23 12:15:02,964 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:15:02,964 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:15:02,964 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 12:15:02,964 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:15:02,964 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:15:02,964 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:15:02,964 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 12:15:02,964 - INFO - joeynmt.training - Example #6
2021-11-23 12:15:02,964 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:15:02,964 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:15:02,964 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '5']
2021-11-23 12:15:02,964 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:15:02,964 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:15:02,964 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:15:02,964 - INFO - joeynmt.training - 	Hypothesis: ▁5 5
2021-11-23 12:15:02,965 - INFO - joeynmt.training - Validation result (greedy) at epoch  55, step   185000: bleu:  14.24, loss: 73349.2578, ppl:   8.7216, duration: 102.7761s
2021-11-23 12:15:17,388 - INFO - joeynmt.training - Epoch  55, Step:   185100, Batch Loss:     1.930126, Tokens per Sec:     2187, Lr: 0.000100
2021-11-23 12:15:32,347 - INFO - joeynmt.training - Epoch  55, Step:   185200, Batch Loss:     1.994553, Tokens per Sec:     2086, Lr: 0.000100
2021-11-23 12:15:46,929 - INFO - joeynmt.training - Epoch  55, Step:   185300, Batch Loss:     2.131331, Tokens per Sec:     2188, Lr: 0.000100
2021-11-23 12:16:01,039 - INFO - joeynmt.training - Epoch  55, Step:   185400, Batch Loss:     1.971278, Tokens per Sec:     2170, Lr: 0.000100
2021-11-23 12:16:15,329 - INFO - joeynmt.training - Epoch  55, Step:   185500, Batch Loss:     2.005560, Tokens per Sec:     2172, Lr: 0.000100
2021-11-23 12:16:30,643 - INFO - joeynmt.training - Epoch  55, Step:   185600, Batch Loss:     1.824405, Tokens per Sec:     2002, Lr: 0.000100
2021-11-23 12:16:44,424 - INFO - joeynmt.training - Epoch  55, Step:   185700, Batch Loss:     2.109663, Tokens per Sec:     2269, Lr: 0.000100
2021-11-23 12:16:58,946 - INFO - joeynmt.training - Epoch  55, Step:   185800, Batch Loss:     1.892968, Tokens per Sec:     2188, Lr: 0.000100
2021-11-23 12:17:13,366 - INFO - joeynmt.training - Epoch  55, Step:   185900, Batch Loss:     1.782710, Tokens per Sec:     2195, Lr: 0.000100
2021-11-23 12:17:28,004 - INFO - joeynmt.training - Epoch  55, Step:   186000, Batch Loss:     2.032306, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 12:19:18,388 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:19:18,388 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:19:18,388 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:19:18,404 - INFO - joeynmt.training - Example #0
2021-11-23 12:19:18,404 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:19:18,404 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:19:18,404 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁were', '▁count', 'ry', 'ing', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁people', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 12:19:18,404 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:19:18,404 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:19:18,404 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁were ▁count ry ing ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁people ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁all ow ed .
2021-11-23 12:19:18,405 - INFO - joeynmt.training - Example #1
2021-11-23 12:19:18,405 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:19:18,405 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:19:18,405 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:19:18,405 - INFO - joeynmt.training - Example #2
2021-11-23 12:19:18,405 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:19:18,405 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:19:18,405 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁great', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁work', '▁with', '▁each', '▁other', ',', '▁one', '▁another', '.']
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁great ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other , ▁work ▁with ▁each ▁other , ▁one ▁another .
2021-11-23 12:19:18,405 - INFO - joeynmt.training - Example #3
2021-11-23 12:19:18,405 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:19:18,405 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:19:18,405 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:19:18,405 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 12:19:18,406 - INFO - joeynmt.training - Example #6
2021-11-23 12:19:18,406 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:19:18,406 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:19:18,406 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '5']
2021-11-23 12:19:18,406 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:19:18,406 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:19:18,406 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:19:18,406 - INFO - joeynmt.training - 	Hypothesis: ▁5 5
2021-11-23 12:19:18,406 - INFO - joeynmt.training - Validation result (greedy) at epoch  55, step   186000: bleu:  14.15, loss: 72952.3984, ppl:   8.6200, duration: 110.4016s
2021-11-23 12:19:33,068 - INFO - joeynmt.training - Epoch  55, Step:   186100, Batch Loss:     1.995943, Tokens per Sec:     2163, Lr: 0.000100
2021-11-23 12:19:47,802 - INFO - joeynmt.training - Epoch  55, Step:   186200, Batch Loss:     2.059181, Tokens per Sec:     2140, Lr: 0.000100
2021-11-23 12:20:02,435 - INFO - joeynmt.training - Epoch  55, Step:   186300, Batch Loss:     2.046490, Tokens per Sec:     2195, Lr: 0.000100
2021-11-23 12:20:15,894 - INFO - joeynmt.training - Epoch  55: total training loss 6520.15
2021-11-23 12:20:15,894 - INFO - joeynmt.training - EPOCH 56
2021-11-23 12:20:16,668 - INFO - joeynmt.training - Epoch  56, Step:   186400, Batch Loss:     1.930994, Tokens per Sec:     1721, Lr: 0.000100
2021-11-23 12:20:30,664 - INFO - joeynmt.training - Epoch  56, Step:   186500, Batch Loss:     1.836143, Tokens per Sec:     2196, Lr: 0.000100
2021-11-23 12:20:44,487 - INFO - joeynmt.training - Epoch  56, Step:   186600, Batch Loss:     1.957780, Tokens per Sec:     2177, Lr: 0.000100
2021-11-23 12:20:58,942 - INFO - joeynmt.training - Epoch  56, Step:   186700, Batch Loss:     1.869124, Tokens per Sec:     2089, Lr: 0.000100
2021-11-23 12:21:14,382 - INFO - joeynmt.training - Epoch  56, Step:   186800, Batch Loss:     1.752295, Tokens per Sec:     2059, Lr: 0.000100
2021-11-23 12:21:29,735 - INFO - joeynmt.training - Epoch  56, Step:   186900, Batch Loss:     1.771560, Tokens per Sec:     2152, Lr: 0.000100
2021-11-23 12:21:43,813 - INFO - joeynmt.training - Epoch  56, Step:   187000, Batch Loss:     1.799643, Tokens per Sec:     2245, Lr: 0.000100
2021-11-23 12:23:28,093 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:23:28,093 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:23:28,094 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:23:28,105 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 12:23:28,978 - INFO - joeynmt.helpers - delete models/baseline_multilingual/185000.ckpt
2021-11-23 12:23:28,979 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/185000.ckpt
2021-11-23 12:23:28,979 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/185000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/185000.ckpt')
2021-11-23 12:23:29,034 - INFO - joeynmt.training - Example #0
2021-11-23 12:23:29,035 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:23:29,035 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:23:29,035 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁are', '▁count', 'ed', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 12:23:29,035 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:23:29,035 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:23:29,035 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:23:29,036 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁are ▁count ed ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁follow ed ▁all ▁his ▁follow ers ▁and ▁all ▁his ▁follow ers .
2021-11-23 12:23:29,036 - INFO - joeynmt.training - Example #1
2021-11-23 12:23:29,036 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:23:29,036 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:23:29,036 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:23:29,036 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:23:29,036 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:23:29,037 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:23:29,037 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:23:29,037 - INFO - joeynmt.training - Example #2
2021-11-23 12:23:29,037 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:23:29,037 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:23:29,037 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁hap', 'p', 'y', '▁to', '▁ple', 'ase', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 12:23:29,037 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:23:29,037 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:23:29,037 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:23:29,038 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁hap p y ▁to ▁ple ase ▁with ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 12:23:29,038 - INFO - joeynmt.training - Example #3
2021-11-23 12:23:29,038 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:23:29,038 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:23:29,038 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'so']
2021-11-23 12:23:29,038 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:23:29,038 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:23:29,038 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:23:29,038 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur so
2021-11-23 12:23:29,038 - INFO - joeynmt.training - Example #6
2021-11-23 12:23:29,038 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:23:29,038 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:23:29,038 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '5']
2021-11-23 12:23:29,038 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:23:29,039 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:23:29,039 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:23:29,039 - INFO - joeynmt.training - 	Hypothesis: ▁5 5
2021-11-23 12:23:29,039 - INFO - joeynmt.training - Validation result (greedy) at epoch  56, step   187000: bleu:  14.47, loss: 73407.2188, ppl:   8.7365, duration: 105.2253s
2021-11-23 12:23:44,045 - INFO - joeynmt.training - Epoch  56, Step:   187100, Batch Loss:     1.756916, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 12:23:58,578 - INFO - joeynmt.training - Epoch  56, Step:   187200, Batch Loss:     1.987488, Tokens per Sec:     2138, Lr: 0.000100
2021-11-23 12:24:13,749 - INFO - joeynmt.training - Epoch  56, Step:   187300, Batch Loss:     1.891084, Tokens per Sec:     2054, Lr: 0.000100
2021-11-23 12:24:28,439 - INFO - joeynmt.training - Epoch  56, Step:   187400, Batch Loss:     1.900768, Tokens per Sec:     2189, Lr: 0.000100
2021-11-23 12:24:44,286 - INFO - joeynmt.training - Epoch  56, Step:   187500, Batch Loss:     2.044250, Tokens per Sec:     2111, Lr: 0.000100
2021-11-23 12:24:59,175 - INFO - joeynmt.training - Epoch  56, Step:   187600, Batch Loss:     1.936106, Tokens per Sec:     2081, Lr: 0.000100
2021-11-23 12:25:13,726 - INFO - joeynmt.training - Epoch  56, Step:   187700, Batch Loss:     1.839860, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 12:25:28,385 - INFO - joeynmt.training - Epoch  56, Step:   187800, Batch Loss:     2.439996, Tokens per Sec:     2114, Lr: 0.000100
2021-11-23 12:25:42,921 - INFO - joeynmt.training - Epoch  56, Step:   187900, Batch Loss:     1.836992, Tokens per Sec:     2202, Lr: 0.000100
2021-11-23 12:25:57,285 - INFO - joeynmt.training - Epoch  56, Step:   188000, Batch Loss:     2.000190, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 12:27:52,723 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:27:52,723 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:27:52,723 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:27:52,742 - INFO - joeynmt.training - Example #0
2021-11-23 12:27:52,743 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:27:52,743 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:27:52,743 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁were', '▁count', 'ry', 'ing', '▁from', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁were ▁count ry ing ▁from ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 12:27:52,743 - INFO - joeynmt.training - Example #1
2021-11-23 12:27:52,743 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:27:52,743 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:27:52,743 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:27:52,743 - INFO - joeynmt.training - Example #2
2021-11-23 12:27:52,743 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:27:52,743 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:27:52,743 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:27:52,743 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 12:27:52,744 - INFO - joeynmt.training - Example #3
2021-11-23 12:27:52,744 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:27:52,744 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:27:52,744 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 12:27:52,744 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:27:52,744 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:27:52,744 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:27:52,744 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 12:27:52,744 - INFO - joeynmt.training - Example #6
2021-11-23 12:27:52,744 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:27:52,744 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:27:52,744 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 12:27:52,744 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:27:52,744 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:27:52,744 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:27:52,744 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 12:27:52,744 - INFO - joeynmt.training - Validation result (greedy) at epoch  56, step   188000: bleu:  14.05, loss: 73368.1016, ppl:   8.7265, duration: 115.4585s
2021-11-23 12:28:07,354 - INFO - joeynmt.training - Epoch  56, Step:   188100, Batch Loss:     1.934250, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 12:28:21,887 - INFO - joeynmt.training - Epoch  56, Step:   188200, Batch Loss:     1.904100, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 12:28:37,283 - INFO - joeynmt.training - Epoch  56, Step:   188300, Batch Loss:     2.014290, Tokens per Sec:     2101, Lr: 0.000100
2021-11-23 12:28:51,301 - INFO - joeynmt.training - Epoch  56, Step:   188400, Batch Loss:     2.097170, Tokens per Sec:     2253, Lr: 0.000100
2021-11-23 12:29:05,933 - INFO - joeynmt.training - Epoch  56, Step:   188500, Batch Loss:     1.901902, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 12:29:20,271 - INFO - joeynmt.training - Epoch  56, Step:   188600, Batch Loss:     1.818817, Tokens per Sec:     2105, Lr: 0.000100
2021-11-23 12:29:34,357 - INFO - joeynmt.training - Epoch  56, Step:   188700, Batch Loss:     2.115502, Tokens per Sec:     2155, Lr: 0.000100
2021-11-23 12:29:48,501 - INFO - joeynmt.training - Epoch  56, Step:   188800, Batch Loss:     1.989279, Tokens per Sec:     2150, Lr: 0.000100
2021-11-23 12:30:02,778 - INFO - joeynmt.training - Epoch  56, Step:   188900, Batch Loss:     1.992817, Tokens per Sec:     2134, Lr: 0.000100
2021-11-23 12:30:16,920 - INFO - joeynmt.training - Epoch  56, Step:   189000, Batch Loss:     1.941489, Tokens per Sec:     2236, Lr: 0.000100
2021-11-23 12:32:09,971 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:32:09,971 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:32:09,971 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:32:09,994 - INFO - joeynmt.training - Example #0
2021-11-23 12:32:09,994 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:32:09,994 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:32:09,994 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁count', 'ing', ',', '▁J', 'ul', 'i', 'us', '▁was', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁his', '▁follow', 'ers', '▁are', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 12:32:09,994 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:32:09,994 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:32:09,994 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:32:09,994 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁count ing , ▁J ul i us ▁was ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁his ▁follow ers ▁are ▁all ▁his ▁follow ers .
2021-11-23 12:32:09,994 - INFO - joeynmt.training - Example #1
2021-11-23 12:32:09,994 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:32:09,994 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:32:09,994 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:32:09,994 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:32:09,994 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:32:09,994 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:32:09,994 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:32:09,994 - INFO - joeynmt.training - Example #2
2021-11-23 12:32:09,994 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:32:09,995 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:32:09,995 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁one', '▁another', '.']
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁each ▁other , ▁one ▁another .
2021-11-23 12:32:09,995 - INFO - joeynmt.training - Example #3
2021-11-23 12:32:09,995 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:32:09,995 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:32:09,995 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 12:32:09,995 - INFO - joeynmt.training - Example #6
2021-11-23 12:32:09,995 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:32:09,995 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:32:09,995 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:32:09,995 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 12:32:09,995 - INFO - joeynmt.training - Validation result (greedy) at epoch  56, step   189000: bleu:  13.79, loss: 73038.7109, ppl:   8.6420, duration: 113.0748s
2021-11-23 12:32:24,862 - INFO - joeynmt.training - Epoch  56, Step:   189100, Batch Loss:     1.923389, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 12:32:40,690 - INFO - joeynmt.training - Epoch  56, Step:   189200, Batch Loss:     2.147902, Tokens per Sec:     2071, Lr: 0.000100
2021-11-23 12:32:56,029 - INFO - joeynmt.training - Epoch  56, Step:   189300, Batch Loss:     1.820416, Tokens per Sec:     2144, Lr: 0.000100
2021-11-23 12:33:10,987 - INFO - joeynmt.training - Epoch  56, Step:   189400, Batch Loss:     1.872813, Tokens per Sec:     2094, Lr: 0.000100
2021-11-23 12:33:25,085 - INFO - joeynmt.training - Epoch  56, Step:   189500, Batch Loss:     1.624183, Tokens per Sec:     2151, Lr: 0.000100
2021-11-23 12:33:40,009 - INFO - joeynmt.training - Epoch  56, Step:   189600, Batch Loss:     2.152325, Tokens per Sec:     2146, Lr: 0.000100
2021-11-23 12:33:54,567 - INFO - joeynmt.training - Epoch  56, Step:   189700, Batch Loss:     2.174548, Tokens per Sec:     2125, Lr: 0.000100
2021-11-23 12:34:06,944 - INFO - joeynmt.training - Epoch  56: total training loss 6486.01
2021-11-23 12:34:06,944 - INFO - joeynmt.training - EPOCH 57
2021-11-23 12:34:09,133 - INFO - joeynmt.training - Epoch  57, Step:   189800, Batch Loss:     1.808746, Tokens per Sec:     2097, Lr: 0.000100
2021-11-23 12:34:24,190 - INFO - joeynmt.training - Epoch  57, Step:   189900, Batch Loss:     1.937045, Tokens per Sec:     2013, Lr: 0.000100
2021-11-23 12:34:39,221 - INFO - joeynmt.training - Epoch  57, Step:   190000, Batch Loss:     1.821210, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 12:36:23,887 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:36:23,887 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:36:23,887 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:36:23,905 - INFO - joeynmt.training - Example #0
2021-11-23 12:36:23,905 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:36:23,905 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:36:23,906 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁time', ',', '▁you', '▁were', '▁count', 'ing', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁you', '▁are', '▁follow', 'ing', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁your', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁time , ▁you ▁were ▁count ing ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁you ▁are ▁follow ing ▁your ▁follow ers , ▁and ▁all ▁your ▁follow ers ▁are ▁sc atter ed .
2021-11-23 12:36:23,906 - INFO - joeynmt.training - Example #1
2021-11-23 12:36:23,906 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:36:23,906 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:36:23,906 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:36:23,906 - INFO - joeynmt.training - Example #2
2021-11-23 12:36:23,906 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:36:23,906 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:36:23,906 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁be', '▁with', '▁one', '▁another', '.']
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:36:23,906 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁be ▁with ▁one ▁another .
2021-11-23 12:36:23,906 - INFO - joeynmt.training - Example #3
2021-11-23 12:36:23,906 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:36:23,906 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:36:23,907 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 12:36:23,907 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:36:23,907 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:36:23,907 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:36:23,907 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 12:36:23,907 - INFO - joeynmt.training - Example #6
2021-11-23 12:36:23,907 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:36:23,907 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:36:23,907 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 12:36:23,907 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:36:23,907 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:36:23,907 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:36:23,907 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 12:36:23,907 - INFO - joeynmt.training - Validation result (greedy) at epoch  57, step   190000: bleu:  14.14, loss: 73046.6094, ppl:   8.6440, duration: 104.6854s
2021-11-23 12:36:38,845 - INFO - joeynmt.training - Epoch  57, Step:   190100, Batch Loss:     1.665212, Tokens per Sec:     2178, Lr: 0.000100
2021-11-23 12:36:53,162 - INFO - joeynmt.training - Epoch  57, Step:   190200, Batch Loss:     1.774674, Tokens per Sec:     2209, Lr: 0.000100
2021-11-23 12:37:08,464 - INFO - joeynmt.training - Epoch  57, Step:   190300, Batch Loss:     2.029266, Tokens per Sec:     2073, Lr: 0.000100
2021-11-23 12:37:23,145 - INFO - joeynmt.training - Epoch  57, Step:   190400, Batch Loss:     1.837153, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 12:37:37,029 - INFO - joeynmt.training - Epoch  57, Step:   190500, Batch Loss:     2.320323, Tokens per Sec:     2197, Lr: 0.000100
2021-11-23 12:37:51,155 - INFO - joeynmt.training - Epoch  57, Step:   190600, Batch Loss:     1.811265, Tokens per Sec:     2225, Lr: 0.000100
2021-11-23 12:38:05,390 - INFO - joeynmt.training - Epoch  57, Step:   190700, Batch Loss:     1.877422, Tokens per Sec:     2192, Lr: 0.000100
2021-11-23 12:38:19,777 - INFO - joeynmt.training - Epoch  57, Step:   190800, Batch Loss:     1.843667, Tokens per Sec:     2140, Lr: 0.000100
2021-11-23 12:38:34,795 - INFO - joeynmt.training - Epoch  57, Step:   190900, Batch Loss:     1.858716, Tokens per Sec:     2122, Lr: 0.000100
2021-11-23 12:38:49,168 - INFO - joeynmt.training - Epoch  57, Step:   191000, Batch Loss:     1.932847, Tokens per Sec:     2232, Lr: 0.000100
2021-11-23 12:40:37,528 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:40:37,529 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:40:37,529 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:40:37,546 - INFO - joeynmt.training - Example #0
2021-11-23 12:40:37,546 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:40:37,546 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:40:37,546 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁count', 'ed', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 12:40:37,546 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:40:37,546 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:40:37,546 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:40:37,546 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁count ed ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 12:40:37,546 - INFO - joeynmt.training - Example #1
2021-11-23 12:40:37,546 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:40:37,546 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:40:37,546 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:40:37,546 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:40:37,546 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:40:37,546 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:40:37,546 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:40:37,546 - INFO - joeynmt.training - Example #2
2021-11-23 12:40:37,546 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:40:37,546 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:40:37,546 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁the', '▁end', '▁of', '▁love', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁one', '▁another', '.']
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁the ▁end ▁of ▁love , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁one ▁another .
2021-11-23 12:40:37,547 - INFO - joeynmt.training - Example #3
2021-11-23 12:40:37,547 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:40:37,547 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:40:37,547 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'isar']
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Hypothesis: ▁D es c isar
2021-11-23 12:40:37,547 - INFO - joeynmt.training - Example #6
2021-11-23 12:40:37,547 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:40:37,547 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:40:37,547 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:40:37,547 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 12:40:37,547 - INFO - joeynmt.training - Validation result (greedy) at epoch  57, step   191000: bleu:  13.95, loss: 73108.6875, ppl:   8.6599, duration: 108.3789s
2021-11-23 12:40:52,425 - INFO - joeynmt.training - Epoch  57, Step:   191100, Batch Loss:     1.711372, Tokens per Sec:     2137, Lr: 0.000100
2021-11-23 12:41:06,998 - INFO - joeynmt.training - Epoch  57, Step:   191200, Batch Loss:     1.882280, Tokens per Sec:     2156, Lr: 0.000100
2021-11-23 12:41:21,825 - INFO - joeynmt.training - Epoch  57, Step:   191300, Batch Loss:     1.853612, Tokens per Sec:     1991, Lr: 0.000100
2021-11-23 12:41:36,711 - INFO - joeynmt.training - Epoch  57, Step:   191400, Batch Loss:     1.852098, Tokens per Sec:     2107, Lr: 0.000100
2021-11-23 12:41:51,674 - INFO - joeynmt.training - Epoch  57, Step:   191500, Batch Loss:     1.800531, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 12:42:07,478 - INFO - joeynmt.training - Epoch  57, Step:   191600, Batch Loss:     1.706091, Tokens per Sec:     2074, Lr: 0.000100
2021-11-23 12:42:22,468 - INFO - joeynmt.training - Epoch  57, Step:   191700, Batch Loss:     1.785419, Tokens per Sec:     2082, Lr: 0.000100
2021-11-23 12:42:37,271 - INFO - joeynmt.training - Epoch  57, Step:   191800, Batch Loss:     1.866782, Tokens per Sec:     2217, Lr: 0.000100
2021-11-23 12:42:51,254 - INFO - joeynmt.training - Epoch  57, Step:   191900, Batch Loss:     1.954387, Tokens per Sec:     2217, Lr: 0.000100
2021-11-23 12:43:06,048 - INFO - joeynmt.training - Epoch  57, Step:   192000, Batch Loss:     2.010124, Tokens per Sec:     2106, Lr: 0.000100
2021-11-23 12:44:55,219 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:44:55,219 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:44:55,219 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:44:55,238 - INFO - joeynmt.training - Example #0
2021-11-23 12:44:55,238 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:44:55,238 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:44:55,238 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁are', '▁count', 'ed', '▁from', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 12:44:55,238 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁are ▁count ed ▁from ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 12:44:55,239 - INFO - joeynmt.training - Example #1
2021-11-23 12:44:55,239 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:44:55,239 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:44:55,239 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:44:55,239 - INFO - joeynmt.training - Example #2
2021-11-23 12:44:55,239 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:44:55,239 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:44:55,239 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁the', '▁end', '▁of', '▁love', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁be', '▁with', '▁one', '▁another', '.']
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁the ▁end ▁of ▁love , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁be ▁with ▁one ▁another .
2021-11-23 12:44:55,239 - INFO - joeynmt.training - Example #3
2021-11-23 12:44:55,239 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:44:55,239 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:44:55,239 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'so']
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:44:55,239 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:44:55,240 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur so
2021-11-23 12:44:55,240 - INFO - joeynmt.training - Example #6
2021-11-23 12:44:55,240 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:44:55,240 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:44:55,240 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 12:44:55,240 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:44:55,240 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:44:55,240 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:44:55,240 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 12:44:55,240 - INFO - joeynmt.training - Validation result (greedy) at epoch  57, step   192000: bleu:  14.06, loss: 72915.8672, ppl:   8.6107, duration: 109.1913s
2021-11-23 12:45:09,385 - INFO - joeynmt.training - Epoch  57, Step:   192100, Batch Loss:     1.922573, Tokens per Sec:     2228, Lr: 0.000100
2021-11-23 12:45:23,773 - INFO - joeynmt.training - Epoch  57, Step:   192200, Batch Loss:     1.943336, Tokens per Sec:     2239, Lr: 0.000100
2021-11-23 12:45:38,544 - INFO - joeynmt.training - Epoch  57, Step:   192300, Batch Loss:     1.975289, Tokens per Sec:     2118, Lr: 0.000100
2021-11-23 12:45:52,598 - INFO - joeynmt.training - Epoch  57, Step:   192400, Batch Loss:     1.809220, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 12:46:07,697 - INFO - joeynmt.training - Epoch  57, Step:   192500, Batch Loss:     1.763067, Tokens per Sec:     2160, Lr: 0.000100
2021-11-23 12:46:22,310 - INFO - joeynmt.training - Epoch  57, Step:   192600, Batch Loss:     1.951446, Tokens per Sec:     2181, Lr: 0.000100
2021-11-23 12:46:37,217 - INFO - joeynmt.training - Epoch  57, Step:   192700, Batch Loss:     1.913383, Tokens per Sec:     2080, Lr: 0.000100
2021-11-23 12:46:51,979 - INFO - joeynmt.training - Epoch  57, Step:   192800, Batch Loss:     2.182112, Tokens per Sec:     2121, Lr: 0.000100
2021-11-23 12:47:07,568 - INFO - joeynmt.training - Epoch  57, Step:   192900, Batch Loss:     1.956515, Tokens per Sec:     2020, Lr: 0.000100
2021-11-23 12:47:21,938 - INFO - joeynmt.training - Epoch  57, Step:   193000, Batch Loss:     1.823385, Tokens per Sec:     2154, Lr: 0.000100
2021-11-23 12:49:01,167 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:49:01,167 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:49:01,167 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:49:01,184 - INFO - joeynmt.training - Example #0
2021-11-23 12:49:01,184 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:49:01,184 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:49:01,185 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁have', '▁been', '▁count', 'ed', '▁from', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁he', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', '▁and', '▁the', '▁wall', 's', '.']
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁have ▁been ▁count ed ▁from ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁he ▁follow ed ▁all ▁his ▁follow ers ▁and ▁the ▁wall s .
2021-11-23 12:49:01,185 - INFO - joeynmt.training - Example #1
2021-11-23 12:49:01,185 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:49:01,185 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:49:01,185 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:49:01,185 - INFO - joeynmt.training - Example #2
2021-11-23 12:49:01,185 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:49:01,185 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:49:01,185 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁be', '▁with', '▁one', '▁another', '.']
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:49:01,185 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁be ▁with ▁one ▁another .
2021-11-23 12:49:01,185 - INFO - joeynmt.training - Example #3
2021-11-23 12:49:01,185 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:49:01,185 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:49:01,186 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 12:49:01,186 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:49:01,186 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:49:01,186 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:49:01,186 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 12:49:01,186 - INFO - joeynmt.training - Example #6
2021-11-23 12:49:01,186 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:49:01,186 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:49:01,186 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 12:49:01,186 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:49:01,186 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:49:01,186 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:49:01,186 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 12:49:01,186 - INFO - joeynmt.training - Validation result (greedy) at epoch  57, step   193000: bleu:  14.05, loss: 72690.5234, ppl:   8.5536, duration: 99.2472s
2021-11-23 12:49:16,310 - INFO - joeynmt.training - Epoch  57, Step:   193100, Batch Loss:     1.914249, Tokens per Sec:     2011, Lr: 0.000100
2021-11-23 12:49:26,381 - INFO - joeynmt.training - Epoch  57: total training loss 6451.37
2021-11-23 12:49:26,381 - INFO - joeynmt.training - EPOCH 58
2021-11-23 12:49:30,147 - INFO - joeynmt.training - Epoch  58, Step:   193200, Batch Loss:     1.584300, Tokens per Sec:     2284, Lr: 0.000100
2021-11-23 12:49:44,414 - INFO - joeynmt.training - Epoch  58, Step:   193300, Batch Loss:     1.622720, Tokens per Sec:     2176, Lr: 0.000100
2021-11-23 12:49:58,958 - INFO - joeynmt.training - Epoch  58, Step:   193400, Batch Loss:     1.983472, Tokens per Sec:     2189, Lr: 0.000100
2021-11-23 12:50:14,274 - INFO - joeynmt.training - Epoch  58, Step:   193500, Batch Loss:     1.894095, Tokens per Sec:     2072, Lr: 0.000100
2021-11-23 12:50:29,074 - INFO - joeynmt.training - Epoch  58, Step:   193600, Batch Loss:     1.919605, Tokens per Sec:     2079, Lr: 0.000100
2021-11-23 12:50:44,546 - INFO - joeynmt.training - Epoch  58, Step:   193700, Batch Loss:     1.815006, Tokens per Sec:     2111, Lr: 0.000100
2021-11-23 12:50:59,998 - INFO - joeynmt.training - Epoch  58, Step:   193800, Batch Loss:     2.043182, Tokens per Sec:     2042, Lr: 0.000100
2021-11-23 12:51:15,257 - INFO - joeynmt.training - Epoch  58, Step:   193900, Batch Loss:     1.857655, Tokens per Sec:     2083, Lr: 0.000100
2021-11-23 12:51:31,059 - INFO - joeynmt.training - Epoch  58, Step:   194000, Batch Loss:     1.856953, Tokens per Sec:     2040, Lr: 0.000100
2021-11-23 12:53:20,790 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:53:20,790 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:53:20,790 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:53:20,807 - INFO - joeynmt.training - Example #0
2021-11-23 12:53:20,807 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:53:20,807 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:53:20,808 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁have', '▁been', '▁count', 'ed', '▁from', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁follow', 'ed', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁have ▁been ▁count ed ▁from ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁follow ed ▁all ▁his ▁follow ers .
2021-11-23 12:53:20,808 - INFO - joeynmt.training - Example #1
2021-11-23 12:53:20,808 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:53:20,808 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:53:20,808 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:53:20,808 - INFO - joeynmt.training - Example #2
2021-11-23 12:53:20,808 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:53:20,808 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:53:20,808 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁joy', '▁by', '▁the', '▁end', '▁of', '▁love', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁be', '▁with', '▁one', '▁another', '.']
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:53:20,808 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁joy ▁by ▁the ▁end ▁of ▁love , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁be ▁with ▁one ▁another .
2021-11-23 12:53:20,808 - INFO - joeynmt.training - Example #3
2021-11-23 12:53:20,808 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:53:20,809 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:53:20,809 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁d', 'er', 'v', 'id', 'ar']
2021-11-23 12:53:20,809 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:53:20,809 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:53:20,809 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:53:20,809 - INFO - joeynmt.training - 	Hypothesis: ▁d er v id ar
2021-11-23 12:53:20,809 - INFO - joeynmt.training - Example #6
2021-11-23 12:53:20,809 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:53:20,809 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:53:20,809 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 12:53:20,809 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:53:20,809 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:53:20,809 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:53:20,809 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 12:53:20,809 - INFO - joeynmt.training - Validation result (greedy) at epoch  58, step   194000: bleu:  14.36, loss: 72919.3203, ppl:   8.6116, duration: 109.7493s
2021-11-23 12:53:34,576 - INFO - joeynmt.training - Epoch  58, Step:   194100, Batch Loss:     1.689016, Tokens per Sec:     2260, Lr: 0.000100
2021-11-23 12:53:49,259 - INFO - joeynmt.training - Epoch  58, Step:   194200, Batch Loss:     1.909888, Tokens per Sec:     2102, Lr: 0.000100
2021-11-23 12:54:03,465 - INFO - joeynmt.training - Epoch  58, Step:   194300, Batch Loss:     1.987960, Tokens per Sec:     2269, Lr: 0.000100
2021-11-23 12:54:17,931 - INFO - joeynmt.training - Epoch  58, Step:   194400, Batch Loss:     2.088448, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 12:54:32,644 - INFO - joeynmt.training - Epoch  58, Step:   194500, Batch Loss:     1.723967, Tokens per Sec:     2058, Lr: 0.000100
2021-11-23 12:54:48,450 - INFO - joeynmt.training - Epoch  58, Step:   194600, Batch Loss:     1.760360, Tokens per Sec:     2047, Lr: 0.000100
2021-11-23 12:55:03,452 - INFO - joeynmt.training - Epoch  58, Step:   194700, Batch Loss:     1.895835, Tokens per Sec:     2048, Lr: 0.000100
2021-11-23 12:55:18,429 - INFO - joeynmt.training - Epoch  58, Step:   194800, Batch Loss:     1.970110, Tokens per Sec:     2096, Lr: 0.000100
2021-11-23 12:55:32,981 - INFO - joeynmt.training - Epoch  58, Step:   194900, Batch Loss:     1.892086, Tokens per Sec:     2175, Lr: 0.000100
2021-11-23 12:55:46,839 - INFO - joeynmt.training - Epoch  58, Step:   195000, Batch Loss:     1.829513, Tokens per Sec:     2213, Lr: 0.000100
2021-11-23 12:58:02,070 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 12:58:02,071 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 12:58:02,071 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 12:58:02,089 - INFO - joeynmt.training - Example #0
2021-11-23 12:58:02,089 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 12:58:02,089 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 12:58:02,089 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁count', 'ry', 'ing', '▁J', 'ul', 'i', 'us', '▁from', '▁Gal', 'ile', 'e', '.', '▁He', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 12:58:02,089 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 12:58:02,089 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 12:58:02,089 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 12:58:02,089 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁count ry ing ▁J ul i us ▁from ▁Gal ile e . ▁He ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 12:58:02,089 - INFO - joeynmt.training - Example #1
2021-11-23 12:58:02,089 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 12:58:02,089 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 12:58:02,089 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 12:58:02,089 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 12:58:02,090 - INFO - joeynmt.training - Example #2
2021-11-23 12:58:02,090 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 12:58:02,090 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 12:58:02,090 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁work ▁with ▁one ▁another .
2021-11-23 12:58:02,090 - INFO - joeynmt.training - Example #3
2021-11-23 12:58:02,090 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 12:58:02,090 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 12:58:02,090 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 12:58:02,090 - INFO - joeynmt.training - Example #6
2021-11-23 12:58:02,090 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 12:58:02,090 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 12:58:02,090 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 12:58:02,090 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 12:58:02,091 - INFO - joeynmt.training - Validation result (greedy) at epoch  58, step   195000: bleu:  14.41, loss: 72725.9297, ppl:   8.5625, duration: 135.2512s
2021-11-23 12:58:16,716 - INFO - joeynmt.training - Epoch  58, Step:   195100, Batch Loss:     1.895487, Tokens per Sec:     2151, Lr: 0.000070
2021-11-23 12:58:31,381 - INFO - joeynmt.training - Epoch  58, Step:   195200, Batch Loss:     1.869627, Tokens per Sec:     2093, Lr: 0.000070
2021-11-23 12:58:45,648 - INFO - joeynmt.training - Epoch  58, Step:   195300, Batch Loss:     1.963693, Tokens per Sec:     2197, Lr: 0.000070
2021-11-23 12:59:00,844 - INFO - joeynmt.training - Epoch  58, Step:   195400, Batch Loss:     1.958035, Tokens per Sec:     2098, Lr: 0.000070
2021-11-23 12:59:14,957 - INFO - joeynmt.training - Epoch  58, Step:   195500, Batch Loss:     2.195510, Tokens per Sec:     2181, Lr: 0.000070
2021-11-23 12:59:29,009 - INFO - joeynmt.training - Epoch  58, Step:   195600, Batch Loss:     2.006636, Tokens per Sec:     2225, Lr: 0.000070
2021-11-23 12:59:43,665 - INFO - joeynmt.training - Epoch  58, Step:   195700, Batch Loss:     2.002787, Tokens per Sec:     2114, Lr: 0.000070
2021-11-23 12:59:57,623 - INFO - joeynmt.training - Epoch  58, Step:   195800, Batch Loss:     1.724014, Tokens per Sec:     2222, Lr: 0.000070
2021-11-23 13:00:12,927 - INFO - joeynmt.training - Epoch  58, Step:   195900, Batch Loss:     2.103979, Tokens per Sec:     2102, Lr: 0.000070
2021-11-23 13:00:27,175 - INFO - joeynmt.training - Epoch  58, Step:   196000, Batch Loss:     2.134586, Tokens per Sec:     2149, Lr: 0.000070
2021-11-23 13:02:26,869 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:02:26,869 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:02:26,869 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:02:26,887 - INFO - joeynmt.training - Example #0
2021-11-23 13:02:26,887 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:02:26,887 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:02:26,887 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁are', '▁count', 'ed', '▁from', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 13:02:26,887 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:02:26,887 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:02:26,887 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:02:26,887 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁are ▁count ed ▁from ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 13:02:26,888 - INFO - joeynmt.training - Example #1
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:02:26,888 - INFO - joeynmt.training - Example #2
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁and', '▁tell', 'ing', '▁one', '▁another', '.']
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁one ▁another , ▁and ▁tell ing ▁one ▁another .
2021-11-23 13:02:26,888 - INFO - joeynmt.training - Example #3
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:02:26,888 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 13:02:26,888 - INFO - joeynmt.training - Example #6
2021-11-23 13:02:26,888 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:02:26,889 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:02:26,889 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:02:26,889 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:02:26,889 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:02:26,889 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:02:26,889 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:02:26,889 - INFO - joeynmt.training - Validation result (greedy) at epoch  58, step   196000: bleu:  14.38, loss: 72393.2812, ppl:   8.4789, duration: 119.7133s
2021-11-23 13:02:41,398 - INFO - joeynmt.training - Epoch  58, Step:   196100, Batch Loss:     1.777959, Tokens per Sec:     2231, Lr: 0.000070
2021-11-23 13:02:55,605 - INFO - joeynmt.training - Epoch  58, Step:   196200, Batch Loss:     1.842396, Tokens per Sec:     2257, Lr: 0.000070
2021-11-23 13:03:10,387 - INFO - joeynmt.training - Epoch  58, Step:   196300, Batch Loss:     1.923384, Tokens per Sec:     2079, Lr: 0.000070
2021-11-23 13:03:25,088 - INFO - joeynmt.training - Epoch  58, Step:   196400, Batch Loss:     1.702452, Tokens per Sec:     2188, Lr: 0.000070
2021-11-23 13:03:40,246 - INFO - joeynmt.training - Epoch  58, Step:   196500, Batch Loss:     2.059596, Tokens per Sec:     2095, Lr: 0.000070
2021-11-23 13:03:49,266 - INFO - joeynmt.training - Epoch  58: total training loss 6399.16
2021-11-23 13:03:49,266 - INFO - joeynmt.training - EPOCH 59
2021-11-23 13:03:55,060 - INFO - joeynmt.training - Epoch  59, Step:   196600, Batch Loss:     1.637475, Tokens per Sec:     2199, Lr: 0.000070
2021-11-23 13:04:09,949 - INFO - joeynmt.training - Epoch  59, Step:   196700, Batch Loss:     1.872632, Tokens per Sec:     2143, Lr: 0.000070
2021-11-23 13:04:25,061 - INFO - joeynmt.training - Epoch  59, Step:   196800, Batch Loss:     1.825945, Tokens per Sec:     2100, Lr: 0.000070
2021-11-23 13:04:39,208 - INFO - joeynmt.training - Epoch  59, Step:   196900, Batch Loss:     1.876529, Tokens per Sec:     2234, Lr: 0.000070
2021-11-23 13:04:53,571 - INFO - joeynmt.training - Epoch  59, Step:   197000, Batch Loss:     1.794320, Tokens per Sec:     2162, Lr: 0.000070
2021-11-23 13:06:45,399 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:06:45,399 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:06:45,399 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:06:45,412 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 13:06:46,285 - INFO - joeynmt.helpers - delete models/baseline_multilingual/187000.ckpt
2021-11-23 13:06:46,286 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/187000.ckpt
2021-11-23 13:06:46,286 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/187000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/187000.ckpt')
2021-11-23 13:06:46,341 - INFO - joeynmt.training - Example #0
2021-11-23 13:06:46,341 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:06:46,341 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:06:46,341 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁go', '▁to', '▁Jerusalem', ',', '▁and', '▁you', '▁are', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 13:06:46,342 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:06:46,342 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:06:46,342 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:06:46,342 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁go ▁to ▁Jerusalem , ▁and ▁you ▁are ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 13:06:46,342 - INFO - joeynmt.training - Example #1
2021-11-23 13:06:46,342 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:06:46,343 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:06:46,343 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 13:06:46,343 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:06:46,343 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:06:46,343 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:06:46,343 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 13:06:46,343 - INFO - joeynmt.training - Example #2
2021-11-23 13:06:46,343 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:06:46,344 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:06:46,344 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁and', '▁love', '▁with', '▁one', '▁another', '.']
2021-11-23 13:06:46,344 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:06:46,344 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:06:46,344 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:06:46,344 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁each ▁other , ▁and ▁love ▁with ▁one ▁another .
2021-11-23 13:06:46,345 - INFO - joeynmt.training - Example #3
2021-11-23 13:06:46,345 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:06:46,345 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:06:46,345 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 13:06:46,345 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:06:46,345 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:06:46,345 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:06:46,345 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 13:06:46,346 - INFO - joeynmt.training - Example #6
2021-11-23 13:06:46,346 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:06:46,346 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:06:46,346 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁5', '00']
2021-11-23 13:06:46,346 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:06:46,346 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:06:46,346 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:06:46,346 - INFO - joeynmt.training - 	Hypothesis: ▁5 00
2021-11-23 13:06:46,347 - INFO - joeynmt.training - Validation result (greedy) at epoch  59, step   197000: bleu:  14.58, loss: 72542.0078, ppl:   8.5162, duration: 112.7753s
2021-11-23 13:07:01,398 - INFO - joeynmt.training - Epoch  59, Step:   197100, Batch Loss:     1.814236, Tokens per Sec:     2172, Lr: 0.000070
2021-11-23 13:07:16,061 - INFO - joeynmt.training - Epoch  59, Step:   197200, Batch Loss:     1.841959, Tokens per Sec:     2178, Lr: 0.000070
2021-11-23 13:07:30,774 - INFO - joeynmt.training - Epoch  59, Step:   197300, Batch Loss:     1.850926, Tokens per Sec:     2065, Lr: 0.000070
2021-11-23 13:07:44,817 - INFO - joeynmt.training - Epoch  59, Step:   197400, Batch Loss:     1.765251, Tokens per Sec:     2194, Lr: 0.000070
2021-11-23 13:07:59,221 - INFO - joeynmt.training - Epoch  59, Step:   197500, Batch Loss:     1.725088, Tokens per Sec:     2161, Lr: 0.000070
2021-11-23 13:08:13,737 - INFO - joeynmt.training - Epoch  59, Step:   197600, Batch Loss:     1.764335, Tokens per Sec:     2148, Lr: 0.000070
2021-11-23 13:08:29,114 - INFO - joeynmt.training - Epoch  59, Step:   197700, Batch Loss:     1.878974, Tokens per Sec:     2090, Lr: 0.000070
2021-11-23 13:08:43,758 - INFO - joeynmt.training - Epoch  59, Step:   197800, Batch Loss:     1.665358, Tokens per Sec:     2097, Lr: 0.000070
2021-11-23 13:08:59,635 - INFO - joeynmt.training - Epoch  59, Step:   197900, Batch Loss:     1.827297, Tokens per Sec:     2071, Lr: 0.000070
2021-11-23 13:09:15,069 - INFO - joeynmt.training - Epoch  59, Step:   198000, Batch Loss:     1.571846, Tokens per Sec:     2085, Lr: 0.000070
2021-11-23 13:11:11,335 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:11:11,335 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:11:11,335 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:11:11,349 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 13:11:12,174 - INFO - joeynmt.helpers - delete models/baseline_multilingual/197000.ckpt
2021-11-23 13:11:12,178 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/197000.ckpt
2021-11-23 13:11:12,178 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/197000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/197000.ckpt')
2021-11-23 13:11:12,263 - INFO - joeynmt.training - Example #0
2021-11-23 13:11:12,264 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:11:12,264 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:11:12,264 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 't', 'and', '▁you', ',', '▁as', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 13:11:12,264 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:11:12,264 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:11:12,264 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:11:12,264 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S t and ▁you , ▁as ▁you ▁were ▁count ed ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 13:11:12,265 - INFO - joeynmt.training - Example #1
2021-11-23 13:11:12,265 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:11:12,265 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:11:12,265 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:11:12,265 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:11:12,265 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:11:12,265 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:11:12,265 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:11:12,266 - INFO - joeynmt.training - Example #2
2021-11-23 13:11:12,266 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:11:12,266 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:11:12,266 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁and', '▁be', '▁with', '▁one', '▁another', '.']
2021-11-23 13:11:12,266 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:11:12,266 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:11:12,266 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:11:12,266 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁one ▁another , ▁and ▁be ▁with ▁one ▁another .
2021-11-23 13:11:12,267 - INFO - joeynmt.training - Example #3
2021-11-23 13:11:12,267 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:11:12,267 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:11:12,267 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 13:11:12,267 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:11:12,267 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:11:12,267 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:11:12,267 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 13:11:12,267 - INFO - joeynmt.training - Example #6
2021-11-23 13:11:12,268 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:11:12,268 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:11:12,268 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:11:12,268 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:11:12,268 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:11:12,268 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:11:12,268 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:11:12,268 - INFO - joeynmt.training - Validation result (greedy) at epoch  59, step   198000: bleu:  14.64, loss: 72602.9609, ppl:   8.5315, duration: 117.1987s
2021-11-23 13:11:27,393 - INFO - joeynmt.training - Epoch  59, Step:   198100, Batch Loss:     1.725678, Tokens per Sec:     2125, Lr: 0.000070
2021-11-23 13:11:41,953 - INFO - joeynmt.training - Epoch  59, Step:   198200, Batch Loss:     1.849110, Tokens per Sec:     2160, Lr: 0.000070
2021-11-23 13:11:57,168 - INFO - joeynmt.training - Epoch  59, Step:   198300, Batch Loss:     1.979914, Tokens per Sec:     1996, Lr: 0.000070
2021-11-23 13:12:12,465 - INFO - joeynmt.training - Epoch  59, Step:   198400, Batch Loss:     1.846705, Tokens per Sec:     2089, Lr: 0.000070
2021-11-23 13:12:27,036 - INFO - joeynmt.training - Epoch  59, Step:   198500, Batch Loss:     2.360431, Tokens per Sec:     2142, Lr: 0.000070
2021-11-23 13:12:41,969 - INFO - joeynmt.training - Epoch  59, Step:   198600, Batch Loss:     1.808053, Tokens per Sec:     2100, Lr: 0.000070
2021-11-23 13:12:56,215 - INFO - joeynmt.training - Epoch  59, Step:   198700, Batch Loss:     1.899273, Tokens per Sec:     2191, Lr: 0.000070
2021-11-23 13:13:10,523 - INFO - joeynmt.training - Epoch  59, Step:   198800, Batch Loss:     1.857480, Tokens per Sec:     2186, Lr: 0.000070
2021-11-23 13:13:24,634 - INFO - joeynmt.training - Epoch  59, Step:   198900, Batch Loss:     1.585691, Tokens per Sec:     2185, Lr: 0.000070
2021-11-23 13:13:39,058 - INFO - joeynmt.training - Epoch  59, Step:   199000, Batch Loss:     1.810385, Tokens per Sec:     2075, Lr: 0.000070
2021-11-23 13:15:09,330 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:15:09,330 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:15:09,330 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:15:09,343 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 13:15:10,831 - INFO - joeynmt.helpers - delete models/baseline_multilingual/198000.ckpt
2021-11-23 13:15:10,831 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/198000.ckpt
2021-11-23 13:15:10,832 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/198000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/198000.ckpt')
2021-11-23 13:15:10,890 - INFO - joeynmt.training - Example #0
2021-11-23 13:15:10,890 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:15:10,890 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:15:10,891 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁have', '▁been', '▁count', 'ed', '▁by', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 13:15:10,891 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:15:10,891 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:15:10,891 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:15:10,891 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁have ▁been ▁count ed ▁by ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁other ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 13:15:10,891 - INFO - joeynmt.training - Example #1
2021-11-23 13:15:10,891 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:15:10,892 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:15:10,892 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:15:10,892 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:15:10,892 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:15:10,892 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:15:10,892 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:15:10,892 - INFO - joeynmt.training - Example #2
2021-11-23 13:15:10,893 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:15:10,893 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:15:10,893 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', '.']
2021-11-23 13:15:10,893 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:15:10,893 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:15:10,893 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:15:10,893 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another .
2021-11-23 13:15:10,894 - INFO - joeynmt.training - Example #3
2021-11-23 13:15:10,894 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:15:10,894 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:15:10,894 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 13:15:10,894 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:15:10,894 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:15:10,894 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:15:10,894 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 13:15:10,895 - INFO - joeynmt.training - Example #6
2021-11-23 13:15:10,895 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:15:10,895 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:15:10,895 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:15:10,895 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:15:10,895 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:15:10,895 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:15:10,896 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:15:10,896 - INFO - joeynmt.training - Validation result (greedy) at epoch  59, step   199000: bleu:  14.65, loss: 72379.4531, ppl:   8.4754, duration: 91.8370s
2021-11-23 13:15:25,933 - INFO - joeynmt.training - Epoch  59, Step:   199100, Batch Loss:     1.777867, Tokens per Sec:     2090, Lr: 0.000070
2021-11-23 13:15:41,458 - INFO - joeynmt.training - Epoch  59, Step:   199200, Batch Loss:     1.936252, Tokens per Sec:     2093, Lr: 0.000070
2021-11-23 13:15:56,331 - INFO - joeynmt.training - Epoch  59, Step:   199300, Batch Loss:     1.912568, Tokens per Sec:     2075, Lr: 0.000070
2021-11-23 13:16:10,914 - INFO - joeynmt.training - Epoch  59, Step:   199400, Batch Loss:     1.823645, Tokens per Sec:     2113, Lr: 0.000070
2021-11-23 13:16:25,780 - INFO - joeynmt.training - Epoch  59, Step:   199500, Batch Loss:     2.000005, Tokens per Sec:     2086, Lr: 0.000070
2021-11-23 13:16:39,951 - INFO - joeynmt.training - Epoch  59, Step:   199600, Batch Loss:     1.821638, Tokens per Sec:     2159, Lr: 0.000070
2021-11-23 13:16:54,252 - INFO - joeynmt.training - Epoch  59, Step:   199700, Batch Loss:     1.838698, Tokens per Sec:     2172, Lr: 0.000070
2021-11-23 13:17:09,535 - INFO - joeynmt.training - Epoch  59, Step:   199800, Batch Loss:     1.648370, Tokens per Sec:     2084, Lr: 0.000070
2021-11-23 13:17:25,096 - INFO - joeynmt.training - Epoch  59, Step:   199900, Batch Loss:     1.710526, Tokens per Sec:     2045, Lr: 0.000070
2021-11-23 13:17:32,376 - INFO - joeynmt.training - Epoch  59: total training loss 6311.05
2021-11-23 13:17:32,376 - INFO - joeynmt.training - EPOCH 60
2021-11-23 13:17:39,690 - INFO - joeynmt.training - Epoch  60, Step:   200000, Batch Loss:     1.681405, Tokens per Sec:     1978, Lr: 0.000070
2021-11-23 13:19:14,358 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:19:14,359 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:19:14,359 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:19:14,372 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 13:19:15,181 - INFO - joeynmt.helpers - delete models/baseline_multilingual/199000.ckpt
2021-11-23 13:19:15,181 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/199000.ckpt
2021-11-23 13:19:15,181 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/199000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/199000.ckpt')
2021-11-23 13:19:15,240 - INFO - joeynmt.training - Example #0
2021-11-23 13:19:15,240 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:19:15,240 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:19:15,240 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁count', 'ing', ',', '▁you', '▁were', '▁count', 'ing', '▁J', 'ul', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁their', '▁follow', 'ers', '.']
2021-11-23 13:19:15,240 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:19:15,241 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:19:15,241 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:19:15,241 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁count ing , ▁you ▁were ▁count ing ▁J ul as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁other ▁follow ers ▁are ▁follow ing ▁their ▁follow ers .
2021-11-23 13:19:15,241 - INFO - joeynmt.training - Example #1
2021-11-23 13:19:15,241 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:19:15,241 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:19:15,242 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:19:15,242 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:19:15,242 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:19:15,242 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:19:15,242 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:19:15,242 - INFO - joeynmt.training - Example #2
2021-11-23 13:19:15,242 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:19:15,243 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:19:15,243 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '.']
2021-11-23 13:19:15,243 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:19:15,243 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:19:15,243 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:19:15,243 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another .
2021-11-23 13:19:15,243 - INFO - joeynmt.training - Example #3
2021-11-23 13:19:15,244 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:19:15,244 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:19:15,244 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 13:19:15,244 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:19:15,244 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:19:15,244 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:19:15,244 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 13:19:15,244 - INFO - joeynmt.training - Example #6
2021-11-23 13:19:15,245 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:19:15,245 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:19:15,245 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:19:15,245 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:19:15,245 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:19:15,245 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:19:15,245 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:19:15,246 - INFO - joeynmt.training - Validation result (greedy) at epoch  60, step   200000: bleu:  14.75, loss: 72402.5625, ppl:   8.4812, duration: 95.5557s
2021-11-23 13:19:29,737 - INFO - joeynmt.training - Epoch  60, Step:   200100, Batch Loss:     2.160746, Tokens per Sec:     2159, Lr: 0.000070
2021-11-23 13:19:44,935 - INFO - joeynmt.training - Epoch  60, Step:   200200, Batch Loss:     1.592607, Tokens per Sec:     2023, Lr: 0.000070
2021-11-23 13:19:59,709 - INFO - joeynmt.training - Epoch  60, Step:   200300, Batch Loss:     1.945662, Tokens per Sec:     2206, Lr: 0.000070
2021-11-23 13:20:14,206 - INFO - joeynmt.training - Epoch  60, Step:   200400, Batch Loss:     1.926971, Tokens per Sec:     2164, Lr: 0.000070
2021-11-23 13:20:29,127 - INFO - joeynmt.training - Epoch  60, Step:   200500, Batch Loss:     1.830365, Tokens per Sec:     2202, Lr: 0.000070
2021-11-23 13:20:43,870 - INFO - joeynmt.training - Epoch  60, Step:   200600, Batch Loss:     1.751581, Tokens per Sec:     2076, Lr: 0.000070
2021-11-23 13:20:58,155 - INFO - joeynmt.training - Epoch  60, Step:   200700, Batch Loss:     1.818181, Tokens per Sec:     2174, Lr: 0.000070
2021-11-23 13:21:13,072 - INFO - joeynmt.training - Epoch  60, Step:   200800, Batch Loss:     1.600150, Tokens per Sec:     2061, Lr: 0.000070
2021-11-23 13:21:27,973 - INFO - joeynmt.training - Epoch  60, Step:   200900, Batch Loss:     2.105745, Tokens per Sec:     2085, Lr: 0.000070
2021-11-23 13:21:42,791 - INFO - joeynmt.training - Epoch  60, Step:   201000, Batch Loss:     1.915191, Tokens per Sec:     2168, Lr: 0.000070
2021-11-23 13:23:24,511 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:23:24,511 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:23:24,511 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:23:24,528 - INFO - joeynmt.training - Example #0
2021-11-23 13:23:24,529 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:23:24,529 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:23:24,529 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁have', '▁been', '▁count', 'ed', '▁to', '▁Jerusalem', ',', '▁and', '▁you', '▁are', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁have ▁been ▁count ed ▁to ▁Jerusalem , ▁and ▁you ▁are ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 13:23:24,529 - INFO - joeynmt.training - Example #1
2021-11-23 13:23:24,529 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:23:24,529 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:23:24,529 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:23:24,529 - INFO - joeynmt.training - Example #2
2021-11-23 13:23:24,529 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:23:24,529 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:23:24,529 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁with', '▁each', '▁other', ',', '▁one', '▁another', ',', '▁one', '▁another', '.']
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:23:24,529 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁love ▁with ▁each ▁other , ▁one ▁another , ▁one ▁another .
2021-11-23 13:23:24,530 - INFO - joeynmt.training - Example #3
2021-11-23 13:23:24,530 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:23:24,530 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:23:24,530 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 13:23:24,530 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:23:24,530 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:23:24,530 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:23:24,530 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 13:23:24,530 - INFO - joeynmt.training - Example #6
2021-11-23 13:23:24,530 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:23:24,530 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:23:24,530 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:23:24,530 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:23:24,530 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:23:24,530 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:23:24,530 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:23:24,530 - INFO - joeynmt.training - Validation result (greedy) at epoch  60, step   201000: bleu:  14.68, loss: 72502.3359, ppl:   8.5062, duration: 101.7389s
2021-11-23 13:23:39,192 - INFO - joeynmt.training - Epoch  60, Step:   201100, Batch Loss:     1.929035, Tokens per Sec:     2082, Lr: 0.000070
2021-11-23 13:23:53,986 - INFO - joeynmt.training - Epoch  60, Step:   201200, Batch Loss:     1.764513, Tokens per Sec:     2128, Lr: 0.000070
2021-11-23 13:24:08,687 - INFO - joeynmt.training - Epoch  60, Step:   201300, Batch Loss:     1.987234, Tokens per Sec:     2148, Lr: 0.000070
2021-11-23 13:24:23,497 - INFO - joeynmt.training - Epoch  60, Step:   201400, Batch Loss:     2.064987, Tokens per Sec:     2189, Lr: 0.000070
2021-11-23 13:24:37,231 - INFO - joeynmt.training - Epoch  60, Step:   201500, Batch Loss:     1.806535, Tokens per Sec:     2217, Lr: 0.000070
2021-11-23 13:24:52,430 - INFO - joeynmt.training - Epoch  60, Step:   201600, Batch Loss:     1.892758, Tokens per Sec:     2068, Lr: 0.000070
2021-11-23 13:25:07,411 - INFO - joeynmt.training - Epoch  60, Step:   201700, Batch Loss:     1.965598, Tokens per Sec:     2157, Lr: 0.000070
2021-11-23 13:25:22,195 - INFO - joeynmt.training - Epoch  60, Step:   201800, Batch Loss:     1.875850, Tokens per Sec:     2124, Lr: 0.000070
2021-11-23 13:25:36,898 - INFO - joeynmt.training - Epoch  60, Step:   201900, Batch Loss:     1.744739, Tokens per Sec:     2125, Lr: 0.000070
2021-11-23 13:25:51,792 - INFO - joeynmt.training - Epoch  60, Step:   202000, Batch Loss:     1.670696, Tokens per Sec:     2152, Lr: 0.000070
2021-11-23 13:27:51,814 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:27:51,814 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:27:51,814 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:27:51,827 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 13:27:52,651 - INFO - joeynmt.helpers - delete models/baseline_multilingual/200000.ckpt
2021-11-23 13:27:52,652 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/200000.ckpt
2021-11-23 13:27:52,652 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/200000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/200000.ckpt')
2021-11-23 13:27:52,702 - INFO - joeynmt.training - Example #0
2021-11-23 13:27:52,703 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:27:52,703 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:27:52,703 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'G', 'o', '▁to', '▁you', ',', '▁and', '▁you', '▁were', '▁count', 'ry', 'ing', '▁in', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁people', '▁follow', 'ed', '▁him', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 13:27:52,703 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:27:52,703 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:27:52,703 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:27:52,703 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" G o ▁to ▁you , ▁and ▁you ▁were ▁count ry ing ▁in ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁people ▁follow ed ▁him , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 13:27:52,704 - INFO - joeynmt.training - Example #1
2021-11-23 13:27:52,704 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:27:52,704 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:27:52,704 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:27:52,704 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:27:52,704 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:27:52,704 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:27:52,704 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:27:52,705 - INFO - joeynmt.training - Example #2
2021-11-23 13:27:52,705 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:27:52,705 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:27:52,705 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁the', '▁end', '▁of', '▁love', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 13:27:52,705 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:27:52,705 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:27:52,705 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:27:52,706 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁the ▁end ▁of ▁love , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 13:27:52,706 - INFO - joeynmt.training - Example #3
2021-11-23 13:27:52,706 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:27:52,706 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:27:52,706 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 13:27:52,706 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:27:52,706 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:27:52,706 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:27:52,706 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 13:27:52,707 - INFO - joeynmt.training - Example #6
2021-11-23 13:27:52,707 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:27:52,707 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:27:52,707 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:27:52,707 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:27:52,707 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:27:52,707 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:27:52,707 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:27:52,707 - INFO - joeynmt.training - Validation result (greedy) at epoch  60, step   202000: bleu:  14.98, loss: 71949.8828, ppl:   8.3686, duration: 120.9145s
2021-11-23 13:28:07,896 - INFO - joeynmt.training - Epoch  60, Step:   202100, Batch Loss:     1.807097, Tokens per Sec:     2110, Lr: 0.000070
2021-11-23 13:28:22,738 - INFO - joeynmt.training - Epoch  60, Step:   202200, Batch Loss:     1.713613, Tokens per Sec:     2141, Lr: 0.000070
2021-11-23 13:28:37,240 - INFO - joeynmt.training - Epoch  60, Step:   202300, Batch Loss:     1.982795, Tokens per Sec:     2040, Lr: 0.000070
2021-11-23 13:28:51,925 - INFO - joeynmt.training - Epoch  60, Step:   202400, Batch Loss:     1.781795, Tokens per Sec:     2173, Lr: 0.000070
2021-11-23 13:29:06,714 - INFO - joeynmt.training - Epoch  60, Step:   202500, Batch Loss:     1.649799, Tokens per Sec:     2108, Lr: 0.000070
2021-11-23 13:29:21,307 - INFO - joeynmt.training - Epoch  60, Step:   202600, Batch Loss:     2.259410, Tokens per Sec:     2164, Lr: 0.000070
2021-11-23 13:29:36,602 - INFO - joeynmt.training - Epoch  60, Step:   202700, Batch Loss:     1.855098, Tokens per Sec:     2050, Lr: 0.000070
2021-11-23 13:29:51,787 - INFO - joeynmt.training - Epoch  60, Step:   202800, Batch Loss:     1.949171, Tokens per Sec:     2161, Lr: 0.000070
2021-11-23 13:30:06,366 - INFO - joeynmt.training - Epoch  60, Step:   202900, Batch Loss:     1.776137, Tokens per Sec:     2147, Lr: 0.000070
2021-11-23 13:30:21,195 - INFO - joeynmt.training - Epoch  60, Step:   203000, Batch Loss:     1.757713, Tokens per Sec:     2094, Lr: 0.000070
2021-11-23 13:32:18,756 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:32:18,756 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:32:18,756 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:32:18,770 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 13:32:19,589 - INFO - joeynmt.helpers - delete models/baseline_multilingual/202000.ckpt
2021-11-23 13:32:19,590 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/202000.ckpt
2021-11-23 13:32:19,590 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/202000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/202000.ckpt')
2021-11-23 13:32:19,643 - INFO - joeynmt.training - Example #0
2021-11-23 13:32:19,643 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:32:19,643 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:32:19,643 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁time', ',', '▁you', '▁count', 'ed', '▁Jud', 'as', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 13:32:19,644 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:32:19,644 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:32:19,644 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:32:19,644 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁time , ▁you ▁count ed ▁Jud as ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 13:32:19,644 - INFO - joeynmt.training - Example #1
2021-11-23 13:32:19,644 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:32:19,644 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:32:19,645 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:32:19,645 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:32:19,645 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:32:19,645 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:32:19,645 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:32:19,645 - INFO - joeynmt.training - Example #2
2021-11-23 13:32:19,645 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:32:19,645 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:32:19,646 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 13:32:19,646 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:32:19,646 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:32:19,646 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:32:19,646 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other ▁with ▁one ▁another , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 13:32:19,646 - INFO - joeynmt.training - Example #3
2021-11-23 13:32:19,646 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:32:19,646 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:32:19,647 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 13:32:19,647 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:32:19,647 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:32:19,647 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:32:19,647 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 13:32:19,647 - INFO - joeynmt.training - Example #6
2021-11-23 13:32:19,647 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:32:19,647 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:32:19,648 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:32:19,648 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:32:19,648 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:32:19,648 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:32:19,648 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:32:19,648 - INFO - joeynmt.training - Validation result (greedy) at epoch  60, step   203000: bleu:  14.99, loss: 72295.3516, ppl:   8.4544, duration: 118.4525s
2021-11-23 13:32:35,293 - INFO - joeynmt.training - Epoch  60, Step:   203100, Batch Loss:     1.931829, Tokens per Sec:     2077, Lr: 0.000070
2021-11-23 13:32:50,576 - INFO - joeynmt.training - Epoch  60, Step:   203200, Batch Loss:     1.904188, Tokens per Sec:     2038, Lr: 0.000070
2021-11-23 13:33:04,803 - INFO - joeynmt.training - Epoch  60, Step:   203300, Batch Loss:     1.953166, Tokens per Sec:     2158, Lr: 0.000070
2021-11-23 13:33:10,975 - INFO - joeynmt.training - Epoch  60: total training loss 6267.42
2021-11-23 13:33:10,976 - INFO - joeynmt.training - EPOCH 61
2021-11-23 13:33:20,198 - INFO - joeynmt.training - Epoch  61, Step:   203400, Batch Loss:     1.791053, Tokens per Sec:     2053, Lr: 0.000070
2021-11-23 13:33:35,270 - INFO - joeynmt.training - Epoch  61, Step:   203500, Batch Loss:     1.937011, Tokens per Sec:     2101, Lr: 0.000070
2021-11-23 13:33:49,899 - INFO - joeynmt.training - Epoch  61, Step:   203600, Batch Loss:     1.750334, Tokens per Sec:     2174, Lr: 0.000070
2021-11-23 13:34:04,206 - INFO - joeynmt.training - Epoch  61, Step:   203700, Batch Loss:     1.662240, Tokens per Sec:     2116, Lr: 0.000070
2021-11-23 13:34:19,563 - INFO - joeynmt.training - Epoch  61, Step:   203800, Batch Loss:     2.000286, Tokens per Sec:     2059, Lr: 0.000070
2021-11-23 13:34:34,818 - INFO - joeynmt.training - Epoch  61, Step:   203900, Batch Loss:     1.576488, Tokens per Sec:     2073, Lr: 0.000070
2021-11-23 13:34:49,438 - INFO - joeynmt.training - Epoch  61, Step:   204000, Batch Loss:     1.998623, Tokens per Sec:     2151, Lr: 0.000070
2021-11-23 13:36:31,233 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:36:31,234 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:36:31,234 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:36:31,246 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 13:36:32,078 - INFO - joeynmt.helpers - delete models/baseline_multilingual/203000.ckpt
2021-11-23 13:36:32,078 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/203000.ckpt
2021-11-23 13:36:32,079 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/203000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/203000.ckpt')
2021-11-23 13:36:32,126 - INFO - joeynmt.training - Example #0
2021-11-23 13:36:32,126 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:36:32,126 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:36:32,126 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁have', '▁been', '▁count', 'ed', '▁by', '▁Jud', 'as', '▁and', '▁gra', 'in', '▁from', '▁Gal', 'ile', 'e', '.', '▁He', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁his', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '▁to', '▁sc', 'atter', '▁the', '▁wall', 's', '.']
2021-11-23 13:36:32,126 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:36:32,127 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:36:32,127 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:36:32,127 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁have ▁been ▁count ed ▁by ▁Jud as ▁and ▁gra in ▁from ▁Gal ile e . ▁He ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁his ▁follow ers ▁are ▁all ow ed ▁to ▁sc atter ▁the ▁wall s .
2021-11-23 13:36:32,127 - INFO - joeynmt.training - Example #1
2021-11-23 13:36:32,127 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:36:32,127 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:36:32,127 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:36:32,128 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:36:32,128 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:36:32,128 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:36:32,128 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:36:32,128 - INFO - joeynmt.training - Example #2
2021-11-23 13:36:32,128 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:36:32,128 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:36:32,129 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', '▁with', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '▁mean', 'ing', '.']
2021-11-23 13:36:32,129 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:36:32,129 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:36:32,129 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:36:32,129 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ▁with ▁each ▁other , ▁work ▁with ▁one ▁another , ▁one ▁another ▁mean ing .
2021-11-23 13:36:32,129 - INFO - joeynmt.training - Example #3
2021-11-23 13:36:32,129 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:36:32,129 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:36:32,130 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'so']
2021-11-23 13:36:32,130 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:36:32,130 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:36:32,130 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:36:32,130 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur so
2021-11-23 13:36:32,130 - INFO - joeynmt.training - Example #6
2021-11-23 13:36:32,130 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:36:32,130 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:36:32,131 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:36:32,131 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:36:32,131 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:36:32,131 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:36:32,131 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:36:32,131 - INFO - joeynmt.training - Validation result (greedy) at epoch  61, step   204000: bleu:  15.03, loss: 72325.9922, ppl:   8.4620, duration: 102.6924s
2021-11-23 13:36:46,464 - INFO - joeynmt.training - Epoch  61, Step:   204100, Batch Loss:     2.038256, Tokens per Sec:     2189, Lr: 0.000070
2021-11-23 13:37:00,598 - INFO - joeynmt.training - Epoch  61, Step:   204200, Batch Loss:     1.927656, Tokens per Sec:     2172, Lr: 0.000070
2021-11-23 13:37:16,293 - INFO - joeynmt.training - Epoch  61, Step:   204300, Batch Loss:     1.952586, Tokens per Sec:     2080, Lr: 0.000070
2021-11-23 13:37:30,722 - INFO - joeynmt.training - Epoch  61, Step:   204400, Batch Loss:     1.849757, Tokens per Sec:     2227, Lr: 0.000070
2021-11-23 13:37:44,906 - INFO - joeynmt.training - Epoch  61, Step:   204500, Batch Loss:     1.731719, Tokens per Sec:     2174, Lr: 0.000070
2021-11-23 13:37:59,571 - INFO - joeynmt.training - Epoch  61, Step:   204600, Batch Loss:     2.052412, Tokens per Sec:     2062, Lr: 0.000070
2021-11-23 13:38:14,683 - INFO - joeynmt.training - Epoch  61, Step:   204700, Batch Loss:     1.773909, Tokens per Sec:     2123, Lr: 0.000070
2021-11-23 13:38:29,146 - INFO - joeynmt.training - Epoch  61, Step:   204800, Batch Loss:     1.815669, Tokens per Sec:     2132, Lr: 0.000070
2021-11-23 13:38:43,736 - INFO - joeynmt.training - Epoch  61, Step:   204900, Batch Loss:     1.733131, Tokens per Sec:     2113, Lr: 0.000070
2021-11-23 13:38:58,773 - INFO - joeynmt.training - Epoch  61, Step:   205000, Batch Loss:     1.655478, Tokens per Sec:     2119, Lr: 0.000070
2021-11-23 13:40:51,555 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:40:51,555 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:40:51,555 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:40:51,573 - INFO - joeynmt.training - Example #0
2021-11-23 13:40:51,573 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:40:51,573 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:40:51,573 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁count', 'ing', ',', '▁you', '▁were', '▁count', 'ing', '▁J', 'ul', 'ia', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁your', '▁follow', 'ers', '.']
2021-11-23 13:40:51,573 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:40:51,573 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:40:51,573 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:40:51,573 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁count ing , ▁you ▁were ▁count ing ▁J ul ia . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁your ▁follow ers .
2021-11-23 13:40:51,573 - INFO - joeynmt.training - Example #1
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 13:40:51,574 - INFO - joeynmt.training - Example #2
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 13:40:51,574 - INFO - joeynmt.training - Example #3
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'ur', 'ar']
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:40:51,574 - INFO - joeynmt.training - 	Hypothesis: ▁D es c ur ar
2021-11-23 13:40:51,574 - INFO - joeynmt.training - Example #6
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:40:51,574 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:40:51,575 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:40:51,575 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:40:51,575 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:40:51,575 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:40:51,575 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:40:51,575 - INFO - joeynmt.training - Validation result (greedy) at epoch  61, step   205000: bleu:  14.83, loss: 72214.5234, ppl:   8.4342, duration: 112.8018s
2021-11-23 13:41:05,956 - INFO - joeynmt.training - Epoch  61, Step:   205100, Batch Loss:     2.137501, Tokens per Sec:     2133, Lr: 0.000070
2021-11-23 13:41:21,032 - INFO - joeynmt.training - Epoch  61, Step:   205200, Batch Loss:     2.049392, Tokens per Sec:     2147, Lr: 0.000070
2021-11-23 13:41:36,259 - INFO - joeynmt.training - Epoch  61, Step:   205300, Batch Loss:     1.736619, Tokens per Sec:     2054, Lr: 0.000070
2021-11-23 13:41:50,215 - INFO - joeynmt.training - Epoch  61, Step:   205400, Batch Loss:     1.985226, Tokens per Sec:     2182, Lr: 0.000070
2021-11-23 13:42:04,913 - INFO - joeynmt.training - Epoch  61, Step:   205500, Batch Loss:     1.865651, Tokens per Sec:     2148, Lr: 0.000070
2021-11-23 13:42:19,739 - INFO - joeynmt.training - Epoch  61, Step:   205600, Batch Loss:     1.782693, Tokens per Sec:     2061, Lr: 0.000070
2021-11-23 13:42:34,218 - INFO - joeynmt.training - Epoch  61, Step:   205700, Batch Loss:     1.939603, Tokens per Sec:     2197, Lr: 0.000070
2021-11-23 13:42:49,132 - INFO - joeynmt.training - Epoch  61, Step:   205800, Batch Loss:     1.592305, Tokens per Sec:     2146, Lr: 0.000070
2021-11-23 13:43:03,593 - INFO - joeynmt.training - Epoch  61, Step:   205900, Batch Loss:     1.735501, Tokens per Sec:     2196, Lr: 0.000070
2021-11-23 13:43:18,899 - INFO - joeynmt.training - Epoch  61, Step:   206000, Batch Loss:     1.768852, Tokens per Sec:     2000, Lr: 0.000070
2021-11-23 13:45:07,596 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:45:07,596 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:45:07,596 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:45:07,614 - INFO - joeynmt.training - Example #0
2021-11-23 13:45:07,614 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:45:07,614 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:45:07,614 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁and', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', '▁are', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 13:45:07,614 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:45:07,614 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:45:07,614 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:45:07,614 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁have ▁been ▁count ed , ▁and ▁you ▁were ▁count ed ▁from ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁other ▁follow ers ▁are ▁all ▁his ▁follow ers .
2021-11-23 13:45:07,614 - INFO - joeynmt.training - Example #1
2021-11-23 13:45:07,614 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:45:07,615 - INFO - joeynmt.training - Example #2
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁one', '▁another', ',', '▁and', '▁be', '▁with', '▁one', '▁another', '.']
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁one ▁another , ▁and ▁be ▁with ▁one ▁another .
2021-11-23 13:45:07,615 - INFO - joeynmt.training - Example #3
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'rit', 'ar']
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Hypothesis: ▁D es c rit ar
2021-11-23 13:45:07,615 - INFO - joeynmt.training - Example #6
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:45:07,615 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:45:07,615 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:45:07,616 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:45:07,616 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:45:07,616 - INFO - joeynmt.training - Validation result (greedy) at epoch  61, step   206000: bleu:  14.69, loss: 72246.0625, ppl:   8.4421, duration: 108.7163s
2021-11-23 13:45:22,284 - INFO - joeynmt.training - Epoch  61, Step:   206100, Batch Loss:     1.710744, Tokens per Sec:     2148, Lr: 0.000070
2021-11-23 13:45:37,348 - INFO - joeynmt.training - Epoch  61, Step:   206200, Batch Loss:     1.865139, Tokens per Sec:     2067, Lr: 0.000070
2021-11-23 13:45:52,948 - INFO - joeynmt.training - Epoch  61, Step:   206300, Batch Loss:     1.844000, Tokens per Sec:     2106, Lr: 0.000070
2021-11-23 13:46:07,819 - INFO - joeynmt.training - Epoch  61, Step:   206400, Batch Loss:     1.871856, Tokens per Sec:     2118, Lr: 0.000070
2021-11-23 13:46:22,627 - INFO - joeynmt.training - Epoch  61, Step:   206500, Batch Loss:     1.822188, Tokens per Sec:     2106, Lr: 0.000070
2021-11-23 13:46:37,062 - INFO - joeynmt.training - Epoch  61, Step:   206600, Batch Loss:     1.758670, Tokens per Sec:     2162, Lr: 0.000070
2021-11-23 13:46:52,446 - INFO - joeynmt.training - Epoch  61, Step:   206700, Batch Loss:     1.845945, Tokens per Sec:     2123, Lr: 0.000070
2021-11-23 13:46:56,678 - INFO - joeynmt.training - Epoch  61: total training loss 6235.51
2021-11-23 13:46:56,678 - INFO - joeynmt.training - EPOCH 62
2021-11-23 13:47:07,130 - INFO - joeynmt.training - Epoch  62, Step:   206800, Batch Loss:     1.720169, Tokens per Sec:     2127, Lr: 0.000070
2021-11-23 13:47:21,987 - INFO - joeynmt.training - Epoch  62, Step:   206900, Batch Loss:     1.953483, Tokens per Sec:     2227, Lr: 0.000070
2021-11-23 13:47:36,261 - INFO - joeynmt.training - Epoch  62, Step:   207000, Batch Loss:     1.729136, Tokens per Sec:     2173, Lr: 0.000070
2021-11-23 13:49:21,080 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:49:21,080 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:49:21,080 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:49:21,103 - INFO - joeynmt.training - Example #0
2021-11-23 13:49:21,103 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:49:21,103 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:49:21,103 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'h', 'ile', '▁you', '▁were', '▁count', 'ed', ',', '▁you', '▁count', 'ry', 'ing', '▁Jud', 'as', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁him', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 13:49:21,103 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:49:21,103 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:49:21,103 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:49:21,103 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W h ile ▁you ▁were ▁count ed , ▁you ▁count ry ing ▁Jud as ▁from ▁Gal ile e . ▁You ▁follow ed ▁him , ▁but ▁some ▁of ▁the ▁other ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 13:49:21,103 - INFO - joeynmt.training - Example #1
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:49:21,104 - INFO - joeynmt.training - Example #2
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', '▁with', '▁each', '▁other', ',', '▁and', '▁work', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ▁with ▁each ▁other , ▁and ▁work ▁with ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 13:49:21,104 - INFO - joeynmt.training - Example #3
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'con', 'he', 'c', 'imento']
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:49:21,104 - INFO - joeynmt.training - 	Hypothesis: ▁D es con he c imento
2021-11-23 13:49:21,104 - INFO - joeynmt.training - Example #6
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:49:21,104 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:49:21,105 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:49:21,105 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:49:21,105 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:49:21,105 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:49:21,105 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:49:21,105 - INFO - joeynmt.training - Validation result (greedy) at epoch  62, step   207000: bleu:  14.91, loss: 72166.3203, ppl:   8.4222, duration: 104.8436s
2021-11-23 13:49:36,003 - INFO - joeynmt.training - Epoch  62, Step:   207100, Batch Loss:     1.643215, Tokens per Sec:     2086, Lr: 0.000070
2021-11-23 13:49:50,484 - INFO - joeynmt.training - Epoch  62, Step:   207200, Batch Loss:     1.862022, Tokens per Sec:     2205, Lr: 0.000070
2021-11-23 13:50:04,820 - INFO - joeynmt.training - Epoch  62, Step:   207300, Batch Loss:     1.795412, Tokens per Sec:     2133, Lr: 0.000070
2021-11-23 13:50:19,777 - INFO - joeynmt.training - Epoch  62, Step:   207400, Batch Loss:     2.079887, Tokens per Sec:     2046, Lr: 0.000070
2021-11-23 13:50:35,434 - INFO - joeynmt.training - Epoch  62, Step:   207500, Batch Loss:     1.713285, Tokens per Sec:     2040, Lr: 0.000070
2021-11-23 13:50:50,233 - INFO - joeynmt.training - Epoch  62, Step:   207600, Batch Loss:     1.764368, Tokens per Sec:     2119, Lr: 0.000070
2021-11-23 13:51:04,848 - INFO - joeynmt.training - Epoch  62, Step:   207700, Batch Loss:     1.770325, Tokens per Sec:     2081, Lr: 0.000070
2021-11-23 13:51:19,875 - INFO - joeynmt.training - Epoch  62, Step:   207800, Batch Loss:     1.698516, Tokens per Sec:     2105, Lr: 0.000070
2021-11-23 13:51:35,304 - INFO - joeynmt.training - Epoch  62, Step:   207900, Batch Loss:     1.806055, Tokens per Sec:     2093, Lr: 0.000070
2021-11-23 13:51:50,390 - INFO - joeynmt.training - Epoch  62, Step:   208000, Batch Loss:     1.863109, Tokens per Sec:     2027, Lr: 0.000070
2021-11-23 13:53:23,249 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:53:23,249 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:53:23,249 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:53:23,261 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 13:53:24,072 - INFO - joeynmt.helpers - delete models/baseline_multilingual/204000.ckpt
2021-11-23 13:53:24,072 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/204000.ckpt
2021-11-23 13:53:24,073 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/204000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/204000.ckpt')
2021-11-23 13:53:24,128 - INFO - joeynmt.training - Example #0
2021-11-23 13:53:24,128 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:53:24,128 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:53:24,128 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁count', 'ed', '▁Jud', 'as', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁some', '▁of', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁your', '▁follow', 'ers', '.']
2021-11-23 13:53:24,128 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:53:24,129 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:53:24,129 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:53:24,129 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁count ed ▁Jud as ▁from ▁Gal ile e . ▁You ▁follow ed ▁some ▁of ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁your ▁follow ers .
2021-11-23 13:53:24,129 - INFO - joeynmt.training - Example #1
2021-11-23 13:53:24,129 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:53:24,129 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:53:24,129 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:53:24,130 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:53:24,130 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:53:24,130 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:53:24,130 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:53:24,130 - INFO - joeynmt.training - Example #2
2021-11-23 13:53:24,130 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:53:24,130 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:53:24,131 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁hap', 'p', 'y', '▁how', '▁to', '▁love', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', ',', '▁and', '▁be', '▁with', '▁one', '▁another', '.']
2021-11-23 13:53:24,131 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:53:24,131 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:53:24,131 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:53:24,131 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁hap p y ▁how ▁to ▁love ▁each ▁other , ▁work ▁with ▁one ▁another , ▁and ▁be ▁with ▁one ▁another .
2021-11-23 13:53:24,131 - INFO - joeynmt.training - Example #3
2021-11-23 13:53:24,131 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:53:24,131 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:53:24,131 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'con', 'he', 'c', 'imento']
2021-11-23 13:53:24,131 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:53:24,131 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:53:24,132 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:53:24,132 - INFO - joeynmt.training - 	Hypothesis: ▁D es con he c imento
2021-11-23 13:53:24,132 - INFO - joeynmt.training - Example #6
2021-11-23 13:53:24,132 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:53:24,132 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:53:24,132 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:53:24,132 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:53:24,132 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:53:24,132 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:53:24,132 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:53:24,132 - INFO - joeynmt.training - Validation result (greedy) at epoch  62, step   208000: bleu:  15.36, loss: 72196.7578, ppl:   8.4298, duration: 93.7423s
2021-11-23 13:53:38,269 - INFO - joeynmt.training - Epoch  62, Step:   208100, Batch Loss:     1.767149, Tokens per Sec:     2165, Lr: 0.000070
2021-11-23 13:53:52,081 - INFO - joeynmt.training - Epoch  62, Step:   208200, Batch Loss:     1.942167, Tokens per Sec:     2171, Lr: 0.000070
2021-11-23 13:54:07,695 - INFO - joeynmt.training - Epoch  62, Step:   208300, Batch Loss:     1.554004, Tokens per Sec:     2072, Lr: 0.000070
2021-11-23 13:54:22,690 - INFO - joeynmt.training - Epoch  62, Step:   208400, Batch Loss:     1.705006, Tokens per Sec:     2119, Lr: 0.000070
2021-11-23 13:54:37,717 - INFO - joeynmt.training - Epoch  62, Step:   208500, Batch Loss:     2.083786, Tokens per Sec:     2149, Lr: 0.000070
2021-11-23 13:54:52,634 - INFO - joeynmt.training - Epoch  62, Step:   208600, Batch Loss:     1.851229, Tokens per Sec:     2140, Lr: 0.000070
2021-11-23 13:55:08,292 - INFO - joeynmt.training - Epoch  62, Step:   208700, Batch Loss:     1.743009, Tokens per Sec:     2037, Lr: 0.000070
2021-11-23 13:55:22,524 - INFO - joeynmt.training - Epoch  62, Step:   208800, Batch Loss:     2.111663, Tokens per Sec:     2209, Lr: 0.000070
2021-11-23 13:55:36,781 - INFO - joeynmt.training - Epoch  62, Step:   208900, Batch Loss:     1.942580, Tokens per Sec:     2224, Lr: 0.000070
2021-11-23 13:55:51,185 - INFO - joeynmt.training - Epoch  62, Step:   209000, Batch Loss:     1.749455, Tokens per Sec:     2105, Lr: 0.000070
2021-11-23 13:57:38,051 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 13:57:38,051 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 13:57:38,051 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 13:57:38,069 - INFO - joeynmt.training - Example #0
2021-11-23 13:57:38,069 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 13:57:38,069 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 13:57:38,069 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁have', '▁been', '▁count', 'ed', '▁by', '▁the', '▁time', '▁of', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 13:57:38,069 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 13:57:38,069 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 13:57:38,069 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 13:57:38,069 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁have ▁been ▁count ed ▁by ▁the ▁time ▁of ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁other ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 13:57:38,070 - INFO - joeynmt.training - Example #1
2021-11-23 13:57:38,070 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 13:57:38,070 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 13:57:38,070 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 13:57:38,070 - INFO - joeynmt.training - Example #2
2021-11-23 13:57:38,070 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 13:57:38,070 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 13:57:38,070 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 13:57:38,070 - INFO - joeynmt.training - Example #3
2021-11-23 13:57:38,070 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 13:57:38,070 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 13:57:38,070 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 13:57:38,070 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 13:57:38,071 - INFO - joeynmt.training - Example #6
2021-11-23 13:57:38,071 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 13:57:38,071 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 13:57:38,071 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 13:57:38,071 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 13:57:38,071 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 13:57:38,071 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 13:57:38,071 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 13:57:38,071 - INFO - joeynmt.training - Validation result (greedy) at epoch  62, step   209000: bleu:  14.98, loss: 72048.6250, ppl:   8.3930, duration: 106.8852s
2021-11-23 13:57:52,791 - INFO - joeynmt.training - Epoch  62, Step:   209100, Batch Loss:     1.855271, Tokens per Sec:     2031, Lr: 0.000070
2021-11-23 13:58:07,464 - INFO - joeynmt.training - Epoch  62, Step:   209200, Batch Loss:     1.732262, Tokens per Sec:     2179, Lr: 0.000070
2021-11-23 13:58:22,304 - INFO - joeynmt.training - Epoch  62, Step:   209300, Batch Loss:     1.601373, Tokens per Sec:     2091, Lr: 0.000070
2021-11-23 13:58:37,769 - INFO - joeynmt.training - Epoch  62, Step:   209400, Batch Loss:     1.563275, Tokens per Sec:     2107, Lr: 0.000070
2021-11-23 13:58:52,830 - INFO - joeynmt.training - Epoch  62, Step:   209500, Batch Loss:     1.878318, Tokens per Sec:     2090, Lr: 0.000070
2021-11-23 13:59:07,684 - INFO - joeynmt.training - Epoch  62, Step:   209600, Batch Loss:     2.036093, Tokens per Sec:     2146, Lr: 0.000070
2021-11-23 13:59:23,199 - INFO - joeynmt.training - Epoch  62, Step:   209700, Batch Loss:     1.638405, Tokens per Sec:     2068, Lr: 0.000070
2021-11-23 13:59:37,748 - INFO - joeynmt.training - Epoch  62, Step:   209800, Batch Loss:     1.807044, Tokens per Sec:     2232, Lr: 0.000070
2021-11-23 13:59:52,320 - INFO - joeynmt.training - Epoch  62, Step:   209900, Batch Loss:     1.934776, Tokens per Sec:     2118, Lr: 0.000070
2021-11-23 14:00:07,294 - INFO - joeynmt.training - Epoch  62, Step:   210000, Batch Loss:     1.925971, Tokens per Sec:     2123, Lr: 0.000070
2021-11-23 14:01:42,385 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:01:42,385 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:01:42,385 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:01:42,406 - INFO - joeynmt.training - Example #0
2021-11-23 14:01:42,406 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:01:42,406 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:01:42,406 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁count', 'ed', ',', '▁you', '▁were', '▁count', 'ed', '▁by', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁people', '▁follow', 'ed', '▁him', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 14:01:42,406 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:01:42,406 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:01:42,406 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:01:42,406 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁count ed , ▁you ▁were ▁count ed ▁by ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁people ▁follow ed ▁him , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 14:01:42,406 - INFO - joeynmt.training - Example #1
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:01:42,407 - INFO - joeynmt.training - Example #2
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', '▁with', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ▁with ▁each ▁other , ▁work ▁with ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 14:01:42,407 - INFO - joeynmt.training - Example #3
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:01:42,407 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 14:01:42,407 - INFO - joeynmt.training - Example #6
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:01:42,407 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:01:42,408 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 14:01:42,408 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:01:42,408 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:01:42,408 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:01:42,408 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 14:01:42,408 - INFO - joeynmt.training - Validation result (greedy) at epoch  62, step   210000: bleu:  15.25, loss: 71799.5078, ppl:   8.3315, duration: 95.1133s
2021-11-23 14:01:57,039 - INFO - joeynmt.training - Epoch  62, Step:   210100, Batch Loss:     1.856297, Tokens per Sec:     2059, Lr: 0.000070
2021-11-23 14:01:59,660 - INFO - joeynmt.training - Epoch  62: total training loss 6208.14
2021-11-23 14:01:59,660 - INFO - joeynmt.training - EPOCH 63
2021-11-23 14:02:11,879 - INFO - joeynmt.training - Epoch  63, Step:   210200, Batch Loss:     1.663079, Tokens per Sec:     2189, Lr: 0.000070
2021-11-23 14:02:26,228 - INFO - joeynmt.training - Epoch  63, Step:   210300, Batch Loss:     1.728294, Tokens per Sec:     2157, Lr: 0.000070
2021-11-23 14:02:42,075 - INFO - joeynmt.training - Epoch  63, Step:   210400, Batch Loss:     1.624210, Tokens per Sec:     2066, Lr: 0.000070
2021-11-23 14:02:56,643 - INFO - joeynmt.training - Epoch  63, Step:   210500, Batch Loss:     1.717897, Tokens per Sec:     2147, Lr: 0.000070
2021-11-23 14:03:10,929 - INFO - joeynmt.training - Epoch  63, Step:   210600, Batch Loss:     1.934855, Tokens per Sec:     2146, Lr: 0.000070
2021-11-23 14:03:25,991 - INFO - joeynmt.training - Epoch  63, Step:   210700, Batch Loss:     1.667367, Tokens per Sec:     2106, Lr: 0.000070
2021-11-23 14:03:42,066 - INFO - joeynmt.training - Epoch  63, Step:   210800, Batch Loss:     1.692789, Tokens per Sec:     2077, Lr: 0.000070
2021-11-23 14:03:56,703 - INFO - joeynmt.training - Epoch  63, Step:   210900, Batch Loss:     1.653783, Tokens per Sec:     2173, Lr: 0.000070
2021-11-23 14:04:11,244 - INFO - joeynmt.training - Epoch  63, Step:   211000, Batch Loss:     1.665325, Tokens per Sec:     2122, Lr: 0.000070
2021-11-23 14:05:53,749 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:05:53,750 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:05:53,750 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:05:53,763 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 14:05:54,580 - INFO - joeynmt.helpers - delete models/baseline_multilingual/208000.ckpt
2021-11-23 14:05:54,581 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/208000.ckpt
2021-11-23 14:05:54,581 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/208000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/208000.ckpt')
2021-11-23 14:05:54,628 - INFO - joeynmt.training - Example #0
2021-11-23 14:05:54,628 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:05:54,628 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:05:54,628 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁have', '▁been', '▁count', 'ed', '▁by', '▁the', '▁time', '▁of', '▁Jud', 'as', '▁and', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 14:05:54,628 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:05:54,629 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:05:54,629 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:05:54,629 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁have ▁been ▁count ed ▁by ▁the ▁time ▁of ▁Jud as ▁and ▁the ▁people ▁of ▁Gal ile e . ▁He ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁his ▁follow ers .
2021-11-23 14:05:54,629 - INFO - joeynmt.training - Example #1
2021-11-23 14:05:54,629 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:05:54,629 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:05:54,630 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:05:54,630 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:05:54,630 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:05:54,630 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:05:54,630 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:05:54,630 - INFO - joeynmt.training - Example #2
2021-11-23 14:05:54,630 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:05:54,630 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:05:54,631 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 14:05:54,631 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:05:54,631 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:05:54,631 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:05:54,631 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 14:05:54,631 - INFO - joeynmt.training - Example #3
2021-11-23 14:05:54,631 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:05:54,631 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:05:54,632 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'isar']
2021-11-23 14:05:54,632 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:05:54,632 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:05:54,632 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:05:54,632 - INFO - joeynmt.training - 	Hypothesis: ▁D es c isar
2021-11-23 14:05:54,632 - INFO - joeynmt.training - Example #6
2021-11-23 14:05:54,632 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:05:54,632 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:05:54,632 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 14:05:54,633 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:05:54,633 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:05:54,633 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:05:54,633 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 14:05:54,633 - INFO - joeynmt.training - Validation result (greedy) at epoch  63, step   211000: bleu:  15.39, loss: 72023.1016, ppl:   8.3867, duration: 103.3886s
2021-11-23 14:06:09,016 - INFO - joeynmt.training - Epoch  63, Step:   211100, Batch Loss:     1.726585, Tokens per Sec:     2223, Lr: 0.000070
2021-11-23 14:06:23,961 - INFO - joeynmt.training - Epoch  63, Step:   211200, Batch Loss:     1.728903, Tokens per Sec:     2088, Lr: 0.000070
2021-11-23 14:06:38,638 - INFO - joeynmt.training - Epoch  63, Step:   211300, Batch Loss:     1.941483, Tokens per Sec:     2139, Lr: 0.000070
2021-11-23 14:06:52,844 - INFO - joeynmt.training - Epoch  63, Step:   211400, Batch Loss:     1.679210, Tokens per Sec:     2166, Lr: 0.000070
2021-11-23 14:07:07,116 - INFO - joeynmt.training - Epoch  63, Step:   211500, Batch Loss:     1.709072, Tokens per Sec:     2163, Lr: 0.000070
2021-11-23 14:07:22,275 - INFO - joeynmt.training - Epoch  63, Step:   211600, Batch Loss:     1.904252, Tokens per Sec:     2120, Lr: 0.000070
2021-11-23 14:07:37,750 - INFO - joeynmt.training - Epoch  63, Step:   211700, Batch Loss:     1.741088, Tokens per Sec:     1981, Lr: 0.000070
2021-11-23 14:07:53,278 - INFO - joeynmt.training - Epoch  63, Step:   211800, Batch Loss:     1.956451, Tokens per Sec:     2133, Lr: 0.000070
2021-11-23 14:08:07,955 - INFO - joeynmt.training - Epoch  63, Step:   211900, Batch Loss:     1.887887, Tokens per Sec:     2071, Lr: 0.000070
2021-11-23 14:08:21,922 - INFO - joeynmt.training - Epoch  63, Step:   212000, Batch Loss:     1.818810, Tokens per Sec:     2208, Lr: 0.000070
2021-11-23 14:09:53,787 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:09:53,787 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:09:53,787 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:09:53,805 - INFO - joeynmt.training - Example #0
2021-11-23 14:09:53,805 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:09:53,805 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:09:53,805 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁time', ',', '▁you', '▁count', 'ed', '▁Jud', 'as', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 14:09:53,805 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:09:53,805 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:09:53,805 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:09:53,805 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁time , ▁you ▁count ed ▁Jud as ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁his ▁follow ers .
2021-11-23 14:09:53,806 - INFO - joeynmt.training - Example #1
2021-11-23 14:09:53,806 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:09:53,806 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:09:53,806 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 14:09:53,806 - INFO - joeynmt.training - Example #2
2021-11-23 14:09:53,806 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:09:53,806 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:09:53,806 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 14:09:53,806 - INFO - joeynmt.training - Example #3
2021-11-23 14:09:53,806 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:09:53,806 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:09:53,806 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:09:53,806 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 14:09:53,806 - INFO - joeynmt.training - Example #6
2021-11-23 14:09:53,807 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:09:53,807 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:09:53,807 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 14:09:53,807 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:09:53,807 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:09:53,807 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:09:53,807 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 14:09:53,807 - INFO - joeynmt.training - Validation result (greedy) at epoch  63, step   212000: bleu:  15.29, loss: 71824.4844, ppl:   8.3376, duration: 91.8847s
2021-11-23 14:10:08,094 - INFO - joeynmt.training - Epoch  63, Step:   212100, Batch Loss:     1.663849, Tokens per Sec:     2151, Lr: 0.000070
2021-11-23 14:10:23,193 - INFO - joeynmt.training - Epoch  63, Step:   212200, Batch Loss:     1.637552, Tokens per Sec:     2140, Lr: 0.000070
2021-11-23 14:10:37,447 - INFO - joeynmt.training - Epoch  63, Step:   212300, Batch Loss:     2.177240, Tokens per Sec:     2163, Lr: 0.000070
2021-11-23 14:10:52,723 - INFO - joeynmt.training - Epoch  63, Step:   212400, Batch Loss:     1.941525, Tokens per Sec:     2044, Lr: 0.000070
2021-11-23 14:11:08,378 - INFO - joeynmt.training - Epoch  63, Step:   212500, Batch Loss:     2.049232, Tokens per Sec:     2056, Lr: 0.000070
2021-11-23 14:11:23,802 - INFO - joeynmt.training - Epoch  63, Step:   212600, Batch Loss:     1.817505, Tokens per Sec:     2080, Lr: 0.000070
2021-11-23 14:11:38,879 - INFO - joeynmt.training - Epoch  63, Step:   212700, Batch Loss:     2.056988, Tokens per Sec:     2036, Lr: 0.000070
2021-11-23 14:11:52,851 - INFO - joeynmt.training - Epoch  63, Step:   212800, Batch Loss:     1.689949, Tokens per Sec:     2217, Lr: 0.000070
2021-11-23 14:12:08,053 - INFO - joeynmt.training - Epoch  63, Step:   212900, Batch Loss:     1.765575, Tokens per Sec:     2100, Lr: 0.000070
2021-11-23 14:12:22,715 - INFO - joeynmt.training - Epoch  63, Step:   213000, Batch Loss:     1.728733, Tokens per Sec:     2097, Lr: 0.000070
2021-11-23 14:14:09,238 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:14:09,239 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:14:09,239 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:14:09,257 - INFO - joeynmt.training - Example #0
2021-11-23 14:14:09,257 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:14:09,257 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:14:09,257 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'S', 'ome', '▁time', '▁you', '▁have', '▁been', '▁count', 'ed', '▁from', '▁Jud', 'as', '▁and', '▁gra', 'in', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁some', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 14:14:09,257 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:14:09,257 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:14:09,257 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:14:09,257 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" S ome ▁time ▁you ▁have ▁been ▁count ed ▁from ▁Jud as ▁and ▁gra in ▁from ▁Gal ile e . ▁You ▁follow ed ▁some ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 14:14:09,257 - INFO - joeynmt.training - Example #1
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:14:09,258 - INFO - joeynmt.training - Example #2
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 14:14:09,258 - INFO - joeynmt.training - Example #3
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:14:09,258 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 14:14:09,258 - INFO - joeynmt.training - Example #6
2021-11-23 14:14:09,258 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:14:09,259 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:14:09,259 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 14:14:09,259 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:14:09,259 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:14:09,259 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:14:09,259 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 14:14:09,259 - INFO - joeynmt.training - Validation result (greedy) at epoch  63, step   213000: bleu:  15.13, loss: 71640.6406, ppl:   8.2925, duration: 106.5439s
2021-11-23 14:14:24,443 - INFO - joeynmt.training - Epoch  63, Step:   213100, Batch Loss:     1.988036, Tokens per Sec:     2053, Lr: 0.000070
2021-11-23 14:14:38,568 - INFO - joeynmt.training - Epoch  63, Step:   213200, Batch Loss:     1.782107, Tokens per Sec:     2142, Lr: 0.000070
2021-11-23 14:14:53,096 - INFO - joeynmt.training - Epoch  63, Step:   213300, Batch Loss:     1.794567, Tokens per Sec:     2144, Lr: 0.000070
2021-11-23 14:15:08,559 - INFO - joeynmt.training - Epoch  63, Step:   213400, Batch Loss:     1.753696, Tokens per Sec:     2107, Lr: 0.000070
2021-11-23 14:15:23,966 - INFO - joeynmt.training - Epoch  63, Step:   213500, Batch Loss:     1.775431, Tokens per Sec:     1978, Lr: 0.000070
2021-11-23 14:15:24,917 - INFO - joeynmt.training - Epoch  63: total training loss 6173.89
2021-11-23 14:15:24,918 - INFO - joeynmt.training - EPOCH 64
2021-11-23 14:15:38,446 - INFO - joeynmt.training - Epoch  64, Step:   213600, Batch Loss:     1.798565, Tokens per Sec:     2076, Lr: 0.000070
2021-11-23 14:15:53,496 - INFO - joeynmt.training - Epoch  64, Step:   213700, Batch Loss:     1.832938, Tokens per Sec:     2168, Lr: 0.000070
2021-11-23 14:16:08,557 - INFO - joeynmt.training - Epoch  64, Step:   213800, Batch Loss:     2.162221, Tokens per Sec:     2086, Lr: 0.000070
2021-11-23 14:16:23,913 - INFO - joeynmt.training - Epoch  64, Step:   213900, Batch Loss:     1.943624, Tokens per Sec:     2078, Lr: 0.000070
2021-11-23 14:16:39,286 - INFO - joeynmt.training - Epoch  64, Step:   214000, Batch Loss:     1.840854, Tokens per Sec:     2077, Lr: 0.000070
2021-11-23 14:18:19,958 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:18:19,958 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:18:19,958 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:18:19,975 - INFO - joeynmt.training - Example #0
2021-11-23 14:18:19,976 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:18:19,976 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:18:19,976 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁Jerusalem', ',', '▁and', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁sc', 'atter', 'ed', '.']
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁Jerusalem , ▁and ▁you ▁were ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁other ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁sc atter ed .
2021-11-23 14:18:19,976 - INFO - joeynmt.training - Example #1
2021-11-23 14:18:19,976 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:18:19,976 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:18:19,976 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:18:19,976 - INFO - joeynmt.training - Example #2
2021-11-23 14:18:19,976 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:18:19,976 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:18:19,976 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:18:19,976 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:18:19,977 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 14:18:19,977 - INFO - joeynmt.training - Example #3
2021-11-23 14:18:19,977 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:18:19,977 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:18:19,977 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'rit', 'ar']
2021-11-23 14:18:19,977 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:18:19,977 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:18:19,977 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:18:19,977 - INFO - joeynmt.training - 	Hypothesis: ▁D es c rit ar
2021-11-23 14:18:19,977 - INFO - joeynmt.training - Example #6
2021-11-23 14:18:19,977 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:18:19,977 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:18:19,977 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 14:18:19,977 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:18:19,977 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:18:19,977 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:18:19,977 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 14:18:19,977 - INFO - joeynmt.training - Validation result (greedy) at epoch  64, step   214000: bleu:  14.93, loss: 71771.0703, ppl:   8.3245, duration: 100.6908s
2021-11-23 14:18:34,403 - INFO - joeynmt.training - Epoch  64, Step:   214100, Batch Loss:     1.829073, Tokens per Sec:     2159, Lr: 0.000070
2021-11-23 14:18:49,681 - INFO - joeynmt.training - Epoch  64, Step:   214200, Batch Loss:     1.752335, Tokens per Sec:     2082, Lr: 0.000070
2021-11-23 14:19:04,876 - INFO - joeynmt.training - Epoch  64, Step:   214300, Batch Loss:     1.622440, Tokens per Sec:     2047, Lr: 0.000070
2021-11-23 14:19:20,093 - INFO - joeynmt.training - Epoch  64, Step:   214400, Batch Loss:     1.943349, Tokens per Sec:     2134, Lr: 0.000070
2021-11-23 14:19:35,883 - INFO - joeynmt.training - Epoch  64, Step:   214500, Batch Loss:     2.131964, Tokens per Sec:     2015, Lr: 0.000070
2021-11-23 14:19:50,575 - INFO - joeynmt.training - Epoch  64, Step:   214600, Batch Loss:     1.943425, Tokens per Sec:     2203, Lr: 0.000070
2021-11-23 14:20:05,031 - INFO - joeynmt.training - Epoch  64, Step:   214700, Batch Loss:     2.088391, Tokens per Sec:     2171, Lr: 0.000070
2021-11-23 14:20:19,747 - INFO - joeynmt.training - Epoch  64, Step:   214800, Batch Loss:     1.552230, Tokens per Sec:     2211, Lr: 0.000070
2021-11-23 14:20:35,032 - INFO - joeynmt.training - Epoch  64, Step:   214900, Batch Loss:     1.839069, Tokens per Sec:     2079, Lr: 0.000070
2021-11-23 14:20:49,491 - INFO - joeynmt.training - Epoch  64, Step:   215000, Batch Loss:     1.722777, Tokens per Sec:     2114, Lr: 0.000070
2021-11-23 14:22:31,278 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:22:31,278 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:22:31,278 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:22:31,328 - INFO - joeynmt.training - Example #0
2021-11-23 14:22:31,329 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:22:31,329 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:22:31,329 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁J', 'ul', 'ia', '▁and', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 14:22:31,329 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:22:31,329 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:22:31,329 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:22:31,329 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁J ul ia ▁and ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁his ▁follow ers .
2021-11-23 14:22:31,329 - INFO - joeynmt.training - Example #1
2021-11-23 14:22:31,330 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:22:31,330 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:22:31,330 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:22:31,330 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:22:31,330 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:22:31,330 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:22:31,330 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:22:31,330 - INFO - joeynmt.training - Example #2
2021-11-23 14:22:31,330 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:22:31,330 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:22:31,330 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁with', '▁each', '▁other', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 14:22:31,331 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:22:31,331 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:22:31,331 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:22:31,331 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁with ▁each ▁other , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 14:22:31,331 - INFO - joeynmt.training - Example #3
2021-11-23 14:22:31,331 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:22:31,331 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:22:31,331 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'con', 'he', 'c', 'imento']
2021-11-23 14:22:31,331 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:22:31,331 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:22:31,331 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:22:31,332 - INFO - joeynmt.training - 	Hypothesis: ▁D es con he c imento
2021-11-23 14:22:31,332 - INFO - joeynmt.training - Example #6
2021-11-23 14:22:31,332 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:22:31,332 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:22:31,332 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 14:22:31,332 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:22:31,332 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:22:31,332 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:22:31,332 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 14:22:31,332 - INFO - joeynmt.training - Validation result (greedy) at epoch  64, step   215000: bleu:  14.97, loss: 71766.8594, ppl:   8.3235, duration: 101.8404s
2021-11-23 14:22:45,723 - INFO - joeynmt.training - Epoch  64, Step:   215100, Batch Loss:     1.671692, Tokens per Sec:     2158, Lr: 0.000070
2021-11-23 14:23:00,611 - INFO - joeynmt.training - Epoch  64, Step:   215200, Batch Loss:     1.929208, Tokens per Sec:     2143, Lr: 0.000070
2021-11-23 14:23:15,987 - INFO - joeynmt.training - Epoch  64, Step:   215300, Batch Loss:     1.648352, Tokens per Sec:     2035, Lr: 0.000070
2021-11-23 14:23:30,625 - INFO - joeynmt.training - Epoch  64, Step:   215400, Batch Loss:     1.792391, Tokens per Sec:     2181, Lr: 0.000070
2021-11-23 14:23:46,120 - INFO - joeynmt.training - Epoch  64, Step:   215500, Batch Loss:     1.882532, Tokens per Sec:     2014, Lr: 0.000070
2021-11-23 14:24:00,443 - INFO - joeynmt.training - Epoch  64, Step:   215600, Batch Loss:     1.855090, Tokens per Sec:     2119, Lr: 0.000070
2021-11-23 14:24:15,188 - INFO - joeynmt.training - Epoch  64, Step:   215700, Batch Loss:     1.815500, Tokens per Sec:     2111, Lr: 0.000070
2021-11-23 14:24:30,457 - INFO - joeynmt.training - Epoch  64, Step:   215800, Batch Loss:     1.741342, Tokens per Sec:     2059, Lr: 0.000070
2021-11-23 14:24:45,201 - INFO - joeynmt.training - Epoch  64, Step:   215900, Batch Loss:     1.794092, Tokens per Sec:     2149, Lr: 0.000070
2021-11-23 14:25:00,049 - INFO - joeynmt.training - Epoch  64, Step:   216000, Batch Loss:     2.159121, Tokens per Sec:     2112, Lr: 0.000070
2021-11-23 14:26:56,079 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:26:56,080 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:26:56,080 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:26:56,116 - INFO - joeynmt.training - Example #0
2021-11-23 14:26:56,116 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:26:56,116 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:26:56,117 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁time', ',', '▁you', '▁count', 'ed', '▁J', 'ul', 'i', 'us', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 14:26:56,117 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:26:56,117 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:26:56,117 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:26:56,117 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁time , ▁you ▁count ed ▁J ul i us ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁his ▁follow ers .
2021-11-23 14:26:56,117 - INFO - joeynmt.training - Example #1
2021-11-23 14:26:56,117 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:26:56,117 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:26:56,117 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:26:56,117 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:26:56,117 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:26:56,117 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:26:56,117 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:26:56,117 - INFO - joeynmt.training - Example #2
2021-11-23 14:26:56,117 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:26:56,117 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:26:56,117 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁work', '▁with', '▁one', '▁another', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 14:26:56,117 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁work ▁with ▁one ▁another , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 14:26:56,118 - INFO - joeynmt.training - Example #3
2021-11-23 14:26:56,118 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:26:56,118 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:26:56,118 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'con', 'he', 'c', 'imento']
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Hypothesis: ▁D es con he c imento
2021-11-23 14:26:56,118 - INFO - joeynmt.training - Example #6
2021-11-23 14:26:56,118 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:26:56,118 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:26:56,118 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:26:56,118 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 14:26:56,119 - INFO - joeynmt.training - Validation result (greedy) at epoch  64, step   216000: bleu:  15.30, loss: 71953.5781, ppl:   8.3695, duration: 116.0689s
2021-11-23 14:27:10,654 - INFO - joeynmt.training - Epoch  64, Step:   216100, Batch Loss:     1.626242, Tokens per Sec:     2076, Lr: 0.000070
2021-11-23 14:27:25,351 - INFO - joeynmt.training - Epoch  64, Step:   216200, Batch Loss:     1.722669, Tokens per Sec:     2072, Lr: 0.000070
2021-11-23 14:27:41,006 - INFO - joeynmt.training - Epoch  64, Step:   216300, Batch Loss:     1.907646, Tokens per Sec:     2038, Lr: 0.000070
2021-11-23 14:27:55,797 - INFO - joeynmt.training - Epoch  64, Step:   216400, Batch Loss:     1.899111, Tokens per Sec:     2122, Lr: 0.000070
2021-11-23 14:28:10,187 - INFO - joeynmt.training - Epoch  64, Step:   216500, Batch Loss:     1.915786, Tokens per Sec:     2110, Lr: 0.000070
2021-11-23 14:28:24,964 - INFO - joeynmt.training - Epoch  64, Step:   216600, Batch Loss:     1.874037, Tokens per Sec:     2146, Lr: 0.000070
2021-11-23 14:28:39,535 - INFO - joeynmt.training - Epoch  64, Step:   216700, Batch Loss:     1.644965, Tokens per Sec:     2110, Lr: 0.000070
2021-11-23 14:28:54,134 - INFO - joeynmt.training - Epoch  64, Step:   216800, Batch Loss:     1.733542, Tokens per Sec:     2139, Lr: 0.000070
2021-11-23 14:29:08,774 - INFO - joeynmt.training - Epoch  64: total training loss 6148.92
2021-11-23 14:29:08,775 - INFO - joeynmt.training - EPOCH 65
2021-11-23 14:29:09,545 - INFO - joeynmt.training - Epoch  65, Step:   216900, Batch Loss:     1.920874, Tokens per Sec:     1877, Lr: 0.000070
2021-11-23 14:29:24,586 - INFO - joeynmt.training - Epoch  65, Step:   217000, Batch Loss:     1.674656, Tokens per Sec:     2142, Lr: 0.000070
2021-11-23 14:30:50,078 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:30:50,078 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:30:50,078 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:30:50,090 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 14:30:51,036 - INFO - joeynmt.helpers - delete models/baseline_multilingual/211000.ckpt
2021-11-23 14:30:51,068 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/211000.ckpt
2021-11-23 14:30:51,077 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/211000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/211000.ckpt')
2021-11-23 14:30:51,147 - INFO - joeynmt.training - Example #0
2021-11-23 14:30:51,147 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:30:51,148 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:30:51,148 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁count', 'ry', ',', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁you', '▁are', '▁follow', 'ing', '▁your', '▁follow', 'ers', '▁and', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 14:30:51,148 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:30:51,148 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:30:51,148 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:30:51,148 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁count ry , ▁you ▁were ▁count ed ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁you ▁are ▁follow ing ▁your ▁follow ers ▁and ▁all ▁his ▁follow ers .
2021-11-23 14:30:51,149 - INFO - joeynmt.training - Example #1
2021-11-23 14:30:51,149 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:30:51,149 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:30:51,149 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:30:51,149 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:30:51,149 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:30:51,149 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:30:51,150 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:30:51,150 - INFO - joeynmt.training - Example #2
2021-11-23 14:30:51,150 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:30:51,150 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:30:51,150 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁faith', 'ful', 'ness', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁work', 'ing', '▁with', '▁one', '▁another', '.']
2021-11-23 14:30:51,150 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:30:51,150 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:30:51,151 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:30:51,151 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁faith ful ness , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁work ing ▁with ▁one ▁another .
2021-11-23 14:30:51,151 - INFO - joeynmt.training - Example #3
2021-11-23 14:30:51,151 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:30:51,151 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:30:51,151 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'con', 'he', 'c', 'imento']
2021-11-23 14:30:51,151 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:30:51,151 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:30:51,152 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:30:51,152 - INFO - joeynmt.training - 	Hypothesis: ▁D es con he c imento
2021-11-23 14:30:51,152 - INFO - joeynmt.training - Example #6
2021-11-23 14:30:51,152 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:30:51,152 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:30:51,152 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 14:30:51,152 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:30:51,153 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:30:51,153 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:30:51,153 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 14:30:51,153 - INFO - joeynmt.training - Validation result (greedy) at epoch  65, step   217000: bleu:  15.54, loss: 71499.6016, ppl:   8.2580, duration: 86.5670s
2021-11-23 14:31:06,981 - INFO - joeynmt.training - Epoch  65, Step:   217100, Batch Loss:     2.072908, Tokens per Sec:     2048, Lr: 0.000070
2021-11-23 14:31:21,551 - INFO - joeynmt.training - Epoch  65, Step:   217200, Batch Loss:     1.677264, Tokens per Sec:     2155, Lr: 0.000070
2021-11-23 14:31:36,663 - INFO - joeynmt.training - Epoch  65, Step:   217300, Batch Loss:     1.652357, Tokens per Sec:     2097, Lr: 0.000070
2021-11-23 14:31:51,124 - INFO - joeynmt.training - Epoch  65, Step:   217400, Batch Loss:     1.829493, Tokens per Sec:     2182, Lr: 0.000070
2021-11-23 14:32:05,163 - INFO - joeynmt.training - Epoch  65, Step:   217500, Batch Loss:     1.884906, Tokens per Sec:     2218, Lr: 0.000070
2021-11-23 14:32:19,516 - INFO - joeynmt.training - Epoch  65, Step:   217600, Batch Loss:     1.854430, Tokens per Sec:     2175, Lr: 0.000070
2021-11-23 14:32:34,154 - INFO - joeynmt.training - Epoch  65, Step:   217700, Batch Loss:     1.788643, Tokens per Sec:     2212, Lr: 0.000070
2021-11-23 14:32:49,208 - INFO - joeynmt.training - Epoch  65, Step:   217800, Batch Loss:     1.896553, Tokens per Sec:     2083, Lr: 0.000070
2021-11-23 14:33:03,939 - INFO - joeynmt.training - Epoch  65, Step:   217900, Batch Loss:     1.639696, Tokens per Sec:     2164, Lr: 0.000070
2021-11-23 14:33:18,431 - INFO - joeynmt.training - Epoch  65, Step:   218000, Batch Loss:     1.913478, Tokens per Sec:     2147, Lr: 0.000070
2021-11-23 14:35:24,930 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:35:24,931 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:35:24,931 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:35:24,977 - INFO - joeynmt.training - Example #0
2021-11-23 14:35:24,977 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:35:24,977 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:35:24,977 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁the', '▁time', '▁of', '▁Jud', 'as', ',', '▁and', '▁you', '▁were', '▁with', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁him', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 14:35:24,977 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:35:24,977 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:35:24,977 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:35:24,977 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁the ▁time ▁of ▁Jud as , ▁and ▁you ▁were ▁with ▁the ▁people ▁of ▁Gal ile e . ▁You ▁follow ed ▁him , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 14:35:24,977 - INFO - joeynmt.training - Example #1
2021-11-23 14:35:24,977 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:35:24,977 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:35:24,977 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 14:35:24,977 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:35:24,977 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 14:35:24,978 - INFO - joeynmt.training - Example #2
2021-11-23 14:35:24,978 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:35:24,978 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:35:24,978 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁work ▁with ▁one ▁another .
2021-11-23 14:35:24,978 - INFO - joeynmt.training - Example #3
2021-11-23 14:35:24,978 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:35:24,978 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:35:24,978 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:35:24,978 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 14:35:24,979 - INFO - joeynmt.training - Example #6
2021-11-23 14:35:24,979 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:35:24,979 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:35:24,979 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 14:35:24,979 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:35:24,979 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:35:24,979 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:35:24,979 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 14:35:24,979 - INFO - joeynmt.training - Validation result (greedy) at epoch  65, step   218000: bleu:  15.48, loss: 71543.7266, ppl:   8.2688, duration: 126.5479s
2021-11-23 14:35:40,346 - INFO - joeynmt.training - Epoch  65, Step:   218100, Batch Loss:     1.626135, Tokens per Sec:     2053, Lr: 0.000070
2021-11-23 14:35:54,346 - INFO - joeynmt.training - Epoch  65, Step:   218200, Batch Loss:     1.963423, Tokens per Sec:     2278, Lr: 0.000070
2021-11-23 14:36:09,179 - INFO - joeynmt.training - Epoch  65, Step:   218300, Batch Loss:     1.720846, Tokens per Sec:     2158, Lr: 0.000070
2021-11-23 14:36:23,876 - INFO - joeynmt.training - Epoch  65, Step:   218400, Batch Loss:     1.606447, Tokens per Sec:     2155, Lr: 0.000070
2021-11-23 14:36:38,960 - INFO - joeynmt.training - Epoch  65, Step:   218500, Batch Loss:     1.804545, Tokens per Sec:     2061, Lr: 0.000070
2021-11-23 14:36:53,272 - INFO - joeynmt.training - Epoch  65, Step:   218600, Batch Loss:     1.499876, Tokens per Sec:     2129, Lr: 0.000070
2021-11-23 14:37:07,702 - INFO - joeynmt.training - Epoch  65, Step:   218700, Batch Loss:     1.656582, Tokens per Sec:     2076, Lr: 0.000070
2021-11-23 14:37:22,913 - INFO - joeynmt.training - Epoch  65, Step:   218800, Batch Loss:     1.611807, Tokens per Sec:     2046, Lr: 0.000070
2021-11-23 14:37:38,126 - INFO - joeynmt.training - Epoch  65, Step:   218900, Batch Loss:     1.787578, Tokens per Sec:     2088, Lr: 0.000070
2021-11-23 14:37:53,689 - INFO - joeynmt.training - Epoch  65, Step:   219000, Batch Loss:     1.819125, Tokens per Sec:     2049, Lr: 0.000070
2021-11-23 14:39:27,198 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:39:27,198 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:39:27,198 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:39:27,225 - INFO - joeynmt.training - Example #0
2021-11-23 14:39:27,225 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:39:27,225 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:39:27,225 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁count', 'ry', '▁about', '▁Jud', 'as', '▁and', '▁J', 'ul', 'ia', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', 'ow', 'ed', '.']
2021-11-23 14:39:27,225 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:39:27,225 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:39:27,225 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:39:27,225 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁count ry ▁about ▁Jud as ▁and ▁J ul ia . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ow ed .
2021-11-23 14:39:27,225 - INFO - joeynmt.training - Example #1
2021-11-23 14:39:27,225 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:39:27,225 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:39:27,225 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:39:27,225 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:39:27,226 - INFO - joeynmt.training - Example #2
2021-11-23 14:39:27,226 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:39:27,226 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:39:27,226 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', 'ing', '▁with', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '.']
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ing ▁with ▁each ▁other , ▁work ▁with ▁one ▁another , ▁one ▁another .
2021-11-23 14:39:27,226 - INFO - joeynmt.training - Example #3
2021-11-23 14:39:27,226 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:39:27,226 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:39:27,226 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:39:27,226 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 14:39:27,227 - INFO - joeynmt.training - Example #6
2021-11-23 14:39:27,227 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:39:27,227 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:39:27,227 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 14:39:27,227 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:39:27,227 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:39:27,227 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:39:27,227 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 14:39:27,227 - INFO - joeynmt.training - Validation result (greedy) at epoch  65, step   219000: bleu:  15.14, loss: 71699.7422, ppl:   8.3070, duration: 93.5381s
2021-11-23 14:39:42,276 - INFO - joeynmt.training - Epoch  65, Step:   219100, Batch Loss:     1.979756, Tokens per Sec:     2131, Lr: 0.000070
2021-11-23 14:39:57,657 - INFO - joeynmt.training - Epoch  65, Step:   219200, Batch Loss:     1.759698, Tokens per Sec:     2085, Lr: 0.000070
2021-11-23 14:40:12,608 - INFO - joeynmt.training - Epoch  65, Step:   219300, Batch Loss:     1.861356, Tokens per Sec:     2112, Lr: 0.000070
2021-11-23 14:40:27,565 - INFO - joeynmt.training - Epoch  65, Step:   219400, Batch Loss:     1.863558, Tokens per Sec:     2094, Lr: 0.000070
2021-11-23 14:40:42,664 - INFO - joeynmt.training - Epoch  65, Step:   219500, Batch Loss:     2.029800, Tokens per Sec:     2031, Lr: 0.000070
2021-11-23 14:40:58,045 - INFO - joeynmt.training - Epoch  65, Step:   219600, Batch Loss:     1.927687, Tokens per Sec:     2018, Lr: 0.000070
2021-11-23 14:41:13,062 - INFO - joeynmt.training - Epoch  65, Step:   219700, Batch Loss:     1.821830, Tokens per Sec:     2074, Lr: 0.000070
2021-11-23 14:41:28,104 - INFO - joeynmt.training - Epoch  65, Step:   219800, Batch Loss:     1.721399, Tokens per Sec:     2152, Lr: 0.000070
2021-11-23 14:41:42,331 - INFO - joeynmt.training - Epoch  65, Step:   219900, Batch Loss:     1.929287, Tokens per Sec:     2201, Lr: 0.000070
2021-11-23 14:41:57,243 - INFO - joeynmt.training - Epoch  65, Step:   220000, Batch Loss:     1.856718, Tokens per Sec:     2090, Lr: 0.000070
2021-11-23 14:43:43,811 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:43:43,812 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:43:43,812 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:43:43,836 - INFO - joeynmt.training - Example #0
2021-11-23 14:43:43,836 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:43:43,836 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:43:43,836 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁come', ',', '▁you', '▁have', '▁been', '▁count', 'ed', '▁by', '▁the', '▁time', '▁of', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁your', '▁follow', 'ers', '.']
2021-11-23 14:43:43,836 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:43:43,836 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁come , ▁you ▁have ▁been ▁count ed ▁by ▁the ▁time ▁of ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁your ▁follow ers .
2021-11-23 14:43:43,837 - INFO - joeynmt.training - Example #1
2021-11-23 14:43:43,837 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:43:43,837 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:43:43,837 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:43:43,837 - INFO - joeynmt.training - Example #2
2021-11-23 14:43:43,837 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:43:43,837 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:43:43,837 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', '▁with', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', ',', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:43:43,837 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ▁with ▁each ▁other , ▁work ▁with ▁one ▁another , ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 14:43:43,838 - INFO - joeynmt.training - Example #3
2021-11-23 14:43:43,838 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:43:43,838 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:43:43,838 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 14:43:43,838 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:43:43,838 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:43:43,838 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:43:43,838 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 14:43:43,838 - INFO - joeynmt.training - Example #6
2021-11-23 14:43:43,838 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:43:43,838 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:43:43,838 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 14:43:43,838 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:43:43,838 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:43:43,838 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:43:43,838 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 14:43:43,838 - INFO - joeynmt.training - Validation result (greedy) at epoch  65, step   220000: bleu:  15.33, loss: 71432.7969, ppl:   8.2418, duration: 106.5951s
2021-11-23 14:43:59,101 - INFO - joeynmt.training - Epoch  65, Step:   220100, Batch Loss:     1.913377, Tokens per Sec:     2036, Lr: 0.000070
2021-11-23 14:44:13,080 - INFO - joeynmt.training - Epoch  65, Step:   220200, Batch Loss:     1.912446, Tokens per Sec:     2148, Lr: 0.000070
2021-11-23 14:44:25,464 - INFO - joeynmt.training - Epoch  65: total training loss 6120.97
2021-11-23 14:44:25,465 - INFO - joeynmt.training - EPOCH 66
2021-11-23 14:44:27,635 - INFO - joeynmt.training - Epoch  66, Step:   220300, Batch Loss:     1.531251, Tokens per Sec:     2122, Lr: 0.000070
2021-11-23 14:44:42,304 - INFO - joeynmt.training - Epoch  66, Step:   220400, Batch Loss:     1.672878, Tokens per Sec:     2122, Lr: 0.000070
2021-11-23 14:44:57,713 - INFO - joeynmt.training - Epoch  66, Step:   220500, Batch Loss:     1.816993, Tokens per Sec:     2016, Lr: 0.000070
2021-11-23 14:45:13,170 - INFO - joeynmt.training - Epoch  66, Step:   220600, Batch Loss:     1.984893, Tokens per Sec:     2091, Lr: 0.000070
2021-11-23 14:45:28,339 - INFO - joeynmt.training - Epoch  66, Step:   220700, Batch Loss:     1.718653, Tokens per Sec:     2053, Lr: 0.000070
2021-11-23 14:45:43,578 - INFO - joeynmt.training - Epoch  66, Step:   220800, Batch Loss:     1.686826, Tokens per Sec:     2082, Lr: 0.000070
2021-11-23 14:45:58,543 - INFO - joeynmt.training - Epoch  66, Step:   220900, Batch Loss:     1.905062, Tokens per Sec:     2121, Lr: 0.000070
2021-11-23 14:46:13,278 - INFO - joeynmt.training - Epoch  66, Step:   221000, Batch Loss:     2.037255, Tokens per Sec:     2129, Lr: 0.000070
2021-11-23 14:48:21,793 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:48:21,793 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:48:21,793 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:48:21,814 - INFO - joeynmt.training - Example #0
2021-11-23 14:48:21,814 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:48:21,814 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:48:21,814 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁count', 'ed', '▁from', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', '▁are', '▁going', '▁to', '▁sc', 'atter', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 14:48:21,814 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:48:21,814 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁count ed ▁from ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁other ▁follow ers ▁are ▁going ▁to ▁sc atter ▁all ▁his ▁follow ers .
2021-11-23 14:48:21,815 - INFO - joeynmt.training - Example #1
2021-11-23 14:48:21,815 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:48:21,815 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:48:21,815 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:48:21,815 - INFO - joeynmt.training - Example #2
2021-11-23 14:48:21,815 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:48:21,815 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:48:21,815 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁work', '▁with', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁joy ▁by ▁each ▁other , ▁and ▁work ▁with ▁each ▁other , ▁work ▁with ▁one ▁another , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 14:48:21,815 - INFO - joeynmt.training - Example #3
2021-11-23 14:48:21,815 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:48:21,815 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:48:21,815 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'con', 'he', 'c', 'imento']
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:48:21,815 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:48:21,816 - INFO - joeynmt.training - 	Hypothesis: ▁D es con he c imento
2021-11-23 14:48:21,816 - INFO - joeynmt.training - Example #6
2021-11-23 14:48:21,816 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:48:21,816 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:48:21,816 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 14:48:21,816 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:48:21,816 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:48:21,816 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:48:21,816 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 14:48:21,816 - INFO - joeynmt.training - Validation result (greedy) at epoch  66, step   221000: bleu:  15.34, loss: 71762.5859, ppl:   8.3224, duration: 128.5373s
2021-11-23 14:48:36,185 - INFO - joeynmt.training - Epoch  66, Step:   221100, Batch Loss:     1.830318, Tokens per Sec:     2180, Lr: 0.000070
2021-11-23 14:48:50,820 - INFO - joeynmt.training - Epoch  66, Step:   221200, Batch Loss:     1.701911, Tokens per Sec:     2091, Lr: 0.000070
2021-11-23 14:49:05,783 - INFO - joeynmt.training - Epoch  66, Step:   221300, Batch Loss:     1.601408, Tokens per Sec:     2174, Lr: 0.000070
2021-11-23 14:49:21,441 - INFO - joeynmt.training - Epoch  66, Step:   221400, Batch Loss:     1.747025, Tokens per Sec:     2054, Lr: 0.000070
2021-11-23 14:49:35,687 - INFO - joeynmt.training - Epoch  66, Step:   221500, Batch Loss:     1.698008, Tokens per Sec:     2184, Lr: 0.000070
2021-11-23 14:49:51,150 - INFO - joeynmt.training - Epoch  66, Step:   221600, Batch Loss:     1.704069, Tokens per Sec:     2127, Lr: 0.000070
2021-11-23 14:50:05,796 - INFO - joeynmt.training - Epoch  66, Step:   221700, Batch Loss:     1.630037, Tokens per Sec:     2092, Lr: 0.000070
2021-11-23 14:50:20,084 - INFO - joeynmt.training - Epoch  66, Step:   221800, Batch Loss:     1.678976, Tokens per Sec:     2188, Lr: 0.000070
2021-11-23 14:50:34,828 - INFO - joeynmt.training - Epoch  66, Step:   221900, Batch Loss:     1.921654, Tokens per Sec:     2185, Lr: 0.000070
2021-11-23 14:50:49,687 - INFO - joeynmt.training - Epoch  66, Step:   222000, Batch Loss:     1.622670, Tokens per Sec:     2103, Lr: 0.000070
2021-11-23 14:52:32,852 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:52:32,852 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:52:32,852 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:52:32,918 - INFO - joeynmt.training - Example #0
2021-11-23 14:52:32,918 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:52:32,919 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:52:32,919 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁were', '▁there', ',', '▁you', '▁were', '▁count', 'ry', 'ing', '▁J', 'ul', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁people', '▁follow', 'ed', '▁him', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁sc', 'atter', 'ed', '▁him', '.']
2021-11-23 14:52:32,919 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:52:32,919 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:52:32,919 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:52:32,919 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁were ▁there , ▁you ▁were ▁count ry ing ▁J ul as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁people ▁follow ed ▁him , ▁and ▁all ▁his ▁follow ers ▁sc atter ed ▁him .
2021-11-23 14:52:32,919 - INFO - joeynmt.training - Example #1
2021-11-23 14:52:32,919 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:52:32,919 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:52:32,919 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:52:32,919 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:52:32,919 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:52:32,919 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:52:32,919 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:52:32,920 - INFO - joeynmt.training - Example #2
2021-11-23 14:52:32,920 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:52:32,920 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:52:32,920 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁work', '▁with', '▁one', '▁another', ',', '▁one', '▁mean', 'ing', '.']
2021-11-23 14:52:32,920 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:52:32,920 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:52:32,920 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:52:32,920 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁work ▁with ▁one ▁another , ▁one ▁mean ing .
2021-11-23 14:52:32,920 - INFO - joeynmt.training - Example #3
2021-11-23 14:52:32,920 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:52:32,920 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:52:32,920 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'rer']
2021-11-23 14:52:32,920 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:52:32,920 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:52:32,921 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:52:32,921 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or rer
2021-11-23 14:52:32,921 - INFO - joeynmt.training - Example #6
2021-11-23 14:52:32,921 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:52:32,921 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:52:32,921 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 14:52:32,921 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:52:32,921 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:52:32,921 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:52:32,921 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 14:52:32,921 - INFO - joeynmt.training - Validation result (greedy) at epoch  66, step   222000: bleu:  15.32, loss: 71376.7031, ppl:   8.2281, duration: 103.2342s
2021-11-23 14:52:47,784 - INFO - joeynmt.training - Epoch  66, Step:   222100, Batch Loss:     1.987162, Tokens per Sec:     2016, Lr: 0.000070
2021-11-23 14:53:02,236 - INFO - joeynmt.training - Epoch  66, Step:   222200, Batch Loss:     1.746486, Tokens per Sec:     2088, Lr: 0.000070
2021-11-23 14:53:16,821 - INFO - joeynmt.training - Epoch  66, Step:   222300, Batch Loss:     1.677793, Tokens per Sec:     2133, Lr: 0.000070
2021-11-23 14:53:32,384 - INFO - joeynmt.training - Epoch  66, Step:   222400, Batch Loss:     1.794479, Tokens per Sec:     2124, Lr: 0.000070
2021-11-23 14:53:47,279 - INFO - joeynmt.training - Epoch  66, Step:   222500, Batch Loss:     1.720889, Tokens per Sec:     2196, Lr: 0.000070
2021-11-23 14:54:02,172 - INFO - joeynmt.training - Epoch  66, Step:   222600, Batch Loss:     1.892913, Tokens per Sec:     2063, Lr: 0.000070
2021-11-23 14:54:17,051 - INFO - joeynmt.training - Epoch  66, Step:   222700, Batch Loss:     1.729307, Tokens per Sec:     2123, Lr: 0.000070
2021-11-23 14:54:31,636 - INFO - joeynmt.training - Epoch  66, Step:   222800, Batch Loss:     1.629081, Tokens per Sec:     2098, Lr: 0.000070
2021-11-23 14:54:46,566 - INFO - joeynmt.training - Epoch  66, Step:   222900, Batch Loss:     1.900233, Tokens per Sec:     2097, Lr: 0.000070
2021-11-23 14:55:00,458 - INFO - joeynmt.training - Epoch  66, Step:   223000, Batch Loss:     1.973853, Tokens per Sec:     2144, Lr: 0.000070
2021-11-23 14:57:06,792 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 14:57:06,792 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 14:57:06,792 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 14:57:06,815 - INFO - joeynmt.training - Example #0
2021-11-23 14:57:06,815 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 14:57:06,815 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 14:57:06,815 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁Jud', 'as', ',', '▁and', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Jud', 'as', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 14:57:06,815 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 14:57:06,815 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁Jud as , ▁and ▁you ▁were ▁count ed ▁from ▁Jud as . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁his ▁follow ers .
2021-11-23 14:57:06,816 - INFO - joeynmt.training - Example #1
2021-11-23 14:57:06,816 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 14:57:06,816 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 14:57:06,816 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 14:57:06,816 - INFO - joeynmt.training - Example #2
2021-11-23 14:57:06,816 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 14:57:06,816 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 14:57:06,816 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 14:57:06,816 - INFO - joeynmt.training - Example #3
2021-11-23 14:57:06,816 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 14:57:06,816 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 14:57:06,816 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'rer']
2021-11-23 14:57:06,816 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 14:57:06,817 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 14:57:06,817 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 14:57:06,817 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or rer
2021-11-23 14:57:06,817 - INFO - joeynmt.training - Example #6
2021-11-23 14:57:06,817 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 14:57:06,817 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 14:57:06,817 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 14:57:06,817 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 14:57:06,817 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 14:57:06,817 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 14:57:06,817 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 14:57:06,817 - INFO - joeynmt.training - Validation result (greedy) at epoch  66, step   223000: bleu:  15.43, loss: 71355.7422, ppl:   8.2230, duration: 126.3590s
2021-11-23 14:57:21,215 - INFO - joeynmt.training - Epoch  66, Step:   223100, Batch Loss:     1.962415, Tokens per Sec:     2129, Lr: 0.000070
2021-11-23 14:57:36,716 - INFO - joeynmt.training - Epoch  66, Step:   223200, Batch Loss:     1.862107, Tokens per Sec:     2100, Lr: 0.000070
2021-11-23 14:57:51,335 - INFO - joeynmt.training - Epoch  66, Step:   223300, Batch Loss:     1.726875, Tokens per Sec:     2105, Lr: 0.000070
2021-11-23 14:58:06,588 - INFO - joeynmt.training - Epoch  66, Step:   223400, Batch Loss:     2.065721, Tokens per Sec:     2109, Lr: 0.000070
2021-11-23 14:58:21,285 - INFO - joeynmt.training - Epoch  66, Step:   223500, Batch Loss:     1.593608, Tokens per Sec:     2168, Lr: 0.000070
2021-11-23 14:58:36,285 - INFO - joeynmt.training - Epoch  66, Step:   223600, Batch Loss:     1.964517, Tokens per Sec:     2121, Lr: 0.000070
2021-11-23 14:58:47,400 - INFO - joeynmt.training - Epoch  66: total training loss 6093.71
2021-11-23 14:58:47,400 - INFO - joeynmt.training - EPOCH 67
2021-11-23 14:58:51,168 - INFO - joeynmt.training - Epoch  67, Step:   223700, Batch Loss:     1.979031, Tokens per Sec:     2225, Lr: 0.000070
2021-11-23 14:59:06,716 - INFO - joeynmt.training - Epoch  67, Step:   223800, Batch Loss:     1.724234, Tokens per Sec:     2108, Lr: 0.000070
2021-11-23 14:59:22,666 - INFO - joeynmt.training - Epoch  67, Step:   223900, Batch Loss:     2.072285, Tokens per Sec:     2058, Lr: 0.000070
2021-11-23 14:59:37,708 - INFO - joeynmt.training - Epoch  67, Step:   224000, Batch Loss:     1.934282, Tokens per Sec:     2193, Lr: 0.000070
2021-11-23 15:01:26,329 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:01:26,329 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:01:26,329 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:01:26,358 - INFO - joeynmt.training - Example #0
2021-11-23 15:01:26,359 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:01:26,359 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:01:26,359 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁Jerusalem', ',', '▁and', '▁you', '▁were', '▁with', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁some', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁your', '▁follow', 'ers', '.']
2021-11-23 15:01:26,359 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:01:26,359 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:01:26,359 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:01:26,359 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁Jerusalem , ▁and ▁you ▁were ▁with ▁the ▁people ▁of ▁Gal ile e . ▁You ▁follow ed ▁some , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁your ▁follow ers .
2021-11-23 15:01:26,359 - INFO - joeynmt.training - Example #1
2021-11-23 15:01:26,359 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:01:26,359 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:01:26,359 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:01:26,359 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:01:26,359 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:01:26,359 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:01:26,359 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:01:26,359 - INFO - joeynmt.training - Example #2
2021-11-23 15:01:26,359 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:01:26,360 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:01:26,360 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 15:01:26,360 - INFO - joeynmt.training - Example #3
2021-11-23 15:01:26,360 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:01:26,360 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:01:26,360 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:01:26,360 - INFO - joeynmt.training - Example #6
2021-11-23 15:01:26,360 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:01:26,360 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:01:26,360 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:01:26,360 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:01:26,361 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:01:26,361 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:01:26,361 - INFO - joeynmt.training - Validation result (greedy) at epoch  67, step   224000: bleu:  15.30, loss: 71662.8281, ppl:   8.2979, duration: 108.6521s
2021-11-23 15:01:41,242 - INFO - joeynmt.training - Epoch  67, Step:   224100, Batch Loss:     1.883774, Tokens per Sec:     2016, Lr: 0.000070
2021-11-23 15:01:55,888 - INFO - joeynmt.training - Epoch  67, Step:   224200, Batch Loss:     2.073632, Tokens per Sec:     2161, Lr: 0.000070
2021-11-23 15:02:10,169 - INFO - joeynmt.training - Epoch  67, Step:   224300, Batch Loss:     1.744523, Tokens per Sec:     2155, Lr: 0.000070
2021-11-23 15:02:25,467 - INFO - joeynmt.training - Epoch  67, Step:   224400, Batch Loss:     1.690381, Tokens per Sec:     2033, Lr: 0.000070
2021-11-23 15:02:39,627 - INFO - joeynmt.training - Epoch  67, Step:   224500, Batch Loss:     1.779946, Tokens per Sec:     2238, Lr: 0.000070
2021-11-23 15:02:54,426 - INFO - joeynmt.training - Epoch  67, Step:   224600, Batch Loss:     1.597352, Tokens per Sec:     2135, Lr: 0.000070
2021-11-23 15:03:09,346 - INFO - joeynmt.training - Epoch  67, Step:   224700, Batch Loss:     1.700984, Tokens per Sec:     2136, Lr: 0.000070
2021-11-23 15:03:24,512 - INFO - joeynmt.training - Epoch  67, Step:   224800, Batch Loss:     2.057219, Tokens per Sec:     2078, Lr: 0.000070
2021-11-23 15:03:39,786 - INFO - joeynmt.training - Epoch  67, Step:   224900, Batch Loss:     1.802060, Tokens per Sec:     2164, Lr: 0.000070
2021-11-23 15:03:54,235 - INFO - joeynmt.training - Epoch  67, Step:   225000, Batch Loss:     1.653372, Tokens per Sec:     2155, Lr: 0.000070
2021-11-23 15:05:30,507 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:05:32,266 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:05:32,280 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:05:32,317 - INFO - joeynmt.training - Example #0
2021-11-23 15:05:32,317 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:05:32,317 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:05:32,317 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁Jerusalem', ',', '▁and', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁some', '▁of', '▁you', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁Jerusalem , ▁and ▁you ▁were ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁some ▁of ▁you , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁sc atter ed .
2021-11-23 15:05:32,318 - INFO - joeynmt.training - Example #1
2021-11-23 15:05:32,318 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:05:32,318 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:05:32,318 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:05:32,318 - INFO - joeynmt.training - Example #2
2021-11-23 15:05:32,318 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:05:32,318 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:05:32,318 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:05:32,318 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 15:05:32,319 - INFO - joeynmt.training - Example #3
2021-11-23 15:05:32,319 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:05:32,319 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:05:32,319 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:05:32,319 - INFO - joeynmt.training - Example #6
2021-11-23 15:05:32,319 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:05:32,319 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:05:32,319 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:05:32,319 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:05:32,320 - INFO - joeynmt.training - Validation result (greedy) at epoch  67, step   225000: bleu:  15.49, loss: 71411.7578, ppl:   8.2367, duration: 98.0742s
2021-11-23 15:05:46,531 - INFO - joeynmt.training - Epoch  67, Step:   225100, Batch Loss:     1.866780, Tokens per Sec:     2180, Lr: 0.000049
2021-11-23 15:06:00,991 - INFO - joeynmt.training - Epoch  67, Step:   225200, Batch Loss:     1.705354, Tokens per Sec:     2112, Lr: 0.000049
2021-11-23 15:06:15,447 - INFO - joeynmt.training - Epoch  67, Step:   225300, Batch Loss:     1.772325, Tokens per Sec:     2176, Lr: 0.000049
2021-11-23 15:06:30,544 - INFO - joeynmt.training - Epoch  67, Step:   225400, Batch Loss:     2.035037, Tokens per Sec:     2033, Lr: 0.000049
2021-11-23 15:06:45,120 - INFO - joeynmt.training - Epoch  67, Step:   225500, Batch Loss:     1.835270, Tokens per Sec:     2182, Lr: 0.000049
2021-11-23 15:07:00,234 - INFO - joeynmt.training - Epoch  67, Step:   225600, Batch Loss:     1.707245, Tokens per Sec:     2017, Lr: 0.000049
2021-11-23 15:07:14,688 - INFO - joeynmt.training - Epoch  67, Step:   225700, Batch Loss:     1.609900, Tokens per Sec:     2138, Lr: 0.000049
2021-11-23 15:07:28,718 - INFO - joeynmt.training - Epoch  67, Step:   225800, Batch Loss:     1.854057, Tokens per Sec:     2183, Lr: 0.000049
2021-11-23 15:07:42,945 - INFO - joeynmt.training - Epoch  67, Step:   225900, Batch Loss:     1.792517, Tokens per Sec:     2239, Lr: 0.000049
2021-11-23 15:07:57,932 - INFO - joeynmt.training - Epoch  67, Step:   226000, Batch Loss:     1.954645, Tokens per Sec:     2123, Lr: 0.000049
2021-11-23 15:09:38,497 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:09:38,520 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:09:38,546 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:09:38,585 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 15:09:39,639 - INFO - joeynmt.helpers - delete models/baseline_multilingual/217000.ckpt
2021-11-23 15:09:39,772 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/217000.ckpt
2021-11-23 15:09:39,871 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/217000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/217000.ckpt')
2021-11-23 15:09:40,010 - INFO - joeynmt.training - Example #0
2021-11-23 15:09:40,064 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:09:40,103 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:09:40,162 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'L', 'et', '▁you', '▁have', '▁been', '▁count', 'ed', '▁in', '▁Jud', 'as', ',', '▁and', '▁you', '▁were', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁some', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 15:09:40,209 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:09:40,247 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:09:40,306 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:09:40,357 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" L et ▁you ▁have ▁been ▁count ed ▁in ▁Jud as , ▁and ▁you ▁were ▁from ▁Gal ile e . ▁You ▁follow ed ▁some , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 15:09:40,382 - INFO - joeynmt.training - Example #1
2021-11-23 15:09:40,437 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:09:40,472 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:09:40,510 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:09:40,561 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:09:40,597 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:09:40,646 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:09:40,683 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:09:40,712 - INFO - joeynmt.training - Example #2
2021-11-23 15:09:40,738 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:09:40,764 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:09:40,798 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 15:09:40,833 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:09:40,870 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:09:40,912 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:09:40,969 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 15:09:41,021 - INFO - joeynmt.training - Example #3
2021-11-23 15:09:41,095 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:09:41,138 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:09:41,174 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:09:41,199 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:09:41,233 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:09:41,253 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:09:41,265 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:09:41,302 - INFO - joeynmt.training - Example #6
2021-11-23 15:09:41,335 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:09:41,362 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:09:41,386 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:09:41,419 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:09:41,445 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:09:41,475 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:09:41,505 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:09:41,537 - INFO - joeynmt.training - Validation result (greedy) at epoch  67, step   226000: bleu:  15.87, loss: 71199.8672, ppl:   8.1853, duration: 103.6044s
2021-11-23 15:09:57,087 - INFO - joeynmt.training - Epoch  67, Step:   226100, Batch Loss:     2.067276, Tokens per Sec:     2099, Lr: 0.000049
2021-11-23 15:10:11,244 - INFO - joeynmt.training - Epoch  67, Step:   226200, Batch Loss:     1.840974, Tokens per Sec:     2106, Lr: 0.000049
2021-11-23 15:10:25,862 - INFO - joeynmt.training - Epoch  67, Step:   226300, Batch Loss:     2.038420, Tokens per Sec:     2101, Lr: 0.000049
2021-11-23 15:10:42,111 - INFO - joeynmt.training - Epoch  67, Step:   226400, Batch Loss:     1.934799, Tokens per Sec:     1998, Lr: 0.000049
2021-11-23 15:10:56,849 - INFO - joeynmt.training - Epoch  67, Step:   226500, Batch Loss:     1.980128, Tokens per Sec:     2022, Lr: 0.000049
2021-11-23 15:11:12,222 - INFO - joeynmt.training - Epoch  67, Step:   226600, Batch Loss:     1.872789, Tokens per Sec:     2110, Lr: 0.000049
2021-11-23 15:11:26,795 - INFO - joeynmt.training - Epoch  67, Step:   226700, Batch Loss:     1.650915, Tokens per Sec:     2146, Lr: 0.000049
2021-11-23 15:11:40,774 - INFO - joeynmt.training - Epoch  67, Step:   226800, Batch Loss:     1.873492, Tokens per Sec:     2145, Lr: 0.000049
2021-11-23 15:11:56,076 - INFO - joeynmt.training - Epoch  67, Step:   226900, Batch Loss:     1.941800, Tokens per Sec:     2125, Lr: 0.000049
2021-11-23 15:12:11,143 - INFO - joeynmt.training - Epoch  67, Step:   227000, Batch Loss:     1.834818, Tokens per Sec:     2058, Lr: 0.000049
2021-11-23 15:13:52,720 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:13:52,720 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:13:52,720 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:13:52,763 - INFO - joeynmt.training - Example #0
2021-11-23 15:13:52,763 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:13:52,763 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:13:52,763 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁Jud', 'as', ',', '▁and', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁him', ',', '▁but', '▁some', '▁of', '▁the', '▁people', '▁k', 'illed', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 15:13:52,763 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:13:52,763 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:13:52,763 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:13:52,763 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁Jud as , ▁and ▁you ▁were ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁him , ▁but ▁some ▁of ▁the ▁people ▁k illed , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 15:13:52,763 - INFO - joeynmt.training - Example #1
2021-11-23 15:13:52,763 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:13:52,764 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:13:52,764 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:13:52,764 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:13:52,764 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:13:52,764 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:13:52,764 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:13:52,764 - INFO - joeynmt.training - Example #2
2021-11-23 15:13:52,764 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:13:52,764 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:13:52,764 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 15:13:52,764 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:13:52,764 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:13:52,764 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:13:52,764 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ▁with ▁one ▁another , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 15:13:52,764 - INFO - joeynmt.training - Example #3
2021-11-23 15:13:52,765 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:13:52,765 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:13:52,765 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'rit', 'ar']
2021-11-23 15:13:52,765 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:13:52,765 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:13:52,765 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:13:52,765 - INFO - joeynmt.training - 	Hypothesis: ▁D es c rit ar
2021-11-23 15:13:52,765 - INFO - joeynmt.training - Example #6
2021-11-23 15:13:52,765 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:13:52,765 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:13:52,765 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:13:52,765 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:13:52,765 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:13:52,765 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:13:52,765 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:13:52,766 - INFO - joeynmt.training - Validation result (greedy) at epoch  67, step   227000: bleu:  15.63, loss: 71132.4062, ppl:   8.1690, duration: 101.6218s
2021-11-23 15:14:02,695 - INFO - joeynmt.training - Epoch  67: total training loss 6049.98
2021-11-23 15:14:02,695 - INFO - joeynmt.training - EPOCH 68
2021-11-23 15:14:07,869 - INFO - joeynmt.training - Epoch  68, Step:   227100, Batch Loss:     1.737512, Tokens per Sec:     2240, Lr: 0.000049
2021-11-23 15:14:23,243 - INFO - joeynmt.training - Epoch  68, Step:   227200, Batch Loss:     1.485921, Tokens per Sec:     2108, Lr: 0.000049
2021-11-23 15:14:38,919 - INFO - joeynmt.training - Epoch  68, Step:   227300, Batch Loss:     1.712857, Tokens per Sec:     2058, Lr: 0.000049
2021-11-23 15:14:53,680 - INFO - joeynmt.training - Epoch  68, Step:   227400, Batch Loss:     1.702269, Tokens per Sec:     2125, Lr: 0.000049
2021-11-23 15:15:07,963 - INFO - joeynmt.training - Epoch  68, Step:   227500, Batch Loss:     1.859854, Tokens per Sec:     2123, Lr: 0.000049
2021-11-23 15:15:22,639 - INFO - joeynmt.training - Epoch  68, Step:   227600, Batch Loss:     1.771070, Tokens per Sec:     2143, Lr: 0.000049
2021-11-23 15:15:37,120 - INFO - joeynmt.training - Epoch  68, Step:   227700, Batch Loss:     1.573651, Tokens per Sec:     2095, Lr: 0.000049
2021-11-23 15:15:52,134 - INFO - joeynmt.training - Epoch  68, Step:   227800, Batch Loss:     1.873901, Tokens per Sec:     2076, Lr: 0.000049
2021-11-23 15:16:06,289 - INFO - joeynmt.training - Epoch  68, Step:   227900, Batch Loss:     1.646587, Tokens per Sec:     2212, Lr: 0.000049
2021-11-23 15:16:20,847 - INFO - joeynmt.training - Epoch  68, Step:   228000, Batch Loss:     1.850414, Tokens per Sec:     2132, Lr: 0.000049
2021-11-23 15:18:03,138 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:18:03,138 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:18:03,138 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:18:03,197 - INFO - joeynmt.training - Example #0
2021-11-23 15:18:03,198 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:18:03,198 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:18:03,198 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁have', '▁been', '▁count', 'ed', '▁by', '▁the', '▁time', '▁of', '▁Jud', 'as', '▁and', '▁gra', 'in', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 15:18:03,198 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:18:03,198 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:18:03,198 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:18:03,198 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁have ▁been ▁count ed ▁by ▁the ▁time ▁of ▁Jud as ▁and ▁gra in . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁his ▁follow ers .
2021-11-23 15:18:03,198 - INFO - joeynmt.training - Example #1
2021-11-23 15:18:03,198 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:18:03,199 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:18:03,199 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:18:03,199 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:18:03,199 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:18:03,199 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:18:03,199 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:18:03,199 - INFO - joeynmt.training - Example #2
2021-11-23 15:18:03,199 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:18:03,199 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:18:03,199 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', 'ing', '▁with', '▁one', '▁another', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 15:18:03,199 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:18:03,199 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:18:03,199 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:18:03,200 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ing ▁with ▁one ▁another , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 15:18:03,200 - INFO - joeynmt.training - Example #3
2021-11-23 15:18:03,200 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:18:03,200 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:18:03,200 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'con', 'he', 'c', 'imento']
2021-11-23 15:18:03,200 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:18:03,200 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:18:03,200 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:18:03,200 - INFO - joeynmt.training - 	Hypothesis: ▁D es con he c imento
2021-11-23 15:18:03,200 - INFO - joeynmt.training - Example #6
2021-11-23 15:18:03,200 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:18:03,200 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:18:03,200 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:18:03,200 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:18:03,201 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:18:03,201 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:18:03,201 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:18:03,201 - INFO - joeynmt.training - Validation result (greedy) at epoch  68, step   228000: bleu:  15.62, loss: 71307.2422, ppl:   8.2113, duration: 102.3538s
2021-11-23 15:18:18,174 - INFO - joeynmt.training - Epoch  68, Step:   228100, Batch Loss:     1.784135, Tokens per Sec:     2143, Lr: 0.000049
2021-11-23 15:18:33,433 - INFO - joeynmt.training - Epoch  68, Step:   228200, Batch Loss:     1.844585, Tokens per Sec:     2156, Lr: 0.000049
2021-11-23 15:18:48,381 - INFO - joeynmt.training - Epoch  68, Step:   228300, Batch Loss:     1.649424, Tokens per Sec:     2032, Lr: 0.000049
2021-11-23 15:19:04,012 - INFO - joeynmt.training - Epoch  68, Step:   228400, Batch Loss:     1.793298, Tokens per Sec:     2041, Lr: 0.000049
2021-11-23 15:19:19,183 - INFO - joeynmt.training - Epoch  68, Step:   228500, Batch Loss:     1.814477, Tokens per Sec:     2087, Lr: 0.000049
2021-11-23 15:19:34,145 - INFO - joeynmt.training - Epoch  68, Step:   228600, Batch Loss:     1.748891, Tokens per Sec:     2125, Lr: 0.000049
2021-11-23 15:19:48,678 - INFO - joeynmt.training - Epoch  68, Step:   228700, Batch Loss:     1.648925, Tokens per Sec:     2160, Lr: 0.000049
2021-11-23 15:20:04,295 - INFO - joeynmt.training - Epoch  68, Step:   228800, Batch Loss:     1.737951, Tokens per Sec:     2062, Lr: 0.000049
2021-11-23 15:20:18,636 - INFO - joeynmt.training - Epoch  68, Step:   228900, Batch Loss:     1.789657, Tokens per Sec:     2150, Lr: 0.000049
2021-11-23 15:20:33,814 - INFO - joeynmt.training - Epoch  68, Step:   229000, Batch Loss:     1.640419, Tokens per Sec:     2096, Lr: 0.000049
2021-11-23 15:22:18,907 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:22:18,907 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:22:18,907 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:22:18,944 - INFO - joeynmt.training - Example #0
2021-11-23 15:22:18,944 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:22:18,944 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:22:18,944 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁Judah', ',', '▁and', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 15:22:18,944 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:22:18,944 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:22:18,944 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:22:18,944 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁Judah , ▁and ▁you ▁were ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 15:22:18,944 - INFO - joeynmt.training - Example #1
2021-11-23 15:22:18,945 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:22:18,945 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:22:18,945 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 15:22:18,945 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:22:18,945 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:22:18,945 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:22:18,945 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 15:22:18,945 - INFO - joeynmt.training - Example #2
2021-11-23 15:22:18,945 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:22:18,945 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:22:18,945 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 15:22:18,945 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:22:18,945 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:22:18,945 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:22:18,945 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁work ▁with ▁one ▁another .
2021-11-23 15:22:18,945 - INFO - joeynmt.training - Example #3
2021-11-23 15:22:18,945 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:22:18,945 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:22:18,945 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:22:18,946 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:22:18,946 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:22:18,946 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:22:18,946 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:22:18,946 - INFO - joeynmt.training - Example #6
2021-11-23 15:22:18,946 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:22:18,946 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:22:18,946 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'und', 'red']
2021-11-23 15:22:18,946 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:22:18,946 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:22:18,946 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:22:18,946 - INFO - joeynmt.training - 	Hypothesis: ▁h und red
2021-11-23 15:22:18,946 - INFO - joeynmt.training - Validation result (greedy) at epoch  68, step   229000: bleu:  15.75, loss: 71212.6406, ppl:   8.1884, duration: 105.1318s
2021-11-23 15:22:33,562 - INFO - joeynmt.training - Epoch  68, Step:   229100, Batch Loss:     1.747059, Tokens per Sec:     2219, Lr: 0.000049
2021-11-23 15:22:48,269 - INFO - joeynmt.training - Epoch  68, Step:   229200, Batch Loss:     1.722030, Tokens per Sec:     2063, Lr: 0.000049
2021-11-23 15:23:03,354 - INFO - joeynmt.training - Epoch  68, Step:   229300, Batch Loss:     1.737663, Tokens per Sec:     2055, Lr: 0.000049
2021-11-23 15:23:17,793 - INFO - joeynmt.training - Epoch  68, Step:   229400, Batch Loss:     1.979785, Tokens per Sec:     2160, Lr: 0.000049
2021-11-23 15:23:32,054 - INFO - joeynmt.training - Epoch  68, Step:   229500, Batch Loss:     1.787888, Tokens per Sec:     2241, Lr: 0.000049
2021-11-23 15:23:47,036 - INFO - joeynmt.training - Epoch  68, Step:   229600, Batch Loss:     1.641464, Tokens per Sec:     2048, Lr: 0.000049
2021-11-23 15:24:02,188 - INFO - joeynmt.training - Epoch  68, Step:   229700, Batch Loss:     1.725607, Tokens per Sec:     2113, Lr: 0.000049
2021-11-23 15:24:17,203 - INFO - joeynmt.training - Epoch  68, Step:   229800, Batch Loss:     1.833219, Tokens per Sec:     2050, Lr: 0.000049
2021-11-23 15:24:32,442 - INFO - joeynmt.training - Epoch  68, Step:   229900, Batch Loss:     1.551249, Tokens per Sec:     2055, Lr: 0.000049
2021-11-23 15:24:46,843 - INFO - joeynmt.training - Epoch  68, Step:   230000, Batch Loss:     1.930845, Tokens per Sec:     2107, Lr: 0.000049
2021-11-23 15:26:24,320 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:26:24,320 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:26:24,320 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:26:24,345 - INFO - joeynmt.training - Example #0
2021-11-23 15:26:24,345 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:26:24,345 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:26:24,345 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁Jud', 'e', 'a', '▁and', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 15:26:24,345 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:26:24,345 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:26:24,345 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:26:24,345 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁Jud e a ▁and ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 15:26:24,345 - INFO - joeynmt.training - Example #1
2021-11-23 15:26:24,345 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:26:24,346 - INFO - joeynmt.training - Example #2
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁love', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁love ▁each ▁other , ▁work ▁with ▁one ▁another .
2021-11-23 15:26:24,346 - INFO - joeynmt.training - Example #3
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'con', 'he', 'c', 'imento']
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:26:24,346 - INFO - joeynmt.training - 	Hypothesis: ▁D es con he c imento
2021-11-23 15:26:24,346 - INFO - joeynmt.training - Example #6
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:26:24,346 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:26:24,347 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:26:24,347 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:26:24,347 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:26:24,347 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:26:24,347 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:26:24,347 - INFO - joeynmt.training - Validation result (greedy) at epoch  68, step   230000: bleu:  15.71, loss: 71137.7734, ppl:   8.1703, duration: 97.5036s
2021-11-23 15:26:38,792 - INFO - joeynmt.training - Epoch  68, Step:   230100, Batch Loss:     1.775963, Tokens per Sec:     2147, Lr: 0.000049
2021-11-23 15:26:53,655 - INFO - joeynmt.training - Epoch  68, Step:   230200, Batch Loss:     1.669745, Tokens per Sec:     2144, Lr: 0.000049
2021-11-23 15:27:08,547 - INFO - joeynmt.training - Epoch  68, Step:   230300, Batch Loss:     1.769747, Tokens per Sec:     2143, Lr: 0.000049
2021-11-23 15:27:23,644 - INFO - joeynmt.training - Epoch  68, Step:   230400, Batch Loss:     1.924824, Tokens per Sec:     2087, Lr: 0.000049
2021-11-23 15:27:31,395 - INFO - joeynmt.training - Epoch  68: total training loss 5991.73
2021-11-23 15:27:31,396 - INFO - joeynmt.training - EPOCH 69
2021-11-23 15:27:38,561 - INFO - joeynmt.training - Epoch  69, Step:   230500, Batch Loss:     1.978228, Tokens per Sec:     2147, Lr: 0.000049
2021-11-23 15:27:53,011 - INFO - joeynmt.training - Epoch  69, Step:   230600, Batch Loss:     1.689147, Tokens per Sec:     2122, Lr: 0.000049
2021-11-23 15:28:07,476 - INFO - joeynmt.training - Epoch  69, Step:   230700, Batch Loss:     1.640675, Tokens per Sec:     2037, Lr: 0.000049
2021-11-23 15:28:22,066 - INFO - joeynmt.training - Epoch  69, Step:   230800, Batch Loss:     1.764410, Tokens per Sec:     2059, Lr: 0.000049
2021-11-23 15:28:36,568 - INFO - joeynmt.training - Epoch  69, Step:   230900, Batch Loss:     1.884753, Tokens per Sec:     2166, Lr: 0.000049
2021-11-23 15:28:50,581 - INFO - joeynmt.training - Epoch  69, Step:   231000, Batch Loss:     1.873035, Tokens per Sec:     2223, Lr: 0.000049
2021-11-23 15:30:28,250 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:30:28,250 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:30:28,250 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:30:28,262 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 15:30:29,110 - INFO - joeynmt.helpers - delete models/baseline_multilingual/226000.ckpt
2021-11-23 15:30:29,113 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/226000.ckpt
2021-11-23 15:30:29,115 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/226000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/226000.ckpt')
2021-11-23 15:30:29,173 - INFO - joeynmt.training - Example #0
2021-11-23 15:30:29,173 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:30:29,173 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:30:29,173 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁count', 'ed', '▁by', '▁Jud', 'as', '▁and', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 15:30:29,174 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:30:29,174 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:30:29,174 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:30:29,174 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁count ed ▁by ▁Jud as ▁and ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁other ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 15:30:29,174 - INFO - joeynmt.training - Example #1
2021-11-23 15:30:29,174 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:30:29,175 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:30:29,175 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 15:30:29,175 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:30:29,175 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:30:29,175 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:30:29,175 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 15:30:29,175 - INFO - joeynmt.training - Example #2
2021-11-23 15:30:29,176 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:30:29,176 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:30:29,176 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 15:30:29,176 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:30:29,176 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:30:29,176 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:30:29,176 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ▁with ▁one ▁another , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 15:30:29,177 - INFO - joeynmt.training - Example #3
2021-11-23 15:30:29,177 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:30:29,177 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:30:29,177 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:30:29,177 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:30:29,177 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:30:29,177 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:30:29,177 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:30:29,177 - INFO - joeynmt.training - Example #6
2021-11-23 15:30:29,177 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:30:29,177 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:30:29,177 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:30:29,177 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:30:29,177 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:30:29,177 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:30:29,178 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:30:29,178 - INFO - joeynmt.training - Validation result (greedy) at epoch  69, step   231000: bleu:  15.87, loss: 71276.5391, ppl:   8.2038, duration: 98.5966s
2021-11-23 15:30:43,968 - INFO - joeynmt.training - Epoch  69, Step:   231100, Batch Loss:     1.675590, Tokens per Sec:     2174, Lr: 0.000049
2021-11-23 15:30:58,126 - INFO - joeynmt.training - Epoch  69, Step:   231200, Batch Loss:     1.766386, Tokens per Sec:     2149, Lr: 0.000049
2021-11-23 15:31:13,691 - INFO - joeynmt.training - Epoch  69, Step:   231300, Batch Loss:     2.025462, Tokens per Sec:     2077, Lr: 0.000049
2021-11-23 15:31:28,071 - INFO - joeynmt.training - Epoch  69, Step:   231400, Batch Loss:     1.679485, Tokens per Sec:     2083, Lr: 0.000049
2021-11-23 15:31:43,477 - INFO - joeynmt.training - Epoch  69, Step:   231500, Batch Loss:     1.914408, Tokens per Sec:     2063, Lr: 0.000049
2021-11-23 15:31:57,903 - INFO - joeynmt.training - Epoch  69, Step:   231600, Batch Loss:     1.874377, Tokens per Sec:     2179, Lr: 0.000049
2021-11-23 15:32:12,384 - INFO - joeynmt.training - Epoch  69, Step:   231700, Batch Loss:     1.839459, Tokens per Sec:     2137, Lr: 0.000049
2021-11-23 15:32:27,619 - INFO - joeynmt.training - Epoch  69, Step:   231800, Batch Loss:     1.669011, Tokens per Sec:     2072, Lr: 0.000049
2021-11-23 15:32:42,470 - INFO - joeynmt.training - Epoch  69, Step:   231900, Batch Loss:     2.038512, Tokens per Sec:     2082, Lr: 0.000049
2021-11-23 15:32:58,124 - INFO - joeynmt.training - Epoch  69, Step:   232000, Batch Loss:     1.778482, Tokens per Sec:     2033, Lr: 0.000049
2021-11-23 15:34:36,195 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:34:36,195 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:34:36,195 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:34:36,208 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 15:34:37,032 - INFO - joeynmt.helpers - delete models/baseline_multilingual/231000.ckpt
2021-11-23 15:34:37,034 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/231000.ckpt
2021-11-23 15:34:37,035 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/231000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/231000.ckpt')
2021-11-23 15:34:37,091 - INFO - joeynmt.training - Example #0
2021-11-23 15:34:37,091 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:34:37,091 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:34:37,091 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁Jud', 'as', ',', '▁and', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁people', '▁follow', 'ed', '▁him', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁are', '▁sc', 'atter', 'ed', '.']
2021-11-23 15:34:37,091 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:34:37,091 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:34:37,092 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:34:37,092 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁Jud as , ▁and ▁you ▁were ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁people ▁follow ed ▁him , ▁and ▁all ▁his ▁follow ers ▁are ▁sc atter ed .
2021-11-23 15:34:37,092 - INFO - joeynmt.training - Example #1
2021-11-23 15:34:37,092 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:34:37,092 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:34:37,092 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 15:34:37,092 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:34:37,092 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:34:37,093 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:34:37,093 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 15:34:37,093 - INFO - joeynmt.training - Example #2
2021-11-23 15:34:37,093 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:34:37,093 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:34:37,093 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 15:34:37,093 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:34:37,094 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:34:37,094 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:34:37,094 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁each ▁other , ▁work ▁with ▁one ▁another .
2021-11-23 15:34:37,094 - INFO - joeynmt.training - Example #3
2021-11-23 15:34:37,094 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:34:37,094 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:34:37,094 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:34:37,094 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:34:37,094 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:34:37,094 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:34:37,094 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:34:37,095 - INFO - joeynmt.training - Example #6
2021-11-23 15:34:37,095 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:34:37,095 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:34:37,095 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:34:37,095 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:34:37,095 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:34:37,095 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:34:37,095 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:34:37,095 - INFO - joeynmt.training - Validation result (greedy) at epoch  69, step   232000: bleu:  15.90, loss: 71230.3594, ppl:   8.1927, duration: 98.9702s
2021-11-23 15:34:52,279 - INFO - joeynmt.training - Epoch  69, Step:   232100, Batch Loss:     1.583884, Tokens per Sec:     2008, Lr: 0.000049
2021-11-23 15:35:06,648 - INFO - joeynmt.training - Epoch  69, Step:   232200, Batch Loss:     1.596295, Tokens per Sec:     2193, Lr: 0.000049
2021-11-23 15:35:22,051 - INFO - joeynmt.training - Epoch  69, Step:   232300, Batch Loss:     1.924636, Tokens per Sec:     2040, Lr: 0.000049
2021-11-23 15:35:37,180 - INFO - joeynmt.training - Epoch  69, Step:   232400, Batch Loss:     1.892355, Tokens per Sec:     2163, Lr: 0.000049
2021-11-23 15:35:50,777 - INFO - joeynmt.training - Epoch  69, Step:   232500, Batch Loss:     1.473985, Tokens per Sec:     2172, Lr: 0.000049
2021-11-23 15:36:05,928 - INFO - joeynmt.training - Epoch  69, Step:   232600, Batch Loss:     1.617431, Tokens per Sec:     2073, Lr: 0.000049
2021-11-23 15:36:20,542 - INFO - joeynmt.training - Epoch  69, Step:   232700, Batch Loss:     1.895635, Tokens per Sec:     2114, Lr: 0.000049
2021-11-23 15:36:35,929 - INFO - joeynmt.training - Epoch  69, Step:   232800, Batch Loss:     1.707496, Tokens per Sec:     2061, Lr: 0.000049
2021-11-23 15:36:51,892 - INFO - joeynmt.training - Epoch  69, Step:   232900, Batch Loss:     1.640541, Tokens per Sec:     2113, Lr: 0.000049
2021-11-23 15:37:06,859 - INFO - joeynmt.training - Epoch  69, Step:   233000, Batch Loss:     1.835025, Tokens per Sec:     2142, Lr: 0.000049
2021-11-23 15:39:00,488 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:39:00,488 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:39:00,488 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:39:00,501 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 15:39:01,343 - INFO - joeynmt.helpers - delete models/baseline_multilingual/232000.ckpt
2021-11-23 15:39:01,344 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/232000.ckpt
2021-11-23 15:39:01,345 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/232000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/232000.ckpt')
2021-11-23 15:39:01,401 - INFO - joeynmt.training - Example #0
2021-11-23 15:39:01,401 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:39:01,401 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:39:01,401 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁the', '▁time', '▁of', '▁Judah', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁his', '▁follow', 'ers', '▁are', '▁follow', 'ing', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 15:39:01,402 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:39:01,402 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:39:01,402 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:39:01,402 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁the ▁time ▁of ▁Judah . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁his ▁follow ers ▁are ▁follow ing ▁all ▁his ▁follow ers .
2021-11-23 15:39:01,402 - INFO - joeynmt.training - Example #1
2021-11-23 15:39:01,402 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:39:01,403 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:39:01,403 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:39:01,403 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:39:01,403 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:39:01,403 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:39:01,403 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:39:01,403 - INFO - joeynmt.training - Example #2
2021-11-23 15:39:01,403 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:39:01,404 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:39:01,404 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', '▁with', '▁each', '▁other', ',', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 15:39:01,404 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:39:01,404 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:39:01,404 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:39:01,404 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ▁with ▁each ▁other , ▁work ▁with ▁one ▁another .
2021-11-23 15:39:01,404 - INFO - joeynmt.training - Example #3
2021-11-23 15:39:01,404 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:39:01,404 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:39:01,404 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'con', 'he', 'c', 'imento']
2021-11-23 15:39:01,404 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:39:01,404 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:39:01,404 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:39:01,405 - INFO - joeynmt.training - 	Hypothesis: ▁D es con he c imento
2021-11-23 15:39:01,405 - INFO - joeynmt.training - Example #6
2021-11-23 15:39:01,405 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:39:01,405 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:39:01,405 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:39:01,405 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:39:01,405 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:39:01,405 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:39:01,405 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:39:01,405 - INFO - joeynmt.training - Validation result (greedy) at epoch  69, step   233000: bleu:  15.94, loss: 71182.6719, ppl:   8.1811, duration: 114.5460s
2021-11-23 15:39:15,930 - INFO - joeynmt.training - Epoch  69, Step:   233100, Batch Loss:     1.690754, Tokens per Sec:     2155, Lr: 0.000049
2021-11-23 15:39:30,985 - INFO - joeynmt.training - Epoch  69, Step:   233200, Batch Loss:     1.862870, Tokens per Sec:     2106, Lr: 0.000049
2021-11-23 15:39:45,692 - INFO - joeynmt.training - Epoch  69, Step:   233300, Batch Loss:     1.750209, Tokens per Sec:     2192, Lr: 0.000049
2021-11-23 15:40:00,836 - INFO - joeynmt.training - Epoch  69, Step:   233400, Batch Loss:     1.651537, Tokens per Sec:     2121, Lr: 0.000049
2021-11-23 15:40:15,943 - INFO - joeynmt.training - Epoch  69, Step:   233500, Batch Loss:     1.551868, Tokens per Sec:     2099, Lr: 0.000049
2021-11-23 15:40:31,157 - INFO - joeynmt.training - Epoch  69, Step:   233600, Batch Loss:     1.631870, Tokens per Sec:     2124, Lr: 0.000049
2021-11-23 15:40:46,265 - INFO - joeynmt.training - Epoch  69, Step:   233700, Batch Loss:     1.483902, Tokens per Sec:     2165, Lr: 0.000049
2021-11-23 15:41:01,221 - INFO - joeynmt.training - Epoch  69, Step:   233800, Batch Loss:     1.737542, Tokens per Sec:     2099, Lr: 0.000049
2021-11-23 15:41:06,752 - INFO - joeynmt.training - Epoch  69: total training loss 5964.99
2021-11-23 15:41:06,753 - INFO - joeynmt.training - EPOCH 70
2021-11-23 15:41:15,573 - INFO - joeynmt.training - Epoch  70, Step:   233900, Batch Loss:     1.820508, Tokens per Sec:     2174, Lr: 0.000049
2021-11-23 15:41:30,310 - INFO - joeynmt.training - Epoch  70, Step:   234000, Batch Loss:     1.984043, Tokens per Sec:     2017, Lr: 0.000049
2021-11-23 15:43:02,109 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:43:02,109 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:43:02,109 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:43:02,122 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-11-23 15:43:03,047 - INFO - joeynmt.helpers - delete models/baseline_multilingual/233000.ckpt
2021-11-23 15:43:03,062 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/233000.ckpt
2021-11-23 15:43:03,070 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/233000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_multilingual/233000.ckpt')
2021-11-23 15:43:03,148 - INFO - joeynmt.training - Example #0
2021-11-23 15:43:03,148 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:43:03,149 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:43:03,149 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁Jud', 'as', ',', '▁and', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁sc', 'atter', 'ed', '▁him', '.']
2021-11-23 15:43:03,149 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:43:03,149 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:43:03,149 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:43:03,149 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁Jud as , ▁and ▁you ▁were ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁other ▁follow ers , ▁and ▁all ▁his ▁follow ers ▁sc atter ed ▁him .
2021-11-23 15:43:03,150 - INFO - joeynmt.training - Example #1
2021-11-23 15:43:03,150 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:43:03,150 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:43:03,150 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:43:03,150 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:43:03,150 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:43:03,150 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:43:03,151 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:43:03,151 - INFO - joeynmt.training - Example #2
2021-11-23 15:43:03,151 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:43:03,151 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:43:03,151 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁work', '▁with', '▁each', '▁other', ',', '▁and', '▁work', '▁with', '▁one', '▁another', '.']
2021-11-23 15:43:03,151 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:43:03,151 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:43:03,152 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:43:03,152 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁work ▁with ▁each ▁other , ▁and ▁work ▁with ▁one ▁another .
2021-11-23 15:43:03,152 - INFO - joeynmt.training - Example #3
2021-11-23 15:43:03,152 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:43:03,152 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:43:03,152 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:43:03,152 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:43:03,153 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:43:03,153 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:43:03,153 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:43:03,153 - INFO - joeynmt.training - Example #6
2021-11-23 15:43:03,153 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:43:03,153 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:43:03,154 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:43:03,154 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:43:03,154 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:43:03,154 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:43:03,154 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:43:03,154 - INFO - joeynmt.training - Validation result (greedy) at epoch  70, step   234000: bleu:  16.29, loss: 71041.7812, ppl:   8.1472, duration: 92.8437s
2021-11-23 15:43:17,291 - INFO - joeynmt.training - Epoch  70, Step:   234100, Batch Loss:     1.682910, Tokens per Sec:     2227, Lr: 0.000049
2021-11-23 15:43:31,530 - INFO - joeynmt.training - Epoch  70, Step:   234200, Batch Loss:     1.910647, Tokens per Sec:     2099, Lr: 0.000049
2021-11-23 15:43:46,246 - INFO - joeynmt.training - Epoch  70, Step:   234300, Batch Loss:     1.656099, Tokens per Sec:     2119, Lr: 0.000049
2021-11-23 15:44:01,350 - INFO - joeynmt.training - Epoch  70, Step:   234400, Batch Loss:     1.817571, Tokens per Sec:     2085, Lr: 0.000049
2021-11-23 15:44:15,664 - INFO - joeynmt.training - Epoch  70, Step:   234500, Batch Loss:     1.540995, Tokens per Sec:     2221, Lr: 0.000049
2021-11-23 15:44:30,628 - INFO - joeynmt.training - Epoch  70, Step:   234600, Batch Loss:     1.753317, Tokens per Sec:     2120, Lr: 0.000049
2021-11-23 15:44:45,280 - INFO - joeynmt.training - Epoch  70, Step:   234700, Batch Loss:     1.650006, Tokens per Sec:     2140, Lr: 0.000049
2021-11-23 15:45:00,334 - INFO - joeynmt.training - Epoch  70, Step:   234800, Batch Loss:     1.857990, Tokens per Sec:     2135, Lr: 0.000049
2021-11-23 15:45:15,382 - INFO - joeynmt.training - Epoch  70, Step:   234900, Batch Loss:     1.687132, Tokens per Sec:     2071, Lr: 0.000049
2021-11-23 15:45:30,389 - INFO - joeynmt.training - Epoch  70, Step:   235000, Batch Loss:     1.791884, Tokens per Sec:     2104, Lr: 0.000049
2021-11-23 15:47:10,116 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:47:10,116 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:47:10,116 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:47:10,138 - INFO - joeynmt.training - Example #0
2021-11-23 15:47:10,138 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:47:10,138 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:47:10,138 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'A', 's', '▁you', '▁arri', 'ved', '▁in', '▁the', '▁time', '▁of', '▁Jud', 'as', '▁and', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁your', '▁follow', 'ers', '▁are', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 15:47:10,138 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:47:10,138 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:47:10,138 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:47:10,138 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" A s ▁you ▁arri ved ▁in ▁the ▁time ▁of ▁Jud as ▁and ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁your ▁follow ers ▁are ▁all ▁his ▁follow ers .
2021-11-23 15:47:10,138 - INFO - joeynmt.training - Example #1
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:47:10,139 - INFO - joeynmt.training - Example #2
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 15:47:10,139 - INFO - joeynmt.training - Example #3
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'rit', 'ar']
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:47:10,139 - INFO - joeynmt.training - 	Hypothesis: ▁D es c rit ar
2021-11-23 15:47:10,139 - INFO - joeynmt.training - Example #6
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:47:10,139 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:47:10,140 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:47:10,140 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:47:10,140 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:47:10,140 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:47:10,140 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:47:10,140 - INFO - joeynmt.training - Validation result (greedy) at epoch  70, step   235000: bleu:  16.15, loss: 71012.5000, ppl:   8.1401, duration: 99.7502s
2021-11-23 15:47:24,631 - INFO - joeynmt.training - Epoch  70, Step:   235100, Batch Loss:     1.507707, Tokens per Sec:     2192, Lr: 0.000049
2021-11-23 15:47:38,769 - INFO - joeynmt.training - Epoch  70, Step:   235200, Batch Loss:     1.704385, Tokens per Sec:     2249, Lr: 0.000049
2021-11-23 15:47:54,085 - INFO - joeynmt.training - Epoch  70, Step:   235300, Batch Loss:     1.735591, Tokens per Sec:     2075, Lr: 0.000049
2021-11-23 15:48:08,719 - INFO - joeynmt.training - Epoch  70, Step:   235400, Batch Loss:     1.597671, Tokens per Sec:     2133, Lr: 0.000049
2021-11-23 15:48:23,591 - INFO - joeynmt.training - Epoch  70, Step:   235500, Batch Loss:     1.975538, Tokens per Sec:     2093, Lr: 0.000049
2021-11-23 15:48:38,259 - INFO - joeynmt.training - Epoch  70, Step:   235600, Batch Loss:     1.826709, Tokens per Sec:     2163, Lr: 0.000049
2021-11-23 15:48:53,060 - INFO - joeynmt.training - Epoch  70, Step:   235700, Batch Loss:     1.525485, Tokens per Sec:     2095, Lr: 0.000049
2021-11-23 15:49:07,827 - INFO - joeynmt.training - Epoch  70, Step:   235800, Batch Loss:     1.955727, Tokens per Sec:     2020, Lr: 0.000049
2021-11-23 15:49:23,256 - INFO - joeynmt.training - Epoch  70, Step:   235900, Batch Loss:     1.830630, Tokens per Sec:     2082, Lr: 0.000049
2021-11-23 15:49:37,783 - INFO - joeynmt.training - Epoch  70, Step:   236000, Batch Loss:     1.675451, Tokens per Sec:     2116, Lr: 0.000049
2021-11-23 15:51:27,452 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:51:27,453 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:51:27,453 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:51:27,471 - INFO - joeynmt.training - Example #0
2021-11-23 15:51:27,471 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:51:27,472 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:51:27,472 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'L', 'et', '▁you', '▁have', '▁been', '▁count', 'ed', '▁by', '▁the', '▁time', '▁of', '▁Jud', 'e', 'a', '▁and', '▁count', 'ed', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', '▁and', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" L et ▁you ▁have ▁been ▁count ed ▁by ▁the ▁time ▁of ▁Jud e a ▁and ▁count ed ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁other ▁follow ers ▁and ▁all ▁his ▁follow ers .
2021-11-23 15:51:27,472 - INFO - joeynmt.training - Example #1
2021-11-23 15:51:27,472 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:51:27,472 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:51:27,472 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:51:27,472 - INFO - joeynmt.training - Example #2
2021-11-23 15:51:27,472 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:51:27,472 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:51:27,472 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:51:27,472 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 15:51:27,472 - INFO - joeynmt.training - Example #3
2021-11-23 15:51:27,473 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:51:27,473 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:51:27,473 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:51:27,473 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:51:27,473 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:51:27,473 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:51:27,473 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:51:27,473 - INFO - joeynmt.training - Example #6
2021-11-23 15:51:27,473 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:51:27,473 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:51:27,473 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:51:27,473 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:51:27,473 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:51:27,473 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:51:27,473 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:51:27,473 - INFO - joeynmt.training - Validation result (greedy) at epoch  70, step   236000: bleu:  16.13, loss: 70845.8906, ppl:   8.1002, duration: 109.6896s
2021-11-23 15:51:42,275 - INFO - joeynmt.training - Epoch  70, Step:   236100, Batch Loss:     1.967792, Tokens per Sec:     2156, Lr: 0.000049
2021-11-23 15:51:57,689 - INFO - joeynmt.training - Epoch  70, Step:   236200, Batch Loss:     1.566262, Tokens per Sec:     2044, Lr: 0.000049
2021-11-23 15:52:12,773 - INFO - joeynmt.training - Epoch  70, Step:   236300, Batch Loss:     1.601211, Tokens per Sec:     2088, Lr: 0.000049
2021-11-23 15:52:27,525 - INFO - joeynmt.training - Epoch  70, Step:   236400, Batch Loss:     1.862637, Tokens per Sec:     2121, Lr: 0.000049
2021-11-23 15:52:42,860 - INFO - joeynmt.training - Epoch  70, Step:   236500, Batch Loss:     1.749540, Tokens per Sec:     2043, Lr: 0.000049
2021-11-23 15:52:57,981 - INFO - joeynmt.training - Epoch  70, Step:   236600, Batch Loss:     1.701603, Tokens per Sec:     2156, Lr: 0.000049
2021-11-23 15:53:14,403 - INFO - joeynmt.training - Epoch  70, Step:   236700, Batch Loss:     2.478257, Tokens per Sec:     1945, Lr: 0.000049
2021-11-23 15:53:28,739 - INFO - joeynmt.training - Epoch  70, Step:   236800, Batch Loss:     1.776102, Tokens per Sec:     2207, Lr: 0.000049
2021-11-23 15:53:44,001 - INFO - joeynmt.training - Epoch  70, Step:   236900, Batch Loss:     1.853161, Tokens per Sec:     2076, Lr: 0.000049
2021-11-23 15:53:58,897 - INFO - joeynmt.training - Epoch  70, Step:   237000, Batch Loss:     1.879008, Tokens per Sec:     2093, Lr: 0.000049
2021-11-23 15:55:34,569 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:55:34,570 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:55:34,570 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:55:34,589 - INFO - joeynmt.training - Example #0
2021-11-23 15:55:34,589 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:55:34,589 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:55:34,589 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁count', 'ed', '▁by', '▁Jud', 'as', '▁from', '▁Gal', 'ile', 'e', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', ',', '▁but', '▁some', '▁of', '▁the', '▁other', '▁follow', 'ers', '▁and', '▁all', '▁his', '▁follow', 'ers', '.']
2021-11-23 15:55:34,589 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:55:34,589 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:55:34,589 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁count ed ▁by ▁Jud as ▁from ▁Gal ile e . ▁You ▁follow ed ▁the ▁people , ▁but ▁some ▁of ▁the ▁other ▁follow ers ▁and ▁all ▁his ▁follow ers .
2021-11-23 15:55:34,590 - INFO - joeynmt.training - Example #1
2021-11-23 15:55:34,590 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:55:34,590 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:55:34,590 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'el']
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri el
2021-11-23 15:55:34,590 - INFO - joeynmt.training - Example #2
2021-11-23 15:55:34,590 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:55:34,590 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:55:34,590 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 15:55:34,590 - INFO - joeynmt.training - Example #3
2021-11-23 15:55:34,590 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:55:34,590 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:55:34,590 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:55:34,590 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:55:34,591 - INFO - joeynmt.training - Example #6
2021-11-23 15:55:34,591 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:55:34,591 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:55:34,591 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:55:34,591 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:55:34,591 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:55:34,591 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:55:34,591 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:55:34,591 - INFO - joeynmt.training - Validation result (greedy) at epoch  70, step   237000: bleu:  16.04, loss: 70899.2891, ppl:   8.1130, duration: 95.6933s
2021-11-23 15:55:50,466 - INFO - joeynmt.training - Epoch  70, Step:   237100, Batch Loss:     1.743470, Tokens per Sec:     1987, Lr: 0.000049
2021-11-23 15:56:05,541 - INFO - joeynmt.training - Epoch  70, Step:   237200, Batch Loss:     2.084410, Tokens per Sec:     2115, Lr: 0.000049
2021-11-23 15:56:09,796 - INFO - joeynmt.training - Epoch  70: total training loss 5950.02
2021-11-23 15:56:09,797 - INFO - joeynmt.training - EPOCH 71
2021-11-23 15:56:20,240 - INFO - joeynmt.training - Epoch  71, Step:   237300, Batch Loss:     1.612139, Tokens per Sec:     2035, Lr: 0.000049
2021-11-23 15:56:34,925 - INFO - joeynmt.training - Epoch  71, Step:   237400, Batch Loss:     1.834455, Tokens per Sec:     2122, Lr: 0.000049
2021-11-23 15:56:49,903 - INFO - joeynmt.training - Epoch  71, Step:   237500, Batch Loss:     1.693546, Tokens per Sec:     2098, Lr: 0.000049
2021-11-23 15:57:04,119 - INFO - joeynmt.training - Epoch  71, Step:   237600, Batch Loss:     1.877635, Tokens per Sec:     2128, Lr: 0.000049
2021-11-23 15:57:18,745 - INFO - joeynmt.training - Epoch  71, Step:   237700, Batch Loss:     1.601617, Tokens per Sec:     2068, Lr: 0.000049
2021-11-23 15:57:33,726 - INFO - joeynmt.training - Epoch  71, Step:   237800, Batch Loss:     1.866236, Tokens per Sec:     2134, Lr: 0.000049
2021-11-23 15:57:48,260 - INFO - joeynmt.training - Epoch  71, Step:   237900, Batch Loss:     1.699222, Tokens per Sec:     2137, Lr: 0.000049
2021-11-23 15:58:02,563 - INFO - joeynmt.training - Epoch  71, Step:   238000, Batch Loss:     1.743128, Tokens per Sec:     2232, Lr: 0.000049
2021-11-23 15:59:42,237 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-11-23 15:59:42,237 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-11-23 15:59:42,237 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-11-23 15:59:42,256 - INFO - joeynmt.training - Example #0
2021-11-23 15:59:42,257 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'S1a520', 'P', 'S38800', 'M', 'S15a56', 'S15a41', 'S2b700', 'S37c06', 'S36d01', 'S30d00', 'M', 'S10040', 'P', 'S38700', 'M', 'S37806', 'S10050', 'S20356', 'S36d01', 'M', 'S15a37', 'S1ce51', 'S26a07', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S11520', 'S10120', 'S1f720', 'S20320', 'S36d01', 'M', 'S10018', 'S26505', 'S10641', 'M', 'S1f000', 'S1f720', 'S1dc20', 'S19220', 'S14a20', 'S1dc20', 'S14a20', 'P', 'S38800', 'M', 'S10041', 'S30d00', 'S36d01', 'M', 'S15a31', 'S10018', 'S26503', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S26521', 'S1f548', 'S1f540', 'M', 'S10041', 'P', 'S38700', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S36d01', 'M', 'S2ea3e', 'S10000', 'M', 'S15a18', 'S10051', 'S26601', 'M', 'S10058', 'S26526', 'S10050', 'S20500', 'S20500', 'P', 'S38900', 'M', 'S15a37', 'S15a01', 'S2e900', 'S36d01', 'M', 'S15a20', 'S26501', 'M', 'S26521', 'S23b0a', 'S1f548', 'S15a40', 'S15a48', 'S23b1a', 'S1f540', 'M', 'S14c57', 'S14c5f', 'S26511', 'S26507', 'S22527', 'S20314', 'S22521', 'S2031c', 'P', 'S38800']
2021-11-23 15:59:42,257 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S11e', 'S1a5', 'P', 'S388', 'M', 'S15a', 'S15a', 'S2b7', 'S37c', 'S36d', 'S30d', 'M', 'S100', 'P', 'S387', 'M', 'S378', 'S100', 'S203', 'S36d', 'M', 'S15a', 'S1ce', 'S26a', 'P', 'S387', 'M', 'S192', 'S2a2', 'S115', 'S101', 'S1f7', 'S203', 'S36d', 'M', 'S100', 'S265', 'S106', 'M', 'S1f0', 'S1f7', 'S1dc', 'S192', 'S14a', 'S1dc', 'S14a', 'P', 'S388', 'M', 'S100', 'S30d', 'S36d', 'M', 'S15a', 'S100', 'S265', 'M', 'S2e7', 'S142', 'S2e7', 'S142', 'M', 'S265', 'S1f5', 'S1f5', 'M', 'S100', 'P', 'S387', 'M', 'S100', 'S100', 'S22a', 'S22a', 'S36d', 'M', 'S2ea', 'S100', 'M', 'S15a', 'S100', 'S266', 'M', 'S100', 'S265', 'S100', 'S205', 'S205', 'P', 'S389', 'M', 'S15a', 'S15a', 'S2e9', 'S36d', 'M', 'S15a', 'S265', 'M', 'S265', 'S23b', 'S1f5', 'S15a', 'S15a', 'S23b', 'S1f5', 'M', 'S14c', 'S14c', 'S265', 'S265', 'S225', 'S203', 'S225', 'S203', 'P', 'S388']
2021-11-23 15:59:42,257 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁3', '7.', '▁"', 'W', 'hen', '▁you', '▁have', '▁been', '▁count', 'ed', ',', '▁you', '▁were', '▁count', 'ed', '▁from', '▁Jud', 'e', 'a', '.', '▁You', '▁follow', 'ed', '▁the', '▁people', '▁of', '▁Gal', 'ile', 'e', ',', '▁but', '▁some', '▁of', '▁the', '▁people', '▁follow', 'ed', '▁him', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁sc', 'atter', 'ed', '▁him', '.']
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S11e S1a5 P S388 M S15a S15a S2b7 S37c S36d S30d M S100 P S387 M S378 S100 S203 S36d M S15a S1ce S26a P S387 M S192 S2a2 S115 S101 S1f7 S203 S36d M S100 S265 S106 M S1f0 S1f7 S1dc S192 S14a S1dc S14a P S388 M S100 S30d S36d M S15a S100 S265 M S2e7 S142 S2e7 S142 M S265 S1f5 S1f5 M S100 P S387 M S100 S100 S22a S22a S36d M S2ea S100 M S15a S100 S266 M S100 S265 S100 S205 S205 P S389 M S15a S15a S2e9 S36d M S15a S265 M S265 S23b S1f5 S15a S15a S23b S1f5 M S14c S14c S265 S265 S225 S203 S225 S203 P S388
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁sc atter ed .
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁3 7. ▁" W hen ▁you ▁have ▁been ▁count ed , ▁you ▁were ▁count ed ▁from ▁Jud e a . ▁You ▁follow ed ▁the ▁people ▁of ▁Gal ile e , ▁but ▁some ▁of ▁the ▁people ▁follow ed ▁him , ▁and ▁all ▁his ▁follow ers ▁sc atter ed ▁him .
2021-11-23 15:59:42,257 - INFO - joeynmt.training - Example #1
2021-11-23 15:59:42,257 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S34700', 'S21100', 'S1f410']
2021-11-23 15:59:42,257 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S347', 'S211', 'S1f4']
2021-11-23 15:59:42,257 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁G', 'ab', 'ri', 'ela']
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S34700 S21100 S1f410
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S347 S211 S1f4
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Reference:  ▁L á p is
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Hypothesis: ▁G ab ri ela
2021-11-23 15:59:42,257 - INFO - joeynmt.training - Example #2
2021-11-23 15:59:42,257 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a07', 'S1f010', 'S26507', 'M', 'S10e00', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20302', 'S2030a', 'S20340', 'S20348', 'S30e00', 'S30124', 'M', 'S20500', 'S10013', 'M', 'S30124', 'S10010', 'S26500', 'M', 'S22f10', 'S20500', 'S15a0a', 'S22f00', 'S15a02', 'S20500', 'P', 'S38900', 'M', 'S17911', 'S17919', 'S2c300', 'S2c311', 'S30a00', 'P', 'S38700', 'M', 'S15a06', 'S15a41', 'S23d04', 'M', 'S2ff00', 'S10050', 'S10058', 'S10011', 'S22a04', 'M', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'R', 'S3770b', 'S20305', 'S20500', 'S20303', 'S20500', 'S37713', 'S30e00', 'S30124', 'R', 'S1f522', 'S2ea46', 'S2ea02', 'S1f50a', 'P', 'S38700', 'M', 'S20356', 'S20350', 'S37706', 'S22f04', 'S30e00', 'S30124', 'M', 'S1f740', 'S1f748', 'S26a20', 'M', 'S1814b', 'S20500', 'S20500', 'S18143', 'R', 'S10000', 'S26500', 'R', 'S10011', 'S2ff00', 'P', 'S38700', 'M', 'S10000', 'S26500', 'M', 'S15a18', 'S15a18', 'S10e22', 'S10e02', 'P', 'S38800']
2021-11-23 15:59:42,257 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<sent>', 'M', 'S15a', 'S1f0', 'S265', 'M', 'S10e', 'P', 'S388', 'M', 'S1dc', 'S100', 'S205', 'S205', 'S30a', 'M', 'S203', 'S203', 'S203', 'S203', 'S30e', 'S301', 'M', 'S205', 'S100', 'M', 'S301', 'S100', 'S265', 'M', 'S22f', 'S205', 'S15a', 'S22f', 'S15a', 'S205', 'P', 'S389', 'M', 'S179', 'S179', 'S2c3', 'S2c3', 'S30a', 'P', 'S387', 'M', 'S15a', 'S15a', 'S23d', 'M', 'S2ff', 'S100', 'S100', 'S100', 'S22a', 'M', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'R', 'S377', 'S203', 'S205', 'S203', 'S205', 'S377', 'S30e', 'S301', 'R', 'S1f5', 'S2ea', 'S2ea', 'S1f5', 'P', 'S387', 'M', 'S203', 'S203', 'S377', 'S22f', 'S30e', 'S301', 'M', 'S1f7', 'S1f7', 'S26a', 'M', 'S181', 'S205', 'S205', 'S181', 'R', 'S100', 'S265', 'R', 'S100', 'S2ff', 'P', 'S387', 'M', 'S100', 'S265', 'M', 'S15a', 'S15a', 'S10e', 'S10e', 'P', 'S388']
2021-11-23 15:59:42,257 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁very', '▁joy', '▁by', '▁each', '▁other', ',', '▁and', '▁love', '▁each', '▁other', '▁with', '▁one', '▁another', ',', '▁one', '▁another', '▁means', '.']
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Source:     <2en> <4us> <sent> M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <sent> M S15a S1f0 S265 M S10e P S388 M S1dc S100 S205 S205 S30a M S203 S203 S203 S203 S30e S301 M S205 S100 M S301 S100 S265 M S22f S205 S15a S22f S15a S205 P S389 M S179 S179 S2c3 S2c3 S30a P S387 M S15a S15a S23d M S2ff S100 S100 S100 S22a M S1f5 S2ea S2ea S1f5 P S387 R S377 S203 S205 S203 S205 S377 S30e S301 R S1f5 S2ea S2ea S1f5 P S387 M S203 S203 S377 S22f S30e S301 M S1f7 S1f7 S26a M S181 S205 S205 S181 R S100 S265 R S100 S2ff P S387 M S100 S265 M S15a S15a S10e S10e P S388
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Reference:  ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁hap p y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo v ing ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁p ur p ose .
2021-11-23 15:59:42,257 - INFO - joeynmt.training - 	Hypothesis: ▁Verse ▁2. ▁Then ▁make ▁me ▁very ▁joy ▁by ▁each ▁other , ▁and ▁love ▁each ▁other ▁with ▁one ▁another , ▁one ▁another ▁means .
2021-11-23 15:59:42,258 - INFO - joeynmt.training - Example #3
2021-11-23 15:59:42,258 - DEBUG - joeynmt.training - 	Raw source:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e40', 'S11040', 'S26504', 'S2fb04']
2021-11-23 15:59:42,258 - DEBUG - joeynmt.training - 	Raw factor:     ['<2pt>', '<4br>', '<dict>', 'M', 'S10e', 'S110', 'S265', 'S2fb']
2021-11-23 15:59:42,258 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁D', 'es', 'c', 'or', 'ar']
2021-11-23 15:59:42,258 - INFO - joeynmt.training - 	Source:     <2pt> <4br> <dict> M S10e40 S11040 S26504 S2fb04
2021-11-23 15:59:42,258 - INFO - joeynmt.training - 	Factor:     <2pt> <4br> <dict> M S10e S110 S265 S2fb
2021-11-23 15:59:42,258 - INFO - joeynmt.training - 	Reference:  ▁expl or ar
2021-11-23 15:59:42,258 - INFO - joeynmt.training - 	Hypothesis: ▁D es c or ar
2021-11-23 15:59:42,258 - INFO - joeynmt.training - Example #6
2021-11-23 15:59:42,258 - DEBUG - joeynmt.training - 	Raw source:     ['<2en>', '<4us>', '<dict>', 'M', 'S20340', 'S21800']
2021-11-23 15:59:42,258 - DEBUG - joeynmt.training - 	Raw factor:     ['<2en>', '<4us>', '<dict>', 'M', 'S203', 'S218']
2021-11-23 15:59:42,258 - DEBUG - joeynmt.training - 	Raw hypothesis: ['▁h', 'u', 'h']
2021-11-23 15:59:42,258 - INFO - joeynmt.training - 	Source:     <2en> <4us> <dict> M S20340 S21800
2021-11-23 15:59:42,258 - INFO - joeynmt.training - 	Factor:     <2en> <4us> <dict> M S203 S218
2021-11-23 15:59:42,258 - INFO - joeynmt.training - 	Reference:  ▁m il k
2021-11-23 15:59:42,258 - INFO - joeynmt.training - 	Hypothesis: ▁h u h
2021-11-23 15:59:42,258 - INFO - joeynmt.training - Validation result (greedy) at epoch  71, step   238000: bleu:  16.18, loss: 70987.5391, ppl:   8.1341, duration: 99.6953s
2021-11-23 15:59:56,247 - INFO - joeynmt.training - Epoch  71, Step:   238100, Batch Loss:     1.750553, Tokens per Sec:     2141, Lr: 0.000049
2021-11-23 16:00:11,478 - INFO - joeynmt.training - Epoch  71, Step:   238200, Batch Loss:     1.866518, Tokens per Sec:     2122, Lr: 0.000049
2021-11-23 16:00:25,710 - INFO - joeynmt.training - Epoch  71, Step:   238300, Batch Loss:     1.734125, Tokens per Sec:     2178, Lr: 0.000049
2021-11-23 16:00:40,585 - INFO - joeynmt.training - Epoch  71, Step:   238400, Batch Loss:     1.625530, Tokens per Sec:     2122, Lr: 0.000049
2021-11-23 16:00:55,073 - INFO - joeynmt.training - Epoch  71, Step:   238500, Batch Loss:     1.908404, Tokens per Sec:     2210, Lr: 0.000049
2021-11-23 16:01:09,920 - INFO - joeynmt.training - Epoch  71, Step:   238600, Batch Loss:     1.706990, Tokens per Sec:     2134, Lr: 0.000049
2021-11-23 16:01:25,065 - INFO - joeynmt.training - Epoch  71, Step:   238700, Batch Loss:     1.624828, Tokens per Sec:     2160, Lr: 0.000049
2021-11-23 16:01:39,681 - INFO - joeynmt.training - Epoch  71, Step:   238800, Batch Loss:     1.725259, Tokens per Sec:     2183, Lr: 0.000049
2021-11-23 16:01:55,165 - INFO - joeynmt.training - Epoch  71, Step:   238900, Batch Loss:     1.901497, Tokens per Sec:     1975, Lr: 0.000049
2021-11-23 16:02:10,297 - INFO - joeynmt.training - Epoch  71, Step:   239000, Batch Loss:     1.513651, Tokens per Sec:     2020, Lr: 0.000049
