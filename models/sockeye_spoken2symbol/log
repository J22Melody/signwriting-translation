[2021-12-16:14:30:13:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.5, commit 64c3b09b3402fffb63799e9ad33c81c6b97d8629, path /opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-16:14:30:13:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-16:14:30:13:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0 (/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-16:14:30:13:INFO:sockeye.utils:log_basic_info] Command: /opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/train.py --prepared-data data_sockeye -vs data_reverse/dev.spm.spoken -vt data_reverse/dev.symbol --output models/sockeye_spoken2symbol --max-num-checkpoint-not-improved 7
[2021-12-16:14:30:13:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(allow_missing_params=False, amp=False, apex_amp=False, batch_sentences_multiple_of=8, batch_size=4096, batch_type='word', bucket_scaling=False, bucket_width=8, cache_last_best_params=0, cache_metric='perplexity', cache_strategy='best', checkpoint_improvement_threshold=0.0, checkpoint_interval=4000, config=None, decode_and_evaluate=500, decode_and_evaluate_device_id=None, decoder='transformer', device_id=0, device_ids=[-1], disable_device_locking=False, dist=False, dry_run=False, dtype='float32', embed_dropout=(0.0, 0.0), encoder='transformer', env=None, fixed_param_names=[], fixed_param_strategy=None, gradient_clipping_threshold=1.0, gradient_clipping_type='none', horovod=False, ignore_extra_params=False, initial_learning_rate=0.0002, keep_initializations=False, keep_last_params=-1, kvstore='device', label_smoothing=0.1, label_smoothing_impl='mxnet', learning_rate_reduce_factor=0.9, learning_rate_reduce_num_not_improved=8, learning_rate_scheduler_type='plateau-reduce', learning_rate_t_scale=1.0, learning_rate_warmup=0, length_task=None, length_task_layers=1, length_task_weight=1.0, lhuc=None, lock_dir='/tmp', loglevel='INFO', loglevel_secondary_workers='INFO', loss='cross-entropy-without-softmax-output', max_checkpoints=None, max_num_checkpoint_not_improved=7, max_num_epochs=None, max_samples=None, max_seconds=None, max_seq_len=(95, 95), max_updates=None, min_num_epochs=None, min_samples=None, min_updates=None, momentum=0.0, no_bucketing=False, no_hybridization=False, no_logfile=False, num_embed=(None, None), num_layers=(6, 6), num_words=(0, 0), optimized_metric='perplexity', optimizer='adam', optimizer_betas=(0.9, 0.999), optimizer_eps=1e-08, optimizer_params=None, output='models/sockeye_spoken2symbol', overwrite_output=False, pad_vocab_to_multiple_of=8, params=None, prepared_data='data_sockeye', quiet=False, quiet_secondary_workers=False, seed=1, shared_vocab=False, source=None, source_factor_vocabs=[], source_factors=[], source_factors_combine=[], source_factors_num_embed=[], source_factors_share_embedding=[], source_factors_use_source_vocab=[], source_vocab=None, stop_training_on_decoder_failure=False, target=None, target_factor_vocabs=[], target_factors=[], target_factors_combine=[], target_factors_num_embed=[], target_factors_share_embedding=[], target_factors_use_target_vocab=[], target_factors_weight=[1.0], target_vocab=None, transformer_activation_type=('relu', 'relu'), transformer_attention_heads=(8, 8), transformer_dropout_act=(0.1, 0.1), transformer_dropout_attention=(0.1, 0.1), transformer_dropout_prepost=(0.1, 0.1), transformer_feed_forward_num_hidden=(2048, 2048), transformer_feed_forward_use_glu=False, transformer_model_size=(512, 512), transformer_positional_embedding_type='fixed', transformer_postprocess=('dr', 'dr'), transformer_preprocess=('n', 'n'), update_interval=1, use_cpu=False, validation_source='data_reverse/dev.spm.spoken', validation_source_factors=[], validation_target='data_reverse/dev.symbol', validation_target_factors=[], weight_decay=0.0, weight_init='xavier', weight_init_scale=3.0, weight_init_xavier_factor_type='avg', weight_init_xavier_rand_type='uniform', weight_tying_type='src_trg_softmax', word_min_count=(1, 1))
[2021-12-16:14:30:13:INFO:__main__:train] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (96, 96)
[2021-12-16:14:30:13:ERROR:root:exception_hook] Uncaught exception
Traceback (most recent call last):
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/train.py", line 1153, in <module>
    main()
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/train.py", line 906, in main
    train(args)
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/train.py", line 981, in train
    context = utils.determine_context(device_ids=args.device_ids,
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/utils.py", line 385, in determine_context
    check_condition(num_gpus >= 1,
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/utils.py", line 153, in check_condition
    raise SockeyeError(error_message)
sockeye.utils.SockeyeError: No GPUs found, consider running on the CPU with --use-cpu 
[2021-12-16:14:30:28:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.5, commit 64c3b09b3402fffb63799e9ad33c81c6b97d8629, path /opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-16:14:30:28:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-16:14:30:28:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0 (/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-16:14:30:28:INFO:sockeye.utils:log_basic_info] Command: /opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/train.py --prepared-data data_sockeye -vs data_reverse/dev.spm.spoken -vt data_reverse/dev.symbol --output models/sockeye_spoken2symbol --max-num-checkpoint-not-improved 7 --use-cpu
[2021-12-16:14:30:28:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(allow_missing_params=False, amp=False, apex_amp=False, batch_sentences_multiple_of=8, batch_size=4096, batch_type='word', bucket_scaling=False, bucket_width=8, cache_last_best_params=0, cache_metric='perplexity', cache_strategy='best', checkpoint_improvement_threshold=0.0, checkpoint_interval=4000, config=None, decode_and_evaluate=500, decode_and_evaluate_device_id=None, decoder='transformer', device_id=0, device_ids=[-1], disable_device_locking=False, dist=False, dry_run=False, dtype='float32', embed_dropout=(0.0, 0.0), encoder='transformer', env=None, fixed_param_names=[], fixed_param_strategy=None, gradient_clipping_threshold=1.0, gradient_clipping_type='none', horovod=False, ignore_extra_params=False, initial_learning_rate=0.0002, keep_initializations=False, keep_last_params=-1, kvstore='device', label_smoothing=0.1, label_smoothing_impl='mxnet', learning_rate_reduce_factor=0.9, learning_rate_reduce_num_not_improved=8, learning_rate_scheduler_type='plateau-reduce', learning_rate_t_scale=1.0, learning_rate_warmup=0, length_task=None, length_task_layers=1, length_task_weight=1.0, lhuc=None, lock_dir='/tmp', loglevel='INFO', loglevel_secondary_workers='INFO', loss='cross-entropy-without-softmax-output', max_checkpoints=None, max_num_checkpoint_not_improved=7, max_num_epochs=None, max_samples=None, max_seconds=None, max_seq_len=(95, 95), max_updates=None, min_num_epochs=None, min_samples=None, min_updates=None, momentum=0.0, no_bucketing=False, no_hybridization=False, no_logfile=False, num_embed=(None, None), num_layers=(6, 6), num_words=(0, 0), optimized_metric='perplexity', optimizer='adam', optimizer_betas=(0.9, 0.999), optimizer_eps=1e-08, optimizer_params=None, output='models/sockeye_spoken2symbol', overwrite_output=False, pad_vocab_to_multiple_of=8, params=None, prepared_data='data_sockeye', quiet=False, quiet_secondary_workers=False, seed=1, shared_vocab=False, source=None, source_factor_vocabs=[], source_factors=[], source_factors_combine=[], source_factors_num_embed=[], source_factors_share_embedding=[], source_factors_use_source_vocab=[], source_vocab=None, stop_training_on_decoder_failure=False, target=None, target_factor_vocabs=[], target_factors=[], target_factors_combine=[], target_factors_num_embed=[], target_factors_share_embedding=[], target_factors_use_target_vocab=[], target_factors_weight=[1.0], target_vocab=None, transformer_activation_type=('relu', 'relu'), transformer_attention_heads=(8, 8), transformer_dropout_act=(0.1, 0.1), transformer_dropout_attention=(0.1, 0.1), transformer_dropout_prepost=(0.1, 0.1), transformer_feed_forward_num_hidden=(2048, 2048), transformer_feed_forward_use_glu=False, transformer_model_size=(512, 512), transformer_positional_embedding_type='fixed', transformer_postprocess=('dr', 'dr'), transformer_preprocess=('n', 'n'), update_interval=1, use_cpu=True, validation_source='data_reverse/dev.spm.spoken', validation_source_factors=[], validation_target='data_reverse/dev.symbol', validation_target_factors=[], weight_decay=0.0, weight_init='xavier', weight_init_scale=3.0, weight_init_xavier_factor_type='avg', weight_init_xavier_rand_type='uniform', weight_tying_type='src_trg_softmax', word_min_count=(1, 1))
[2021-12-16:14:30:28:INFO:__main__:train] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (96, 96)
[2021-12-16:14:30:28:INFO:__main__:train] Training Device(s): cpu(0)
[2021-12-16:14:30:28:INFO:sockeye.utils:seed_rngs] Random seed: 1
[2021-12-16:14:30:28:INFO:sockeye.utils:seed_rngs] PyTorch seed: 1
[2021-12-16:14:30:28:INFO:__main__:use_shared_vocab] A shared source/target vocabulary will be used as weight tying source/target weight tying is enabled
[2021-12-16:14:30:28:INFO:sockeye.data_io:get_prepared_data_iters] ===============================
[2021-12-16:14:30:28:INFO:sockeye.data_io:get_prepared_data_iters] Creating training data iterator
[2021-12-16:14:30:28:INFO:sockeye.data_io:get_prepared_data_iters] ===============================
[2021-12-16:14:30:28:ERROR:root:exception_hook] Uncaught exception
Traceback (most recent call last):
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/train.py", line 1153, in <module>
    main()
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/train.py", line 906, in main
    train(args)
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/train.py", line 994, in train
    train_iter, eval_iter, config_data, source_vocabs, target_vocabs = create_data_iters_and_vocabs(
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/train.py", line 303, in create_data_iters_and_vocabs
    train_iter, validation_iter, data_config, source_vocabs, target_vocabs = data_io.get_prepared_data_iters(
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/data_io.py", line 833, in get_prepared_data_iters
    check_condition(shared_vocab == data_info.shared_vocab, "Shared vocabulary settings need to match these "
  File "/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/utils.py", line 153, in check_condition
    raise SockeyeError(error_message)
sockeye.utils.SockeyeError: Shared vocabulary settings need to match these of the prepared data (e.g. for weight tying). Specify or omit --shared-vocab consistently when training and preparing the data.
