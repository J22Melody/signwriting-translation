[2021-12-16:22:57:25:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.4, commit 8e5033be2a2f09d935c682f33703eff34cf8b3f4, path /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-16:22:57:25:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-16:22:57:25:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0+cu102 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-16:22:57:25:INFO:sockeye.utils:log_basic_info] Command: /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/translate.py --models models/sockeye_spoken2symbol --input data_reverse/test.spm.spoken --output models/sockeye_spoken2symbol/test.hyps.symbol --max-input-length 99999 --beam-size 3 --device-id 0 --disable-device-locking --seed 42 --output-type translation_with_factors
[2021-12-16:22:57:25:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(avoid_list=None, batch_size=1, beam_search_stop='all', beam_size=3, brevity_penalty_constant_length_ratio=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, bucket_width=10, checkpoints=None, chunk_size=None, config=None, device_id=0, device_ids=[-1], disable_device_locking=True, dtype=None, ensemble_mode='linear', env=None, greedy=False, input='data_reverse/test.spm.spoken', input_factors=None, json_input=False, length_penalty_alpha=1.0, length_penalty_beta=0.0, lock_dir='/tmp', loglevel='INFO', loglevel_secondary_workers='INFO', max_input_length=99999, max_output_length=None, max_output_length_num_stds=2, mc_dropout=False, models=['models/sockeye_spoken2symbol'], nbest_size=1, no_hybridization=False, no_logfile=False, output='models/sockeye_spoken2symbol/test.hyps.symbol', output_type='translation_with_factors', prevent_unk=False, quiet=False, quiet_secondary_workers=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=42, softmax_temperature=None, strip_unknown_words=False, use_cpu=False)
[2021-12-16:22:57:25:WARNING:sockeye.utils:expand_requested_device_ids] Sockeye currently does not respect CUDA_VISIBLE_DEVICE settings when locking GPU devices.
[2021-12-16:22:57:25:INFO:sockeye.utils:_expand_requested_device_ids] Attempting to acquire 1 GPUs of 1 GPUs.
[2021-12-16:22:57:25:INFO:__main__:run_translate] Translate Device: gpu(0)
[2021-12-16:22:57:25:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye_spoken2symbol'] ...
[2021-12-16:22:57:25:INFO:sockeye.vocab:vocab_from_json] Vocabulary (2000 words) loaded from "models/sockeye_spoken2symbol/vocab.src.0.json"
[2021-12-16:22:57:25:INFO:sockeye.vocab:vocab_from_json] Vocabulary (12224 words) loaded from "models/sockeye_spoken2symbol/vocab.trg.0.json"
[2021-12-16:22:57:25:INFO:sockeye.model:load_model] Model version: 3.0.4
[2021-12-16:22:57:25:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye_spoken2symbol/config"
[2021-12-16:22:57:25:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2021-12-16:22:57:25:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=111529, num_discarded=417, num_tokens_source=2075941, num_tokens_target=2225438, num_unks_source=0, num_unks_target=0, max_observed_len_source=185, max_observed_len_target=201, size_vocab_source=2000, size_vocab_target=12224, length_ratio_mean=0.7952563989633317, length_ratio_std=0.6990334237388166, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)], num_sents_per_bucket=[0, 81219, 14620, 1193, 457, 408, 628, 1030, 1224, 1199, 1150, 1259, 1170, 1106, 1014, 916, 731, 552, 498, 361, 263, 213, 145, 95, 68, 10], average_len_target_per_bucket=[None, 7.676615077752828, 10.917852257181917, 15.969823973176855, 30.378555798687103, 42.40196078431373, 51.130573248407686, 59.50485436893204, 67.60049019607851, 75.63886572143453, 84.04869565217392, 92.31691818903899, 100.22478632478625, 108.258589511754, 116.40631163708095, 124.24999999999997, 132.4924760601916, 140.4692028985508, 148.30120481927696, 155.7811634349031, 164.2927756653993, 172.24413145539899, 179.1999999999999, 187.85263157894744, 195.8088235294118, 201.0], length_ratio_stats_per_bucket=[(None, None), (0.5731306316243342, 0.20605685798846987), (0.6421342240936343, 0.39770008592915274), (0.859732548795569, 0.7448782250345781), (1.548934235200316, 0.8692084159265917), (1.8718311852655898, 0.8023738240479706), (1.7827641324506083, 0.7199393121842907), (1.8144343418607083, 0.6790160245445268), (1.849389302228943, 0.6483646482433103), (1.9460433022889274, 0.714701152942034), (2.082878803106982, 0.7668277390407361), (2.1917070789285207, 0.7718414511646764), (2.2440640194205312, 0.763463890478365), (2.29744984926137, 0.8628994817056892), (2.376561672214239, 0.9278811630432776), (2.4055202846639103, 1.0308439838665555), (2.47307220374083, 1.1927088662158885), (2.449640906406911, 0.9844225288697896), (2.506961480708306, 1.1401135689536712), (2.738755276705606, 1.6542230528380326), (2.633704509461338, 1.5948046208089743), (2.695802278434618, 1.3733845272690017), (3.283258200500435, 2.5112983223576277), (3.6306240624382267, 3.172481624967147), (3.417168104320764, 2.6170087795834664), (2.253037210632548, 0.5958326376020144)]), max_seq_len_source=201, max_seq_len_target=201, num_source_factors=1, num_target_factors=1), vocab_source_size=2000, vocab_target_size=12224, config_embed_source=EmbeddingConfig(vocab_size=2000, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_embed_target=EmbeddingConfig(vocab_size=12224, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='trg_softmax', lhuc=False, dtype='float32')
[2021-12-16:22:57:32:INFO:sockeye.model:load_model] Model dtype: float32
[2021-12-16:22:57:33:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye_spoken2symbol/params.best" to "gpu(0)"
[2021-12-16:22:57:33:INFO:sockeye.model:load_models] 1 model(s) loaded in 8.0282s
[2021-12-16:22:57:33:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=3 algorithm=BeamSearch, beam_search_stop=all max_input_length=200 nbest_size=1 ensemble_mode=None max_batch_size=1 avoiding=0 dtype=float32 softmax_temperature=None)
[2021-12-16:22:57:33:INFO:__main__:read_and_translate] Translating...
[2021-12-16:23:00:41:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.4, commit 8e5033be2a2f09d935c682f33703eff34cf8b3f4, path /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-16:23:00:41:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-16:23:00:41:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0+cu102 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-16:23:00:41:INFO:sockeye.utils:log_basic_info] Command: /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/translate.py --models models/sockeye_spoken2symbol --input data_reverse/test.spm.spoken --output models/sockeye_spoken2symbol/test.hyps.symbol --max-input-length 99999 --beam-size 3 --device-id 0 --disable-device-locking --seed 42
[2021-12-16:23:00:41:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(avoid_list=None, batch_size=1, beam_search_stop='all', beam_size=3, brevity_penalty_constant_length_ratio=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, bucket_width=10, checkpoints=None, chunk_size=None, config=None, device_id=0, device_ids=[-1], disable_device_locking=True, dtype=None, ensemble_mode='linear', env=None, greedy=False, input='data_reverse/test.spm.spoken', input_factors=None, json_input=False, length_penalty_alpha=1.0, length_penalty_beta=0.0, lock_dir='/tmp', loglevel='INFO', loglevel_secondary_workers='INFO', max_input_length=99999, max_output_length=None, max_output_length_num_stds=2, mc_dropout=False, models=['models/sockeye_spoken2symbol'], nbest_size=1, no_hybridization=False, no_logfile=False, output='models/sockeye_spoken2symbol/test.hyps.symbol', output_type='translation', prevent_unk=False, quiet=False, quiet_secondary_workers=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=42, softmax_temperature=None, strip_unknown_words=False, use_cpu=False)
[2021-12-16:23:00:41:WARNING:sockeye.utils:expand_requested_device_ids] Sockeye currently does not respect CUDA_VISIBLE_DEVICE settings when locking GPU devices.
[2021-12-16:23:00:41:INFO:sockeye.utils:_expand_requested_device_ids] Attempting to acquire 1 GPUs of 1 GPUs.
[2021-12-16:23:00:41:INFO:__main__:run_translate] Translate Device: gpu(0)
[2021-12-16:23:00:41:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye_spoken2symbol'] ...
[2021-12-16:23:00:41:INFO:sockeye.vocab:vocab_from_json] Vocabulary (2000 words) loaded from "models/sockeye_spoken2symbol/vocab.src.0.json"
[2021-12-16:23:00:41:INFO:sockeye.vocab:vocab_from_json] Vocabulary (12224 words) loaded from "models/sockeye_spoken2symbol/vocab.trg.0.json"
[2021-12-16:23:00:41:INFO:sockeye.model:load_model] Model version: 3.0.4
[2021-12-16:23:00:41:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye_spoken2symbol/config"
[2021-12-16:23:00:41:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2021-12-16:23:00:41:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=111529, num_discarded=417, num_tokens_source=2075941, num_tokens_target=2225438, num_unks_source=0, num_unks_target=0, max_observed_len_source=185, max_observed_len_target=201, size_vocab_source=2000, size_vocab_target=12224, length_ratio_mean=0.7952563989633317, length_ratio_std=0.6990334237388166, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)], num_sents_per_bucket=[0, 81219, 14620, 1193, 457, 408, 628, 1030, 1224, 1199, 1150, 1259, 1170, 1106, 1014, 916, 731, 552, 498, 361, 263, 213, 145, 95, 68, 10], average_len_target_per_bucket=[None, 7.676615077752828, 10.917852257181917, 15.969823973176855, 30.378555798687103, 42.40196078431373, 51.130573248407686, 59.50485436893204, 67.60049019607851, 75.63886572143453, 84.04869565217392, 92.31691818903899, 100.22478632478625, 108.258589511754, 116.40631163708095, 124.24999999999997, 132.4924760601916, 140.4692028985508, 148.30120481927696, 155.7811634349031, 164.2927756653993, 172.24413145539899, 179.1999999999999, 187.85263157894744, 195.8088235294118, 201.0], length_ratio_stats_per_bucket=[(None, None), (0.5731306316243342, 0.20605685798846987), (0.6421342240936343, 0.39770008592915274), (0.859732548795569, 0.7448782250345781), (1.548934235200316, 0.8692084159265917), (1.8718311852655898, 0.8023738240479706), (1.7827641324506083, 0.7199393121842907), (1.8144343418607083, 0.6790160245445268), (1.849389302228943, 0.6483646482433103), (1.9460433022889274, 0.714701152942034), (2.082878803106982, 0.7668277390407361), (2.1917070789285207, 0.7718414511646764), (2.2440640194205312, 0.763463890478365), (2.29744984926137, 0.8628994817056892), (2.376561672214239, 0.9278811630432776), (2.4055202846639103, 1.0308439838665555), (2.47307220374083, 1.1927088662158885), (2.449640906406911, 0.9844225288697896), (2.506961480708306, 1.1401135689536712), (2.738755276705606, 1.6542230528380326), (2.633704509461338, 1.5948046208089743), (2.695802278434618, 1.3733845272690017), (3.283258200500435, 2.5112983223576277), (3.6306240624382267, 3.172481624967147), (3.417168104320764, 2.6170087795834664), (2.253037210632548, 0.5958326376020144)]), max_seq_len_source=201, max_seq_len_target=201, num_source_factors=1, num_target_factors=1), vocab_source_size=2000, vocab_target_size=12224, config_embed_source=EmbeddingConfig(vocab_size=2000, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_embed_target=EmbeddingConfig(vocab_size=12224, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='trg_softmax', lhuc=False, dtype='float32')
[2021-12-16:23:00:45:INFO:sockeye.model:load_model] Model dtype: float32
[2021-12-16:23:00:46:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye_spoken2symbol/params.best" to "gpu(0)"
[2021-12-16:23:00:46:INFO:sockeye.model:load_models] 1 model(s) loaded in 4.6235s
[2021-12-16:23:00:46:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=3 algorithm=BeamSearch, beam_search_stop=all max_input_length=200 nbest_size=1 ensemble_mode=None max_batch_size=1 avoiding=0 dtype=float32 softmax_temperature=None)
[2021-12-16:23:00:46:INFO:__main__:read_and_translate] Translating...
[2021-12-16:23:04:03:INFO:__main__:read_and_translate] Processed 1143 lines. Total time: 196.6089, sec/sent: 0.1720, sent/sec: 5.8136
[2021-12-17:13:08:06:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.4, commit 8e5033be2a2f09d935c682f33703eff34cf8b3f4, path /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-17:13:08:06:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-17:13:08:06:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0+cu102 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-17:13:08:06:INFO:sockeye.utils:log_basic_info] Command: /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/translate.py --models models/sockeye_spoken2symbol --input data_reverse/test.spm.spoken --output models/sockeye_spoken2symbol/test.hyps.symbol --max-input-length 99999 --beam-size 3 --device-id 0 --disable-device-locking --seed 42
[2021-12-17:13:08:06:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(avoid_list=None, batch_size=1, beam_search_stop='all', beam_size=3, brevity_penalty_constant_length_ratio=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, bucket_width=10, checkpoints=None, chunk_size=None, config=None, device_id=0, device_ids=[-1], disable_device_locking=True, dtype=None, ensemble_mode='linear', env=None, greedy=False, input='data_reverse/test.spm.spoken', input_factors=None, json_input=False, length_penalty_alpha=1.0, length_penalty_beta=0.0, lock_dir='/tmp', loglevel='INFO', loglevel_secondary_workers='INFO', max_input_length=99999, max_output_length=None, max_output_length_num_stds=2, mc_dropout=False, models=['models/sockeye_spoken2symbol'], nbest_size=1, no_hybridization=False, no_logfile=False, output='models/sockeye_spoken2symbol/test.hyps.symbol', output_type='translation', prevent_unk=False, quiet=False, quiet_secondary_workers=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=42, softmax_temperature=None, strip_unknown_words=False, use_cpu=False)
[2021-12-17:13:08:06:WARNING:sockeye.utils:expand_requested_device_ids] Sockeye currently does not respect CUDA_VISIBLE_DEVICE settings when locking GPU devices.
[2021-12-17:13:08:06:INFO:sockeye.utils:_expand_requested_device_ids] Attempting to acquire 1 GPUs of 1 GPUs.
[2021-12-17:13:08:06:INFO:__main__:run_translate] Translate Device: gpu(0)
[2021-12-17:13:08:06:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye_spoken2symbol'] ...
[2021-12-17:13:08:06:INFO:sockeye.vocab:vocab_from_json] Vocabulary (2000 words) loaded from "models/sockeye_spoken2symbol/vocab.src.0.json"
[2021-12-17:13:08:06:INFO:sockeye.vocab:vocab_from_json] Vocabulary (12224 words) loaded from "models/sockeye_spoken2symbol/vocab.trg.0.json"
[2021-12-17:13:08:06:INFO:sockeye.model:load_model] Model version: 3.0.4
[2021-12-17:13:08:06:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye_spoken2symbol/config"
[2021-12-17:13:08:06:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2021-12-17:13:08:06:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=111529, num_discarded=417, num_tokens_source=2075941, num_tokens_target=2225438, num_unks_source=0, num_unks_target=0, max_observed_len_source=185, max_observed_len_target=201, size_vocab_source=2000, size_vocab_target=12224, length_ratio_mean=0.7952563989633317, length_ratio_std=0.6990334237388166, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)], num_sents_per_bucket=[0, 81219, 14620, 1193, 457, 408, 628, 1030, 1224, 1199, 1150, 1259, 1170, 1106, 1014, 916, 731, 552, 498, 361, 263, 213, 145, 95, 68, 10], average_len_target_per_bucket=[None, 7.676615077752828, 10.917852257181917, 15.969823973176855, 30.378555798687103, 42.40196078431373, 51.130573248407686, 59.50485436893204, 67.60049019607851, 75.63886572143453, 84.04869565217392, 92.31691818903899, 100.22478632478625, 108.258589511754, 116.40631163708095, 124.24999999999997, 132.4924760601916, 140.4692028985508, 148.30120481927696, 155.7811634349031, 164.2927756653993, 172.24413145539899, 179.1999999999999, 187.85263157894744, 195.8088235294118, 201.0], length_ratio_stats_per_bucket=[(None, None), (0.5731306316243342, 0.20605685798846987), (0.6421342240936343, 0.39770008592915274), (0.859732548795569, 0.7448782250345781), (1.548934235200316, 0.8692084159265917), (1.8718311852655898, 0.8023738240479706), (1.7827641324506083, 0.7199393121842907), (1.8144343418607083, 0.6790160245445268), (1.849389302228943, 0.6483646482433103), (1.9460433022889274, 0.714701152942034), (2.082878803106982, 0.7668277390407361), (2.1917070789285207, 0.7718414511646764), (2.2440640194205312, 0.763463890478365), (2.29744984926137, 0.8628994817056892), (2.376561672214239, 0.9278811630432776), (2.4055202846639103, 1.0308439838665555), (2.47307220374083, 1.1927088662158885), (2.449640906406911, 0.9844225288697896), (2.506961480708306, 1.1401135689536712), (2.738755276705606, 1.6542230528380326), (2.633704509461338, 1.5948046208089743), (2.695802278434618, 1.3733845272690017), (3.283258200500435, 2.5112983223576277), (3.6306240624382267, 3.172481624967147), (3.417168104320764, 2.6170087795834664), (2.253037210632548, 0.5958326376020144)]), max_seq_len_source=201, max_seq_len_target=201, num_source_factors=1, num_target_factors=1), vocab_source_size=2000, vocab_target_size=12224, config_embed_source=EmbeddingConfig(vocab_size=2000, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_embed_target=EmbeddingConfig(vocab_size=12224, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='trg_softmax', lhuc=False, dtype='float32')
[2021-12-17:13:08:10:INFO:sockeye.model:load_model] Model dtype: float32
[2021-12-17:13:08:11:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye_spoken2symbol/params.best" to "gpu(0)"
[2021-12-17:13:08:11:INFO:sockeye.model:load_models] 1 model(s) loaded in 4.4984s
[2021-12-17:13:08:11:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=3 algorithm=BeamSearch, beam_search_stop=all max_input_length=200 nbest_size=1 ensemble_mode=None max_batch_size=1 avoiding=0 dtype=float32 softmax_temperature=None)
[2021-12-17:13:08:11:INFO:__main__:read_and_translate] Translating...
[2021-12-17:13:11:13:INFO:__main__:read_and_translate] Processed 1143 lines. Total time: 182.0015, sec/sent: 0.1592, sent/sec: 6.2802
[2021-12-18:12:57:09:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.4, commit 8e5033be2a2f09d935c682f33703eff34cf8b3f4, path /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-18:12:57:09:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.4, commit 8e5033be2a2f09d935c682f33703eff34cf8b3f4, path /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-18:12:57:09:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.4, commit 8e5033be2a2f09d935c682f33703eff34cf8b3f4, path /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-18:12:57:09:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-18:12:57:09:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-18:12:57:09:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-18:12:57:09:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0+cu102 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-18:12:57:09:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0+cu102 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-18:12:57:09:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0+cu102 (/home/cluster/zifjia/.local/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-18:12:57:09:INFO:sockeye.utils:log_basic_info] Command: /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/translate.py --models models/sockeye_spoken2symbol --input data_reverse/test.spm.spoken --output models/sockeye_spoken2symbol/test.hyps.symbol --max-input-length 99999 --beam-size 3 --device-id 0 --disable-device-locking --seed 42
[2021-12-18:12:57:09:INFO:sockeye.utils:log_basic_info] Command: /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/translate.py --models models/sockeye_spoken2symbol --input data_reverse/test.spm.spoken --output models/sockeye_spoken2symbol/test.hyps.symbol --max-input-length 99999 --beam-size 3 --device-id 0 --disable-device-locking --seed 42
[2021-12-18:12:57:09:INFO:sockeye.utils:log_basic_info] Command: /home/cluster/zifjia/.local/lib/python3.8/site-packages/sockeye/translate.py --models models/sockeye_spoken2symbol --input data_reverse/test.spm.spoken --output models/sockeye_spoken2symbol/test.hyps.symbol --max-input-length 99999 --beam-size 3 --device-id 0 --disable-device-locking --seed 42
[2021-12-18:12:57:09:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(avoid_list=None, batch_size=1, beam_search_stop='all', beam_size=3, brevity_penalty_constant_length_ratio=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, bucket_width=10, checkpoints=None, chunk_size=None, config=None, device_id=0, device_ids=[-1], disable_device_locking=True, dtype=None, ensemble_mode='linear', env=None, greedy=False, input='data_reverse/test.spm.spoken', input_factors=None, json_input=False, length_penalty_alpha=1.0, length_penalty_beta=0.0, lock_dir='/tmp', loglevel='INFO', loglevel_secondary_workers='INFO', max_input_length=99999, max_output_length=None, max_output_length_num_stds=2, mc_dropout=False, models=['models/sockeye_spoken2symbol'], nbest_size=1, no_hybridization=False, no_logfile=False, output='models/sockeye_spoken2symbol/test.hyps.symbol', output_type='translation', prevent_unk=False, quiet=False, quiet_secondary_workers=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=42, softmax_temperature=None, strip_unknown_words=False, use_cpu=False)
[2021-12-18:12:57:09:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(avoid_list=None, batch_size=1, beam_search_stop='all', beam_size=3, brevity_penalty_constant_length_ratio=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, bucket_width=10, checkpoints=None, chunk_size=None, config=None, device_id=0, device_ids=[-1], disable_device_locking=True, dtype=None, ensemble_mode='linear', env=None, greedy=False, input='data_reverse/test.spm.spoken', input_factors=None, json_input=False, length_penalty_alpha=1.0, length_penalty_beta=0.0, lock_dir='/tmp', loglevel='INFO', loglevel_secondary_workers='INFO', max_input_length=99999, max_output_length=None, max_output_length_num_stds=2, mc_dropout=False, models=['models/sockeye_spoken2symbol'], nbest_size=1, no_hybridization=False, no_logfile=False, output='models/sockeye_spoken2symbol/test.hyps.symbol', output_type='translation', prevent_unk=False, quiet=False, quiet_secondary_workers=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=42, softmax_temperature=None, strip_unknown_words=False, use_cpu=False)
[2021-12-18:12:57:09:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(avoid_list=None, batch_size=1, beam_search_stop='all', beam_size=3, brevity_penalty_constant_length_ratio=0.0, brevity_penalty_type='none', brevity_penalty_weight=1.0, bucket_width=10, checkpoints=None, chunk_size=None, config=None, device_id=0, device_ids=[-1], disable_device_locking=True, dtype=None, ensemble_mode='linear', env=None, greedy=False, input='data_reverse/test.spm.spoken', input_factors=None, json_input=False, length_penalty_alpha=1.0, length_penalty_beta=0.0, lock_dir='/tmp', loglevel='INFO', loglevel_secondary_workers='INFO', max_input_length=99999, max_output_length=None, max_output_length_num_stds=2, mc_dropout=False, models=['models/sockeye_spoken2symbol'], nbest_size=1, no_hybridization=False, no_logfile=False, output='models/sockeye_spoken2symbol/test.hyps.symbol', output_type='translation', prevent_unk=False, quiet=False, quiet_secondary_workers=False, restrict_lexicon=None, restrict_lexicon_topk=None, sample=None, seed=42, softmax_temperature=None, strip_unknown_words=False, use_cpu=False)
[2021-12-18:12:57:10:WARNING:sockeye.utils:expand_requested_device_ids] Sockeye currently does not respect CUDA_VISIBLE_DEVICE settings when locking GPU devices.
[2021-12-18:12:57:10:INFO:sockeye.utils:_expand_requested_device_ids] Attempting to acquire 1 GPUs of 1 GPUs.
[2021-12-18:12:57:10:INFO:__main__:run_translate] Translate Device: gpu(0)
[2021-12-18:12:57:10:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye_spoken2symbol'] ...
[2021-12-18:12:57:10:INFO:sockeye.vocab:vocab_from_json] Vocabulary (2000 words) loaded from "models/sockeye_spoken2symbol/vocab.src.0.json"
[2021-12-18:12:57:10:INFO:sockeye.vocab:vocab_from_json] Vocabulary (12224 words) loaded from "models/sockeye_spoken2symbol/vocab.trg.0.json"
[2021-12-18:12:57:10:INFO:sockeye.model:load_model] Model version: 3.0.4
[2021-12-18:12:57:10:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye_spoken2symbol/config"
[2021-12-18:12:57:10:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2021-12-18:12:57:10:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=111529, num_discarded=417, num_tokens_source=2075941, num_tokens_target=2225438, num_unks_source=0, num_unks_target=0, max_observed_len_source=185, max_observed_len_target=201, size_vocab_source=2000, size_vocab_target=12224, length_ratio_mean=0.7952563989633317, length_ratio_std=0.6990334237388166, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)], num_sents_per_bucket=[0, 81219, 14620, 1193, 457, 408, 628, 1030, 1224, 1199, 1150, 1259, 1170, 1106, 1014, 916, 731, 552, 498, 361, 263, 213, 145, 95, 68, 10], average_len_target_per_bucket=[None, 7.676615077752828, 10.917852257181917, 15.969823973176855, 30.378555798687103, 42.40196078431373, 51.130573248407686, 59.50485436893204, 67.60049019607851, 75.63886572143453, 84.04869565217392, 92.31691818903899, 100.22478632478625, 108.258589511754, 116.40631163708095, 124.24999999999997, 132.4924760601916, 140.4692028985508, 148.30120481927696, 155.7811634349031, 164.2927756653993, 172.24413145539899, 179.1999999999999, 187.85263157894744, 195.8088235294118, 201.0], length_ratio_stats_per_bucket=[(None, None), (0.5731306316243342, 0.20605685798846987), (0.6421342240936343, 0.39770008592915274), (0.859732548795569, 0.7448782250345781), (1.548934235200316, 0.8692084159265917), (1.8718311852655898, 0.8023738240479706), (1.7827641324506083, 0.7199393121842907), (1.8144343418607083, 0.6790160245445268), (1.849389302228943, 0.6483646482433103), (1.9460433022889274, 0.714701152942034), (2.082878803106982, 0.7668277390407361), (2.1917070789285207, 0.7718414511646764), (2.2440640194205312, 0.763463890478365), (2.29744984926137, 0.8628994817056892), (2.376561672214239, 0.9278811630432776), (2.4055202846639103, 1.0308439838665555), (2.47307220374083, 1.1927088662158885), (2.449640906406911, 0.9844225288697896), (2.506961480708306, 1.1401135689536712), (2.738755276705606, 1.6542230528380326), (2.633704509461338, 1.5948046208089743), (2.695802278434618, 1.3733845272690017), (3.283258200500435, 2.5112983223576277), (3.6306240624382267, 3.172481624967147), (3.417168104320764, 2.6170087795834664), (2.253037210632548, 0.5958326376020144)]), max_seq_len_source=201, max_seq_len_target=201, num_source_factors=1, num_target_factors=1), vocab_source_size=2000, vocab_target_size=12224, config_embed_source=EmbeddingConfig(vocab_size=2000, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_embed_target=EmbeddingConfig(vocab_size=12224, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='trg_softmax', lhuc=False, dtype='float32')
[2021-12-18:12:57:10:WARNING:sockeye.utils:expand_requested_device_ids] Sockeye currently does not respect CUDA_VISIBLE_DEVICE settings when locking GPU devices.
[2021-12-18:12:57:10:INFO:sockeye.utils:_expand_requested_device_ids] Attempting to acquire 1 GPUs of 1 GPUs.
[2021-12-18:12:57:10:INFO:__main__:run_translate] Translate Device: gpu(0)
[2021-12-18:12:57:10:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye_spoken2symbol'] ...
[2021-12-18:12:57:10:INFO:sockeye.vocab:vocab_from_json] Vocabulary (2000 words) loaded from "models/sockeye_spoken2symbol/vocab.src.0.json"
[2021-12-18:12:57:10:INFO:sockeye.vocab:vocab_from_json] Vocabulary (12224 words) loaded from "models/sockeye_spoken2symbol/vocab.trg.0.json"
[2021-12-18:12:57:10:INFO:sockeye.model:load_model] Model version: 3.0.4
[2021-12-18:12:57:10:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye_spoken2symbol/config"
[2021-12-18:12:57:10:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2021-12-18:12:57:10:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=111529, num_discarded=417, num_tokens_source=2075941, num_tokens_target=2225438, num_unks_source=0, num_unks_target=0, max_observed_len_source=185, max_observed_len_target=201, size_vocab_source=2000, size_vocab_target=12224, length_ratio_mean=0.7952563989633317, length_ratio_std=0.6990334237388166, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)], num_sents_per_bucket=[0, 81219, 14620, 1193, 457, 408, 628, 1030, 1224, 1199, 1150, 1259, 1170, 1106, 1014, 916, 731, 552, 498, 361, 263, 213, 145, 95, 68, 10], average_len_target_per_bucket=[None, 7.676615077752828, 10.917852257181917, 15.969823973176855, 30.378555798687103, 42.40196078431373, 51.130573248407686, 59.50485436893204, 67.60049019607851, 75.63886572143453, 84.04869565217392, 92.31691818903899, 100.22478632478625, 108.258589511754, 116.40631163708095, 124.24999999999997, 132.4924760601916, 140.4692028985508, 148.30120481927696, 155.7811634349031, 164.2927756653993, 172.24413145539899, 179.1999999999999, 187.85263157894744, 195.8088235294118, 201.0], length_ratio_stats_per_bucket=[(None, None), (0.5731306316243342, 0.20605685798846987), (0.6421342240936343, 0.39770008592915274), (0.859732548795569, 0.7448782250345781), (1.548934235200316, 0.8692084159265917), (1.8718311852655898, 0.8023738240479706), (1.7827641324506083, 0.7199393121842907), (1.8144343418607083, 0.6790160245445268), (1.849389302228943, 0.6483646482433103), (1.9460433022889274, 0.714701152942034), (2.082878803106982, 0.7668277390407361), (2.1917070789285207, 0.7718414511646764), (2.2440640194205312, 0.763463890478365), (2.29744984926137, 0.8628994817056892), (2.376561672214239, 0.9278811630432776), (2.4055202846639103, 1.0308439838665555), (2.47307220374083, 1.1927088662158885), (2.449640906406911, 0.9844225288697896), (2.506961480708306, 1.1401135689536712), (2.738755276705606, 1.6542230528380326), (2.633704509461338, 1.5948046208089743), (2.695802278434618, 1.3733845272690017), (3.283258200500435, 2.5112983223576277), (3.6306240624382267, 3.172481624967147), (3.417168104320764, 2.6170087795834664), (2.253037210632548, 0.5958326376020144)]), max_seq_len_source=201, max_seq_len_target=201, num_source_factors=1, num_target_factors=1), vocab_source_size=2000, vocab_target_size=12224, config_embed_source=EmbeddingConfig(vocab_size=2000, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_embed_target=EmbeddingConfig(vocab_size=12224, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='trg_softmax', lhuc=False, dtype='float32')
[2021-12-18:12:57:10:WARNING:sockeye.utils:expand_requested_device_ids] Sockeye currently does not respect CUDA_VISIBLE_DEVICE settings when locking GPU devices.
[2021-12-18:12:57:10:INFO:sockeye.utils:_expand_requested_device_ids] Attempting to acquire 1 GPUs of 1 GPUs.
[2021-12-18:12:57:10:INFO:__main__:run_translate] Translate Device: gpu(0)
[2021-12-18:12:57:10:INFO:sockeye.model:load_models] Loading 1 model(s) from ['models/sockeye_spoken2symbol'] ...
[2021-12-18:12:57:10:INFO:sockeye.vocab:vocab_from_json] Vocabulary (2000 words) loaded from "models/sockeye_spoken2symbol/vocab.src.0.json"
[2021-12-18:12:57:10:INFO:sockeye.vocab:vocab_from_json] Vocabulary (12224 words) loaded from "models/sockeye_spoken2symbol/vocab.trg.0.json"
[2021-12-18:12:57:10:INFO:sockeye.model:load_model] Model version: 3.0.4
[2021-12-18:12:57:10:INFO:sockeye.model:load_config] Loaded model config from "models/sockeye_spoken2symbol/config"
[2021-12-18:12:57:10:INFO:sockeye.model:load_model] Disabling dropout layers for performance reasons
[2021-12-18:12:57:10:INFO:sockeye.model:__init__] ModelConfig(config_data=DataConfig(data_statistics=DataStatistics(num_sents=111529, num_discarded=417, num_tokens_source=2075941, num_tokens_target=2225438, num_unks_source=0, num_unks_target=0, max_observed_len_source=185, max_observed_len_target=201, size_vocab_source=2000, size_vocab_target=12224, length_ratio_mean=0.7952563989633317, length_ratio_std=0.6990334237388166, buckets=[(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)], num_sents_per_bucket=[0, 81219, 14620, 1193, 457, 408, 628, 1030, 1224, 1199, 1150, 1259, 1170, 1106, 1014, 916, 731, 552, 498, 361, 263, 213, 145, 95, 68, 10], average_len_target_per_bucket=[None, 7.676615077752828, 10.917852257181917, 15.969823973176855, 30.378555798687103, 42.40196078431373, 51.130573248407686, 59.50485436893204, 67.60049019607851, 75.63886572143453, 84.04869565217392, 92.31691818903899, 100.22478632478625, 108.258589511754, 116.40631163708095, 124.24999999999997, 132.4924760601916, 140.4692028985508, 148.30120481927696, 155.7811634349031, 164.2927756653993, 172.24413145539899, 179.1999999999999, 187.85263157894744, 195.8088235294118, 201.0], length_ratio_stats_per_bucket=[(None, None), (0.5731306316243342, 0.20605685798846987), (0.6421342240936343, 0.39770008592915274), (0.859732548795569, 0.7448782250345781), (1.548934235200316, 0.8692084159265917), (1.8718311852655898, 0.8023738240479706), (1.7827641324506083, 0.7199393121842907), (1.8144343418607083, 0.6790160245445268), (1.849389302228943, 0.6483646482433103), (1.9460433022889274, 0.714701152942034), (2.082878803106982, 0.7668277390407361), (2.1917070789285207, 0.7718414511646764), (2.2440640194205312, 0.763463890478365), (2.29744984926137, 0.8628994817056892), (2.376561672214239, 0.9278811630432776), (2.4055202846639103, 1.0308439838665555), (2.47307220374083, 1.1927088662158885), (2.449640906406911, 0.9844225288697896), (2.506961480708306, 1.1401135689536712), (2.738755276705606, 1.6542230528380326), (2.633704509461338, 1.5948046208089743), (2.695802278434618, 1.3733845272690017), (3.283258200500435, 2.5112983223576277), (3.6306240624382267, 3.172481624967147), (3.417168104320764, 2.6170087795834664), (2.253037210632548, 0.5958326376020144)]), max_seq_len_source=201, max_seq_len_target=201, num_source_factors=1, num_target_factors=1), vocab_source_size=2000, vocab_target_size=12224, config_embed_source=EmbeddingConfig(vocab_size=2000, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_embed_target=EmbeddingConfig(vocab_size=12224, num_embed=512, dropout=0.0, num_factors=1, factor_configs=None, allow_sparse_grad=True), config_encoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_decoder=TransformerConfig(model_size=512, attention_heads=8, feed_forward_num_hidden=2048, act_type='relu', num_layers=6, dropout_attention=0.0, dropout_act=0.0, dropout_prepost=0.0, positional_embedding_type='fixed', preprocess_sequence='n', postprocess_sequence='dr', max_seq_len_source=201, max_seq_len_target=201, decoder_type='transformer', use_lhuc=False, depth_key_value=512, use_glu=False), config_length_task=None, weight_tying_type='trg_softmax', lhuc=False, dtype='float32')
[2021-12-18:12:57:15:INFO:sockeye.model:load_model] Model dtype: float32
[2021-12-18:12:57:15:INFO:sockeye.model:load_model] Model dtype: float32
[2021-12-18:12:57:15:INFO:sockeye.model:load_model] Model dtype: float32
[2021-12-18:12:57:16:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye_spoken2symbol/params.best" to "gpu(0)"
[2021-12-18:12:57:16:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye_spoken2symbol/params.best" to "gpu(0)"
[2021-12-18:12:57:16:INFO:sockeye.model:load_parameters] Loaded params from "models/sockeye_spoken2symbol/params.best" to "gpu(0)"
[2021-12-18:12:57:16:INFO:sockeye.model:load_models] 1 model(s) loaded in 6.2677s
[2021-12-18:12:57:16:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=3 algorithm=BeamSearch, beam_search_stop=all max_input_length=200 nbest_size=1 ensemble_mode=None max_batch_size=1 avoiding=0 dtype=float32 softmax_temperature=None)
[2021-12-18:12:57:16:INFO:__main__:read_and_translate] Translating...
[2021-12-18:12:57:16:INFO:sockeye.model:load_models] 1 model(s) loaded in 6.3067s
[2021-12-18:12:57:16:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=3 algorithm=BeamSearch, beam_search_stop=all max_input_length=200 nbest_size=1 ensemble_mode=None max_batch_size=1 avoiding=0 dtype=float32 softmax_temperature=None)
[2021-12-18:12:57:16:INFO:__main__:read_and_translate] Translating...
[2021-12-18:12:57:16:INFO:sockeye.model:load_models] 1 model(s) loaded in 6.3491s
[2021-12-18:12:57:16:INFO:sockeye.inference:__init__] Translator (1 model(s) beam_size=3 algorithm=BeamSearch, beam_search_stop=all max_input_length=200 nbest_size=1 ensemble_mode=None max_batch_size=1 avoiding=0 dtype=float32 softmax_temperature=None)
[2021-12-18:12:57:16:INFO:__main__:read_and_translate] Translating...
[2021-12-18:13:00:24:INFO:__main__:read_and_translate] Processed 1143 lines. Total time: 188.0582, sec/sent: 0.1645, sent/sec: 6.0779
[2021-12-18:13:00:25:INFO:__main__:read_and_translate] Processed 1143 lines. Total time: 188.9875, sec/sent: 0.1653, sent/sec: 6.0480
[2021-12-18:13:00:28:INFO:__main__:read_and_translate] Processed 1143 lines. Total time: 191.6102, sec/sent: 0.1676, sent/sec: 5.9652
