2021-12-09 15:46:08,786 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-12-09 15:46:08,884 - INFO - joeynmt.data - Loading training data...
2021-12-09 15:46:10,393 - INFO - joeynmt.data - Building vocabulary...
2021-12-09 15:46:12,966 - INFO - joeynmt.data - Loading dev data...
2021-12-09 15:46:12,976 - INFO - joeynmt.data - Loading test data...
2021-12-09 15:46:12,987 - INFO - joeynmt.data - Data loaded.
2021-12-09 15:46:12,987 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-12-09 15:46:13,783 - INFO - joeynmt.model - Enc-dec model built.
2021-12-09 15:46:15,426 - DEBUG - tensorflow - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2021-12-09 15:46:16,105 - DEBUG - h5py._conv - Creating converter from 7 to 5
2021-12-09 15:46:16,105 - DEBUG - h5py._conv - Creating converter from 5 to 7
2021-12-09 15:46:16,106 - DEBUG - h5py._conv - Creating converter from 7 to 5
2021-12-09 15:46:16,106 - DEBUG - h5py._conv - Creating converter from 5 to 7
2021-12-09 15:46:18,129 - INFO - joeynmt.training - Total params: 51227648
2021-12-09 15:46:18,131 - DEBUG - joeynmt.training - Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2021-12-09 15:46:18,132 - WARNING - joeynmt.training - `keep_last_ckpts` option is outdated. Please use `keep_best_ckpts`, instead.
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.name                           : baseline_reverse_symbol
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.data.src                       : spm.spoken
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.data.trg                       : symbol
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.data.train                     : data_reverse/train
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.data.dev                       : data_reverse/dev
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.data.test                      : data_reverse/test
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.data.level                     : word
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 200
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.testing.postprocess            : False
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]
2021-12-09 15:46:21,528 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.patience              : 5
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0001
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.2
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.batch_size            : 4096
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.batch_type            : token
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 4096
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : eval_metric
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.epochs                : 200
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 5000
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 500
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.overwrite             : True
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.shuffle               : True
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 200
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3, 6]
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 1
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/baseline_reverse_symbol
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0
2021-12-09 15:46:21,529 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 8
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.5
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.5
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 8
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.5
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.5
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - Data set sizes: 
	train 111529,
	valid 1137,
	test 1132
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - First training example:
	[SRC] ▁<2 pt > ▁<4 br > ▁< dict > ▁p en ico
	[TRG] M S1ed40 S1ed48 S3780b S20359 S20601 S1a051
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) > (5) ▁< (6) ▁<2 (7) ▁<4 (8) dict (9) de
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) M (5) P (6) S20500 (7) S2ff00 (8) S38700 (9) S38800
2021-12-09 15:46:21,530 - INFO - joeynmt.helpers - Number of Src words (types): 1969
2021-12-09 15:46:21,531 - INFO - joeynmt.helpers - Number of Trg words (types): 11873
2021-12-09 15:46:21,531 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=8),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=512, vocab_size=1969),
	factor_embeds=None,
	trg_embed=Embeddings(embedding_dim=512, vocab_size=11873))
2021-12-09 15:46:21,538 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 4096
	total batch size (w. parallel & accumulation): 4096
2021-12-09 15:46:21,538 - INFO - joeynmt.training - EPOCH 1
2021-12-09 15:47:31,003 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     4.135277, Tokens per Sec:     4300, Lr: 0.000100
2021-12-09 15:48:40,014 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.595931, Tokens per Sec:     4328, Lr: 0.000100
2021-12-09 15:49:48,578 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.740256, Tokens per Sec:     4323, Lr: 0.000100
2021-12-09 15:50:57,116 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     3.352581, Tokens per Sec:     4384, Lr: 0.000100
2021-12-09 15:52:06,042 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     3.010733, Tokens per Sec:     4369, Lr: 0.000100
2021-12-09 15:53:14,923 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.943622, Tokens per Sec:     4468, Lr: 0.000100
2021-12-09 15:54:23,359 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     3.260958, Tokens per Sec:     4384, Lr: 0.000100
2021-12-09 15:54:51,804 - INFO - joeynmt.training - Epoch   1: total training loss 13291.59
2021-12-09 15:54:51,804 - INFO - joeynmt.training - EPOCH 2
2021-12-09 15:55:32,020 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     3.303544, Tokens per Sec:     4253, Lr: 0.000100
2021-12-09 15:56:40,634 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.730419, Tokens per Sec:     4297, Lr: 0.000100
2021-12-09 15:57:49,623 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     3.084083, Tokens per Sec:     4377, Lr: 0.000100
2021-12-09 16:00:40,499 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-09 16:00:41,564 - INFO - joeynmt.training - Example #0
2021-12-09 16:00:41,564 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁3', '7.', '▁After', '▁him', ',', '▁at', '▁the', '▁time', '▁of', '▁the', '▁c', 'ens', 'us', ',', '▁there', '▁was', '▁Jud', 'as', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁g', 'ot', '▁people', '▁to', '▁follow', '▁him', ',', '▁but', '▁he', '▁was', '▁k', 'illed', ',', '▁too', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁s', 'ca', 't', 'ter', 'ed', '.']
2021-12-09 16:00:41,564 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S20500', 'S30a00', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M']
2021-12-09 16:00:41,564 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁s ca t ter ed .
2021-12-09 16:00:41,564 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-09 16:00:41,564 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S11e20 P S38800 M S1dc0a S10003 S20500 S20500 S20500 S30a00 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S22a04 M
2021-12-09 16:00:41,564 - INFO - joeynmt.training - Example #1
2021-12-09 16:00:41,564 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁L', 'á', 'p', 'is']
2021-12-09 16:00:41,564 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S36d00', 'S20500', 'S20500', 'S20500']
2021-12-09 16:00:41,564 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁L á p is
2021-12-09 16:00:41,564 - INFO - joeynmt.training - 	Reference:  M S34700 S21100 S1f410
2021-12-09 16:00:41,564 - INFO - joeynmt.training - 	Hypothesis: M S36d00 S20500 S20500 S20500
2021-12-09 16:00:41,564 - INFO - joeynmt.training - Example #2
2021-12-09 16:00:41,564 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁tr', 'ul', 'y', '▁happ', 'y', '▁by', '▁ag', 'ree', 'ing', '▁whole', 'he', 'art', 'ed', 'ly', '▁with', '▁each', '▁other', ',', '▁lo', 'ving', '▁one', '▁another', ',', '▁and', '▁work', 'ing', '▁together', '▁with', '▁one', '▁m', 'ind', '▁and', '▁pur', 'po', 'se', '.']
2021-12-09 16:00:41,564 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00']
2021-12-09 16:00:41,565 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁happ y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo ving ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁pur po se .
2021-12-09 16:00:41,565 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-09 16:00:41,565 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S11e20 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00
2021-12-09 16:00:41,565 - INFO - joeynmt.training - Example #3
2021-12-09 16:00:41,565 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁ex', 'pl', 'or', 'ar']
2021-12-09 16:00:41,565 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S36d00', 'S20500', 'S20500', 'S20500']
2021-12-09 16:00:41,565 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁ex pl or ar
2021-12-09 16:00:41,565 - INFO - joeynmt.training - 	Reference:  M S10e40 S11040 S26504 S2fb04
2021-12-09 16:00:41,565 - INFO - joeynmt.training - 	Hypothesis: M S36d00 S20500 S20500 S20500
2021-12-09 16:00:41,565 - INFO - joeynmt.training - Example #6
2021-12-09 16:00:41,565 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'dict', '>', '▁m', 'il', 'k']
2021-12-09 16:00:41,565 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S10011']
2021-12-09 16:00:41,565 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< dict > ▁m il k
2021-12-09 16:00:41,565 - INFO - joeynmt.training - 	Reference:  M S20340 S21800
2021-12-09 16:00:41,565 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S10011
2021-12-09 16:00:41,565 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     5000: bleu:   1.39, loss: 66885.7734, ppl:  20.1431, duration: 171.9412s
2021-12-09 16:01:50,186 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.770820, Tokens per Sec:     4315, Lr: 0.000100
2021-12-09 16:02:59,222 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     3.016310, Tokens per Sec:     4288, Lr: 0.000100
2021-12-09 16:04:08,398 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     2.691691, Tokens per Sec:     4330, Lr: 0.000100
2021-12-09 16:05:17,075 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     2.739455, Tokens per Sec:     4387, Lr: 0.000100
2021-12-09 16:06:16,773 - INFO - joeynmt.training - Epoch   2: total training loss 11069.85
2021-12-09 16:06:16,774 - INFO - joeynmt.training - EPOCH 3
2021-12-09 16:06:26,241 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     2.988216, Tokens per Sec:     4458, Lr: 0.000100
2021-12-09 16:07:34,828 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     3.227389, Tokens per Sec:     4394, Lr: 0.000100
2021-12-09 16:08:43,821 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     2.892932, Tokens per Sec:     4386, Lr: 0.000100
2021-12-09 16:09:52,500 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     2.709007, Tokens per Sec:     4354, Lr: 0.000100
2021-12-09 16:11:01,236 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     2.526565, Tokens per Sec:     4396, Lr: 0.000100
2021-12-09 16:12:10,319 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     2.769492, Tokens per Sec:     4383, Lr: 0.000100
2021-12-09 16:15:01,066 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-09 16:15:01,898 - INFO - joeynmt.helpers - delete models/baseline_reverse_symbol/5000.ckpt
2021-12-09 16:15:01,899 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/5000.ckpt
2021-12-09 16:15:01,899 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/5000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/5000.ckpt')
2021-12-09 16:15:01,948 - INFO - joeynmt.training - Example #0
2021-12-09 16:15:01,948 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁3', '7.', '▁After', '▁him', ',', '▁at', '▁the', '▁time', '▁of', '▁the', '▁c', 'ens', 'us', ',', '▁there', '▁was', '▁Jud', 'as', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁g', 'ot', '▁people', '▁to', '▁follow', '▁him', ',', '▁but', '▁he', '▁was', '▁k', 'illed', ',', '▁too', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁s', 'ca', 't', 'ter', 'ed', '.']
2021-12-09 16:15:01,949 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S15a18', 'S1dc10', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S22a04', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S15a10', 'S15a18', 'S1dc10', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S22a04', 'M', 'S2ff00', 'S10011', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S15a10', 'S15a18', 'S1dc10', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S22a04', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S15a10', 'S15a18']
2021-12-09 16:15:01,949 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁s ca t ter ed .
2021-12-09 16:15:01,949 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-09 16:15:01,949 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S11e20 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S15a18 S1dc10 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S22a04 M S2ff00 S2df08 M S2ff00 S15a10 S15a18 S1dc10 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S22a04 M S2ff00 S10011 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S15a10 S15a18 S1dc10 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S22a04 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S15a10 S15a18
2021-12-09 16:15:01,949 - INFO - joeynmt.training - Example #1
2021-12-09 16:15:01,950 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁L', 'á', 'p', 'is']
2021-12-09 16:15:01,950 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 16:15:01,950 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁L á p is
2021-12-09 16:15:01,950 - INFO - joeynmt.training - 	Reference:  M S34700 S21100 S1f410
2021-12-09 16:15:01,950 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500 S20500
2021-12-09 16:15:01,950 - INFO - joeynmt.training - Example #2
2021-12-09 16:15:01,950 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁tr', 'ul', 'y', '▁happ', 'y', '▁by', '▁ag', 'ree', 'ing', '▁whole', 'he', 'art', 'ed', 'ly', '▁with', '▁each', '▁other', ',', '▁lo', 'ving', '▁one', '▁another', ',', '▁and', '▁work', 'ing', '▁together', '▁with', '▁one', '▁m', 'ind', '▁and', '▁pur', 'po', 'se', '.']
2021-12-09 16:15:01,951 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'P', 'S38800', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S30a00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00', 'S15a10', 'S2b700', 'M', 'S2ff00']
2021-12-09 16:15:01,951 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁happ y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo ving ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁pur po se .
2021-12-09 16:15:01,951 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-09 16:15:01,951 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S11e20 P S38800 M S10021 S10029 S22a07 S22a11 S30a00 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00 S15a10 S2b700 M S2ff00
2021-12-09 16:15:01,951 - INFO - joeynmt.training - Example #3
2021-12-09 16:15:01,951 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁ex', 'pl', 'or', 'ar']
2021-12-09 16:15:01,952 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500']
2021-12-09 16:15:01,952 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁ex pl or ar
2021-12-09 16:15:01,952 - INFO - joeynmt.training - 	Reference:  M S10e40 S11040 S26504 S2fb04
2021-12-09 16:15:01,952 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500
2021-12-09 16:15:01,952 - INFO - joeynmt.training - Example #6
2021-12-09 16:15:01,952 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'dict', '>', '▁m', 'il', 'k']
2021-12-09 16:15:01,952 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S10011', 'S20500', 'S20500']
2021-12-09 16:15:01,952 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< dict > ▁m il k
2021-12-09 16:15:01,953 - INFO - joeynmt.training - 	Reference:  M S20340 S21800
2021-12-09 16:15:01,953 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S10011 S20500 S20500
2021-12-09 16:15:01,953 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step    10000: bleu:   1.74, loss: 60680.7422, ppl:  15.2455, duration: 171.6338s
2021-12-09 16:16:10,315 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     2.879819, Tokens per Sec:     4399, Lr: 0.000100
2021-12-09 16:17:18,473 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     2.818457, Tokens per Sec:     4386, Lr: 0.000100
2021-12-09 16:17:36,718 - INFO - joeynmt.training - Epoch   3: total training loss 10198.43
2021-12-09 16:17:36,719 - INFO - joeynmt.training - EPOCH 4
2021-12-09 16:18:27,328 - INFO - joeynmt.training - Epoch   4, Step:    11500, Batch Loss:     2.270579, Tokens per Sec:     4296, Lr: 0.000100
2021-12-09 16:19:36,316 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     2.492064, Tokens per Sec:     4365, Lr: 0.000100
2021-12-09 16:20:45,168 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     3.321278, Tokens per Sec:     4413, Lr: 0.000100
2021-12-09 16:21:53,712 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     2.481271, Tokens per Sec:     4338, Lr: 0.000100
2021-12-09 16:23:02,464 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     2.717922, Tokens per Sec:     4420, Lr: 0.000100
2021-12-09 16:24:11,592 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     2.295503, Tokens per Sec:     4333, Lr: 0.000100
2021-12-09 16:25:20,038 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     2.749612, Tokens per Sec:     4357, Lr: 0.000100
2021-12-09 16:26:06,271 - INFO - joeynmt.training - Epoch   4: total training loss 9691.28
2021-12-09 16:26:06,272 - INFO - joeynmt.training - EPOCH 5
2021-12-09 16:26:28,932 - INFO - joeynmt.training - Epoch   5, Step:    15000, Batch Loss:     2.156501, Tokens per Sec:     4239, Lr: 0.000100
2021-12-09 16:29:19,752 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-09 16:29:20,590 - INFO - joeynmt.helpers - delete models/baseline_reverse_symbol/10000.ckpt
2021-12-09 16:29:20,590 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/10000.ckpt
2021-12-09 16:29:20,590 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/10000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/10000.ckpt')
2021-12-09 16:29:20,634 - INFO - joeynmt.training - Example #0
2021-12-09 16:29:20,634 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁3', '7.', '▁After', '▁him', ',', '▁at', '▁the', '▁time', '▁of', '▁the', '▁c', 'ens', 'us', ',', '▁there', '▁was', '▁Jud', 'as', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁g', 'ot', '▁people', '▁to', '▁follow', '▁him', ',', '▁but', '▁he', '▁was', '▁k', 'illed', ',', '▁too', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁s', 'ca', 't', 'ter', 'ed', '.']
2021-12-09 16:29:20,634 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S1bb20', 'P', 'S38800', 'M', 'S14c37', 'S14c3f', 'S22a04', 'S22a14', 'S30a00', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S10011', 'S22a04', 'S15d39', 'S15d51', 'P', 'S38700', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S10011', 'S22a04', 'S15d39', 'S15d51', 'P', 'S38700', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'P', 'S38800']
2021-12-09 16:29:20,634 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁s ca t ter ed .
2021-12-09 16:29:20,634 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-09 16:29:20,635 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S1bb20 P S38800 M S14c37 S14c3f S22a04 S22a14 S30a00 M S10041 S2d60e M S2ff00 S10011 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S10011 S22a04 S15d39 S15d51 P S38700 M S10041 S2d60e M S2ff00 S10011 S15d39 S15d51 M S2ff00 S2df08 M S2ff00 S10011 S15d39 S15d51 M S2ff00 S2df08 M S2ff00 S10011 S22a04 S15d39 S15d51 P S38700 M S10041 S2d60e M S2ff00 S10011 S15d39 S15d51 M S2ff00 S2df08 M S2ff00 S10011 S15d39 S15d51 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S10011 S15d39 S15d51 P S38800
2021-12-09 16:29:20,635 - INFO - joeynmt.training - Example #1
2021-12-09 16:29:20,635 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁L', 'á', 'p', 'is']
2021-12-09 16:29:20,635 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S36d00', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 16:29:20,635 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁L á p is
2021-12-09 16:29:20,635 - INFO - joeynmt.training - 	Reference:  M S34700 S21100 S1f410
2021-12-09 16:29:20,635 - INFO - joeynmt.training - 	Hypothesis: M S36d00 S20500 S20500 S20500 S20500
2021-12-09 16:29:20,635 - INFO - joeynmt.training - Example #2
2021-12-09 16:29:20,636 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁tr', 'ul', 'y', '▁happ', 'y', '▁by', '▁ag', 'ree', 'ing', '▁whole', 'he', 'art', 'ed', 'ly', '▁with', '▁each', '▁other', ',', '▁lo', 'ving', '▁one', '▁another', ',', '▁and', '▁work', 'ing', '▁together', '▁with', '▁one', '▁m', 'ind', '▁and', '▁pur', 'po', 'se', '.']
2021-12-09 16:29:20,636 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S1bb20', 'P', 'S38800', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S30a00', 'M', 'S2ff00', 'S15a10', 'S22a04', 'M', 'S2ff00', 'S15a10', 'S22a04', 'S32107', 'M', 'S2ff00', 'S15a10', 'S22a04', 'S32107', 'M', 'S2ff00', 'S15a10', 'S22a04', 'S32107', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'P', 'S38800']
2021-12-09 16:29:20,636 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁happ y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo ving ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁pur po se .
2021-12-09 16:29:20,636 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-09 16:29:20,636 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S1bb20 P S38800 M S10021 S10029 S22a07 S22a11 S30a00 M S2ff00 S15a10 S22a04 M S2ff00 S15a10 S22a04 S32107 M S2ff00 S15a10 S22a04 S32107 M S2ff00 S15a10 S22a04 S32107 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 P S38800
2021-12-09 16:29:20,636 - INFO - joeynmt.training - Example #3
2021-12-09 16:29:20,636 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁ex', 'pl', 'or', 'ar']
2021-12-09 16:29:20,637 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500']
2021-12-09 16:29:20,637 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁ex pl or ar
2021-12-09 16:29:20,637 - INFO - joeynmt.training - 	Reference:  M S10e40 S11040 S26504 S2fb04
2021-12-09 16:29:20,637 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500
2021-12-09 16:29:20,637 - INFO - joeynmt.training - Example #6
2021-12-09 16:29:20,637 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'dict', '>', '▁m', 'il', 'k']
2021-12-09 16:29:20,637 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S10011', 'S20500']
2021-12-09 16:29:20,637 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< dict > ▁m il k
2021-12-09 16:29:20,638 - INFO - joeynmt.training - 	Reference:  M S20340 S21800
2021-12-09 16:29:20,638 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S10011 S20500
2021-12-09 16:29:20,638 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step    15000: bleu:   1.87, loss: 56936.8164, ppl:  12.8868, duration: 171.7057s
2021-12-09 16:30:29,263 - INFO - joeynmt.training - Epoch   5, Step:    15500, Batch Loss:     2.455518, Tokens per Sec:     4392, Lr: 0.000100
2021-12-09 16:31:37,948 - INFO - joeynmt.training - Epoch   5, Step:    16000, Batch Loss:     2.731206, Tokens per Sec:     4360, Lr: 0.000100
2021-12-09 16:32:46,891 - INFO - joeynmt.training - Epoch   5, Step:    16500, Batch Loss:     3.042493, Tokens per Sec:     4397, Lr: 0.000100
2021-12-09 16:33:55,448 - INFO - joeynmt.training - Epoch   5, Step:    17000, Batch Loss:     2.594959, Tokens per Sec:     4335, Lr: 0.000100
2021-12-09 16:35:03,836 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     3.196737, Tokens per Sec:     4328, Lr: 0.000100
2021-12-09 16:36:12,316 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     2.402431, Tokens per Sec:     4422, Lr: 0.000100
2021-12-09 16:37:21,510 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     2.234540, Tokens per Sec:     4367, Lr: 0.000100
2021-12-09 16:37:27,785 - INFO - joeynmt.training - Epoch   5: total training loss 9339.66
2021-12-09 16:37:27,786 - INFO - joeynmt.training - EPOCH 6
2021-12-09 16:38:30,318 - INFO - joeynmt.training - Epoch   6, Step:    19000, Batch Loss:     2.670662, Tokens per Sec:     4384, Lr: 0.000100
2021-12-09 16:39:38,804 - INFO - joeynmt.training - Epoch   6, Step:    19500, Batch Loss:     1.888395, Tokens per Sec:     4382, Lr: 0.000100
2021-12-09 16:40:47,406 - INFO - joeynmt.training - Epoch   6, Step:    20000, Batch Loss:     2.138471, Tokens per Sec:     4391, Lr: 0.000100
2021-12-09 16:43:38,206 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-09 16:43:39,040 - INFO - joeynmt.helpers - delete models/baseline_reverse_symbol/15000.ckpt
2021-12-09 16:43:39,040 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/15000.ckpt
2021-12-09 16:43:39,041 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/15000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/15000.ckpt')
2021-12-09 16:43:39,088 - INFO - joeynmt.training - Example #0
2021-12-09 16:43:39,089 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁3', '7.', '▁After', '▁him', ',', '▁at', '▁the', '▁time', '▁of', '▁the', '▁c', 'ens', 'us', ',', '▁there', '▁was', '▁Jud', 'as', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁g', 'ot', '▁people', '▁to', '▁follow', '▁him', ',', '▁but', '▁he', '▁was', '▁k', 'illed', ',', '▁too', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁s', 'ca', 't', 'ter', 'ed', '.']
2021-12-09 16:43:39,089 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S1c519', 'S1c511', 'S15a17', 'S15a1f', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S1c519', 'S1c511', 'S15a17', 'S15a1f', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S18510', 'S18518', 'S23b0a', 'S23b1a', 'S15d51', 'P', 'S38700', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S18510', 'S18518', 'M', 'S2ff00', 'S18510', 'S18518', 'M', 'S2ff00', 'S18510', 'S18518', 'S18518', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S18510', 'S18518', 'M', 'S2ff00', 'S18510', 'S22104', 'M', 'S2ff00', 'S18510', 'S18518', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S18510', 'S22104', 'M', 'S2ff00', 'S18510', 'S22104', 'M', 'S2ff00', 'S18510', 'S18518', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S18510', 'S22104', 'M', 'S2ff00', 'S18510', 'S22104', 'M', 'S2ff00', 'S18510', 'S22104', 'M', 'S10041', 'S2d60e', 'P', 'S38800']
2021-12-09 16:43:39,089 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁s ca t ter ed .
2021-12-09 16:43:39,089 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-09 16:43:39,089 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S11e20 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S1c519 S1c511 S15a17 S15a1f M S2ff00 S10002 S2ea00 P S38700 M S1c519 S1c511 S15a17 S15a1f M S2ff00 S10002 S2ea00 P S38700 M S10041 S2d60e M S2ff00 S10011 S15d39 S15d51 M S2ff00 S18510 S18518 S23b0a S23b1a S15d51 P S38700 M S10041 S2d60e M S2ff00 S18510 S18518 M S2ff00 S18510 S18518 M S2ff00 S18510 S18518 S18518 M S10041 S2d60e M S2ff00 S18510 S18518 M S2ff00 S18510 S22104 M S2ff00 S18510 S18518 M S10041 S2d60e M S2ff00 S18510 S22104 M S2ff00 S18510 S22104 M S2ff00 S18510 S18518 M S10041 S2d60e M S2ff00 S18510 S22104 M S2ff00 S18510 S22104 M S2ff00 S18510 S22104 M S10041 S2d60e P S38800
2021-12-09 16:43:39,089 - INFO - joeynmt.training - Example #1
2021-12-09 16:43:39,089 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁L', 'á', 'p', 'is']
2021-12-09 16:43:39,090 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 16:43:39,090 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁L á p is
2021-12-09 16:43:39,090 - INFO - joeynmt.training - 	Reference:  M S34700 S21100 S1f410
2021-12-09 16:43:39,090 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500 S20500 S20500
2021-12-09 16:43:39,090 - INFO - joeynmt.training - Example #2
2021-12-09 16:43:39,090 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁tr', 'ul', 'y', '▁happ', 'y', '▁by', '▁ag', 'ree', 'ing', '▁whole', 'he', 'art', 'ed', 'ly', '▁with', '▁each', '▁other', ',', '▁lo', 'ving', '▁one', '▁another', ',', '▁and', '▁work', 'ing', '▁together', '▁with', '▁one', '▁m', 'ind', '▁and', '▁pur', 'po', 'se', '.']
2021-12-09 16:43:39,090 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S1ce20', 'P', 'S38800', 'M', 'S10021', 'S10029', 'S22a07', 'S22a11', 'S30a00', 'M', 'S2ff00', 'S10010', 'S2770f', 'M', 'S2ff00', 'S10010', 'S2770f', 'M', 'S2ff00', 'S10010', 'S2770f', 'P', 'S38700', 'M', 'S20500', 'S20500', 'S10043', 'S2d600', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'S22f03', 'S22f15', 'P', 'S38700', 'M', 'S20500', 'S20500', 'S10043', 'S2d600', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S10011', 'S2e707', 'S19a10', 'S26500', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'S15a00', 'S15a07', 'S15a21', 'S15a01', 'S15a29', 'M', 'S2ff00', 'S15a10', 'S26500', 'M', 'S2ff00', 'P', 'S38800']
2021-12-09 16:43:39,091 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁happ y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo ving ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁pur po se .
2021-12-09 16:43:39,091 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-09 16:43:39,091 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S1ce20 P S38800 M S10021 S10029 S22a07 S22a11 S30a00 M S2ff00 S10010 S2770f M S2ff00 S10010 S2770f M S2ff00 S10010 S2770f P S38700 M S20500 S20500 S10043 S2d600 M S2ff00 S10011 S15d39 S15d51 M S2ff00 S10011 S15d39 S15d51 S22f03 S22f15 P S38700 M S20500 S20500 S10043 S2d600 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S10011 S15d39 S15d51 M S2ff00 S2df08 M S2ff00 S10011 S15d39 S15d51 M S2ff00 S2df08 M S2ff00 S10011 S15d39 S15d51 M S2ff00 S2df08 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S2df08 M S2ff00 S10011 S2e707 S19a10 S26500 M S2ff00 S2df08 M S2ff00 S2df08 M S2ff00 S15a10 S26500 M S2ff00 S2df08 M S2ff00 S15a10 S26500 M S2ff00 S15a10 S26500 M S2ff00 S15a00 S15a07 S15a21 S15a01 S15a29 M S2ff00 S15a10 S26500 M S2ff00 P S38800
2021-12-09 16:43:39,091 - INFO - joeynmt.training - Example #3
2021-12-09 16:43:39,091 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁ex', 'pl', 'or', 'ar']
2021-12-09 16:43:39,091 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S36d00', 'S36d00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 16:43:39,091 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁ex pl or ar
2021-12-09 16:43:39,091 - INFO - joeynmt.training - 	Reference:  M S10e40 S11040 S26504 S2fb04
2021-12-09 16:43:39,092 - INFO - joeynmt.training - 	Hypothesis: M S36d00 S36d00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 16:43:39,092 - INFO - joeynmt.training - Example #6
2021-12-09 16:43:39,092 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'dict', '>', '▁m', 'il', 'k']
2021-12-09 16:43:39,092 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 16:43:39,092 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< dict > ▁m il k
2021-12-09 16:43:39,092 - INFO - joeynmt.training - 	Reference:  M S20340 S21800
2021-12-09 16:43:39,092 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 16:43:39,093 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step    20000: bleu:   2.33, loss: 54729.0117, ppl:  11.6707, duration: 171.6858s
2021-12-09 16:44:48,061 - INFO - joeynmt.training - Epoch   6, Step:    20500, Batch Loss:     2.193966, Tokens per Sec:     4344, Lr: 0.000100
2021-12-09 16:45:56,278 - INFO - joeynmt.training - Epoch   6, Step:    21000, Batch Loss:     2.645082, Tokens per Sec:     4423, Lr: 0.000100
2021-12-09 16:47:05,094 - INFO - joeynmt.training - Epoch   6, Step:    21500, Batch Loss:     2.385028, Tokens per Sec:     4407, Lr: 0.000100
2021-12-09 16:48:13,598 - INFO - joeynmt.training - Epoch   6, Step:    22000, Batch Loss:     2.217885, Tokens per Sec:     4331, Lr: 0.000100
2021-12-09 16:48:47,792 - INFO - joeynmt.training - Epoch   6: total training loss 9024.45
2021-12-09 16:48:47,792 - INFO - joeynmt.training - EPOCH 7
2021-12-09 16:49:22,821 - INFO - joeynmt.training - Epoch   7, Step:    22500, Batch Loss:     2.252247, Tokens per Sec:     4445, Lr: 0.000100
2021-12-09 16:50:32,080 - INFO - joeynmt.training - Epoch   7, Step:    23000, Batch Loss:     3.075724, Tokens per Sec:     4358, Lr: 0.000100
2021-12-09 16:51:40,440 - INFO - joeynmt.training - Epoch   7, Step:    23500, Batch Loss:     1.926506, Tokens per Sec:     4399, Lr: 0.000100
2021-12-09 16:52:49,325 - INFO - joeynmt.training - Epoch   7, Step:    24000, Batch Loss:     2.477028, Tokens per Sec:     4399, Lr: 0.000100
2021-12-09 16:53:57,925 - INFO - joeynmt.training - Epoch   7, Step:    24500, Batch Loss:     2.005893, Tokens per Sec:     4331, Lr: 0.000100
2021-12-09 16:55:06,661 - INFO - joeynmt.training - Epoch   7, Step:    25000, Batch Loss:     2.249354, Tokens per Sec:     4348, Lr: 0.000100
2021-12-09 16:57:57,584 - INFO - joeynmt.training - Example #0
2021-12-09 16:57:57,584 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁3', '7.', '▁After', '▁him', ',', '▁at', '▁the', '▁time', '▁of', '▁the', '▁c', 'ens', 'us', ',', '▁there', '▁was', '▁Jud', 'as', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁g', 'ot', '▁people', '▁to', '▁follow', '▁him', ',', '▁but', '▁he', '▁was', '▁k', 'illed', ',', '▁too', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁s', 'ca', 't', 'ter', 'ed', '.']
2021-12-09 16:57:57,584 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'P', 'S38800', 'M', 'S1c519', 'S1c511', 'S15a17', 'S15a1f', 'S30a00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S10041', 'S2d608', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'P', 'S38800', 'M', 'S1c519', 'S1c511', 'S15a17', 'S15a1f', 'S30a00', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S18510', 'S26a00', 'S26a10', 'S18518', 'M', 'S2ff00', 'S18510', 'S26a00', 'S26a10', 'S18518', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'P', 'S38800']
2021-12-09 16:57:57,584 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁s ca t ter ed .
2021-12-09 16:57:57,584 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-09 16:57:57,584 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S11e20 P S38800 M S1c519 S1c511 S15a17 S15a1f S30a00 M S2ff00 S10002 S2ea00 P S38700 M S10041 S2d60e M S2ff00 S10002 S2ea00 P S38700 M S2ff00 S10002 S2ea00 P S38700 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S2ff00 S10011 S15d39 S15d51 M S10041 S2d608 M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 P S38800 M S1c519 S1c511 S15a17 S15a1f S30a00 M S2ff00 S10002 S2ea00 P S38700 M S10041 S2d60e M S2ff00 S10011 S15d39 S15d51 M S2ff00 S18510 S26a00 S26a10 S18518 M S2ff00 S18510 S26a00 S26a10 S18518 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 P S38800
2021-12-09 16:57:57,585 - INFO - joeynmt.training - Example #1
2021-12-09 16:57:57,585 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁L', 'á', 'p', 'is']
2021-12-09 16:57:57,585 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁L á p is
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Reference:  M S34700 S21100 S1f410
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 16:57:57,585 - INFO - joeynmt.training - Example #2
2021-12-09 16:57:57,585 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁tr', 'ul', 'y', '▁happ', 'y', '▁by', '▁ag', 'ree', 'ing', '▁whole', 'he', 'art', 'ed', 'ly', '▁with', '▁each', '▁other', ',', '▁lo', 'ving', '▁one', '▁another', ',', '▁and', '▁work', 'ing', '▁together', '▁with', '▁one', '▁m', 'ind', '▁and', '▁pur', 'po', 'se', '.']
2021-12-09 16:57:57,585 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S11e20', 'P', 'S38800', 'M', 'S20500', 'S10043', 'S2d600', 'S30a00', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'S22f03', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'S22f03', 'S22f15', 'P', 'S38700', 'M', 'S20500', 'S10043', 'S2d600', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'S22f03', 'S22f15', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S20500', 'S10043', 'S2d600', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'S22f03', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S20500', 'S10043', 'S2d600', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'S22f03', 'P', 'S38800']
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁happ y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo ving ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁pur po se .
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S11e20 P S38800 M S20500 S10043 S2d600 S30a00 M S2ff00 S10011 S15d39 S15d51 S22f03 M S2ff00 S10011 S15d39 S15d51 S22f03 S22f15 P S38700 M S20500 S10043 S2d600 M S2ff00 S10011 S15d39 S15d51 S22f03 S22f15 M S2ff00 S10011 S15d39 S15d51 M S20500 S10043 S2d600 M S2ff00 S10011 S15d39 S15d51 S22f03 M S2ff00 S10011 S15d39 S15d51 M S20500 S10043 S2d600 M S2ff00 S10011 S15d39 S15d51 S22f03 P S38800
2021-12-09 16:57:57,585 - INFO - joeynmt.training - Example #3
2021-12-09 16:57:57,585 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁ex', 'pl', 'or', 'ar']
2021-12-09 16:57:57,585 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S36d00', 'S36d00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁ex pl or ar
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Reference:  M S10e40 S11040 S26504 S2fb04
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Hypothesis: M S36d00 S36d00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 16:57:57,585 - INFO - joeynmt.training - Example #6
2021-12-09 16:57:57,585 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'dict', '>', '▁m', 'il', 'k']
2021-12-09 16:57:57,585 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S10011', 'S20500']
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< dict > ▁m il k
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Reference:  M S20340 S21800
2021-12-09 16:57:57,585 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S10011 S20500
2021-12-09 16:57:57,586 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step    25000: bleu:   1.63, loss: 52895.5156, ppl:  10.7485, duration: 170.9243s
2021-12-09 16:59:06,625 - INFO - joeynmt.training - Epoch   7, Step:    25500, Batch Loss:     2.886044, Tokens per Sec:     4353, Lr: 0.000100
2021-12-09 17:00:08,874 - INFO - joeynmt.training - Epoch   7: total training loss 8812.12
2021-12-09 17:00:08,875 - INFO - joeynmt.training - EPOCH 8
2021-12-09 17:00:14,959 - INFO - joeynmt.training - Epoch   8, Step:    26000, Batch Loss:     2.583573, Tokens per Sec:     4381, Lr: 0.000100
2021-12-09 17:01:23,447 - INFO - joeynmt.training - Epoch   8, Step:    26500, Batch Loss:     1.885078, Tokens per Sec:     4358, Lr: 0.000100
2021-12-09 17:02:32,020 - INFO - joeynmt.training - Epoch   8, Step:    27000, Batch Loss:     2.211428, Tokens per Sec:     4337, Lr: 0.000100
2021-12-09 17:03:41,012 - INFO - joeynmt.training - Epoch   8, Step:    27500, Batch Loss:     2.375082, Tokens per Sec:     4456, Lr: 0.000100
2021-12-09 17:04:49,860 - INFO - joeynmt.training - Epoch   8, Step:    28000, Batch Loss:     2.168838, Tokens per Sec:     4361, Lr: 0.000100
2021-12-09 17:05:58,715 - INFO - joeynmt.training - Epoch   8, Step:    28500, Batch Loss:     2.079839, Tokens per Sec:     4320, Lr: 0.000100
2021-12-09 17:07:06,961 - INFO - joeynmt.training - Epoch   8, Step:    29000, Batch Loss:     1.993342, Tokens per Sec:     4416, Lr: 0.000100
2021-12-09 17:08:15,384 - INFO - joeynmt.training - Epoch   8, Step:    29500, Batch Loss:     2.646146, Tokens per Sec:     4293, Lr: 0.000100
2021-12-09 17:08:38,703 - INFO - joeynmt.training - Epoch   8: total training loss 8624.14
2021-12-09 17:08:38,704 - INFO - joeynmt.training - EPOCH 9
2021-12-09 17:09:24,037 - INFO - joeynmt.training - Epoch   9, Step:    30000, Batch Loss:     2.630577, Tokens per Sec:     4284, Lr: 0.000100
2021-12-09 17:12:08,877 - INFO - joeynmt.training - Hooray! New best validation result [eval_metric]!
2021-12-09 17:12:09,720 - INFO - joeynmt.helpers - delete models/baseline_reverse_symbol/20000.ckpt
2021-12-09 17:12:09,720 - INFO - joeynmt.helpers - delete /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/20000.ckpt
2021-12-09 17:12:09,720 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/20000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/net/cephfs/home/zifjia/signwriting-translation/models/baseline_reverse_symbol/20000.ckpt')
2021-12-09 17:12:09,762 - INFO - joeynmt.training - Example #0
2021-12-09 17:12:09,763 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁3', '7.', '▁After', '▁him', ',', '▁at', '▁the', '▁time', '▁of', '▁the', '▁c', 'ens', 'us', ',', '▁there', '▁was', '▁Jud', 'as', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁g', 'ot', '▁people', '▁to', '▁follow', '▁him', ',', '▁but', '▁he', '▁was', '▁k', 'illed', ',', '▁too', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁s', 'ca', 't', 'ter', 'ed', '.']
2021-12-09 17:12:09,763 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S1dc20', 'S11e20', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S1c519', 'S1c511', 'S15a17', 'S15a1f', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S10041', 'S2d60e', 'S36d01', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'P', 'S38700', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S36d01', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S18510', 'S26a00', 'S26a10', 'S18518', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S18510', 'S26a00', 'S26a10', 'S18518', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'P', 'S38800']
2021-12-09 17:12:09,763 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁s ca t ter ed .
2021-12-09 17:12:09,763 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-09 17:12:09,763 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S1dc20 S11e20 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S1c519 S1c511 S15a17 S15a1f M S2ff00 S10002 S2ea00 P S38700 M S10041 S2d60e S36d01 M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 P S38700 M S1dc0a S10003 S20500 S20500 S36d01 M S10041 S2d60e M S2ff00 S18510 S26a00 S26a10 S18518 M S10041 S2d60e M S2ff00 S18510 S26a00 S26a10 S18518 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 P S38800
2021-12-09 17:12:09,763 - INFO - joeynmt.training - Example #1
2021-12-09 17:12:09,764 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁L', 'á', 'p', 'is']
2021-12-09 17:12:09,764 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 17:12:09,764 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁L á p is
2021-12-09 17:12:09,764 - INFO - joeynmt.training - 	Reference:  M S34700 S21100 S1f410
2021-12-09 17:12:09,764 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 17:12:09,764 - INFO - joeynmt.training - Example #2
2021-12-09 17:12:09,764 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁tr', 'ul', 'y', '▁happ', 'y', '▁by', '▁ag', 'ree', 'ing', '▁whole', 'he', 'art', 'ed', 'ly', '▁with', '▁each', '▁other', ',', '▁lo', 'ving', '▁one', '▁another', ',', '▁and', '▁work', 'ing', '▁together', '▁with', '▁one', '▁m', 'ind', '▁and', '▁pur', 'po', 'se', '.']
2021-12-09 17:12:09,765 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S1dc20', 'S1a520', 'P', 'S38800', 'M', 'S20500', 'S10043', 'S30a00', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'P', 'S38800', 'M', 'S20500', 'S10043', 'S30a00', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'S22f03', 'P', 'S38700', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'S22f03', 'P', 'S38800']
2021-12-09 17:12:09,765 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁happ y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo ving ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁pur po se .
2021-12-09 17:12:09,765 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-09 17:12:09,765 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S1dc20 S1a520 P S38800 M S20500 S10043 S30a00 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 P S38800 M S20500 S10043 S30a00 M S2ff00 S10011 S15d39 S15d51 M S2ff00 S10011 S15d39 S15d51 S22f03 P S38700 M S20500 S10043 M S2ff00 S10011 S15d39 S15d51 S22f03 P S38800
2021-12-09 17:12:09,765 - INFO - joeynmt.training - Example #3
2021-12-09 17:12:09,765 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁ex', 'pl', 'or', 'ar']
2021-12-09 17:12:09,765 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S36d00', 'S36d00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 17:12:09,765 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁ex pl or ar
2021-12-09 17:12:09,765 - INFO - joeynmt.training - 	Reference:  M S10e40 S11040 S26504 S2fb04
2021-12-09 17:12:09,766 - INFO - joeynmt.training - 	Hypothesis: M S36d00 S36d00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 17:12:09,766 - INFO - joeynmt.training - Example #6
2021-12-09 17:12:09,766 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'dict', '>', '▁m', 'il', 'k']
2021-12-09 17:12:09,766 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S14c00', 'S14c08', 'S22520', 'S22520', 'S22520']
2021-12-09 17:12:09,766 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< dict > ▁m il k
2021-12-09 17:12:09,766 - INFO - joeynmt.training - 	Reference:  M S20340 S21800
2021-12-09 17:12:09,766 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S14c00 S14c08 S22520 S22520 S22520
2021-12-09 17:12:09,767 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    30000: bleu:   3.13, loss: 51616.5156, ppl:  10.1487, duration: 165.7289s
2021-12-09 17:13:18,258 - INFO - joeynmt.training - Epoch   9, Step:    30500, Batch Loss:     2.587037, Tokens per Sec:     4383, Lr: 0.000100
2021-12-09 17:14:26,797 - INFO - joeynmt.training - Epoch   9, Step:    31000, Batch Loss:     1.989045, Tokens per Sec:     4382, Lr: 0.000100
2021-12-09 17:15:35,368 - INFO - joeynmt.training - Epoch   9, Step:    31500, Batch Loss:     2.266699, Tokens per Sec:     4373, Lr: 0.000100
2021-12-09 17:16:43,847 - INFO - joeynmt.training - Epoch   9, Step:    32000, Batch Loss:     2.122652, Tokens per Sec:     4345, Lr: 0.000100
2021-12-09 17:17:53,237 - INFO - joeynmt.training - Epoch   9, Step:    32500, Batch Loss:     2.298949, Tokens per Sec:     4387, Lr: 0.000100
2021-12-09 17:19:01,908 - INFO - joeynmt.training - Epoch   9, Step:    33000, Batch Loss:     2.125896, Tokens per Sec:     4400, Lr: 0.000100
2021-12-09 17:19:54,108 - INFO - joeynmt.training - Epoch   9: total training loss 8431.61
2021-12-09 17:19:54,108 - INFO - joeynmt.training - EPOCH 10
2021-12-09 17:20:10,749 - INFO - joeynmt.training - Epoch  10, Step:    33500, Batch Loss:     2.222986, Tokens per Sec:     4436, Lr: 0.000100
2021-12-09 17:21:19,737 - INFO - joeynmt.training - Epoch  10, Step:    34000, Batch Loss:     2.026568, Tokens per Sec:     4362, Lr: 0.000100
2021-12-09 17:22:28,793 - INFO - joeynmt.training - Epoch  10, Step:    34500, Batch Loss:     2.263397, Tokens per Sec:     4332, Lr: 0.000100
2021-12-09 17:23:37,563 - INFO - joeynmt.training - Epoch  10, Step:    35000, Batch Loss:     2.392689, Tokens per Sec:     4397, Lr: 0.000100
2021-12-09 17:26:28,570 - INFO - joeynmt.training - Example #0
2021-12-09 17:26:28,570 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁3', '7.', '▁After', '▁him', ',', '▁at', '▁the', '▁time', '▁of', '▁the', '▁c', 'ens', 'us', ',', '▁there', '▁was', '▁Jud', 'as', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁g', 'ot', '▁people', '▁to', '▁follow', '▁him', ',', '▁but', '▁he', '▁was', '▁k', 'illed', ',', '▁too', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁s', 'ca', 't', 'ter', 'ed', '.']
2021-12-09 17:26:28,570 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S1dc20', 'S14420', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S1c519', 'S1c511', 'S15a17', 'S15a1f', 'M', 'S2ff00', 'S10002', 'S2ea00', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S15a11', 'S15a19', 'S20600', 'M', 'S19220', 'S2a20c', 'S15a11', 'S15a19', 'S20600', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'P', 'S38800']
2021-12-09 17:26:28,570 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁s ca t ter ed .
2021-12-09 17:26:28,570 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-09 17:26:28,570 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S1dc20 S14420 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S1c519 S1c511 S15a17 S15a1f M S2ff00 S10002 S2ea00 P S38700 M S19220 S2a20c S15a11 S15a19 S20600 M S19220 S2a20c S15a11 S15a19 S20600 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 P S38800
2021-12-09 17:26:28,570 - INFO - joeynmt.training - Example #1
2021-12-09 17:26:28,570 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁L', 'á', 'p', 'is']
2021-12-09 17:26:28,570 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 17:26:28,570 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁L á p is
2021-12-09 17:26:28,570 - INFO - joeynmt.training - 	Reference:  M S34700 S21100 S1f410
2021-12-09 17:26:28,570 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 17:26:28,570 - INFO - joeynmt.training - Example #2
2021-12-09 17:26:28,570 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁tr', 'ul', 'y', '▁happ', 'y', '▁by', '▁ag', 'ree', 'ing', '▁whole', 'he', 'art', 'ed', 'ly', '▁with', '▁each', '▁other', ',', '▁lo', 'ving', '▁one', '▁another', ',', '▁and', '▁work', 'ing', '▁together', '▁with', '▁one', '▁m', 'ind', '▁and', '▁pur', 'po', 'se', '.']
2021-12-09 17:26:28,570 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S1dc20', 'S1a520', 'P', 'S38800', 'M', 'S14c37', 'S14c3f', 'S22a04', 'S22a14', 'S30a00', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S2df08', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15d51', 'S22f03', 'S22f15', 'P', 'S38800']
2021-12-09 17:26:28,571 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁happ y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo ving ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁pur po se .
2021-12-09 17:26:28,571 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-09 17:26:28,571 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S1dc20 S1a520 P S38800 M S14c37 S14c3f S22a04 S22a14 S30a00 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S2ff00 S10011 S15d39 S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S2ff00 S10011 S15d39 S15d51 M S20500 S10043 M S2ff00 S2df08 M S2ff00 S10011 S15d39 S15d51 S22f03 S22f15 P S38800
2021-12-09 17:26:28,571 - INFO - joeynmt.training - Example #3
2021-12-09 17:26:28,571 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁ex', 'pl', 'or', 'ar']
2021-12-09 17:26:28,571 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S36d00', 'S36d00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 17:26:28,571 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁ex pl or ar
2021-12-09 17:26:28,571 - INFO - joeynmt.training - 	Reference:  M S10e40 S11040 S26504 S2fb04
2021-12-09 17:26:28,571 - INFO - joeynmt.training - 	Hypothesis: M S36d00 S36d00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 17:26:28,571 - INFO - joeynmt.training - Example #6
2021-12-09 17:26:28,571 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'dict', '>', '▁m', 'il', 'k']
2021-12-09 17:26:28,571 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 17:26:28,571 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< dict > ▁m il k
2021-12-09 17:26:28,571 - INFO - joeynmt.training - 	Reference:  M S20340 S21800
2021-12-09 17:26:28,571 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 17:26:28,571 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    35000: bleu:   1.18, loss: 50606.5000, ppl:   9.6988, duration: 171.0080s
2021-12-09 17:27:37,427 - INFO - joeynmt.training - Epoch  10, Step:    35500, Batch Loss:     2.450724, Tokens per Sec:     4300, Lr: 0.000100
2021-12-09 17:28:46,263 - INFO - joeynmt.training - Epoch  10, Step:    36000, Batch Loss:     2.283198, Tokens per Sec:     4363, Lr: 0.000100
2021-12-09 17:29:54,921 - INFO - joeynmt.training - Epoch  10, Step:    36500, Batch Loss:     1.814240, Tokens per Sec:     4403, Lr: 0.000100
2021-12-09 17:31:04,246 - INFO - joeynmt.training - Epoch  10, Step:    37000, Batch Loss:     2.004592, Tokens per Sec:     4356, Lr: 0.000100
2021-12-09 17:31:15,755 - INFO - joeynmt.training - Epoch  10: total training loss 8266.04
2021-12-09 17:31:15,755 - INFO - joeynmt.training - EPOCH 11
2021-12-09 17:32:13,531 - INFO - joeynmt.training - Epoch  11, Step:    37500, Batch Loss:     2.185868, Tokens per Sec:     4332, Lr: 0.000100
2021-12-09 17:33:22,200 - INFO - joeynmt.training - Epoch  11, Step:    38000, Batch Loss:     2.248446, Tokens per Sec:     4301, Lr: 0.000100
2021-12-09 17:34:30,946 - INFO - joeynmt.training - Epoch  11, Step:    38500, Batch Loss:     1.931084, Tokens per Sec:     4402, Lr: 0.000100
2021-12-09 17:35:39,818 - INFO - joeynmt.training - Epoch  11, Step:    39000, Batch Loss:     2.340094, Tokens per Sec:     4360, Lr: 0.000100
2021-12-09 17:36:48,432 - INFO - joeynmt.training - Epoch  11, Step:    39500, Batch Loss:     2.476340, Tokens per Sec:     4322, Lr: 0.000100
2021-12-09 17:37:57,149 - INFO - joeynmt.training - Epoch  11, Step:    40000, Batch Loss:     2.824703, Tokens per Sec:     4320, Lr: 0.000100
2021-12-09 17:40:48,150 - INFO - joeynmt.training - Example #0
2021-12-09 17:40:48,150 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁3', '7.', '▁After', '▁him', ',', '▁at', '▁the', '▁time', '▁of', '▁the', '▁c', 'ens', 'us', ',', '▁there', '▁was', '▁Jud', 'as', '▁of', '▁Gal', 'ile', 'e', '.', '▁He', '▁g', 'ot', '▁people', '▁to', '▁follow', '▁him', ',', '▁but', '▁he', '▁was', '▁k', 'illed', ',', '▁too', ',', '▁and', '▁all', '▁his', '▁follow', 'ers', '▁were', '▁s', 'ca', 't', 'ter', 'ed', '.']
2021-12-09 17:40:48,150 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S1dc20', 'S11e20', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S19220', 'S2a20c', 'S15a11', 'S15a19', 'S20600', 'M', 'S19220', 'S2a20c', 'S15a11', 'S15a19', 'S20600', 'M', 'S19220', 'S2a20c', 'S15a11', 'S15a19', 'S20600', 'M', 'S10047', 'P', 'S38700', 'M', 'S19220', 'S2a20c', 'S15a11', 'S15a19', 'S20600', 'M', 'S10047', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10047', 'P', 'S38700', 'M', 'S10047', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S2e74c', 'S14220', 'S2e700', 'S14228', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S10041', 'S2d60e', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S23b0a', 'S23b1a', 'S15d51', 'P', 'S38800']
2021-12-09 17:40:48,150 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁3 7. ▁After ▁him , ▁at ▁the ▁time ▁of ▁the ▁c ens us , ▁there ▁was ▁Jud as ▁of ▁Gal ile e . ▁He ▁g ot ▁people ▁to ▁follow ▁him , ▁but ▁he ▁was ▁k illed , ▁too , ▁and ▁all ▁his ▁follow ers ▁were ▁s ca t ter ed .
2021-12-09 17:40:48,150 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S11e20 S1a520 P S38800 M S15a56 S15a41 S2b700 S37c06 S36d01 S30d00 M S10040 P S38700 M S37806 S10050 S20356 S36d01 M S15a37 S1ce51 S26a07 P S38700 M S19220 S2a20c S11520 S10120 S1f720 S20320 S36d01 M S10018 S26505 S10641 M S1f000 S1f720 S1dc20 S19220 S14a20 S1dc20 S14a20 P S38800 M S10041 S30d00 S36d01 M S15a31 S10018 S26503 M S2e74c S14220 S2e700 S14228 M S26521 S1f548 S1f540 M S10041 P S38700 M S10021 S10029 S22a07 S22a11 S36d01 M S2ea3e S10000 M S15a18 S10051 S26601 M S10058 S26526 S10050 S20500 S20500 P S38900 M S15a37 S15a01 S2e900 S36d01 M S15a20 S26501 M S26521 S23b0a S1f548 S15a40 S15a48 S23b1a S1f540 M S14c57 S14c5f S26511 S26507 S22527 S20314 S22521 S2031c P S38800
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S1dc20 S11e20 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S19220 S2a20c S15a11 S15a19 S20600 M S19220 S2a20c S15a11 S15a19 S20600 M S19220 S2a20c S15a11 S15a19 S20600 M S10047 P S38700 M S19220 S2a20c S15a11 S15a19 S20600 M S10047 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S10047 P S38700 M S10047 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S2e74c S14220 S2e700 S14228 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 M S10041 S2d60e M S2ff00 S10011 S15d39 S15a48 S15a40 S23b0a S23b1a S15d51 P S38800
2021-12-09 17:40:48,151 - INFO - joeynmt.training - Example #1
2021-12-09 17:40:48,151 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁L', 'á', 'p', 'is']
2021-12-09 17:40:48,151 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S36d00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁L á p is
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Reference:  M S34700 S21100 S1f410
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Hypothesis: M S36d00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 17:40:48,151 - INFO - joeynmt.training - Example #2
2021-12-09 17:40:48,151 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'sent', '>', '▁Verse', '▁2.', '▁Then', '▁make', '▁me', '▁tr', 'ul', 'y', '▁happ', 'y', '▁by', '▁ag', 'ree', 'ing', '▁whole', 'he', 'art', 'ed', 'ly', '▁with', '▁each', '▁other', ',', '▁lo', 'ving', '▁one', '▁another', ',', '▁and', '▁work', 'ing', '▁together', '▁with', '▁one', '▁m', 'ind', '▁and', '▁pur', 'po', 'se', '.']
2021-12-09 17:40:48,151 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S15a07', 'S1f010', 'S26507', 'M', 'S1dc20', 'S11e20', 'P', 'S38800', 'M', 'S1dc0a', 'S10003', 'S20500', 'S20500', 'S30a00', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'M', 'S1f740', 'S1f748', 'M', 'S20500', 'S10043', 'M', 'S2ff00', 'S10011', 'S15d39', 'S15a48', 'S15a40', 'S22a04', 'S23b0a', 'S23b1a', 'S15d51', 'P', 'S38800']
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< sent > ▁Verse ▁2. ▁Then ▁make ▁me ▁tr ul y ▁happ y ▁by ▁ag ree ing ▁whole he art ed ly ▁with ▁each ▁other , ▁lo ving ▁one ▁another , ▁and ▁work ing ▁together ▁with ▁one ▁m ind ▁and ▁pur po se .
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Reference:  M S15a07 S1f010 S26507 M S10e00 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20302 S2030a S20340 S20348 S30e00 S30124 M S20500 S10013 M S30124 S10010 S26500 M S22f10 S20500 S15a0a S22f00 S15a02 S20500 P S38900 M S17911 S17919 S2c300 S2c311 S30a00 P S38700 M S15a06 S15a41 S23d04 M S2ff00 S10050 S10058 S10011 S22a04 M S1f522 S2ea46 S2ea02 S1f50a P S38700 R S3770b S20305 S20500 S20303 S20500 S37713 S30e00 S30124 R S1f522 S2ea46 S2ea02 S1f50a P S38700 M S20356 S20350 S37706 S22f04 S30e00 S30124 M S1f740 S1f748 S26a20 M S1814b S20500 S20500 S18143 R S10000 S26500 R S10011 S2ff00 P S38700 M S10000 S26500 M S15a18 S15a18 S10e22 S10e02 P S38800
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Hypothesis: M S15a07 S1f010 S26507 M S1dc20 S11e20 P S38800 M S1dc0a S10003 S20500 S20500 S30a00 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 M S1f740 S1f748 M S20500 S10043 M S2ff00 S10011 S15d39 S15a48 S15a40 S22a04 S23b0a S23b1a S15d51 P S38800
2021-12-09 17:40:48,151 - INFO - joeynmt.training - Example #3
2021-12-09 17:40:48,151 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'pt', '>', '▁<4', 'br', '>', '▁<', 'dict', '>', '▁ex', 'pl', 'or', 'ar']
2021-12-09 17:40:48,151 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S36d00', 'S36d00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Source:     ▁<2 pt > ▁<4 br > ▁< dict > ▁ex pl or ar
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Reference:  M S10e40 S11040 S26504 S2fb04
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Hypothesis: M S36d00 S36d00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 17:40:48,151 - INFO - joeynmt.training - Example #6
2021-12-09 17:40:48,151 - DEBUG - joeynmt.training - 	Raw source:     ['▁<2', 'en', '>', '▁<4', 'us', '>', '▁<', 'dict', '>', '▁m', 'il', 'k']
2021-12-09 17:40:48,151 - DEBUG - joeynmt.training - 	Raw hypothesis: ['M', 'S2ff00', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500', 'S20500']
2021-12-09 17:40:48,151 - INFO - joeynmt.training - 	Source:     ▁<2 en > ▁<4 us > ▁< dict > ▁m il k
2021-12-09 17:40:48,152 - INFO - joeynmt.training - 	Reference:  M S20340 S21800
2021-12-09 17:40:48,152 - INFO - joeynmt.training - 	Hypothesis: M S2ff00 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500 S20500
2021-12-09 17:40:48,152 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    40000: bleu:   1.40, loss: 49647.6797, ppl:   9.2901, duration: 171.0019s
2021-12-09 17:41:56,801 - INFO - joeynmt.training - Epoch  11, Step:    40500, Batch Loss:     1.946661, Tokens per Sec:     4431, Lr: 0.000100
2021-12-09 17:42:36,672 - INFO - joeynmt.training - Epoch  11: total training loss 8147.67
2021-12-09 17:42:36,672 - INFO - joeynmt.training - EPOCH 12
2021-12-09 17:43:05,450 - INFO - joeynmt.training - Epoch  12, Step:    41000, Batch Loss:     2.230999, Tokens per Sec:     4344, Lr: 0.000100
2021-12-09 17:44:13,982 - INFO - joeynmt.training - Epoch  12, Step:    41500, Batch Loss:     2.091377, Tokens per Sec:     4411, Lr: 0.000100
