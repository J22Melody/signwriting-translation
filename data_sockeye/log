[2021-12-16:14:15:25:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.5, commit 64c3b09b3402fffb63799e9ad33c81c6b97d8629, path /opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-16:14:15:25:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-16:14:15:25:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0 (/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-16:14:15:25:INFO:sockeye.utils:log_basic_info] Command: /opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/prepare_data.py --source data_reverse/train.spoken --target data_reverse/train.symbol --max-seq-len 200 --seed 42 --output ./data_sockeye
[2021-12-16:14:15:25:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(bucket_scaling=False, bucket_width=8, config=None, loglevel='INFO', loglevel_secondary_workers='INFO', max_processes=1, max_seq_len=(200, 200), min_num_shards=1, no_bucketing=False, no_logfile=False, num_samples_per_shard=10000000, num_words=(0, 0), output='./data_sockeye', pad_vocab_to_multiple_of=8, quiet=False, quiet_secondary_workers=False, seed=42, shared_vocab=False, source='data_reverse/train.spoken', source_factor_vocabs=[], source_factors=[], source_factors_use_source_vocab=[], source_vocab=None, target='data_reverse/train.symbol', target_factor_vocabs=[], target_factors=[], target_factors_use_target_vocab=[], target_vocab=None, word_min_count=(1, 1))
[2021-12-16:14:15:25:INFO:sockeye.utils:seed_rngs] Random seed: 42
[2021-12-16:14:15:25:INFO:sockeye.utils:seed_rngs] PyTorch seed: 42
[2021-12-16:14:15:25:INFO:__main__:prepare_data] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (201, 201)
[2021-12-16:14:15:25:INFO:__main__:prepare_data] 111946 samples will be split into 1 shard(s) (requested samples/shard=10000000, min_num_shards=1).
[2021-12-16:14:15:25:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2021-12-16:14:15:25:INFO:sockeye.vocab:load_or_create_vocabs] Loading/creating vocabularies
[2021-12-16:14:15:25:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2021-12-16:14:15:25:INFO:sockeye.vocab:load_or_create_vocabs] (1) Surface form vocabularies (source & target)
[2021-12-16:14:15:25:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): data_reverse/train.spoken
[2021-12-16:14:15:26:INFO:sockeye.vocab:build_pruned_vocab] Padding vocabulary to a multiple of 8: 77990 -> 77992
[2021-12-16:14:15:26:INFO:sockeye.vocab:build_pruned_vocab] Vocabulary: types: 77986/77986/77986/77992 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=8]
[2021-12-16:14:15:26:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): data_reverse/train.symbol
[2021-12-16:14:15:27:INFO:sockeye.vocab:build_pruned_vocab] Padding vocabulary to a multiple of 8: 12218 -> 12224
[2021-12-16:14:15:27:INFO:sockeye.vocab:build_pruned_vocab] Vocabulary: types: 12214/12214/12214/12224 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=8]
[2021-12-16:14:15:27:INFO:sockeye.data_io:prepare_data] Preparing data.
[2021-12-16:14:15:27:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/vocab.src.0.json"
[2021-12-16:14:15:27:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/vocab.trg.0.json"
[2021-12-16:14:15:30:INFO:sockeye.data_io:analyze_sequence_lengths] 111533 sequences of maximum length (201, 201) in 'data_reverse/train.spoken' and 'data_reverse/train.symbol'.
[2021-12-16:14:15:30:INFO:sockeye.data_io:analyze_sequence_lengths] Mean training target/source length ratio: 1.93 (+-1.52)
[2021-12-16:14:15:30:INFO:sockeye.data_io:prepare_data] Buckets: [(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)]
[2021-12-16:14:15:37:INFO:sockeye.data_io:load] Created bucketed parallel data set. Introduced padding: source=65.0% target=13.4%)
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] Tokens: source 898704 target 2225801
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] Number of <unk> tokens: source 0 target 0
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] 111533 sequences across 26 buckets
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] 413 sequences did not fit into buckets and were discarded
[2021-12-16:14:15:37:INFO:sockeye.data_io:save_shard] Writing '/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/shard.00000'
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] Tokens: source 898704 target 2225801
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] Number of <unk> tokens: source 0 target 0
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] 111533 sequences across 26 buckets
[2021-12-16:14:15:37:INFO:sockeye.data_io:log] 413 sequences did not fit into buckets and were discarded
[2021-12-16:14:15:37:INFO:sockeye.data_io:prepare_data] Writing data info to '/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/data.info'
[2021-12-16:14:15:37:INFO:sockeye.data_io:prepare_data] Writing data config to '/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/data.config'
[2021-12-16:14:18:30:INFO:sockeye.utils:log_sockeye_version] Sockeye: 3.0.5, commit 64c3b09b3402fffb63799e9ad33c81c6b97d8629, path /opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/__init__.py
[2021-12-16:14:18:30:INFO:sockeye.utils:log_mxnet_version] MXNet: 2.0.0 (/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/mxnet/__init__.py)
[2021-12-16:14:18:30:INFO:sockeye.utils:log_torch_version] PyTorch: 1.10.0 (/opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/torch/__init__.py)
[2021-12-16:14:18:30:INFO:sockeye.utils:log_basic_info] Command: /opt/anaconda3/envs/sockeye/lib/python3.8/site-packages/sockeye/prepare_data.py --source data_reverse/train.spm.spoken --target data_reverse/train.symbol --max-seq-len 200 --seed 42 --output ./data_sockeye
[2021-12-16:14:18:30:INFO:sockeye.utils:log_basic_info] Arguments: Namespace(bucket_scaling=False, bucket_width=8, config=None, loglevel='INFO', loglevel_secondary_workers='INFO', max_processes=1, max_seq_len=(200, 200), min_num_shards=1, no_bucketing=False, no_logfile=False, num_samples_per_shard=10000000, num_words=(0, 0), output='./data_sockeye', pad_vocab_to_multiple_of=8, quiet=False, quiet_secondary_workers=False, seed=42, shared_vocab=False, source='data_reverse/train.spm.spoken', source_factor_vocabs=[], source_factors=[], source_factors_use_source_vocab=[], source_vocab=None, target='data_reverse/train.symbol', target_factor_vocabs=[], target_factors=[], target_factors_use_target_vocab=[], target_vocab=None, word_min_count=(1, 1))
[2021-12-16:14:18:30:INFO:sockeye.utils:seed_rngs] Random seed: 42
[2021-12-16:14:18:30:INFO:sockeye.utils:seed_rngs] PyTorch seed: 42
[2021-12-16:14:18:30:INFO:__main__:prepare_data] Adjusting maximum length to reserve space for a BOS/EOS marker. New maximum length: (201, 201)
[2021-12-16:14:18:30:INFO:__main__:prepare_data] 111946 samples will be split into 1 shard(s) (requested samples/shard=10000000, min_num_shards=1).
[2021-12-16:14:18:30:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2021-12-16:14:18:30:INFO:sockeye.vocab:load_or_create_vocabs] Loading/creating vocabularies
[2021-12-16:14:18:30:INFO:sockeye.vocab:load_or_create_vocabs] =============================
[2021-12-16:14:18:30:INFO:sockeye.vocab:load_or_create_vocabs] (1) Surface form vocabularies (source & target)
[2021-12-16:14:18:30:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): data_reverse/train.spm.spoken
[2021-12-16:14:18:30:INFO:sockeye.vocab:build_pruned_vocab] Padding vocabulary to a multiple of 8: 1999 -> 2000
[2021-12-16:14:18:30:INFO:sockeye.vocab:build_pruned_vocab] Vocabulary: types: 1995/1995/1995/2000 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=8]
[2021-12-16:14:18:30:INFO:sockeye.vocab:build_from_paths] Building vocabulary from dataset(s): data_reverse/train.symbol
[2021-12-16:14:18:31:INFO:sockeye.vocab:build_pruned_vocab] Padding vocabulary to a multiple of 8: 12218 -> 12224
[2021-12-16:14:18:31:INFO:sockeye.vocab:build_pruned_vocab] Vocabulary: types: 12214/12214/12214/12224 (initial/min_pruned/max_pruned/+special) [min_frequency=1, max_num_types=None, pad_to_multiple_of=8]
[2021-12-16:14:18:31:INFO:sockeye.data_io:prepare_data] Preparing data.
[2021-12-16:14:18:31:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/vocab.src.0.json"
[2021-12-16:14:18:31:INFO:sockeye.vocab:vocab_to_json] Vocabulary saved to "/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/vocab.trg.0.json"
[2021-12-16:14:18:34:INFO:sockeye.data_io:analyze_sequence_lengths] 111529 sequences of maximum length (201, 201) in 'data_reverse/train.spm.spoken' and 'data_reverse/train.symbol'.
[2021-12-16:14:18:34:INFO:sockeye.data_io:analyze_sequence_lengths] Mean training target/source length ratio: 0.80 (+-0.70)
[2021-12-16:14:18:34:INFO:sockeye.data_io:prepare_data] Buckets: [(8, 8), (16, 16), (24, 24), (32, 32), (40, 40), (48, 48), (56, 56), (64, 64), (72, 72), (80, 80), (88, 88), (96, 96), (104, 104), (112, 112), (120, 120), (128, 128), (136, 136), (144, 144), (152, 152), (160, 160), (168, 168), (176, 176), (184, 184), (192, 192), (200, 200), (201, 201)]
[2021-12-16:14:18:42:INFO:sockeye.data_io:load] Created bucketed parallel data set. Introduced padding: source=34.6% target=29.9%)
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] Tokens: source 2075941 target 2225438
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] Number of <unk> tokens: source 0 target 0
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] 111529 sequences across 26 buckets
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] 417 sequences did not fit into buckets and were discarded
[2021-12-16:14:18:42:INFO:sockeye.data_io:save_shard] Writing '/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/shard.00000'
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] Tokens: source 2075941 target 2225438
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] Number of <unk> tokens: source 0 target 0
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] Vocabulary coverage: source 100% target 100%
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] 111529 sequences across 26 buckets
[2021-12-16:14:18:42:INFO:sockeye.data_io:log] 417 sequences did not fit into buckets and were discarded
[2021-12-16:14:18:42:INFO:sockeye.data_io:prepare_data] Writing data info to '/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/data.info'
[2021-12-16:14:18:42:INFO:sockeye.data_io:prepare_data] Writing data config to '/Users/jiangzifan/Desktop/workspace/signwriting-translation/data_sockeye/data.config'
